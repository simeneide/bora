
@misc{ivison_camels_2023,
	title = {Camels in a {Changing} {Climate}: {Enhancing} {LM} {Adaptation} with {Tulu} 2},
	shorttitle = {Camels in a {Changing} {Climate}},
	url = {http://arxiv.org/abs/2311.10702},
	doi = {10.48550/arXiv.2311.10702},
	abstract = {Since the release of T{\textbackslash}"ULU [Wang et al., 2023b], open resources for instruction tuning have developed quickly, from better base models to new finetuning techniques. We test and incorporate a number of these advances into T{\textbackslash}"ULU, resulting in T{\textbackslash}"ULU 2, a suite of improved T{\textbackslash}"ULU models for advancing the understanding and best practices of adapting pretrained language models to downstream tasks and user preferences. Concretely, we release: (1) T{\textbackslash}"ULU-V2-mix, an improved collection of high-quality instruction datasets; (2) T{\textbackslash}"ULU 2, LLAMA-2 models finetuned on the V2 mixture; (3) T{\textbackslash}"ULU 2+DPO, T{\textbackslash}"ULU 2 models trained with direct preference optimization (DPO), including the largest DPO-trained model to date (T{\textbackslash}"ULU 2+DPO 70B); (4) CODE T{\textbackslash}"ULU 2, CODE LLAMA models finetuned on our V2 mix that outperform CODE LLAMA and its instruction-tuned variant, CODE LLAMA-Instruct. Our evaluation from multiple perspectives shows that the T{\textbackslash}"ULU 2 suite achieves state-of-the-art performance among open models and matches or exceeds the performance of GPT-3.5-turbo-0301 on several benchmarks. We release all the checkpoints, data, training and evaluation code to facilitate future open efforts on adapting large language models.},
	urldate = {2023-11-24},
	publisher = {arXiv},
	author = {Ivison, Hamish and Wang, Yizhong and Pyatkin, Valentina and Lambert, Nathan and Peters, Matthew and Dasigi, Pradeep and Jang, Joel and Wadden, David and Smith, Noah A. and Beltagy, Iz and Hajishirzi, Hannaneh},
	month = nov,
	year = {2023},
	note = {arXiv:2311.10702 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{li_blip-2_2023,
	title = {{BLIP}-2: {Bootstrapping} {Language}-{Image} {Pre}-training with {Frozen} {Image} {Encoders} and {Large} {Language} {Models}},
	shorttitle = {{BLIP}-2},
	url = {http://arxiv.org/abs/2301.12597},
	abstract = {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7\% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model’s emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.},
	language = {en},
	urldate = {2023-11-10},
	publisher = {arXiv},
	author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
	month = jun,
	year = {2023},
	note = {arXiv:2301.12597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{liu_visual_2023,
	title = {Visual {Instruction} {Tuning}},
	url = {http://arxiv.org/abs/2304.08485},
	abstract = {Instruction tuning large language models (LLMs) using machine-generated instruction-following data has improved zero-shot capabilities on new tasks, but the idea is less explored in the multimodal ﬁeld. In this paper, we present the ﬁrst attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and LLM for generalpurpose visual and language understanding. Our early experiments show that LLaVA demonstrates impressive multimodel chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1\% relative score compared with GPT-4 on a synthetic multimodal instructionfollowing dataset. When ﬁne-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53\%. We make GPT-4 generated visual instruction tuning data, our model and code base publicly available.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
	month = apr,
	year = {2023},
	note = {arXiv:2304.08485 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{liu_improved_2023,
	title = {Improved {Baselines} with {Visual} {Instruction} {Tuning}},
	url = {http://arxiv.org/abs/2310.03744},
	abstract = {Large multimodal models (LMM) have recently shown encouraging progress with visual instruction tuning. In this note, we show that the fully-connected vision-language cross-modal connector in LLaVA is surprisingly powerful and data-efficient. With simple modifications to LLaVA, namely, using CLIP-ViT-L-336px with an MLP projection and adding academic-task-oriented VQA data with simple response formatting prompts, we establish stronger baselines that achieve state-of-the-art across 11 benchmarks. Our final 13B checkpoint uses merely 1.2M publicly available data, and finishes full training in ∼1 day on a single 8-A100 node. We hope this can make state-of-the-art LMM research more accessible. Code and model will be publicly available.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
	month = oct,
	year = {2023},
	note = {arXiv:2310.03744 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@inproceedings{kang_reinforcement_2023,
	address = {Honolulu, HI, USA},
	title = {Reinforcement {Learning} {Based} {Pallet} {Loading} {Algorithm} and its {Application} to a {Real} {Manipulator} {System}},
	isbn = {9798350335170},
	url = {https://ieeexplore.ieee.org/document/10202516/},
	doi = {10.1109/UR57808.2023.10202516},
	abstract = {Manufacturers pallet loading problem (MPLP) aims to ﬁt the maximum number of boxes into a ﬁxed-size pallet capacity. Solving MPLP can be time-consuming due to its complexity, leading to the use of heuristic methods which may not produce optimal results. This paper proposes a pallet loading algorithm using reinforcement learning to ﬁnd the optimal solution. Simulation results indicate that the proposed method utilizes the given pallet space more efﬁciently than the existing heuristic methods. In addition, we introduce a real-life automatic pallet loading system and demonstrate the effectiveness of the proposed algorithm.},
	language = {en},
	urldate = {2023-10-01},
	booktitle = {2023 20th {International} {Conference} on {Ubiquitous} {Robots} ({UR})},
	publisher = {IEEE},
	author = {Kang, Seong Woo and Min, Ye Rin and Choi, Kyuwon and Ahn, Woo Jin and Baek, Sang Ryul and Choi, Dae Woo and Lim, Myo Taeg},
	month = jun,
	year = {2023},
	pages = {115--118},
}

@misc{ye_mastering_2021,
	title = {Mastering {Atari} {Games} with {Limited} {Data}},
	url = {http://arxiv.org/abs/2111.00210},
	doi = {10.48550/arXiv.2111.00210},
	abstract = {Reinforcement learning has achieved great success in many applications. However, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 194.3\% mean human performance and 109.0\% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero's performance is also close to DQN's performance at 200 million frames while we consume 500 times less data. EfficientZero's low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at https://github.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community.},
	urldate = {2023-09-03},
	publisher = {arXiv},
	author = {Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
	month = dec,
	year = {2021},
	note = {arXiv:2111.00210 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics},
}

@article{schrittwieser_mastering_2020,
	title = {Mastering {Atari}, {Go}, {Chess} and {Shogi} by {Planning} with a {Learned} {Model}},
	volume = {588},
	issn = {0028-0836, 1476-4687},
	url = {http://arxiv.org/abs/1911.08265},
	doi = {10.1038/s41586-020-03051-4},
	abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},
	number = {7839},
	urldate = {2023-08-31},
	journal = {Nature},
	author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
	month = dec,
	year = {2020},
	note = {arXiv:1911.08265 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {604--609},
}

@article{matsuo_deep_2022,
	title = {Deep learning, reinforcement learning, and world models},
	volume = {152},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608022001150},
	doi = {10.1016/j.neunet.2022.03.037},
	abstract = {Deep learning (DL) and reinforcement learning (RL) methods seem to be a part of indispensable factors to achieve human-level or super-human AI systems. On the other hand, both DL and RL have strong connections with our brain functions and with neuroscientific findings. In this review, we summarize talks and discussions in the “Deep Learning and Reinforcement Learning” session of the symposium, International Symposium on Artificial Intelligence and Brain Science. In this session, we discussed whether we can achieve comprehensive understanding of human intelligence based on the recent advances of deep learning and reinforcement learning algorithms. Speakers contributed to provide talks about their recent studies that can be key technologies to achieve human-level intelligence.},
	urldate = {2023-08-27},
	journal = {Neural Networks},
	author = {Matsuo, Yutaka and LeCun, Yann and Sahani, Maneesh and Precup, Doina and Silver, David and Sugiyama, Masashi and Uchibe, Eiji and Morimoto, Jun},
	month = aug,
	year = {2022},
	keywords = {Artificial intelligence, Deep learning, Machine learning, Reinforcement learning, World models},
	pages = {267--275},
}

@article{adams_survey_2022,
	title = {A survey of inverse reinforcement learning},
	volume = {55},
	issn = {1573-7462},
	url = {https://doi.org/10.1007/s10462-021-10108-x},
	doi = {10.1007/s10462-021-10108-x},
	abstract = {Learning from demonstration, or imitation learning, is the process of learning to act in an environment from examples provided by a teacher. Inverse reinforcement learning (IRL) is a specific form of learning from demonstration that attempts to estimate the reward function of a Markov decision process from examples provided by the teacher. The reward function is often considered the most succinct description of a task. In simple applications, the reward function may be known or easily derived from properties of the system and hard coded into the learning process. However, in complex applications, this may not be possible, and it may be easier to learn the reward function by observing the actions of the teacher. This paper provides a comprehensive survey of the literature on IRL. This survey outlines the differences between IRL and two similar methods - apprenticeship learning and inverse optimal control. Further, this survey organizes the IRL literature based on the principal method, describes applications of IRL algorithms, and provides areas of future research.},
	language = {en},
	number = {6},
	urldate = {2023-08-27},
	journal = {Artificial Intelligence Review},
	author = {Adams, Stephen and Cody, Tyler and Beling, Peter A.},
	month = aug,
	year = {2022},
	keywords = {Apprenticeship learning, Inverse optimal control, Inverse reinforcement learning, Learning from demonstration, Reinforcement learning},
	pages = {4307--4346},
}

@misc{garg_iq-learn_2022,
	title = {{IQ}-{Learn}: {Inverse} soft-{Q} {Learning} for {Imitation}},
	shorttitle = {{IQ}-{Learn}},
	url = {http://arxiv.org/abs/2106.12142},
	abstract = {In many sequential decision-making problems (e.g., robotics control, game playing, sequential prediction), human or expert data is available containing useful information about the task. However, imitation learning (IL) from a small amount of expert data can be challenging in high-dimensional environments with complex dynamics. Behavioral cloning is a simple method that is widely used due to its simplicity of implementation and stable convergence but doesn't utilize any information involving the environment's dynamics. Many existing methods that exploit dynamics information are difficult to train in practice due to an adversarial optimization process over reward and policy approximators or biased, high variance gradient estimators. We introduce a method for dynamics-aware IL which avoids adversarial training by learning a single Q-function, implicitly representing both reward and policy. On standard benchmarks, the implicitly learned rewards show a high positive correlation with the ground-truth rewards, illustrating our method can also be used for inverse reinforcement learning (IRL). Our method, Inverse soft-Q learning (IQ-Learn) obtains state-of-the-art results in offline and online imitation learning settings, significantly outperforming existing methods both in the number of required environment interactions and scalability in high-dimensional spaces, often by more than 3x.},
	urldate = {2023-08-25},
	publisher = {arXiv},
	author = {Garg, Divyansh and Chakraborty, Shuvam and Cundy, Chris and Song, Jiaming and Geist, Matthieu and Ermon, Stefano},
	month = nov,
	year = {2022},
	note = {arXiv:2106.12142 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{zheng_secrets_2023,
	title = {Secrets of {RLHF} in {Large} {Language} {Models} {Part} {I}: {PPO}},
	shorttitle = {Secrets of {RLHF} in {Large} {Language} {Models} {Part} {I}},
	url = {http://arxiv.org/abs/2307.04964},
	abstract = {Large language models (LLMs) have formulated a blueprint for the advancement of artificial general intelligence. Its primary objective is to function as a humancentric (helpful, honest, and harmless) assistant. Alignment with humans assumes paramount significance, and reinforcement learning with human feedback (RLHF) emerges as the pivotal technological paradigm underpinning this pursuit. Current technical routes usually include reward models to measure human preferences, Proximal Policy Optimization (PPO) to optimize policy model outputs, and process supervision to improve step-by-step reasoning capabilities. However, due to the challenges of reward design, environment interaction, and agent training, coupled with huge trial and error cost of large language models, there is a significant barrier for AI researchers to motivate the development of technical alignment and safe landing of LLMs. The stable training of RLHF has still been a puzzle.},
	language = {en},
	urldate = {2023-07-21},
	publisher = {arXiv},
	author = {Zheng, Rui and Dou, Shihan and Gao, Songyang and Hua, Yuan and Shen, Wei and Wang, Binghai and Liu, Yan and Jin, Senjie and Liu, Qin and Zhou, Yuhao and Xiong, Limao and Chen, Lu and Xi, Zhiheng and Xu, Nuo and Lai, Wenbin and Zhu, Minghao and Chang, Cheng and Yin, Zhangyue and Weng, Rongxiang and Cheng, Wensen and Huang, Haoran and Sun, Tianxiang and Yan, Hang and Gui, Tao and Zhang, Qi and Qiu, Xipeng and Huang, Xuanjing},
	month = jul,
	year = {2023},
	note = {arXiv:2307.04964 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{touvron_llama_nodate,
	title = {Llama 2: {Open} {Foundation} and {Fine}-{Tuned} {Chat} {Models}},
	abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
	language = {en},
	author = {Touvron, Hugo and Martin, Louis and Stone, Kevin},
}

@misc{janner_planning_2022,
	title = {Planning with {Diffusion} for {Flexible} {Behavior} {Synthesis}},
	url = {http://arxiv.org/abs/2205.09991},
	doi = {10.48550/arXiv.2205.09991},
	abstract = {Model-based reinforcement learning methods often use learning only for the purpose of estimating an approximate dynamics model, offloading the rest of the decision-making work to classical trajectory optimizers. While conceptually simple, this combination has a number of empirical shortcomings, suggesting that learned models may not be well-suited to standard trajectory optimization. In this paper, we consider what it would look like to fold as much of the trajectory optimization pipeline as possible into the modeling problem, such that sampling from the model and planning with it become nearly identical. The core of our technical approach lies in a diffusion probabilistic model that plans by iteratively denoising trajectories. We show how classifier-guided sampling and image inpainting can be reinterpreted as coherent planning strategies, explore the unusual and useful properties of diffusion-based planning methods, and demonstrate the effectiveness of our framework in control settings that emphasize long-horizon decision-making and test-time flexibility.},
	urldate = {2023-06-06},
	publisher = {arXiv},
	author = {Janner, Michael and Du, Yilun and Tenenbaum, Joshua B. and Levine, Sergey},
	month = dec,
	year = {2022},
	note = {arXiv:2205.09991 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{gudibande_false_2023,
	title = {The {False} {Promise} of {Imitating} {Proprietary} {LLMs}},
	url = {http://arxiv.org/abs/2305.15717},
	doi = {10.48550/arXiv.2305.15717},
	abstract = {An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model's capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data sources, and imitation data amounts (0.3M--150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models -- they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT's style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.},
	urldate = {2023-06-05},
	publisher = {arXiv},
	author = {Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
	month = may,
	year = {2023},
	note = {arXiv:2305.15717 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{lester_power_2021,
	address = {Online and Punta Cana, Dominican Republic},
	title = {The {Power} of {Scale} for {Parameter}-{Efficient} {Prompt} {Tuning}},
	url = {https://aclanthology.org/2021.emnlp-main.243},
	doi = {10.18653/v1/2021.emnlp-main.243},
	abstract = {In this work, we explore “prompt tuning,” a simple yet effective mechanism for learning “soft prompts” to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method “closes the gap” and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed “prefix tuning” of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient “prompt ensembling.” We release code and model checkpoints to reproduce our experiments.},
	urldate = {2023-05-10},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Lester, Brian and Al-Rfou, Rami and Constant, Noah},
	month = nov,
	year = {2021},
	pages = {3045--3059},
}

@misc{hu_lora_2021,
	title = {{LoRA}: {Low}-{Rank} {Adaptation} of {Large} {Language} {Models}},
	shorttitle = {{LoRA}},
	url = {http://arxiv.org/abs/2106.09685},
	doi = {10.48550/arXiv.2106.09685},
	abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
	urldate = {2023-05-05},
	publisher = {arXiv},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	month = oct,
	year = {2021},
	note = {arXiv:2106.09685 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{ho_denoising_2020,
	title = {Denoising {Diffusion} {Probabilistic} {Models}},
	url = {http://arxiv.org/abs/2006.11239},
	doi = {10.48550/arXiv.2006.11239},
	abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
	urldate = {2023-03-25},
	publisher = {arXiv},
	author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	month = dec,
	year = {2020},
	note = {arXiv:2006.11239 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{ainslie_colt5_2023,
	title = {{CoLT5}: {Faster} {Long}-{Range} {Transformers} with {Conditional} {Computation}},
	shorttitle = {{CoLT5}},
	url = {http://arxiv.org/abs/2303.09752},
	doi = {10.48550/arXiv.2303.09752},
	abstract = {Many natural language processing tasks benefit from long inputs, but processing long documents with Transformers is expensive -- not only due to quadratic attention complexity but also from applying feedforward and projection layers to every token. However, not all tokens are equally important, especially for longer documents. We propose CoLT5, a long-input Transformer model that builds on this intuition by employing conditional computation, devoting more resources to important tokens in both feedforward and attention layers. We show that CoLT5 achieves stronger performance than LongT5 with much faster training and inference, achieving SOTA on the long-input SCROLLS benchmark. Moreover, CoLT5 can effectively and tractably make use of extremely long inputs, showing strong gains up to 64k input length.},
	urldate = {2023-03-21},
	publisher = {arXiv},
	author = {Ainslie, Joshua and Lei, Tao and de Jong, Michiel and Ontañón, Santiago and Brahma, Siddhartha and Zemlyanskiy, Yury and Uthus, David and Guo, Mandy and Lee-Thorp, James and Tay, Yi and Sung, Yun-Hsuan and Sanghai, Sumit},
	month = mar,
	year = {2023},
	note = {arXiv:2303.09752 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{chiang_chatgpt_2023,
	title = {{ChatGPT} {Is} a {Blurry} {JPEG} of the {Web}},
	issn = {0028-792X},
	url = {https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web},
	abstract = {OpenAI’s chatbot offers paraphrases, whereas Google offers quotes. Which do we prefer?},
	language = {en-US},
	urldate = {2023-03-19},
	journal = {The New Yorker},
	author = {Chiang, Ted},
	month = feb,
	year = {2023},
	note = {Section: annals of technology},
	keywords = {algorithms, artificial intelligence (a.i.), images, internet, technology, writing},
}

@misc{park_finetuning_2021,
	title = {Finetuning {Pretrained} {Transformers} into {Variational} {Autoencoders}},
	url = {http://arxiv.org/abs/2108.02446},
	abstract = {Text variational autoencoders (VAEs) are notorious for posterior collapse, a phenomenon where the model's decoder learns to ignore signals from the encoder. Because posterior collapse is known to be exacerbated by expressive decoders, Transformers have seen limited adoption as components of text VAEs. Existing studies that incorporate Transformers into text VAEs (Li et al., 2020; Fang et al., 2021) mitigate posterior collapse using massive pretraining, a technique unavailable to most of the research community without extensive computing resources. We present a simple two-phase training scheme to convert a sequence-to-sequence Transformer into a VAE with just finetuning. The resulting language model is competitive with massively pretrained Transformer-based VAEs in some internal metrics while falling short on others. To facilitate training we comprehensively explore the impact of common posterior collapse alleviation techniques in the literature. We release our code for reproducability.},
	urldate = {2023-03-01},
	publisher = {arXiv},
	author = {Park, Seongmin and Lee, Jihwa},
	month = nov,
	year = {2021},
	note = {arXiv:2108.02446 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{ribeiro_amplification_2023,
	title = {The {Amplification} {Paradox} in {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2302.11225},
	doi = {10.48550/arXiv.2302.11225},
	abstract = {Automated audits of recommender systems found that blindly following recommendations leads users to increasingly partisan, conspiratorial, or false content. At the same time, studies using real user traces suggest that recommender systems are not the primary driver of attention toward extreme content; on the contrary, such content is mostly reached through other means, e.g., other websites. In this paper, we explain the following apparent paradox: if the recommendation algorithm favors extreme content, why is it not driving its consumption? With a simple agent-based model where users attribute different utilities to items in the recommender system, we show that the collaborative-filtering nature of recommender systems and the nicheness of extreme content can resolve the apparent paradox: although blindly following recommendations would indeed lead users to niche content, users rarely consume niche content when given the option because it is of low utility to them, which can lead the recommender system to deamplify such content. Our results call for a nuanced interpretation of ``algorithmic amplification'' and highlight the importance of modeling the utility of content to users when auditing recommender systems.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Ribeiro, Manoel Horta and Veselovsky, Veniamin and West, Robert},
	month = feb,
	year = {2023},
	note = {arXiv:2302.11225 [cs]},
	keywords = {Computer Science - Computers and Society},
}

@misc{noauthor_join_nodate,
	title = {Join conversation},
	url = {https://teams.microsoft.com/dl/launcher/launcher.html?url=%2F_%23%2Fl%2Fteam%2F19%3A323a217dfe5e49d094b195da5837692c%40thread.tacv2%2Fconversations%3FtenantId%3D09a10672-822f-4467-a5ba-5bb375967c05&type=team&deeplinkId=0ca0dd08-445d-48d1-b47d-fafda102e295&directDl=true&msLaunch=true&enableMobilePage=true&suppressPrompt=true},
	language = {en-GB},
	urldate = {2023-02-27},
	journal = {Microsoft Teams},
}

@misc{roberts_scaling_2022,
	title = {Scaling {Up} {Models} and {Data} with \${\textbackslash}texttt\{t5x\}\$ and \${\textbackslash}texttt\{seqio\}\$},
	url = {http://arxiv.org/abs/2203.17189},
	doi = {10.48550/arXiv.2203.17189},
	abstract = {Recent neural network-based language models have benefited greatly from scaling up the size of training datasets and the number of parameters in the models themselves. Scaling can be complicated due to various factors including the need to distribute computation on supercomputer clusters (e.g., TPUs), prevent bottlenecks when infeeding data, and ensure reproducible results. In this work, we present two software libraries that ease these issues: \${\textbackslash}texttt\{t5x\}\$ simplifies the process of building and training large language models at scale while maintaining ease of use, and \${\textbackslash}texttt\{seqio\}\$ provides a task-based API for simple creation of fast and reproducible training data and evaluation pipelines. These open-source libraries have been used to train models with hundreds of billions of parameters on datasets with multiple terabytes of training data. Along with the libraries, we release configurations and instructions for T5-like encoder-decoder models as well as GPT-like decoder-only architectures. \${\textbackslash}texttt\{t5x\}\$ and \${\textbackslash}texttt\{seqio\}\$ are open source and available at https://github.com/google-research/t5x and https://github.com/google/seqio, respectively.},
	urldate = {2023-02-27},
	publisher = {arXiv},
	author = {Roberts, Adam and Chung, Hyung Won and Levskaya, Anselm and Mishra, Gaurav and Bradbury, James and Andor, Daniel and Narang, Sharan and Lester, Brian and Gaffney, Colin and Mohiuddin, Afroz and Hawthorne, Curtis and Lewkowycz, Aitor and Salcianu, Alex and van Zee, Marc and Austin, Jacob and Goodman, Sebastian and Soares, Livio Baldini and Hu, Haitang and Tsvyashchenko, Sasha and Chowdhery, Aakanksha and Bastings, Jasmijn and Bulian, Jannis and Garcia, Xavier and Ni, Jianmo and Chen, Andrew and Kenealy, Kathleen and Clark, Jonathan H. and Lee, Stephan and Garrette, Dan and Lee-Thorp, James and Raffel, Colin and Shazeer, Noam and Ritter, Marvin and Bosma, Maarten and Passos, Alexandre and Maitin-Shepard, Jeremy and Fiedel, Noah and Omernick, Mark and Saeta, Brennan and Sepassi, Ryan and Spiridonov, Alexander and Newlan, Joshua and Gesmundo, Andrea},
	month = mar,
	year = {2022},
	note = {arXiv:2203.17189 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{chen_neural_2019,
	title = {Neural {Ordinary} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1806.07366},
	doi = {10.48550/arXiv.1806.07366},
	abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
	urldate = {2023-02-19},
	publisher = {arXiv},
	author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
	month = dec,
	year = {2019},
	note = {arXiv:1806.07366 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{xu_infinitely_2022,
	title = {Infinitely {Deep} {Bayesian} {Neural} {Networks} with {Stochastic} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2102.06559},
	doi = {10.48550/arXiv.2102.06559},
	abstract = {We perform scalable approximate inference in continuous-depth Bayesian neural networks. In this model class, uncertainty about separate weights in each layer gives hidden units that follow a stochastic differential equation. We demonstrate gradient-based stochastic variational inference in this infinite-parameter setting, producing arbitrarily-flexible approximate posteriors. We also derive a novel gradient estimator that approaches zero variance as the approximate posterior over weights approaches the true posterior. This approach brings continuous-depth Bayesian neural nets to a competitive comparison against discrete-depth alternatives, while inheriting the memory-efficient training and tunable precision of Neural ODEs.},
	urldate = {2023-02-19},
	publisher = {arXiv},
	author = {Xu, Winnie and Chen, Ricky T. Q. and Li, Xuechen and Duvenaud, David},
	month = jan,
	year = {2022},
	note = {arXiv:2102.06559 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{mialon_augmented_2023,
	title = {Augmented {Language} {Models}: a {Survey}},
	shorttitle = {Augmented {Language} {Models}},
	url = {http://arxiv.org/abs/2302.07842},
	doi = {10.48550/arXiv.2302.07842},
	abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
	urldate = {2023-02-17},
	publisher = {arXiv},
	author = {Mialon, Grégoire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07842 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{noauthor_parameter-efficient_nodate,
	title = {Parameter-{Efficient} {Fine}-{Tuning} using 🤗 {PEFT}},
	url = {https://huggingface.co/blog/peft},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-02-15},
}

@article{lecun_path_nodate,
	title = {A {Path} {Towards} {Autonomous} {Machine} {Intelligence} {Version} 0.9.2, 2022-06-27},
	abstract = {How could machines learn as eﬃciently as humans and animals? How could machines learn to reason and plan? How could machines learn representations of percepts and action plans at multiple levels of abstraction, enabling them to reason, predict, and plan at multiple time horizons? This position paper proposes an architecture and training paradigms with which to construct autonomous intelligent agents. It combines concepts such as conﬁgurable predictive world model, behavior driven through intrinsic motivation, and hierarchical joint embedding architectures trained with self-supervised learning.},
	language = {en},
	author = {LeCun, Yann},
}

@misc{noauthor_path_nodate,
	title = {A {Path} {Towards} {Autonomous} {Machine} {Intelligence}},
	url = {https://openreview.net/forum?id=BZ5a1r-kVsf},
	abstract = {How could machines learn as efficiently as humans and animals?  How could machines learn to reason and plan?  How could machines learn representations of percepts and action plans at multiple...},
	language = {en},
	urldate = {2023-02-06},
	journal = {OpenReview},
}

@article{noauthor_race_nodate,
	title = {The race of the {AI} labs heats up},
	issn = {0013-0613},
	url = {https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up?giftId=befa6230-71a8-4b3f-9cb4-09be6c1763c6},
	urldate = {2023-02-01},
	journal = {The Economist},
}

@misc{welleck_neural_2019,
	title = {Neural {Text} {Generation} with {Unlikelihood} {Training}},
	url = {http://arxiv.org/abs/1908.04319},
	abstract = {Neural text generation is a key tool in natural language applications, but it is well known there are major problems at its core. In particular, standard likelihood training and decoding leads to dull and repetitive outputs. While some post-hoc fixes have been proposed, in particular top-\$k\$ and nucleus sampling, they do not address the fact that the token-level probabilities predicted by the model are poor. In this paper we show that the likelihood objective itself is at fault, resulting in a model that assigns too much probability to sequences containing repeats and frequent words, unlike those from the human training distribution. We propose a new objective, unlikelihood training, which forces unlikely generations to be assigned lower probability by the model. We show that both token and sequence level unlikelihood training give less repetitive, less dull text while maintaining perplexity, giving superior generations using standard greedy or beam search. According to human evaluations, our approach with standard beam search also outperforms the currently popular decoding methods of nucleus sampling or beam blocking, thus providing a strong alternative to existing techniques.},
	urldate = {2023-02-01},
	publisher = {arXiv},
	author = {Welleck, Sean and Kulikov, Ilia and Roller, Stephen and Dinan, Emily and Cho, Kyunghyun and Weston, Jason},
	month = sep,
	year = {2019},
	note = {arXiv:1908.04319 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{noauthor_hugging_nodate,
	title = {Hugging {Face} – {The} {AI} community building the future.},
	url = {https://huggingface.co/},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-01-24},
}

@misc{fang_transformer-based_2021,
	title = {Transformer-based {Conditional} {Variational} {Autoencoder} for {Controllable} {Story} {Generation}},
	url = {http://arxiv.org/abs/2101.00828},
	doi = {10.48550/arXiv.2101.00828},
	abstract = {We investigate large-scale latent variable models (LVMs) for neural story generation -- an under-explored application for open-domain long text -- with objectives in two threads: generation effectiveness and controllability. LVMs, especially the variational autoencoder (VAE), have achieved both effective and controllable generation through exploiting flexible distributional latent representations. Recently, Transformers and its variants have achieved remarkable effectiveness without explicit latent representation learning, thus lack satisfying controllability in generation. In this paper, we advocate to revive latent variable modeling, essentially the power of representation learning, in the era of Transformers to enhance controllability without hurting state-of-the-art generation effectiveness. Specifically, we integrate latent representation vectors with a Transformer-based pre-trained architecture to build conditional variational autoencoder (CVAE). Model components such as encoder, decoder and the variational posterior are all built on top of pre-trained language models -- GPT2 specifically in this paper. Experiments demonstrate state-of-the-art conditional generation ability of our model, as well as its excellent representation learning capability and controllability.},
	urldate = {2023-01-17},
	publisher = {arXiv},
	author = {Fang, Le and Zeng, Tao and Liu, Chaochun and Bo, Liefeng and Dong, Wen and Chen, Changyou},
	month = jul,
	year = {2021},
	note = {arXiv:2101.00828 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@inproceedings{liu_transformer-based_2019,
	title = {A {Transformer}-{Based} {Variational} {Autoencoder} for {Sentence} {Generation}},
	doi = {10.1109/IJCNN.2019.8852155},
	abstract = {The variational autoencoder(VAE) has been proved to be a most efficient generative model, but its applications in natural language tasks have not been fully developed. A novel variational autoencoder for natural texts generation is presented in this paper. Compared to the previously introduced variational autoencoder for natural text where both the encoder and decoder are RNN-based, we propose a new transformer-based architecture and augment the decoder with an LSTM language model layer to fully exploit information of latent variables. We also propose some methods to deal with problems during training time, such as KL divergency collapsing and model degradation. In the experiment, we use random sampling and linear interpolation to test our model. Results show that the generated sentences by our approach are more meaningful and the semantics are more coherent in the latent space.},
	booktitle = {2019 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Liu, Danyang and Liu, Gongshen},
	month = jul,
	year = {2019},
	note = {ISSN: 2161-4407},
	keywords = {Computer architecture, Decoding, Gaussian distribution, Natural languages, Neural networks, Task analysis, Training, self-attention, text generation, transformer, variational autoencoder},
	pages = {1--7},
}

@misc{mann_how_2019,
	title = {How to sample from language models},
	url = {https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277},
	abstract = {Causal language models like GPT-2 are trained to predict the probability of the next word given some context. For example, given “I ate a…},
	language = {en},
	urldate = {2023-01-15},
	journal = {Medium},
	author = {Mann, Ben},
	month = may,
	year = {2019},
}

@misc{holtzman_curious_2020,
	title = {The {Curious} {Case} of {Neural} {Text} {Degeneration}},
	url = {http://arxiv.org/abs/1904.09751},
	doi = {10.48550/arXiv.1904.09751},
	abstract = {Despite considerable advancements with deep neural language models, the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, using likelihood as a decoding objective leads to text that is bland and strangely repetitive. In this paper, we reveal surprising distributional differences between human text and machine text. In addition, we find that decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model. Our findings motivate Nucleus Sampling, a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.},
	urldate = {2023-01-15},
	publisher = {arXiv},
	author = {Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
	month = feb,
	year = {2020},
	note = {arXiv:1904.09751 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{radford_language_nodate,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts WebText. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
	language = {en},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
}

@misc{fan_hierarchical_2018,
	title = {Hierarchical {Neural} {Story} {Generation}},
	url = {http://arxiv.org/abs/1805.04833},
	doi = {10.48550/arXiv.1805.04833},
	abstract = {We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.},
	urldate = {2023-01-15},
	publisher = {arXiv},
	author = {Fan, Angela and Lewis, Mike and Dauphin, Yann},
	month = may,
	year = {2018},
	note = {arXiv:1805.04833 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	doi = {10.48550/arXiv.2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
	urldate = {2023-01-15},
	publisher = {arXiv},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = jul,
	year = {2020},
	note = {arXiv:2005.14165 [cs]
version: 4},
	keywords = {Computer Science - Computation and Language},
}

@misc{noauthor_implicit_2022,
	title = {Implicit {Bayesian} {Inference} in {Large} {Language} {Models}},
	url = {https://www.inference.vc/implicit-bayesian-inference-in-sequence-models/},
	abstract = {This intriguing paper kept me thinking long enough for me to I decide it's time to resurrect my blogging (I started writing this during ICLR review period, and realised it might be a good idea to wait until that's concluded) Sang Michael Xie, Aditi Raghunathan, Percy Liang and Tengyu Ma...},
	language = {en},
	urldate = {2023-01-12},
	journal = {inFERENCe},
	month = mar,
	year = {2022},
}

@misc{zou_reinforcement_2019,
	title = {Reinforcement {Learning} to {Optimize} {Long}-term {User} {Engagement} in {Recommender} {Systems}},
	url = {http://arxiv.org/abs/1902.05570},
	doi = {10.48550/arXiv.1902.05570},
	abstract = {Recommender systems play a crucial role in our daily lives. Feed streaming mechanism has been widely used in the recommender system, especially on the mobile Apps. The feed streaming setting provides users the interactive manner of recommendation in never-ending feeds. In such an interactive manner, a good recommender system should pay more attention to user stickiness, which is far beyond classical instant metrics, and typically measured by \{{\textbackslash}bf long-term user engagement\}. Directly optimizing the long-term user engagement is a non-trivial problem, as the learning target is usually not available for conventional supervised learning methods. Though reinforcement learning{\textasciitilde}(RL) naturally fits the problem of maximizing the long term rewards, applying RL to optimize long-term user engagement is still facing challenges: user behaviors are versatile and difficult to model, which typically consists of both instant feedback{\textasciitilde}(e.g. clicks, ordering) and delayed feedback{\textasciitilde}(e.g. dwell time, revisit); in addition, performing effective off-policy learning is still immature, especially when combining bootstrapping and function approximation. To address these issues, in this work, we introduce a reinforcement learning framework --- FeedRec to optimize the long-term user engagement. FeedRec includes two components: 1){\textasciitilde}a Q-Network which designed in hierarchical LSTM takes charge of modeling complex user behaviors, and 2){\textasciitilde}an S-Network, which simulates the environment, assists the Q-Network and voids the instability of convergence in policy learning. Extensive experiments on synthetic data and a real-world large scale data show that FeedRec effectively optimizes the long-term user engagement and outperforms state-of-the-arts.},
	urldate = {2023-01-05},
	publisher = {arXiv},
	author = {Zou, Lixin and Xia, Long and Ding, Zhuoye and Song, Jiaxing and Liu, Weidong and Yin, Dawei},
	month = jul,
	year = {2019},
	note = {arXiv:1902.05570 [cs]},
	keywords = {Computer Science - Information Retrieval},
}

@misc{jeunen_lessons_nodate,
	title = {Lessons {Learned} from {Winning} the {RecoGym} {Challenge}},
	url = {https://olivierjeunen.github.io/recogym/},
	abstract = {Lead Decision Scientist @ ShareChat, UK},
	language = {en},
	urldate = {2023-01-04},
	journal = {Olivier Jeunen},
	author = {Jeunen, Olivier},
}

@inproceedings{bendada_carousel_2020,
	title = {Carousel {Personalization} in {Music} {Streaming} {Apps} with {Contextual} {Bandits}},
	url = {http://arxiv.org/abs/2009.06546},
	doi = {10.1145/3383313.3412217},
	abstract = {Media services providers, such as music streaming platforms, frequently leverage swipeable carousels to recommend personalized content to their users. However, selecting the most relevant items (albums, artists, playlists...) to display in these carousels is a challenging task, as items are numerous and as users have different preferences. In this paper, we model carousel personalization as a contextual multi-armed bandit problem with multiple plays, cascade-based updates and delayed batch feedback. We empirically show the effectiveness of our framework at capturing characteristics of real-world carousels by addressing a large-scale playlist recommendation task on a global music streaming mobile app. Along with this paper, we publicly release industrial data from our experiments, as well as an open-source environment to simulate comparable carousel personalization learning problems.},
	urldate = {2023-01-02},
	booktitle = {Fourteenth {ACM} {Conference} on {Recommender} {Systems}},
	author = {Bendada, Walid and Salha, Guillaume and Bontempelli, Théo},
	month = sep,
	year = {2020},
	note = {arXiv:2009.06546 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {420--425},
}

@article{afsar_reinforcement_2022,
	title = {Reinforcement {Learning} based {Recommender} {Systems}: {A} {Survey}},
	volume = {55},
	issn = {0360-0300},
	shorttitle = {Reinforcement {Learning} based {Recommender} {Systems}},
	url = {https://doi.org/10.1145/3543846},
	doi = {10.1145/3543846},
	abstract = {Recommender systems (RSs) have become an inseparable part of our everyday lives. They help us find our favorite items to purchase, our friends on social networks, and our favorite movies to watch. Traditionally, the recommendation problem was considered to be a classification or prediction problem, but it is now widely agreed that formulating it as a sequential decision problem can better reflect the user-system interaction. Therefore, it can be formulated as a Markov decision process (MDP) and be solved by reinforcement learning (RL) algorithms. Unlike traditional recommendation methods, including collaborative filtering and content-based filtering, RL is able to handle the sequential, dynamic user-system interaction and to take into account the long-term user engagement. Although the idea of using RL for recommendation is not new and has been around for about two decades, it was not very practical, mainly because of scalability problems of traditional RL algorithms. However, a new trend has emerged in the field since the introduction of deep reinforcement learning (DRL), which made it possible to apply RL to the recommendation problem with large state and action spaces. In this paper, a survey on reinforcement learning based recommender systems (RLRSs) is presented. Our aim is to present an outlook on the field and to provide the reader with a fairly complete knowledge of key concepts of the field. We first recognize and illustrate that RLRSs can be generally classified into RL- and DRL-based methods. Then, we propose an RLRS framework with four components, i.e., state representation, policy optimization, reward formulation, and environment building, and survey RLRS algorithms accordingly. We highlight emerging topics and depict important trends using various graphs and tables. Finally, we discuss important aspects and challenges that can be addressed in the future.},
	number = {7},
	urldate = {2022-12-27},
	journal = {ACM Computing Surveys},
	author = {Afsar, M. Mehdi and Crump, Trafford and Far, Behrouz},
	month = dec,
	year = {2022},
	keywords = {Recommender systems, reinforcement learning},
	pages = {145:1--145:38},
}

@inproceedings{maystre_temporally-consistent_2022,
	title = {Temporally-{Consistent} {Survival} {Analysis}},
	url = {https://openreview.net/forum?id=r-CsquKaHvk},
	abstract = {We study survival analysis in the dynamic setting: We seek to model the time to an event of interest given sequences of states. Taking inspiration from temporal-difference learning, a central idea in reinforcement learning, we develop algorithms that estimate a discrete-time survival model by exploiting a temporal-consistency condition. Intuitively, this condition captures the fact that the survival distribution at consecutive states should be similar, accounting for the delay between states. Our method can be combined with any parametric survival model and naturally accommodates right-censored observations. We demonstrate empirically that it achieves better sample-efficiency and predictive performance compared to approaches that directly regress the observed survival outcome.},
	language = {en},
	urldate = {2022-11-27},
	author = {Maystre, Lucas and Russo, Daniel},
	month = oct,
	year = {2022},
}

@article{noauthor_news_nodate,
	title = {News personalization using {Bernoulli} {Matrix} {Factorization} for implicit data},
	language = {en},
	pages = {51},
}

@article{prado_advances_2018,
	title = {Advances in {Financial} {Machine} {Learning}},
	language = {en},
	author = {Prado, Marcos Lopez},
	year = {2018},
	pages = {395},
}

@inproceedings{wu_mind_2020,
	address = {Online},
	title = {{MIND}: {A} {Large}-scale {Dataset} for {News} {Recommendation}},
	shorttitle = {{MIND}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.331},
	doi = {10.18653/v1/2020.acl-main.331},
	abstract = {News recommendation is an important technique for personalized news service. Compared with product and movie recommendations which have been comprehensively studied, the research on news recommendation is much more limited, mainly due to the lack of a high-quality benchmark dataset. In this paper, we present a large-scale dataset named MIND for news recommendation. Constructed from the user click logs of Microsoft News, MIND contains 1 million users and more than 160k English news articles, each of which has rich textual content such as title, abstract and body. We demonstrate MIND a good testbed for news recommendation through a comparative study of several state-of-the-art news recommendation methods which are originally developed on different proprietary datasets. Our results show the performance of news recommendation highly relies on the quality of news content understanding and user interest modeling. Many natural language processing techniques such as effective text representation methods and pre-trained language models can effectively improve the performance of news recommendation. The MIND dataset will be available at https://msnews.github.io.},
	language = {en},
	urldate = {2022-09-22},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Wu, Fangzhao and Qiao, Ying and Chen, Jiun-Hung and Wu, Chuhan and Qi, Tao and Lian, Jianxun and Liu, Danyang and Xie, Xing and Gao, Jianfeng and Wu, Winnie and Zhou, Ming},
	year = {2020},
	pages = {3597--3606},
}

@inproceedings{welling_bayesian_2011,
	title = {Bayesian {Learning} via {Stochastic} {Gradient} {Langevin} {Dynamics}},
	abstract = {In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overﬁtting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a “sampling threshold” and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients.},
	language = {en},
	author = {Welling, Max and Teh, Yee Whye},
	year = {2011},
	pages = {8},
}

@article{maurera_towards_2022,
	title = {Towards the {Evaluation} of {Recommender} {Systems} with {Impressions}},
	abstract = {In Recommender Systems, impressions are a relatively new type of information that records all products previously shown to the users. They are also a complex source of information, combining the effects of the recommender system that generated them, search results, or business rules that may select specific products for recommendations. The fact that the user interacted with a specific item given a list of recommended ones may benefit from a richer interaction signal, in which some items the user did not interact with may be considered negative interactions. This work presents a preliminary evaluation of recommendation models with impressions. First, impressions are characterized by describing their assumptions, signals, and challenges. Then, an evaluation study with impressions is described. The study’s goal is two-fold: to measure the effects of impressions data on properly-tuned recommendation models using current open-source datasets and disentangle the signals within impressions data. Preliminary results suggest that impressions data and signals are nuanced, complex, and effective at improving the recommendation quality of recommenders. This work publishes the source code, datasets, and scripts used in the evaluation to promote reproducibility in the domain.},
	language = {en},
	author = {Maurera, Fernando B Pérez and Dacrema, Maurizio Ferrari and Cremonesi, Paolo},
	year = {2022},
	pages = {6},
}

@techreport{eide_midas_2016,
	title = {Midas {Margin} {Model} {SIX} x-clear {Ltd}},
	author = {Eide, Simen},
	year = {2016},
}

@article{Lin2020,
	title = {Pretrained {Transformers} for {Text} {Ranking}: {BERT} and {Beyond}},
	issn = {23318422},
	url = {http://arxiv.org/abs/2010.06467},
	abstract = {The goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query. Although the most common formulation of text ranking is search, instances of the task can also be found in many natural language processing applications. This survey provides an overview of text ranking with neural network architectures known as transformers, of which BERT is the best-known example. The combination of transformers and self-supervised pretraining has, without exaggeration, revolutionized the fields of natural language processing (NLP), information retrieval (IR), and beyond. In this survey, we provide a synthesis of existing work as a single point of entry for practitioners who wish to gain a better understanding of how to apply transformers to text ranking problems and researchers who wish to pursue work in this area. We cover a wide range of modern techniques, grouped into two high-level categories: transformer models that perform reranking in multi-stage ranking architectures and learned dense representations that attempt to perform ranking directly. There are two themes that pervade our survey: techniques for handling long documents, beyond the typical sentence-by-sentence processing approaches used in NLP, and techniques for addressing the tradeoff between effectiveness (result quality) and efficiency (query latency). Although transformer architectures and pretraining techniques are recent innovations, many aspects of how they are applied to text ranking are relatively well understood and represent mature techniques. However, there remain many open research questions, and thus in addition to laying out the foundations of pretrained transformers for text ranking, this survey also attempts to prognosticate where the field is heading.},
	journal = {arXiv},
	author = {Lin, Jimmy and Nogueira, Rodrigo and Yates, Andrew},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.06467},
}

@article{Deisenroth2011,
	title = {{PILCO}: {A} model-based and data-efficient approach to policy search},
	abstract = {In this paper, we introduce PILCO, a practical, data-efficient model-based policy search method. PILCO reduces model bias, one of the key problems of model-based reinforcement learning, in a principled way. By learning a probabilistic dynamics model and explicitly incorporating model uncertainty into long-term planning, PILCO can cope with very little data and facilitates learning from scratch in only a few trials. Policy evaluation is performed in closed form using state-of-the-art approximate inference. Furthermore, policy gradients are computed analytically for policy improvement. We report unprecedented learning efficiency on challenging and high-dimensional control tasks. Copyright 2011 by the author(s)/owner(s).},
	journal = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
	author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward},
	year = {2011},
	note = {ISBN: 9781450306195},
	pages = {465--472},
}

@article{Ranganath2014,
	title = {Black box variational inference},
	volume = {33},
	issn = {15337928},
	abstract = {Variational inference has become a widely used method to approximate posteriors in complex latent variables models. However, deriving a variational inference algorithm generally requires significant model-specific analysis. These efforts can hinder and deter us from quickly developing and exploring a variety of models for a problem at hand. In this paper, we present a "black box" variational inference algorithm, one that can be quickly applied to many models with little additional derivation. Our method is based on a stochastic optimization of the variational objective where the noisy gradient is computed from Monte Carlo samples from the variational distribution. We develop a number of methods to reduce the variance of the gradient, always maintaining the criterion that we want to avoid difficult model-based derivations. We evaluate our method against the corresponding black box sampling based methods. We find that our method reaches better predictive likelihoods much faster than sampling methods. Finally, we demonstrate that Black Box Variational Inference lets us easily explore a wide space of models by quickly constructing and evaluating several models of longitudinal healthcare data.},
	journal = {Journal of Machine Learning Research},
	author = {Ranganath, Rajesh and Gerrish, Sean and Blei, David M.},
	year = {2014},
	note = {arXiv: 1401.0118},
	pages = {814--822},
}

@techreport{FortunatoDeepMind,
	title = {{BAYESIAN} {RECURRENT} {NEURAL} {NETWORKS}},
	abstract = {In this work we explore a straightforward variational Bayes scheme for Recurrent Neural Networks. Firstly, we show that a simple adaptation of truncated backpropagation through time can yield good quality uncertainty estimates and superior regularisation at only a small extra computational cost during training, also reducing the amount of parameters by 80\%. Secondly, we demonstrate how a novel kind of posterior approximation yields further improvements to the performance of Bayesian RNNs. We incorporate local gradient information into the approximate posterior to sharpen it around the current batch statistics. We show how this technique is not exclusive to recurrent neural networks and can be applied more widely to train Bayesian neural networks. We also empirically demonstrate how Bayesian RNNs are superior to traditional RNNs on a language modelling benchmark and an image captioning task, as well as showing how each of these methods improve our model over a variety of other schemes for training them. We also introduce a new benchmark for studying uncertainty for language models so future methods can be easily compared.},
	urldate = {2018-12-05},
	author = {Fortunato DeepMind, Meire and Blundell DeepMind, Charles and Vinyals DeepMind, Oriol},
	note = {arXiv: 1704.02798v3},
}

@article{Porteous2010,
	title = {Bayesian matrix factorization with side information and dirichlet process mixtures},
	volume = {1},
	abstract = {Matrix factorization is a fundamental technique in machine learning that is applicable to collaborative filtering, information retrieval and many other areas. In collaborative filtering and many other tasks, the objective is to fill in missing elements of a sparse data matrix. One of the biggest challenges in this case is filling in a column or row of the matrix with very few observations. In this paper we introduce a Bayesian matrix factorization model that performs regression against side information known about the data in addition to the observations. The side information helps by adding observed entries to the factored matrices. We also introduce a nonpara-metric mixture model for the prior of the rows and columns of the factored matrices that gives a different regularization for each latent class. Besides providing a richer prior, the posterior distribution of mixture assignments reveals the latent classes. Using Gibbs sampling for inference, we apply our model to the Netflix Prize problem of predicting movie ratings given an incomplete user-movie ratings matrix. In-corporating rating information with gathered metadata infor-mation, our Bayesian approach outperforms other matrix fac-torization techniques even when using fewer dimensions. Copyright © 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	journal = {Proceedings of the National Conference on Artificial Intelligence},
	author = {Porteous, Ian and Asuncion, Arthur and Welling, Max},
	year = {2010},
	note = {ISBN: 9781577354642},
	keywords = {Technical Papers -- Machine Learning},
	pages = {563--568},
}

@article{Liu2019,
	title = {Bandit {Learning} for {Diversified} {Interactive} {Recommendation}},
	url = {http://arxiv.org/abs/1907.01647},
	abstract = {Interactive recommender systems that enable the interactions between users and the recommender system have attracted increasing research attentions. Previous methods mainly focus on optimizing recommendation accuracy. However, they usually ignore the diversity of the recommendation results, thus usually results in unsatisfying user experiences. In this paper, we propose a novel diversified recommendation model, named Diversified Contextual Combinatorial Bandit (DC\${\textasciicircum}2\$B), for interactive recommendation with users' implicit feedback. Specifically, DC\${\textasciicircum}2\$B employs determinantal point process in the recommendation procedure to promote diversity of the recommendation results. To learn the model parameters, a Thompson sampling-type algorithm based on variational Bayesian inference is proposed. In addition, theoretical regret analysis is also provided to guarantee the performance of DC\${\textasciicircum}2\$B. Extensive experiments on real datasets are performed to demonstrate the effectiveness of the proposed method.},
	author = {Liu, Yong and Xiao, Yingtai and Wu, Qiong and Miao, Chunyan and Zhang, Juyong},
	year = {2019},
	note = {arXiv: 1907.01647},
}

@article{Kingma2014,
	title = {Auto-encoding variational bayes},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	number = {Ml},
	journal = {2nd International Conference on Learning Representations, ICLR 2014 - Conference Track Proceedings},
	author = {Kingma, Diederik P. and Welling, Max},
	year = {2014},
	note = {arXiv: 1312.6114},
	pages = {1--14},
}

@article{jin_study_2006,
	title = {A study of mixture models for collaborative filtering},
	volume = {9},
	issn = {13864564},
	doi = {10.1007/s10791-006-4651-1},
	abstract = {Collaborative filtering is a general technique for exploiting the preference patterns of a group of users to predict the utility of items for a particular user. Three different components need to be modeled in a collaborative filtering problem: users, items, and ratings. Previous research on applying probabilistic models to collaborative filtering has shown promising results. However, there is a lack of systematic studies of different ways to model each of the three components and their interactions. In this paper, we conduct a broad and systematic study on different mixture models for collaborative filtering. We discuss general issues related to using a mixture model for collaborative filtering, and propose three properties that a graphical model is expected to satisfy. Using these properties, we thoroughly examine five different mixture models, including Bayesian Clustering (BC), Aspect Model (AM), Flexible Mixture Model (FMM), Joint Mixture Model (JMM), and the Decoupled Model (DM). We compare these models both analytically and experimentally. Experiments over two datasets of movie ratings under different configurations show that in general, whether a model satisfies the proposed properties tends to be correlated with its performance. In particular, the Decoupled Model, which satisfies all the three desired properties, outperforms the other mixture models as well as many other existing approaches for collaborative filtering. Our study shows that graphical models are powerful tools for modeling collaborative filtering, but careful design is necessary to achieve good performance. © Springer Science + Business Media, LLC 2006.},
	number = {3},
	journal = {Information Retrieval},
	author = {Jin, Rong and Si, Luo and Zhai, Chengxiang},
	year = {2006},
	keywords = {Collaborative filtering, Graphical model, Probabilistic model},
	pages = {357--382},
}

@article{jain_split-merge_2004,
	title = {A {Split}-{Merge} {Markov} {Chain} {Monte} {Carlo} {Procedure} for the {Dirichlet} {Process} {Mixture} {Model}},
	volume = {13},
	issn = {10618600},
	doi = {10.1198/1061860043001},
	abstract = {This article proposes a split-merge Markov chain algorithm to address the problem of inefficient sampling for conjugate Dirichlet process mixture models. Traditional Markov chain Monte Carlo methods for Bayesian mixture models, such as Gibbs sampling, can become trapped in isolated modes corresponding to an inappropriate clustering of data points. This article describes a Metropolis-Hastings procedure that can escape such local modes by splitting or merging mixture components. Our algorithm employs a new technique in which an appropriate proposal for splitting or merging components is obtained by using a restricted Gibbs sampling scan. We demonstrate empirically that our method outperforms the Gibbs sampler in situations where two or more components are similar in structure.},
	number = {1},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Jain, Sonia and Neal, Radford M.},
	year = {2004},
	note = {ISBN: 1061860043001},
	keywords = {Gibbs sampler, Latent class analysis, Metropolis-Hastings algorithm},
	pages = {158--182},
}

@article{leslie_dynamic_2021,
	title = {Dynamic {Slate} {Recommendation} with {Gated} {Recurrent} {Units} and {Thompson} {Sampling}},
	url = {http://arxiv.org/abs/2104.15046},
	abstract = {We consider the problem of recommending relevant content to users of an internet platform in the form of lists of items, called slates. We introduce a variational Bayesian Recurrent Neural Net recommender system that acts on time series of interactions between the internet platform and the user, and which scales to real world industrial situations. The recommender system is tested both online on real users, and on an offline dataset collected from a Norwegian web-based marketplace, FINN.no, that is made public for research. This is one of the first publicly available datasets which includes all the slates that are presented to users as well as which items (if any) in the slates were clicked on. Such a data set allows us to move beyond the common assumption that implicitly assumes that users are considering all possible items at each interaction. Instead we build our likelihood using the items that are actually in the slate, and evaluate the strengths and weaknesses of both approaches theoretically and in experiments. We also introduce a hierarchical prior for the item parameters based on group memberships. Both item parameters and user preferences are learned probabilistically. Furthermore, we combine our model with bandit strategies to ensure learning, and introduce `in-slate Thompson Sampling' which makes use of the slates to maximise explorative opportunities. We show experimentally that explorative recommender strategies perform on par or above their greedy counterparts. Even without making use of exploration to learn more effectively, click rates increase simply because of improved diversity in the recommended slates.},
	author = {Leslie, David S. and Frigessi, Arnoldo and Eide, Simen},
	year = {2021},
	note = {arXiv: 2104.15046},
	pages = {1--31},
}

@article{Ledwich2019,
	title = {Algorithmic {Extremism}: {Examining} {YouTube}’s {Rabbit} {Hole} of {Radicalization}},
	issn = {1396-0466},
	doi = {10.5210/fm.v25i3.10419},
	abstract = {—The role that YouTube and its behind-the-scenes recommendation algorithm plays in encouraging online radicalization has been suggested by both journalists and academics alike. This study directly quantifies these claims by examining the role that YouTubes algorithm plays in suggesting radicalized content. After categorizing nearly 800 political channels, we were able to differentiate between political schemas in order to analyze the algorithm traffic flows out and between each group. After conducting a detailed analysis of recommendations received by each channel type, we refute the popular radicalization claims. To the contrary, these data suggest that YouTubes recommendation algorithm actively discourages viewers from visiting radicalizing or extremist content. Instead, the algorithm is shown to favor mainstream media and cable news content over independent YouTube channels with slant towards left-leaning or politically neutral channels. Our study thus suggests that YouTubes recommendation algorithm fails to promote inflammatory or radicalized content, as previously claimed by several outlets.},
	journal = {arXiv},
	author = {Ledwich, Mark and Zaitsev, Anna},
	year = {2019},
	note = {arXiv: 1912.11211},
}

@article{Li2017a,
	title = {Approximate inference with amortised {MCMC}},
	issn = {23318422},
	abstract = {We propose a novel approximate inference framework that approximates a target distribution by amortising the dynamics of a user-selected Markov chain Monte Carlo (MCMC) sampler. The idea is to initialise MCMC using samples from an approximation network, apply the MCMC operator to improve these samples, and finally use the samples to update the approximation network thereby improving its quality. This provides a new generic framework for approximate inference, allowing us to deploy highly complex, or implicitly defined approximation families with intractable densities, including approximations produced by warping a source of randomness through a deep neural network. Experiments consider Bayesian neural network classification and image modelling with deep generative models. Deep models trained using amortised MCMC are shown to generate realistic looking samples as well as producing diverse imputations for images with regions of missing pixels.},
	journal = {arXiv},
	author = {Li, Yingzhen and Turner, Richard E. and Liu, Qiang},
	year = {2017},
	note = {arXiv: 1702.08343},
	pages = {1--17},
}

@article{Merity2018a,
	title = {An {Analysis} of {Neural} {Language} {Modeling} at {Multiple} {Scales}},
	url = {http://arxiv.org/abs/1803.08240},
	abstract = {Many of the leading approaches in language modeling introduce novel, complex and specialized architectures. We take existing state-of-the-art word level language models based on LSTMs and QRNNs and extend them to both larger vocabularies as well as character-level granularity. When properly tuned, LSTMs and QRNNs achieve state-of-the-art results on character-level (Penn Treebank, enwik8) and word-level (WikiText-103) datasets, respectively. Results are obtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single modern GPU.},
	urldate = {2018-03-23},
	author = {Merity, Stephen and Keskar, Nitish Shirish and Socher, Richard},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.08240},
}

@article{Izmailov2021,
	title = {What {Are} {Bayesian} {Neural} {Network} {Posteriors} {Really} {Like}?},
	url = {http://arxiv.org/abs/2104.14421},
	abstract = {The posterior over Bayesian neural network (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in Bayesian deep learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) BNNs can achieve significant performance gains over standard training and deep ensembles; (2) a single long HMC chain can provide a comparable representation of the posterior to multiple shorter chains; (3) in contrast to recent studies, we find posterior tempering is not needed for near-optimal performance, with little evidence for a "cold posterior" effect, which we show is largely an artifact of data augmentation; (4) BMA performance is robust to the choice of prior scale, and relatively similar for diagonal Gaussian, mixture of Gaussian, and logistic priors; (5) Bayesian neural networks show surprisingly poor generalization under domain shift; (6) while cheaper alternatives such as deep ensembles and SGMCMC methods can provide good generalization, they provide distinct predictive distributions from HMC. Notably, deep ensemble predictive distributions are similarly close to HMC as standard SGLD, and closer than standard variational inference.},
	author = {Izmailov, Pavel and Vikram, Sharad and Hoffman, Matthew D. and Wilson, Andrew Gordon},
	year = {2021},
	note = {arXiv: 2104.14421},
}

@article{Wenzel2020,
	title = {How {Good} is the {Bayes} {Posterior} in {Deep} {Neural} {Networks} {Really}?},
	url = {http://arxiv.org/abs/2002.02405},
	abstract = {During the past five years the Bayesian deep learning community has developed increasingly accurate and efficient approximate inference procedures that allow for Bayesian inference in deep neural networks. However, despite this algorithmic progress and the promise of improved uncertainty quantification and sample efficiency there are---as of early 2020---no publicized deployments of Bayesian neural networks in industrial practice. In this work we cast doubt on the current understanding of Bayes posteriors in popular deep neural networks: we demonstrate through careful MCMC sampling that the posterior predictive induced by the Bayes posterior yields systematically worse predictions compared to simpler methods including point estimates obtained from SGD. Furthermore, we demonstrate that predictive performance is improved significantly through the use of a "cold posterior" that overcounts evidence. Such cold posteriors sharply deviate from the Bayesian paradigm but are commonly used as heuristic in Bayesian deep learning papers. We put forward several hypotheses that could explain cold posteriors and evaluate the hypotheses through experiments. Our work questions the goal of accurate posterior approximations in Bayesian deep learning: If the true Bayes posterior is poor, what is the use of more accurate approximations? Instead, we argue that it is timely to focus on understanding the origin of the improved performance of cold posteriors.},
	number = {1},
	journal = {International Conference on Machine Learning},
	author = {Wenzel, Florian and Roth, Kevin and Veeling, Bastiaan S. and Świątkowski, Jakub and Tran, Linh and Mandt, Stephan and Snoek, Jasper and Salimans, Tim and Jenatton, Rodolphe and Nowozin, Sebastian},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.02405},
}

@article{aitchison_statistical_2020,
	title = {A statistical theory of cold posteriors in deep neural networks},
	url = {http://arxiv.org/abs/2008.05912},
	abstract = {To get Bayesian neural networks to perform comparably to standard neural networks it is usually necessary to artificially reduce uncertainty using a "tempered" or "cold" posterior. This is extremely concerning: if the prior is accurate, Bayes inference/decision theory is optimal, and any artificial changes to the posterior should harm performance. While this suggests that the prior may be at fault, here we argue that in fact, BNNs for image classification use the wrong likelihood. In particular, standard image benchmark datasets such as CIFAR-10 are carefully curated. We develop a generative model describing curation which gives a principled Bayesian account of cold posteriors, because the likelihood under this new generative model closely matches the tempered likelihoods used in past work.},
	author = {Aitchison, Laurence},
	year = {2020},
	note = {arXiv: 2008.05912},
	pages = {1--15},
}

@article{hermans_likelihood-free_2020,
	title = {Likelihood-free {MCMC} with amortized approximate ratio estimators},
	volume = {PartF16814},
	abstract = {Posterior inference with an intractable likelihood is becoming an increasingly common task in scientific domains which rely on sophisticated computer simulations. Typically, these forward models do not admit tractable densities forcing practitioners to make use of approximations. This work introduces a novel approach to address the intractability of the likelihood and the marginal model. We achieve this by learning a flexible amortized estimator which approximates the likelihood-to-evidence ratio. We demonstrate that the learned ratio estimator can be embedded in MCMC samplers to approximate likelihood-ratios between consecutive states in the Markov chain, allowing us to draw samples from the intractable posterior. Techniques are presented to improve the numerical stability and to measure the quality of an approximation. The accuracy of our approach is demonstrated on a variety of benchmarks against well-established techniques. Scientific applications in physics show its applicabilit.},
	number = {i},
	journal = {37th International Conference on Machine Learning, ICML 2020},
	author = {Hermans, Joeri and Begy, Volodimir and Louppe, Gilles},
	year = {2020},
	note = {arXiv: 1903.04057
ISBN: 9781713821120},
	pages = {4187--4198},
}

@article{luengo_fully_2013,
	title = {Fully adaptive {Gaussian} mixture {Metropolis}-{Hastings} algorithm},
	issn = {15206149},
	doi = {10.1109/ICASSP.2013.6638846},
	abstract = {Markov Chain Monte Carlo methods are widely used in signal processing and communications for statistical inference and stochastic optimization. In this work, we introduce an efficient adaptive Metropolis-Hastings algorithm to draw samples from generic multimodal and multidimensional target distributions. The proposal density is a mixture of Gaussian densities with all parameters (weights, mean vectors and covariance matrices) updated using all the previously generated samples applying simple recursive rules. Numerical results for the one and two-dimensional cases are provided. © 2013 IEEE.},
	number = {Mcmc},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	author = {Luengo, David and Martino, Luca},
	year = {2013},
	note = {arXiv: 1212.0122
ISBN: 9781479903566},
	keywords = {Gaussian mixtures, Markov Chain Monte Carlo (MCMC), adaptive Metropolis-Hastings},
	pages = {6148--6152},
}

@article{karmakar_stochastic_2021,
	title = {Stochastic {Approximation} with {Iterate}-{Dependent} {Markov} {Noise} under {Verifiable} {Conditions} in {Compact} {State} {Space} with the {Stability} of {Iterates} {Not} {Ensured}},
	volume = {66},
	issn = {15582523},
	doi = {10.1109/TAC.2021.3057299},
	abstract = {This article compiles several aspects of the dynamics of stochastic approximation algorithms with Markov iterate-dependent noise when the iterates are not known to be stable beforehand. We achieve the same by extending the lock-in probability (i.e., the probability of convergence of the iterates to a specific attractor of the limiting ordinary differential equation (o.d.e.) given that the iterates are in its domain of attraction after a sufficiently large number of iterations (say) \$n\_0\$) framework to such recursions. Specifically, with the more restrictive assumption of Markov iterate-dependent noise supported on a bounded subset of the Euclidean space, we give a lower bound for the lock-in probability. We use these results to prove almost sure convergence of the iterates to the specified attractor when the iterates satisfy an asymptotic tightness condition. The novelty of our approach is that if the state space of the Markov process is compact, we prove almost sure convergence under much weaker assumptions compared to the work by Andrieu et al., which solves the general state-space case under much restrictive assumptions by providing sufficient conditions for stability of the iterates. We also extend our single-timescale results to the case where there are two separate recursions over two different timescales. This, in turn, is shown to be useful in analyzing the tracking ability of general adaptive algorithms. Additionally, we show that our results can be used to derive a sample complexity estimate of such recursions, which then can be used for step-size selection.},
	number = {12},
	journal = {IEEE Transactions on Automatic Control},
	author = {Karmakar, Prasenjit and Bhatnagar, Shalabh},
	year = {2021},
	note = {arXiv: 1601.02217
Publisher: IEEE},
	keywords = {Adaptive algorithms, Lock-in probability, Markov noise, Sample complexity},
	pages = {5941--5954},
}

@article{xie_unsupervised_2019,
	title = {Unsupervised {Learning} of {Paragraph} {Embeddings} for {Context}-{Aware} {Recommendation}},
	volume = {7},
	issn = {21693536},
	doi = {10.1109/ACCESS.2019.2906659},
	abstract = {The sparsity of data is one of the main reasons restricting the performance of recommender systems. In order to solve the sparsity problem, some recommender systems use auxiliary information, especially text information, as a supplement to increase the prediction accuracy of the ratings. However, the two mainstream approaches based on text analysis have some limitations. The bag-of-words-based model is one of them, being difficult to use the contextual information of the paragraph effectively so that only the shallow understanding of paragraph can be parsed. Another model based on deep learning can extract the contextual information of the paragraph, but it also increases the complexity of the model. This paper proposes a novel context-aware recommendation model named paragraph vector matrix factorization (P2VMF) which integrates the unsupervised learning of paragraph embeddings into probabilistic matrix factorization (PMF). Therefore, P2VMF can capture the semantic information of the paragraph and can improve the prediction accuracy of the ratings. Our extensive experiments on real-world datasets show that the performance of the P2VMF model is preferable as compared with those multiple recommendation models in the situation, where the ratings are quite sparse. And we also verified that the P2V part of the model can well express the semantics in the form of vectors.},
	journal = {IEEE Access},
	author = {Xie, Jin and Zhu, Fuxi and Huang, Minxue and Xiong, Naixue and Huang, Sheng and Xiong, Wei},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {Context awareness, recommender systems, semantics, text analysis, unsupervised learning},
	pages = {43100--43109},
}

@article{deldjoo_survey_2022,
	title = {A {Survey} of {Research} on {Fair} {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2205.11127},
	abstract = {Recommender systems can strongly influence which information we see online, e.g, on social media, and thus impact our beliefs, decisions, and actions. At the same time, these systems can create substantial business value for different stakeholders. Given the growing potential impact of such AI-based systems on individuals, organizations, and society, questions of fairness have gained increased attention in recent years. However, research on fairness in recommender systems is still a developing area. In this survey, we first review the fundamental concepts and notions of fairness that were put forward in the area in the recent past. Afterward, we provide a survey of how research in this area is currently operationalized, for example, in terms of the general research methodology, fairness metrics, and algorithmic approaches. Overall, our analysis of recent works points to certain research gaps. In particular, we find that in many research works in computer science very abstract problem operationalizations are prevalent, which circumvent the fundamental and important question of what represents a fair recommendation in the context of a given application.},
	author = {Deldjoo, Yashar and Jannach, Dietmar and Bellogin, Alejandro and Diffonzo, Alessandro and Zanzonelli, Dario},
	year = {2022},
	note = {arXiv: 2205.11127},
	keywords = {fairness, recommender systems},
	pages = {1--35},
}

@article{el-kishky_knn-embed_2022,
	title = {{kNN}-{Embed}: {Locally} {Smoothed} {Embedding} {Mixtures} {For} {Multi}-interest {Candidate} {Retrieval}},
	volume = {1},
	url = {http://arxiv.org/abs/2205.06205},
	abstract = {Candidate generation is the first stage in recommendation systems, where a light-weight system is used to retrieve potentially relevant items for an input user. These candidate items are then ranked and pruned in later stages of recommender systems using a more complex ranking model. Since candidate generation is the top of the recommendation funnel, it is important to retrieve a high-recall candidate set to feed into downstream ranking models. A common approach for candidate generation is to leverage approximate nearest neighbor (ANN) search from a single dense query embedding; however, this approach this can yield a low-diversity result set with many near duplicates. As users often have multiple interests, candidate retrieval should ideally return a diverse set of candidates reflective of the user's multiple interests. To this end, we introduce kNN-Embed, a general approach to improving diversity in dense ANN-based retrieval. kNN-Embed represents each user as a smoothed mixture over learned item clusters that represent distinct `interests' of the user. By querying each of a user's mixture component in proportion to their mixture weights, we retrieve a high-diversity set of candidates reflecting elements from each of a user's interests. We experimentally compare kNN-Embed to standard ANN candidate retrieval, and show significant improvements in overall recall and improved diversity across three datasets. Accompanying this work, we open source a large Twitter follow-graph dataset, to spur further research in graph-mining and representation learning for recommender systems.},
	number = {1},
	author = {El-Kishky, Ahmed and Markovich, Thomas and Leung, Kenny and Portman, Frank and Haghighi, Aria},
	year = {2022},
	note = {arXiv: 2205.06205
Publisher: Association for Computing Machinery},
}

@article{wang_modeling_2018,
	title = {Modeling dynamic missingness of implicit feedback for recommendation},
	volume = {2018-Decem},
	issn = {10495258},
	abstract = {Implicit feedback is widely used in collaborative filtering methods for recommendation. It is well known that implicit feedback contains a large number of values that are missing not at random (MNAR); and the missing data is a mixture of negative and unknown feedback, making it difficult to learn users' negative preferences. Recent studies modeled exposure, a latent missingness variable which indicates whether an item is exposed to a user, to give each missing entry a confidence of being negative feedback. However, these studies use static models and ignore the information in temporal dependencies among items, which seems to be an essential underlying factor to subsequent missingness. To model and exploit the dynamics of missingness, we propose a latent variable named “user intent” to govern the temporal changes of item missingness, and a hidden Markov model to represent such a process. The resulting framework captures the dynamic item missingness and incorporate it into matrix factorization (MF) for recommendation. We also explore two types of constraints to achieve a more compact and interpretable representation of user intents. Experiments on real-world datasets demonstrate the superiority of our method against state-of-the-art recommender systems.},
	number = {NeurIPS},
	journal = {Advances in Neural Information Processing Systems},
	author = {Wang, Menghan and Zheng, Xiaolin and Gong, Mingming and Zhang, Kun},
	year = {2018},
	pmid = {30971864},
	pages = {6669--6678},
}

@article{chowdhery_palm_2022,
	title = {{PaLM}: {Scaling} {Language} {Modeling} with {Pathways}},
	url = {http://arxiv.org/abs/2204.02311},
	abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
	author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
	year = {2022},
	note = {arXiv: 2204.02311},
	pages = {1--83},
}

@article{beluch_power_2018,
	title = {The {Power} of {Ensembles} for {Active} {Learning} in {Image} {Classification}},
	issn = {10636919},
	doi = {10.1109/CVPR.2018.00976},
	abstract = {Deep learning methods have become the de-facto standard for challenging image processing tasks such as image classification. One major hurdle of deep learning approaches is that large sets of labeled data are necessary, which can be prohibitively costly to obtain, particularly in medical image diagnosis applications. Active learning techniques can alleviate this labeling effort. In this paper we investigate some recently proposed methods for active learning with high-dimensional data and convolutional neural network classifiers. We compare ensemble-based methods against Monte-Carlo Dropout and geometric approaches. We find that ensembles perform better and lead to more calibrated predictive uncertainties, which are the basis for many active learning algorithms. To investigate why Monte-Carlo Dropout uncertainties perform worse, we explore potential differences in isolation in a series of experiments. We show results for MNIST and CIFAR-10, on which we achieve a test set accuracy of 90\% with roughly 12,200 labeled images, and initial results on ImageNet. Additionally, we show results on a large, highly class-imbalanced diabetic retinopathy dataset. We observe that the ensemble-based active learning effectively counteracts this imbalance during acquisition.},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Beluch, William H. and Genewein, Tim and Nürnberger, Andreas and Köhler, Jan M.},
	year = {2018},
	note = {ISBN: 9781538664209},
	pages = {9368--9377},
}

@article{sinha_variational_2019,
	title = {Variational adversarial active learning},
	volume = {2019-Octob},
	issn = {15505499},
	doi = {10.1109/ICCV.2019.00607},
	abstract = {Active learning aims to develop label-efficient algorithms by sampling the most representative queries to be labeled by an oracle. We describe a pool-based semi-supervised active learning algorithm that implicitly learns this sampling mechanism in an adversarial manner. Our method learns a latent space using a variational autoencoder (VAE) and an adversarial network trained to discriminate between unlabeled and labeled data. The mini-max game between the VAE and the adversarial network is played such that while the VAE tries to trick the adversarial network into predicting that all data points are from the labeled pool, the adversarial network learns how to discriminate between dissimilarities in the latent space. We extensively evaluate our method on various image classification and semantic segmentation benchmark datasets and establish a new state of the art on CIFAR10/100, Caltech-256, ImageNet, Cityscapes, and BDD100K. Our results demonstrate that our adversarial approach learns an effective low dimensional latent space in large-scale settings and provides for a computationally efficient sampling method. Our code is available at url\{https://github.com/sinhasam/vaal\}.},
	journal = {Proceedings of the IEEE International Conference on Computer Vision},
	author = {Sinha, Samrath and Ebrahimi, Sayna and Darrell, Trevor},
	year = {2019},
	note = {arXiv: 1904.00370
ISBN: 9781728148038},
	pages = {5971--5980},
}

@article{rakesh_efficacy_2021,
	title = {Efficacy of bayesian neural networks in active learning},
	issn = {21607516},
	doi = {10.1109/CVPRW53098.2021.00294},
	abstract = {Obtaining labeled data for machine learning tasks can be prohibitively expensive. Active learning mitigates this issue by exploring the unlabeled data space and prioritizing the selection of data that can best improve the model performance. A common approach to active learning is to pick a small sample of data for which the model is most uncertain. In this paper, we explore the efficacy of Bayesian neural networks for active learning, which naturally models uncertainty by learning distribution over the weights of neural networks. By performing a comprehensive set of experiments, we show that Bayesian neural networks are more efficient than ensemble based techniques in capturing uncertainty. Our findings also reveal some key drawbacks of the ensemble techniques, which was recently shown to be more effective than Monte Carlo dropouts.},
	journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	author = {Rakesh, Vineeth and Jain, Swayambhoo},
	year = {2021},
	note = {arXiv: 2104.00896
ISBN: 9781665448994},
	pages = {2601--2609},
}

@article{fang_learning_2017,
	title = {Learning how to active learn: {A} deep reinforcement learning approach},
	doi = {10.18653/v1/d17-1063},
	abstract = {Active learning aims to select a small subset of data for annotation such that a classifier learned on the data is highly accurate. This is usually done using heuristic selection methods, however the effectiveness of such methods is limited and moreover, the performance of heuristics varies between datasets. To address these shortcomings, we introduce a novel formulation by re-framing the active learning as a reinforcement learning problem and explicitly learning a data selection policy, where the policy takes the role of the active learning heuristic. Importantly, our method allows the selection policy learned using simulation on one language to be transferred to other languages. We demonstrate our method using cross-lingual named entity recognition, observing uniform improvements over traditional active learning.},
	journal = {EMNLP 2017 - Conference on Empirical Methods in Natural Language Processing, Proceedings},
	author = {Fang, Meng and Li, Yuan and Cohn, Trevor},
	year = {2017},
	note = {arXiv: 1708.02383
ISBN: 9781945626838},
	pages = {595--605},
}

@article{gal_deep_2017,
	title = {Deep {Bayesian} active learning with image data},
	volume = {3},
	abstract = {Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolu-tional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).},
	journal = {34th International Conference on Machine Learning, ICML 2017},
	author = {Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
	year = {2017},
	note = {arXiv: 1703.02910
ISBN: 9781510855144},
	pages = {1923--1932},
}

@article{eide_draft_nodate,
	title = {draft: {Dynamic} {Slate} {Recommendation} with {Gated} {Recurrent} {Units} and {Thompson} {Sampling}},
	author = {Eide, Simen and Leslie, David S and Frigessi, Arnoldo},
	pages = {1--30},
}

@misc{and_tensorflow_2005,
	title = {{TensorFlow}: {Large}-{Scale} {Machine} {Learning} on {Heterogeneous} {Distributed} {Systems}},
	url = {tensorflow.org},
	abstract = {TensorFlow [1] is an interface for expressing machine lea},
	journal = {Network: Computation in Neural Systems},
	author = {And, Mart{\textbackslash}'\{i\}n{\textasciitilde}Abadi and And, Ashish{\textasciitilde}Agarwal and And, Paul{\textasciitilde}Barham and And, Eugene{\textasciitilde}Brevdo and And, Zhifeng{\textasciitilde}Chen and And, Craig{\textasciitilde}Citro and And, Greg{\textasciitilde}S.{\textasciitilde}Corrado and And, Andy{\textasciitilde}Davis and And, Jeffrey{\textasciitilde}Dean and And, Matthieu{\textasciitilde}Devin and And, Sanjay{\textasciitilde}Ghemawat and And, Ian{\textasciitilde}Goodfellow and And, Andrew{\textasciitilde}Harp and And, Geoffrey{\textasciitilde}Irving and And, Michael{\textasciitilde}Isard and And, Yangqing Jia and And, Rafal{\textasciitilde}Jozefowicz and And, Lukasz{\textasciitilde}Kaiser and And, Manjunath{\textasciitilde}Kudlur and And, Josh{\textasciitilde}Levenberg and And, Dandelion{\textasciitilde}Man{\textbackslash}'\{e\} and And, Rajat{\textasciitilde}Monga and And, Sherry{\textasciitilde}Moore and And, Derek{\textasciitilde}Murray and And, Chris{\textasciitilde}Olah and And, Mike{\textasciitilde}Schuster and And, Jonathon{\textasciitilde}Shlens and And, Benoit{\textasciitilde}Steiner and And, Ilya{\textasciitilde}Sutskever and And, Kunal{\textasciitilde}Talwar and And, Paul{\textasciitilde}Tucker and And, Vincent{\textasciitilde}Vanhoucke and And, Vijay{\textasciitilde}Vasudevan and And, Fernanda{\textasciitilde}Vi{\textbackslash}'\{e\}gas and And, Oriol{\textasciitilde}Vinyals and And, Pete{\textasciitilde}Warden and And, Martin{\textasciitilde}Wattenberg and And, Martin{\textasciitilde}Wicke and And, Yuan{\textasciitilde}Yu and {Xiaoqiang{\textasciitilde}Zheng}},
	year = {2005},
	pmid = {16411492},
	doi = {10.1080/09548980500300507},
	note = {ISSN: 0954898X},
}

@article{paszke_pytorch_2019,
	title = {{PyTorch}: {An} imperative style, high-performance deep learning library},
	volume = {32},
	issn = {10495258},
	abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
	number = {NeurIPS},
	journal = {Advances in Neural Information Processing Systems},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	year = {2019},
	note = {arXiv: 1912.01703},
}

@article{hueber_evaluating_2020,
	title = {Evaluating the potential gain of auditory and audiovisual speech-predictive coding using deep learning},
	volume = {32},
	issn = {1530888X},
	doi = {10.1162/neco_a_01264},
	abstract = {Sensory processing is increasingly conceived in a predictive framework in which neurons would constantly process the error signal resulting from the comparison of expected and observed stimuli. Surprisingly, few data exist on the accuracy of predictions that can be computed in real sensory scenes. Here, we focus on the sensory processing of auditory and audiovisual speech. We propose a set of computational models based on artificial neural networks (mixing deep feedforward and convolutional networks), which are trained to predict future audio observations from present and past audio or audiovisual observations (i.e., including lip movements). Those predictions exploit purely local phonetic regularities with no explicit call to higher linguistic levels. Experiments are conducted on the multispeaker LibriSpeech audio speech database (around 100 hours) and on the NTCD-TIMIT audiovisual speech database (around 7 hours). They appear to be efficient in a short temporal range (25–50 ms), predicting 50\% to 75\% of the variance of the incoming stimulus, which could result in potentially saving up to three-quarters of the processing power. Then they quickly decrease and almost vanish after 250 ms. Adding information on the lips slightly improves predictions, with a 5\% to 10\% increase in explained variance. Interestingly the visual gain vanishes more slowly, and the gain is maximum for a delay of 75 ms between image and predicted sound.},
	number = {3},
	journal = {Neural Computation},
	author = {Hueber, Thomas and Tatulli, Eric and Girin, Laurent and Schwartz, Jean Luc},
	year = {2020},
	pmid = {31951798},
	pages = {596--625},
}

@article{perez_maurera_contentwise_2020,
	title = {{ContentWise} {Impressions}: {An} {Industrial} {Dataset} with {Impressions} {Included}},
	doi = {10.1145/3340531.3412774},
	abstract = {In this article, we introduce the {\textbackslash}dataset dataset, a collection of implicit interactions and impressions of movies and TV series from an Over-The-Top media service, which delivers its media contents over the Internet. The dataset is distinguished from other already available multimedia recommendation datasets by the availability of impressions, {\textbackslash}idest the recommendations shown to the user, its size, and by being open-source. We describe the data collection process, the preprocessing applied, its characteristics, and statistics when compared to other commonly used datasets. We also highlight several possible use cases and research questions that can benefit from the availability of user impressions in an open-source dataset. Furthermore, we release software tools to load and split the data, as well as examples of how to use both user interactions and impressions in several common recommendation algorithms.},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	author = {Pérez Maurera, Fernando B. and Ferrari Dacrema, Maurizio and Saule, Lorenzo and Scriminaci, Mario and Cremonesi, Paolo},
	year = {2020},
	note = {arXiv: 2008.01212
ISBN: 9781450368599},
	keywords = {collaborative filtering, dataset, implicit feedback, impressions, open source},
	pages = {3093--3100},
}

@article{Nemeth2020,
	title = {Stochastic {Gradient} {Markov} {Chain} {Monte} {Carlo}},
	issn = {1537274X},
	url = {http://arxiv.org/abs/1907.06986},
	doi = {10.1080/01621459.2020.1847120},
	abstract = {Markov chain Monte Carlo (MCMC) algorithms are generally regarded as the gold standard technique for Bayesian inference. They are theoretically well-understood and conceptually simple to apply in practice. The drawback of MCMC is that performing exact inference generally requires all of the data to be processed at each iteration of the algorithm. For large datasets, the computational cost of MCMC can be prohibitive, which has led to recent developments in scalable Monte Carlo algorithms that have a significantly lower computational cost than standard MCMC. In this article, we focus on a particular class of scalable Monte Carlo algorithms, stochastic gradient Markov chain Monte Carlo (SGMCMC) which utilizes data subsampling techniques to reduce the per-iteration cost of MCMC. We provide an introduction to some popular SGMCMC algorithms and review the supporting theoretical results, as well as comparing the efficiency of SGMCMC algorithms against MCMC on benchmark examples. The supporting R code is available online athttps://github.com/chris-nemeth/sgmcmc-review-paper.},
	journal = {Journal of the American Statistical Association},
	author = {Nemeth, Christopher and Fearnhead, Paul},
	year = {2020},
	note = {arXiv: 1907.06986},
	keywords = {Bayesian inference, Markov chain Monte Carlo, Scalable Monte Carlo, Stochastic gradients, bayesian inference, markov chain monte carlo, scalable monte carlo, stochastic},
	pages = {1--31},
}

@article{ludewig_performance_2019,
	title = {Performance comparison of neural and non-neural approaches to session-based recommendation},
	doi = {10.1145/3298689.3347041},
	abstract = {The benefts of neural approaches are undisputed in many application areas. However, today's research practice in applied machine learning-where researchers often use a variety of baselines, datasets, and evaluation procedures-can make it difcult to understand how much progress is actually achieved through novel technical approaches. In this work, we focus on the fast-developing area of session-based recommendation and aim to contribute to a better understanding of what represents the state-of-the-art. To that purpose, we have conducted an extensive set of experiments, using a variety of datasets, in which we benchmarked four neural approaches that were published in the last three years against each other and against a set of simpler baseline techniques, e.g., based on nearest neighbors. The evaluation of the algorithms under the exact same conditions revealed that the benefts of applying today's neural approaches to session-based recommendations are still limited. In the majority of the cases, and in particular when precision and recall are used, it turned out that simple techniques in most cases outperform recent neural approaches. Our fndings therefore point to certain major limitations of today's research practice. By sharing our evaluation framework publicly, we hope that some of these limitations can be overcome in the future.},
	number = {February},
	journal = {RecSys 2019 - 13th ACM Conference on Recommender Systems},
	author = {Ludewig, Malte and Mauro, Noemi and Latif, Sara and Jannach, Dietmar},
	year = {2019},
	note = {ISBN: 9781450362436},
	keywords = {Evaluation, Reproducibility, Session-based Recommendation},
	pages = {462--466},
}

@article{kille_plista_2013,
	title = {The plista dataset},
	doi = {10.1145/2516641.2516643},
	abstract = {Releasing datasets has fostered research in fields such as information retrieval and recommender systems. Datasets are typically tailored for specific scenarios. In this work, we present the plista dataset. The dataset contains a collection of news articles published on 13 news portals. Additionally, the dataset comprises user interactions with those articles. We inctroduce the dataset's main characteristics. Further, we illustrate possible applications of the dataset. © 2013 ACM.},
	journal = {ACM International Conference Proceeding Series},
	author = {Kille, Benjamin and Hopfgartner, Frank and Brodt, Torben and Heintz, Tobias},
	year = {2013},
	note = {ISBN: 9781450323024},
	keywords = {dataset, news, recommender systems},
	pages = {16--23},
}

@article{buzzicotti_inferring_2022,
	title = {Inferring {Turbulent} {Parameters} via {Machine} {Learning}},
	url = {http://arxiv.org/abs/2201.00732},
	abstract = {We design a machine learning technique to solve the general problem of inferring physical parameters from the observation of turbulent flows, a relevant exercise in many theoretical and applied fields, from engineering to earth observation and astrophysics. Our approach is to train the machine learning system to regress the rotation frequency of the flow's reference frame, from the observation of the flow's velocity amplitude on a 2d plane extracted from the 3d domain. The machine learning approach consists of a Deep Convolutional Neural Network (DCNN) of the same kind developed in computer vision. The training and validation datasets are produced by means of fully resolved direct numerical simulations. This study shows interesting results from two different points of view. From the machine learning point of view it shows the potential of DCNN, reaching good results on such a particularly complex problem that goes well outside the limits of human vision. Second, from the physics point of view, it provides an example on how machine learning can be exploited in data analysis to infer information that would be inaccessible otherwise. Indeed, by comparing DCNN with the other possible Bayesian approaches, we find that DCNN yields to a much higher inference accuracy in all the examined cases.},
	number = {3},
	author = {Buzzicotti, Michele and Bonaccorso, Fabio and Biferale, Luca},
	year = {2022},
	note = {arXiv: 2201.00732},
	pages = {1--13},
}

@article{green_modelling_2018,
	title = {Modelling {Heterogeneity} with and without the {Dirichlet} {Process}},
	volume = {28},
	number = {2},
	author = {Green, Peter J and Richardson, Sylvia},
	year = {2018},
	pages = {355--375},
}

@book{yotov_cross_2021,
	title = {Cross {Country} {Paragliding}},
	isbn = {978-619-91885-0-7},
	url = {www.skynomad.com/books},
	abstract = {Cross country flying without an engine is the most difficult form of aviation, as it requires an extensive knowledge of aerodynamics and meteorology. At the same time, paragliders are the simplest aircraft to fly. There are top pilots and champions, who haven’t read a single book about flying; they inspire, but they cannot teach you their intuition and feelings about the wind and the wing. This book is an attempt to structure the complex matter of cross country flying and explain the major elements of this puzzle. It should help beginner cross country pilots to identify their mistakes and accelerate their progress. Advanced pilots might be challenged by some new ideas - or at least understand some techniques that, they’ve already been using subconsciously for years. This book may give comprehensive answers, but at the same time it may open a lot more questions. There is an entire universe of processes, even behind a simple wind gust, even behind a simple gliding flight. There is love and eternity when you merge with the wind and your wing. There is peace and humility when you let Nature be.},
	publisher = {Skynomad},
	author = {Yotov, Nikolay},
	year = {2021},
	keywords = {paragliding},
}

@article{neal_markov_2000,
	title = {Markov {Chain} {Sampling} {Methods} for {Dirichlet} {Process} {Mixture} {Models}},
	volume = {9},
	issn = {15372715},
	doi = {10.1080/10618600.2000.10474879},
	abstract = {This article reviews Markov chain methods for sampling from the posterior distribution of a Dirichlet process mixture model and presents two new classes of methods. One new approach is to make Metropolis—Hastings updates of the indicators specifying which mixture component is associated with each observation, perhaps supplemented with a partial form of Gibbs sampling. The other new approach extends Gibbs sampling for these indicators by using a set of auxiliary parameters. These methods are simple to implement and are more efficient than previous ways of handling general Dirichlet process mixture models with non-conjugate priors. © 2000 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
	number = {2},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Neal, Radford M.},
	year = {2000},
	keywords = {Auxiliary variable methods, Density estimation, Latent class models, Metropolis—Hasting algorithm, Monte Carlo},
	pages = {249--265},
}

@article{duran-martin_efficient_2021,
	title = {Efficient {Online} {Bayesian} {Inference} for {Neural} {Bandits}},
	url = {http://arxiv.org/abs/2112.00195},
	abstract = {In this paper we present a new algorithm for online (sequential) inference in Bayesian neural networks, and show its suitability for tackling contextual bandit problems. The key idea is to combine the extended Kalman filter (which locally linearizes the likelihood function at each time step) with a (learned or random) low-dimensional affine subspace for the parameters; the use of a subspace enables us to scale our algorithm to models with \${\textbackslash}sim 1M\$ parameters. While most other neural bandit methods need to store the entire past dataset in order to avoid the problem of "catastrophic forgetting", our approach uses constant memory. This is possible because we represent uncertainty about all the parameters in the model, not just the final linear layer. We show good results on the "Deep Bayesian Bandit Showdown" benchmark, as well as MNIST and a recommender system.},
	author = {Duran-Martin, Gerardo and Kara, Aleyna and Murphy, Kevin},
	year = {2021},
	note = {arXiv: 2112.00195},
	pages = {1--23},
}

@article{palenik_isotrotter_2021,
	title = {{IsoTrotter}: {Visually} {Guided} {Empirical} {Modelling} of {Atmospheric} {Convection}},
	volume = {27},
	issn = {19410506},
	doi = {10.1109/TVCG.2020.3030389},
	abstract = {Empirical models, fitted to data from observations, are often used in natural sciences to describe physical behaviour and support discoveries. However, with more complex models, the regression of parameters quickly becomes insufficient, requiring a visual parameter space analysis to understand and optimize the models. In this work, we present a design study for building a model describing atmospheric convection. We present a mixed-initiative approach to visually guided modelling, integrating an interactive visual parameter space analysis with partial automatic parameter optimization. Our approach includes a new, semi-automatic technique called IsoTrotting, where we optimize the procedure by navigating along isocontours of the model. We evaluate the model with unique observational data of atmospheric convection based on flight trajectories of paragliders.},
	number = {2},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Pálenik, Juraj and Spengler, Thomas and Hauser, Helwig},
	year = {2021},
	pmid = {33079665},
	keywords = {atmospheric convection, scientific modelling, visual parameter space exploration},
	pages = {775--784},
}

@article{andrieu_tutorial_2008,
	title = {A tutorial on adaptive {MCMC}},
	doi = {10.1007/s11222-008-9110-y},
	number = {December},
	author = {Andrieu, Christophe and Thoms, Johannes},
	year = {2008},
	keywords = {adaptive mcmc, also denoted π, assumed for simplicity to, controlled, from which, have a density with, markov chain, mcmc, measure, r n x, re-, spect to the lebesgue, stochastic approximation, x},
	pages = {343--373},
}

@article{tin_turn_2020,
	title = {Turn {Decision}-{Making} for {Improved} {Autonomous} {Thermalling} of {Unmanned} {Aerial} {Gliders}},
	author = {Tin, Fares El and Borowczyk, Alexandre and Sharf, Inna and Nahon, Meyer},
	year = {2020},
	note = {ISBN: 9781728142777},
}

@article{guilliard_autonomous_2018,
	title = {Autonomous {Thermalling} as a {Partially} {Observable} {Markov} {Decision} {Process} ( {Extended} {Version} )},
	journal = {International Conference on Intelligent Robots and Systems (IROS)},
	author = {Guilliard, Iain and Rogahn, Richard and Piavis, Jim and Kolobov, Andrey},
	year = {2018},
	note = {arXiv: 1805.09875v1},
}

@article{vlassis_control_2021,
	title = {Control {Variates} for {Slate} {Off}-{Policy} {Evaluation}},
	url = {http://arxiv.org/abs/2106.07914},
	abstract = {We study the problem of off-policy evaluation from batched contextual bandit data with multidimensional actions, often termed slates. The problem is common to recommender systems and user-interface optimization, and it is particularly challenging because of the combinatorially-sized action space. Swaminathan et al. (2017) have proposed the pseudoinverse (PI) estimator under the assumption that the conditional mean rewards are additive in actions. Using control variates, we consider a large class of unbiased estimators that includes as specific cases the PI estimator and (asymptotically) its self-normalized variant. By optimizing over this class, we obtain new estimators with risk improvement guarantees over both the PI and self-normalized PI estimators. Experiments with real-world recommender data as well as synthetic data validate these improvements in practice.},
	number = {2017},
	author = {Vlassis, Nikos and Chandrashekar, Ashok and Gil, Fernando Amat and Kallus, Nathan},
	year = {2021},
	note = {arXiv: 2106.07914},
}

@article{carbone_robustness_2020,
	title = {Robustness of {Bayesian} neural networks to gradient-based attacks},
	volume = {2020-Decem},
	issn = {10495258},
	abstract = {Vulnerability to adversarial attacks is one of the principal hurdles to the adoption of deep learning in safety-critical applications. Despite significant efforts, both practical and theoretical, the problem remains open. In this paper, we analyse the geometry of adversarial attacks in the large-data, overparametrized limit for Bayesian Neural Networks (BNNs). We show that, in the limit, vulnerability to gradient-based attacks arises as a result of degeneracy in the data distribution, i.e., when the data lies on a lower-dimensional submanifold of the ambient space. As a direct consequence, we demonstrate that in the limit BNN posteriors are robust to gradient-based adversarial attacks. Experimental results on the MNIST and Fashion MNIST datasets, representing the finite data regime, with BNNs trained with Hamiltonian Monte Carlo and Variational Inference support this line of argument, showing that BNNs can display both high accuracy and robustness to gradient based adversarial attacks.},
	number = {February},
	journal = {Advances in Neural Information Processing Systems},
	author = {Carbone, Ginevra and Wicker, Matthew and Laurenti, Luca and Patane, Andrea and Bortolussi, Luca and Sanguinetti, Guido},
	year = {2020},
	note = {arXiv: 2002.04359},
}

@article{gawlikowski_survey_2021,
	title = {A {Survey} of {Uncertainty} in {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2107.03342},
	abstract = {Due to their increasing spread, confidence in neural network predictions became more and more important. However, basic neural networks do not deliver certainty estimates or suffer from over or under confidence. Many researchers have been working on understanding and quantifying uncertainty in a neural network's prediction. As a result, different types and sources of uncertainty have been identified and a variety of approaches to measure and quantify uncertainty in neural networks have been proposed. This work gives a comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. It is intended to give anyone interested in uncertainty estimation in neural networks a broad overview and introduction, without presupposing prior knowledge in this field. A comprehensive introduction to the most crucial sources of uncertainty is given and their separation into reducible model uncertainty and not reducible data uncertainty is presented. The modeling of these uncertainties based on deterministic neural networks, Bayesian neural networks, ensemble of neural networks, and test-time data augmentation approaches is introduced and different branches of these fields as well as the latest developments are discussed. For a practical application, we discuss different measures of uncertainty, approaches for the calibration of neural networks and give an overview of existing baselines and implementations. Different examples from the wide spectrum of challenges in different fields give an idea of the needs and challenges regarding uncertainties in practical applications. Additionally, the practical limitations of current methods for mission- and safety-critical real world applications are discussed and an outlook on the next steps towards a broader usage of such methods is given.},
	author = {Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and Shahzad, Muhammad and Yang, Wen and Bamler, Richard and Zhu, Xiao Xiang},
	year = {2021},
	note = {arXiv: 2107.03342},
	pages = {1--41},
}

@article{chipman_bayesian_2007,
	title = {Bayesian ensemble learning},
	issn = {10495258},
	doi = {10.7551/mitpress/7503.003.0038},
	abstract = {We develop a Bayesian "sum-of-trees" model, named BART, where each tree is constrained by a prior to be a weak learner. Fitting and inference are accomplished via an iterative backfitting MCMC algorithm. This model is motivated by ensemble methods in general, and boosting algorithms in particular. Like boosting, each weak learner (i.e., each weak tree) contributes a small amount to the overall model. However, our procedure is defined by a statistical model: a prior and a likelihood, while boosting is defined by an algorithm. This model-based approach enables a full and accurate assessment of uncertainty in model predictions, while remaining highly competitive in terms of predictive accuracy.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Chipman, Hugh A. and George, Edward I. and McCulloch, Robert E.},
	year = {2007},
	note = {ISBN: 9780262195683},
	pages = {265--272},
}

@article{ruopp_reasonable_2016,
	title = {The reasonable effectiveness of data},
	volume = {2},
	journal = {Proceedings - AMTA 2016: 12th Conference of the Association for Machine Translation in the Americas},
	author = {Ruopp, Achim},
	year = {2016},
	note = {ISBN: 9780000000002},
	pages = {123--142},
}

@article{skauli_modelling_nodate,
	title = {Modelling {Short} {Term} {Changes} in {User} {Interest} for {Online} {Marketplaces}},
	author = {Skauli, Øystein and Scheel, Ida and Eide, Simen and Wender, Stefan},
	keywords = {information retrieval},
	pages = {1--5},
}

@article{cleary_calibrate_2021,
	title = {Calibrate, emulate, sample},
	volume = {424},
	issn = {10902716},
	doi = {10.1016/j.jcp.2020.109716},
	abstract = {Many parameter estimation problems arising in applications can be cast in the framework of Bayesian inversion. This allows not only for an estimate of the parameters, but also for the quantification of uncertainties in the estimates. Often in such problems the parameter-to-data map is very expensive to evaluate, and computing derivatives of the map, or derivative-adjoints, may not be feasible. Additionally, in many applications only noisy evaluations of the map may be available. We propose an approach to Bayesian inversion in such settings that builds on the derivative-free optimization capabilities of ensemble Kalman inversion methods. The overarching approach is to first use ensemble Kalman sampling (EKS) to calibrate the unknown parameters to fit the data; second, to use the output of the EKS to emulate the parameter-to-data map; third, to sample from an approximate Bayesian posterior distribution in which the parameter-to-data map is replaced by its emulator. This results in a principled approach to approximate Bayesian inference that requires only a small number of evaluations of the (possibly noisy approximation of the) parameter-to-data map. It does not require derivatives of this map, but instead leverages the documented power of ensemble Kalman methods. Furthermore, the EKS has the desirable property that it evolves the parameter ensemble towards the regions in which the bulk of the parameter posterior mass is located, thereby locating them well for the emulation phase of the methodology. In essence, the EKS methodology provides a cheap solution to the design problem of where to place points in parameter space to efficiently train an emulator of the parameter-to-data map for the purposes of Bayesian inversion.},
	journal = {Journal of Computational Physics},
	author = {Cleary, Emmet and Garbuno-Inigo, Alfredo and Lan, Shiwei and Schneider, Tapio and Stuart, Andrew M.},
	year = {2021},
	note = {arXiv: 2001.03689},
	keywords = {Approximate Bayesian inversion, Ensemble Kalman sampling, Experimental design, Gaussian process emulation, Uncertainty quantification},
	pages = {1--27},
}

@article{kouki_lab_2020,
	title = {From the lab to production: {A} case study of session-based recommendations in the home-improvement domain},
	doi = {10.1145/3383313.3412235},
	abstract = {E-commerce applications rely heavily on session-based recommendation algorithms to improve the shopping experience of their customers. Recent progress in session-based recommendation algorithms shows great promise. However, translating that promise to real-world outcomes is a challenging task for several reasons, but mostly due to the large number and varying characteristics of the available models. In this paper, we discuss the approach and lessons learned from the process of identifying and deploying a successful session-based recommendation algorithm for a leading e-commerce application in the home-improvement domain. To this end, we initially evaluate fourteen session-based recommendation algorithms in an offline setting using eight different popular evaluation metrics on three datasets. The results indicate that offline evaluation does not provide enough insight to make an informed decision since there is no clear winning method on all metrics. Additionally, we observe that standard offline evaluation metrics fall short for this application. Specifically, they reward an algorithm only when it predicts the exact same item that the user clicked next or eventually purchased. In a practical scenario, however, there are near-identical products which, although they are assigned different identifiers, they should be considered as equally-good recommendations. To overcome these limitations, we perform an additional round of evaluation, where human experts provide both objective and subjective feedback for the recommendations of five algorithms that performed the best in the offline evaluation. We find that the experts' opinion is oftentimes different from the offline evaluation results. Analysis of the feedback confirms that the performance of all models is significantly higher when we evaluate near-identical product recommendations as relevant. Finally, we run an A/B test with one of the models that performed the best in the human evaluation phase. The treatment model increased conversion rate by 15.6\% and revenue per visit by 18.5\% when compared with a leading third-party solution.},
	journal = {RecSys 2020 - 14th ACM Conference on Recommender Systems},
	author = {Kouki, Pigi and Fountalis, Ilias and Vasiloglou, Nikolaos and Cui, Xiquan and Liberty, Edo and Al Jadda, Khalifeh},
	year = {2020},
	note = {ISBN: 9781450375832},
	keywords = {A/B test, comparison of offline evaluation metrics with labe, evaluation using human experts, session-based recommendations},
	pages = {140--149},
}

@article{schon_learning_2017,
	title = {Learning of dynamical systems {Particle} filters and {Markov} chain methods},
	abstract = {Notes for the 2017 SMC Workshop at Uppsala University August 2017},
	author = {Schön, Thomas B and Lindsten, Fredrik},
	year = {2017},
}

@article{carlsson_thompson_2021,
	title = {Thompson {Sampling} for {Bandits} with {Clustered} {Arms}},
	doi = {10.24963/ijcai.2021/305},
	abstract = {We propose algorithms based on a multi-level Thompson sampling scheme, for the stochastic multi-armed bandit and its contextual variant with linear expected rewards, in the setting where arms are clustered. We show, both theoretically and empirically, how exploiting a given cluster structure can significantly improve the regret and computational cost compared to using standard Thompson sampling. In the case of the stochastic multi-armed bandit we give upper bounds on the expected cumulative regret showing how it depends on the quality of the clustering. Finally, we perform an empirical evaluation showing that our algorithms perform well compared to previously proposed algorithms for bandits with clustered arms.},
	author = {Carlsson, Emil and Dubhashi, Devdatt and Johansson, Fredrik D.},
	year = {2021},
	note = {arXiv: 2109.01656},
	pages = {2212--2218},
}

@article{roberts_exponential_1996,
	title = {Exponential convergence of {Langevin} distributions and their discrete approximations},
	volume = {2},
	number = {4},
	journal = {Bernoulli},
	author = {Roberts, Gareth O and Tweedie, Richard L},
	year = {1996},
	keywords = {1, a real explosion in, chain monte carlo methods, geometric convergence of markov, hastings and metropolis, markov chain monte carlo, methods, the langevin method for, the use of the, there has recently been},
	pages = {341--363},
}

@article{obergruber_development_2016,
	title = {Development of a {Paraglide} {Control} {System} for {Automatic} {Pitch} {Stabilization} to {Increase} the {Passive} {Safety}},
	volume = {147},
	issn = {18777058},
	url = {http://dx.doi.org/10.1016/j.proeng.2016.06.184},
	doi = {10.1016/j.proeng.2016.06.184},
	abstract = {Paragliders tend to collapse when entering a too low pitch angle, which can lead to dangerous situations. The aim of this project was to develop a system, which is able to stabilize the pitch axis/movement of a paraglider in order to avoid critical angles of attack and resulting front collapses. A 6 DOF sensor measured these critical pitch values during flight, a microcontroller unit activates linear actuators located in the harness of the pilot, and pulls on the D-risers of the paraglider to stabilize the overshooting. This substitutes the active reaction of a pilot and therefore is able to prevent critical flight situations. For evaluation, pitch values with and without stabilization system, during artificially induced overshooting maneuvers, got compared. The evaluation results showed a distinct influence of the system on the pitch behavior of the canopy proving the successful realization of the concept. This project was a feasibility study in terms of electronic stabilization systems for paragliders. It showed such a system is able to increase the safety of paragliders.},
	journal = {Procedia Engineering},
	author = {Obergruber, Julian and Mehnen, Lars},
	year = {2016},
	note = {Publisher: The Author(s)},
	keywords = {automation, overshoot, paragliding, safety, stabilisation},
	pages = {26--31},
}

@article{liu_que2search_2021,
	title = {{Que2Search} : {Fast} and {Accurate} {Query} and {Document} {Understanding} for {Search} at {Facebook}},
	author = {Liu, Yiqun and Rangadurai, Kaushik and He, Yunzhong and Malreddy, Siddarth and Gui, Xunlong and Liu, Xiaoyi and Borisyuk, Fedor},
	year = {2021},
	note = {ISBN: 9781450383325},
	keywords = {e-commerce, embed-, multi-modal learning, product understanding},
}

@article{naesseth_elements_2019,
	title = {Elements of sequential {Monte} {Carlo}},
	volume = {12},
	issn = {19358245},
	doi = {10.1561/2200000074},
	abstract = {A core problem in statistics and probabilistic machine learning is to compute probability distributions and expectations. This is the fundamental problem of Bayesian statistics and machine learning, which frames all inference as expectations with respect to the posterior distribution. The key challenge is to approximate these intractable expectations. In this tutorial, we review sequential Monte Carlo (SMC), a random-sampling-based class of methods for approximate inference. First, we explain the basics of SMC, discuss practical issues, and review theoretical results. We then examine two of the main user design choices: the proposal distributions and the so called intermediate target distributions. We review recent results on how variational inference and amortization can be used to learn efficient proposals and target distributions. Next, we discuss the SMC estimate of the normalizing constant, how this can be used for pseudo-marginal inference and inference evaluation. Throughout the tutorial we illustrate the use of SMC on various models commonly used in machine learning, such as stochastic recurrent neural networks, probabilistic graphical models, and probabilistic programs.},
	number = {3},
	journal = {Foundations and Trends in Machine Learning},
	author = {Naesseth, Christian A. and Lindsten, Fredrik and Schön, Thomas B.},
	year = {2019},
	note = {arXiv: 1903.04797},
	pages = {187--306},
}

@article{cao_automatic_2017,
	title = {Automatic {Selection} of t-{SNE} {Perplexity}},
	url = {http://arxiv.org/abs/1708.03229},
	abstract = {t-Distributed Stochastic Neighbor Embedding (t-SNE) is one of the most widely used dimensionality reduction methods for data visualization, but it has a perplexity hyperparameter that requires manual selection. In practice, proper tuning of t-SNE perplexity requires users to understand the inner working of the method as well as to have hands-on experience. We propose a model selection objective for t-SNE perplexity that requires negligible extra computation beyond that of the t-SNE itself. We empirically validate that the perplexity settings found by our approach are consistent with preferences elicited from human experts across a number of datasets. The similarities of our approach to Bayesian information criteria (BIC) and minimum description length (MDL) are also analyzed.},
	number = {September},
	author = {Cao, Yanshuai and Wang, Luyu},
	year = {2017},
	note = {arXiv: 1708.03229},
	keywords = {bayesian information criteria, hyperparameter tuning, perplexity, t-sne},
}

@article{eide_finn_2021,
	title = {{FINN} . no {Slates} {Dataset} : {A} new {Sequential} {Dataset} {Logging} {Interactions} , all {Viewed} {Items} and {Click} {Responses} / {No}-{Click} for {Recommender} {Systems}},
	volume = {1},
	doi = {10.1145/3460231.3474607},
	number = {1},
	journal = {Fifteenth ACM Conference on Recommender Systems (RecSys '21), September 27-October 1, 2021, Amsterdam, Netherlands},
	author = {Eide, Simen and Frigessi, Arnoldo and Jenssen, Helge and Leslie, David S. and Rishaug, Joakim and Verrewaere, Sofie},
	year = {2021},
	note = {Publisher: Association for Computing Machinery},
	keywords = {bandit, candidate sampling, item attributes, marketplace data, off-policy, reinforcement learning, search result, slate recommendations, search result, candidate sa},
	pages = {1--5},
}

@article{mladenov_recsim_2021,
	title = {{RecSim} {NG}: {Toward} {Principled} {Uncertainty} {Modeling} for {Recommender} {Ecosystems}},
	url = {http://arxiv.org/abs/2103.08057},
	abstract = {The development of recommender systems that optimize multi-turn interaction with users, and model the interactions of different agents (e.g., users, content providers, vendors) in the recommender ecosystem have drawn increasing attention in recent years. Developing and training models and algorithms for such recommenders can be especially difficult using static datasets, which often fail to offer the types of counterfactual predictions needed to evaluate policies over extended horizons. To address this, we develop RecSim NG, a probabilistic platform for the simulation of multi-agent recommender systems. RecSim NG is a scalable, modular, differentiable simulator implemented in Edward2 and TensorFlow. It offers: a powerful, general probabilistic programming language for agent-behavior specification; tools for probabilistic inference and latent-variable model learning, backed by automatic differentiation and tracing; and a TensorFlow-based runtime for running simulations on accelerated hardware. We describe RecSim NG and illustrate how it can be used to create transparent, configurable, end-to-end models of a recommender ecosystem, complemented by a small set of simple use cases that demonstrate how RecSim NG can help both researchers and practitioners easily develop and train novel algorithms for recommender systems.},
	author = {Mladenov, Martin and Hsu, Chih-Wei and Jain, Vihan and Ie, Eugene and Colby, Christopher and Mayoraz, Nicolas and Pham, Hubert and Tran, Dustin and Vendrov, Ivan and Boutilier, Craig},
	year = {2021},
	note = {arXiv: 2103.08057},
}

@article{edwards_selecting_2020,
	title = {Selecting multiple web adverts: {A} contextual multi-armed bandit with state uncertainty},
	volume = {71},
	issn = {14769360},
	url = {https://doi.org/10.1080/01605682.2018.1546650},
	doi = {10.1080/01605682.2018.1546650},
	abstract = {We present a method to solve the problem of choosing a set of adverts to display to each of a sequence of web users. The objective is to maximise user clicks over time and to do so we must learn about the quality of each advert in an online manner by observing user clicks. We formulate the problem as a novel variant of a contextual combinatorial multi-armed bandit problem. The context takes the form of a probability distribution over the user's latent topic preference, and rewards are a particular nonlinear function of the selected set and the context. These features ensure that optimal sets of adverts are appropriately diverse. We give a flexible solution method which combines submodular optimisation with existing bandit index policies. User state uncertainty creates ambiguity in interpreting user feedback which prohibits exact Bayesian updating, but we give an approximate method that is shown to work well.},
	number = {1},
	journal = {Journal of the Operational Research Society},
	author = {Edwards, James A. and Leslie, David S.},
	year = {2020},
	note = {Publisher: Taylor \& Francis},
	keywords = {Multi-armed bandits, contextual bandits, diverse recommendation, statistical learning},
	pages = {100--116},
}

@book{tagliabue_sigir_2021,
	title = {{SIGIR} 2021 {E}-{Commerce} {Workshop} {Data} {Challenge}},
	volume = {1},
	url = {http://arxiv.org/abs/2104.09423},
	abstract = {The 2021 SIGIR workshop on eCommerce is hosting the Coveo Data Challenge for "In-session prediction for purchase intent and recommendations". The challenge addresses the growing need for reliable predictions within the boundaries of a shopping session, as customer intentions can be different depending on the occasion. The need for efficient procedures for personalization is even clearer if we consider the e-commerce landscape more broadly: outside of giant digital retailers, the constraints of the problem are stricter, due to smaller user bases and the realization that most users are not frequently returning customers. We release a new session-based dataset including more than 30M fine-grained browsing events (product detail, add, purchase), enriched by linguistic behavior (queries made by shoppers, with items clicked and items not clicked after the query) and catalog meta-data (images, text, pricing information). On this dataset, we ask participants to showcase innovative solutions for two open problems: a recommendation task (where a model is shown some events at the start of a session, and it is asked to predict future product interactions); an intent prediction task, where a model is shown a session containing an add-to-cart event, and it is asked to predict whether the item will be bought before the end of the session.},
	publisher = {Association for Computing Machinery},
	author = {Tagliabue, Jacopo and Greco, Ciro and Roy, Jean-Francis and Yu, Bingqing and Chia, Patrick John and Bianchi, Federico and Cassani, Giovanni},
	year = {2021},
	note = {arXiv: 2104.09423
Publication Title: Montreal '21: SIGIR eCom, July, 2021, Montreal,
CA
Issue: 1},
}

@article{jadidinejad_simpsons_2021,
	title = {The {Simpson}'s {Paradox} in the {Offline} {Evaluation} of {Recommendation} {Systems}},
	volume = {1},
	url = {http://arxiv.org/abs/2104.08912},
	doi = {10.1145/xxxxxxx},
	abstract = {Recommendation systems are often evaluated based on user's interactions that were collected from an existing, already deployed recommendation system. In this situation, users only provide feedback on the exposed items and they may not leave feedback on other items since they have not been exposed to them by the deployed system. As a result, the collected feedback dataset that is used to evaluate a new model is influenced by the deployed system, as a form of closed loop feedback. In this paper, we show that the typical offline evaluation of recommender systems suffers from the so-called Simpson's paradox. Simpson's paradox is the name given to a phenomenon observed when a significant trend appears in several different sub-populations of observational data but disappears or is even reversed when these sub-populations are combined together. Our in-depth experiments based on stratified sampling reveal that a very small minority of items that are frequently exposed by the deployed system plays a confounding factor in the offline evaluation of recommendation systems. In addition, we propose a novel evaluation methodology that takes into account the confounder, i.e the deployed system's characteristics. Using the relative comparison of many recommendation models as in the typical offline evaluation of recommender systems, and based on the Kendall rank correlation coefficient, we show that our proposed evaluation methodology exhibits statistically significant improvements of 14\% and 40\% on the examined open loop datasets (Yahoo! and Coat), respectively, in reflecting the true ranking of systems with an open loop (randomised) evaluation in comparison to the standard evaluation.},
	number = {1},
	journal = {ACM Transactions on Information Systems},
	author = {Jadidinejad, Amir H. and Macdonald, Craig and Ounis, Iadh},
	year = {2021},
	note = {arXiv: 2104.08912
Publisher: Association for Computing Machinery},
	keywords = {Offline Evaluation, Simpson's Paradox, Experimenta},
	pages = {1--21},
}

@article{Chen2019,
	title = {Top-k off-policy correction for a reinforce recommender system},
	doi = {10.1145/3289600.3290999},
	abstract = {Industrial recommender systems deal with extremely large action spaces - many millions of items to recommend. Moreover, they need to serve billions of users, who are unique at any point in time, making a complex user state space. Luckily, huge quantities of logged implicit feedback (e.g., user clicks, dwell time) are available for learning. Learning from the logged feedback is however subject to biases caused by only observing feedback on recommendations selected by the previous versions of the recommender. In this work, we present a general recipe of addressing such biases in a production top-K recommender system at YouTube, built with a policy-gradient-based algorithm, i.e. REINFORCE [48]. The contributions of the paper are: (1) scaling REINFORCE to a production recommender system with an action space on the orders of millions; (2) applying off-policy correction to address data biases in learning from logged feedback collected from multiple behavior policies; (3) proposing a novel top-K off-policy correction to account for our policy recommending multiple items at a time; (4) showcasing the value of exploration. We demonstrate the efficacy of our approaches through a series of simulations and multiple live experiments on YouTube.},
	journal = {WSDM 2019 - Proceedings of the 12th ACM International Conference on Web Search and Data Mining},
	author = {Chen, Minmin and Beutel, Alex and Covington, Paul and Jain, Sagar and Belletti, Francois and Chi, Ed H.},
	year = {2019},
	note = {arXiv: 1812.02353
ISBN: 9781450359405},
	pages = {456--464},
}

@inproceedings{Joachims,
	title = {Deep learning with logged bandit feedback},
	url = {http://www.joachims.org/banditnet/},
	abstract = {We propose a new output layer for deep neural networks that permits the use of logged contextual bandit feedback for training. Such contextual bandit feedback can be available in huge quantities (e.g., logs of search engines, recommender systems) at little cost, opening up a path for training deep networks on orders of magnitude more data. To this effect, we propose a counterfactual risk minimization approach for training deep networks using an equivariant empirical risk estima-tor with variance regularization, BanditNet, and show how the resulting objective can be decomposed in a way that allows stochastic gradient descent training. We empirically demonstrate the effectiveness of the method by showing how deep networks-ResNets in particular-can be trained for object recognition without conventionally labeled images.},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Joachims, Thorsten and Swaminathan, Adith and De Rijke, Maarten},
	year = {2018},
}

@book{richard_s_sutton_reinforcement_2018,
	title = {Reinforcement {Learning}: {An} {Introduction}},
	volume = {56},
	abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.},
	author = {Richard S Sutton, Andrew G Barto},
	year = {2018},
	note = {Publication Title: MIT press},
}

@article{McInerney2018,
	title = {Explore, {Exploit}, and {Ex}-plain: {Personalizing} {Explainable} {Recommendations} with {Bandits}},
	url = {https://doi.org/10.1145/3240323.3240354},
	doi = {10.1145/3240323.3240354},
	abstract = {The multi-armed bandit is an important framework for balancing exploration with exploitation in recommendation. Exploitation recommends content (e.g., products, movies, music playlists) with the highest predicted user engagement and has traditionally been the focus of recommender systems. Exploration recommends content with uncertain predicted user engagement for the purpose of gathering more information. The importance of exploration has been recognized in recent years, particularly in settings with new users, new items, non-stationary preferences and attributes. In parallel, explaining recommendations ("recsplanations") is crucial if users are to understand their recommendations. Existing work has looked at bandits and explanations independently. We provide the first method that combines both in a principled manner. In particular, our method is able to jointly (1) learn which explanations each user responds to; (2) learn the best content to recommend for each user; and (3) balance exploration with exploitation to deal with uncertainty. Experiments with historical log data and tests with live production traffic in a large-scale music recommendation service show a significant improvement in user engagement.},
	author = {McInerney, James and Lacker, Benjamin and Hansen, Samantha and Higley, Karl and Bouchard, Hugues and Gruson, Alois and Mehrotra Spotify, Rishabh},
	year = {2018},
	note = {ISBN: 9781450359016},
	keywords = {CCS CONCEPTS • Information systems → Recommender s, Collabo-rative filtering, Reinforcement learning, • Computing methodologies → Causal rea-soning and},
}

@article{Zhao2018,
	title = {Deep {Reinforcement} {Learning} for {List}-wise {Recommendations}},
	doi = {10.1145/nnnnnnn.nnnnnnn},
	abstract = {Recommender systems play a crucial role in mitigating the problem of information overload by suggesting users' personalized items or services. The vast majority of traditional recommender systems consider the recommendation procedure as a static process and make recommendations following a fixed strategy. In this paper, we propose a novel recommender system with the capability of contin-uously improving its strategies during the interactions with users. We model the sequential interactions between users and a recom-mender system as a Markov Decision Process (MDP) and leverage Reinforcement Learning (RL) to automatically learn the optimal strategies via recommending trial-and-error items and receiving re-inforcements of these items from users' feedbacks. In particular, we introduce an online user-agent interacting environment simulator, which can pre-train and evaluate model parameters offline before applying the model online. Moreover, we validate the importance of list-wise recommendations during the interactions between users and agent, and develop a novel approach to incorporate them into the proposed framework LIRD for list-wide recommendations. The experimental results based on a real-world e-commerce dataset demonstrate the effectiveness of the proposed framework.},
	number = {9},
	urldate = {2018-04-25},
	author = {Zhao, Xiangyu and Zhang, Liang and Ding, Zhuoye and Yin, Dawei and Zhao, Yihong and Tang, Jiliang},
	year = {2018},
	note = {Publisher: ACM},
}

@article{gershman_tutorial_2012,
	title = {A tutorial on {Bayesian} nonparametric models},
	volume = {56},
	issn = {00222496},
	url = {http://dx.doi.org/10.1016/j.jmp.2011.08.004},
	doi = {10.1016/j.jmp.2011.08.004},
	abstract = {A key problem in statistical modeling is model selection, that is, how to choose a model at an appropriate level of complexity. This problem appears in many settings, most prominently in choosing the number of clusters in mixture models or the number of factors in factor analysis. In this tutorial, we describe Bayesian nonparametric methods, a class of methods that side-steps this issue by allowing the data to determine the complexity of the model. This tutorial is a high-level introduction to Bayesian nonparametric methods and contains several examples of their application. © 2011 Elsevier Inc.},
	number = {1},
	journal = {Journal of Mathematical Psychology},
	author = {Gershman, Samuel J. and Blei, David M.},
	year = {2012},
	note = {arXiv: 1106.2697
Publisher: Elsevier Inc.},
	keywords = {Bayesian methods, Chinese restaurant process, Indian buffet process},
	pages = {1--12},
}

@article{iey_recsim_2019,
	title = {{RECSIM}: {A} configurable simulation platform for recommender systems},
	issn = {23318422},
	abstract = {We propose RECSIM, a configurable platform for authoring simulation environments for recommender systems (RSs) that naturally supports sequential interaction with users. RECSIM allows the creation of new environments that reflect particular aspects of user behavior and item structure at a level of abstraction well-suited to pushing the limits of current reinforcement learning (RL) and RS techniques in sequential interactive recommendation problems. Environments can be easily configured that vary assumptions about: User preferences and item familiarity; user latent state and its dynamics; and choice models and other user response behavior. We outline how RECSIM offers value to RL and RS researchers and practitioners, and how it can serve as a vehicle for academic-industrial collaboration.},
	journal = {arXiv},
	author = {Iey, Eugene and Hsu, Chih Wei and Mladenov, Martin and Jain, Vihan and Narvekarx, Sanmit and Wang, Jing and Wu, Rui and Boutilier, Craig},
	year = {2019},
	note = {arXiv: 1909.04847},
	pages = {1--23},
}

@article{Lattimore2020,
	title = {Bandit {Algorithms}},
	doi = {10.1017/9781108571401},
	abstract = {After nearly two years since starting to write the blog we have at last completed a first draft of the book, which is to be published by Cambridge University Press. The book is available for free as a PDF and will remain so after publication. We’re grateful to Cambridge for allowing this. Without further ado, here is the link. Although we still have a few things we want to do, the manuscript is sufficiently polished to be useful. Of course we would greatly appreciate any comments you might have, including typos, errors in the proofs, missing references, confusing explanations or anything else you might notice. We will periodically update the book, so it would be helpful if you could quote the revision number on the cover when sending us your comments (banditalgs@gmail.com). The manuscript includes a lot of material not in the blog. The last seven chapters are all new, covering combinatorial (semi-)bandits, non-stationary bandits, ranking, pure exploration, Bayesian methods, Thompson sampling, partial monitoring and an introduction to learning in Markov decision processes. Those chapters that are based on blog posts have been cleaned up and often we have added significant depth. There is a lot of literature that we have not covered. Some of these missing topics are discussed in extreme brevity in the introduction to Part VII. It really is amazing how large the bandit literature has become and we’re sorry not to have found space for everything. The book includes around 250 exercises, some of which have solutions. On average the exercises have been proofread less carefully than the rest of the book, so some caution is advised. The solutions to selected exercises are available here. Finally, we’re very thankful for all the feedback already received, both on the blog and early drafts of the book.},
	journal = {Bandit Algorithms},
	author = {Lattimore, Tor and Szepesvári, Csaba},
	year = {2020},
}

@article{Ie2019,
	title = {Reinforcement learning for slate-based recommender systems: {A} tractable decomposition and practical methodology},
	issn = {23318422},
	url = {http://arxiv.org/abs/1905.12767},
	abstract = {Most practical recommender systems focus on estimating immediate user engagement without considering the long-term effects of recommendations on user behavior. Reinforcement learning (RL) methods offer the potential to optimize recommendations for long-term user engagement. However, since users are often presented with slates of multiple items-which may have interacting effects on user choice-methods are required to deal with the combinatorics of the RL action space. In this work, we address the challenge of making slate-based recommendations to optimize long-term value using RL. Our contributions are three-fold. (i) We develop SLATEQ, a decomposition of value-based temporal-difference and Q-learning that renders RL tractable with slates. Under mild assumptions on user choice behavior, we show that the long-term value (LTV) of a slate can be decomposed into a tractable function of its component item-wise LTVs. (ii) We outline a methodology that leverages existing myopic learning-based recommenders to quickly develop a recommender that handles LTV. (iii) We demonstrate our methods in simulation, and validate the scalability of decomposed TD-learning using SLATEQ in live experiments on YouTube.},
	journal = {arXiv},
	author = {Ie, Eugene and Jain, Vihan and Wang, Jing and Narvekar, Sanmit and Agarwal, Ritesh and Wu, Rui and Cheng, Heng Tze and Lustman, Morgane and Gatto, Vince and Covington, Paul and McFadden, Jim and Chandra, Tushar and Boutilier, Craig},
	month = may,
	year = {2019},
	note = {arXiv: 1905.12767},
	pages = {1--38},
}

@article{Raffel2019,
	title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
	volume = {21},
	issn = {23318422},
	abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.1.},
	journal = {arXiv},
	author = {Transformer, Text-to-text and Raffel, Colin and Roberts, Adam and Liu, Peter J and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Peter, Wei Li and Liu, J.},
	year = {2019},
	note = {arXiv: 1910.10683},
	keywords = {attention-, multi-task learning, natural language processing, transfer learning},
	pages = {1--67},
}

@article{moitra_gaussian_2018,
	title = {Gaussian {Mixture} {Models}},
	doi = {10.1017/9781316882177.008},
	abstract = {A description of Gaussian Mixture Models as applied to instrument classification},
	number = {2},
	journal = {Algorithmic Aspects of Machine Learning},
	author = {Moitra, Ankur},
	year = {2018},
	pages = {107--131},
}

@book{rekabsaz_tripclick_2021,
	title = {{TripClick}: {The} {Log} {Files} of a {Large} {Health} {Web} {Search} {Engine}},
	volume = {1},
	url = {http://arxiv.org/abs/2103.07901},
	abstract = {Click logs are valuable resources for a variety of information retrieval (IR) tasks. This includes query understanding/analysis, as well as learning effective IR models particularly when the models require large amounts of training data. We release a large-scale domain-specific dataset of click logs, obtained from user interactions of the Trip Database health web search engine. Our click log dataset comprises approximately 5.2 million user interactions collected between 2013 and 2020. We use this dataset to create a standard IR evaluation benchmark -- TripClick -- with around 700,000 unique free-text queries and 1.3 million pairs of query-document relevance signals, whose relevance is estimated by two click-through models. As such, the collection is one of the few datasets offering the necessary data richness and scale to train neural IR models with a large amount of parameters, and notably the first in the health domain. Using TripClick, we conduct experiments to evaluate a variety of IR models, showing the benefits of exploiting this data to train neural architectures. In particular, the evaluation results show that the best performing neural IR model significantly improves the performance by a large margin relative to classical IR models, especially for more frequent queries.},
	publisher = {Association for Computing Machinery},
	author = {Rekabsaz, Navid and Lesota, Oleg and Schedl, Markus and Brassey, Jon and Eickhoff, Carsten},
	year = {2021},
	note = {arXiv: 2103.07901
Publication Title: Montreal '21: ACM Special Interest Group on Information Retrieval, July 11, 2021, Montreal, Canada
Issue: 1},
	keywords = {acm reference format, click logs, click logs, collection, health information retriev, collection, health information retrieval, medical informa-, neural ranking models, tion retrieval},
}

@article{eide_bayesian_nodate,
	title = {Bayesian {Sequential} {Slate} {Recommender} {Systems} with {Thompson} {Sampling} {Bandits}},
	author = {Eide, Simen and Leslie, David S and Frigessi, Arnoldo},
	pages = {1--29},
}

@article{Kleinberg2004,
	title = {Using mixture models for collaborative filtering},
	issn = {07349025},
	doi = {10.1145/1007352.1007439},
	abstract = {A collaborative, filtering system at an e-commerce site or similar service uses data about aggregate user behavior to make recommendations tailored to specific user interests. We develop recommendation algorithms with provable performance guarantees in a probabilistic mixture model for collaborative filtering proposed by Hoffman and Puzicha. We identify certain novel parameters of mixture models that are closely connected with the best achievable performance of a recommendation algorithm; we show that for any system in which these parameters are bounded, it is possible to give recommendations whose quality converges to optimal as the amount of data grows. All our bounds depend on a new measure of independence that can be viewed as an L1-analogue of the smallest singular value of a matrix. Using this, we introduce a technique based on generalized pseudoinverse matrices and linear programming for handling sets of high-dimensional vectors. We also show that standard approaches based on L2 spectral methods are not strong enough to yield comparable results, thereby suggesting some inherent limitations of spectral analysis.},
	journal = {Conference Proceedings of the Annual ACM Symposium on Theory of Computing},
	author = {Kleinberg, Jon and Sandler, Mark},
	year = {2004},
	note = {ISBN: 1581138520},
	keywords = {Clustering, Collaborative filtering, Latent class models, Linear programming, Mixture models, Singular value decomposition, Text classification},
	pages = {569--578},
}

@article{puzicha_latent_2014,
	title = {Latent {Class} {Models} for {Collaborative} {Filtering} . {L} a t e n t {Class} {M} o d e l s for {C} o l l a b o r a t i v e {F} i l t e r i n g {Thomas} {Hofmann} and {International} {CS} {Institute} {Institut} fur {Informatik}},
	number = {March},
	author = {Puzicha, Jan and Gmbh, Leanix},
	year = {2014},
}

@article{Cami2019,
	title = {User preferences modeling using dirichlet process mixture model for a content-based recommender system},
	volume = {163},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705118304799},
	doi = {10.1016/j.knosys.2018.09.028},
	abstract = {Recommender systems have been developed to assist users in retrieving relevant resources. Collaborative and content-based filtering are two basic approaches that are used in recommender systems. The former employs the feedback of users with similar interests, while the latter is based on the feature of the selected resources by each user. Recommender systems can consider users’ behavior to more accurately estimate their preferences via a list of recommendations. However, the existing approaches rarely consider both interests and preferences of the users. Also, the dynamic nature of user behavior poses an additional challenge for recommender systems. In this paper, we consider the interactions of each individual user, and analyze them to propose a user model and capture user's interests. We construct the user model based on a Bayesian nonparametric framework, called the Dirichlet Process Mixture Model. The proposed model evolves following the dynamic nature of user behavior to adapt both the user interests and preferences. We implemented the proposed model and evaluated it using both the MovieLens dataset, and a real-world dataset that contains news tweets from five news channels (New York Times, BBC, CNN, Reuters and Associated Press). The experimental results and comparisons with several recently developed approaches show the superiority in accuracy of the proposed approach, and its ability to adapt with user behavior over time.},
	urldate = {2021-04-08},
	journal = {Knowledge-Based Systems},
	author = {Cami, Bagher Rahimpour and Hassanpour, Hamid and Mashayekhi, Hoda},
	month = jan,
	year = {2019},
	note = {Publisher: Elsevier B.V.},
	keywords = {Temporal content-based recommender systems, User behavior modeling, User preferences modeling},
	pages = {644--655},
}

@article{eide_simen_2021,
	title = {Simen eide},
	volume = {2},
	author = {Eide, Simen},
	year = {2021},
	pages = {2021},
}

@article{Kobyzev2020,
	title = {Normalizing {Flows}: {An} {Introduction} and {Review} of {Current} {Methods}},
	issn = {0162-8828},
	doi = {10.1109/tpami.2020.2992934},
	abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kobyzev, Ivan and Prince, Simon and Brubaker, Marcus},
	year = {2020},
	note = {arXiv: 1908.09257},
	pages = {1--1},
}

@article{Liu2020a,
	title = {Variable {Selection} via {Thompson} {Sampling}},
	issn = {23318422},
	abstract = {Thompson sampling is a heuristic algorithm for the multi-armed bandit problem which has a long tradition in machine learning. The algorithm has a Bayesian spirit in the sense that it selects arms based on posterior samples of reward probabilities of each arm. By forging a connection between combinatorial binary bandits and spike-and-slab variable selection, we propose a stochastic optimization approach to subset selection called Thompson Variable Selection (TVS). TVS is a framework for interpretable machine learning which does not rely on the underlying model to be linear. TVS brings together Bayesian reinforcement and machine learning in order to extend the reach of Bayesian subset selection to non-parametric models and large datasets with very many predictors and/or very many observations. Depending on the choice of a reward, TVS can be deployed in offline as well as online setups with streaming data batches. Tailoring multiplay bandits to variable selection, we provide regret bounds without necessarily assuming that the arm mean rewards be unrelated. We show a very strong empirical performance on both simulated and real data. Unlike deterministic optimization methods for spike-and-slab variable selection, the stochastic nature makes TVS less prone to local convergence and thereby more robust.},
	journal = {arXiv},
	author = {Liu, Yi and Ročková, Veronika},
	year = {2020},
	note = {arXiv: 2007.00187},
	keywords = {BART, Combinatorial Bandits, Interpretable Machine Learning, Spike-and-Slab, Thompson Sampling, Variable Selection},
}

@inproceedings{Hu2008,
	title = {Collaborative {Filtering} for {Implicit} {Feedback} {Datasets}},
	isbn = {978-0-7695-3502-9},
	url = {https://www.mendeley.com/import/},
	doi = {10.1109/ICDM.2008.22},
	booktitle = {2008 {Eighth} {IEEE} {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Hu, Yifan and Koren, Yehuda and Volinsky, Chris},
	month = dec,
	year = {2008},
	note = {ISSN: 15504786},
	keywords = {academic research, academic software, academics, bibliography, digital library, library management, library software, reference software, research paper, research tool, researcher},
	pages = {263--272},
}

@article{Blei2011,
	title = {Distance dependent {Chinese} restaurant processes},
	volume = {12},
	issn = {15324435},
	abstract = {We develop the distance dependent Chinese restaurant process, a flxible class of distributions over partitions that allows for dependencies between the elements. This class can be used to model many kinds of dependencies between data in infinit clustering models, including dependencies arising from time, space, and network connectivity. We examine the properties of the distance dependent CRP, discuss its connections to Bayesian nonparametric mixture models, and derive a Gibbs sampler for both fully observed and latent mixture settings. We study its empirical performance with three text corpora. We show that relaxing the assumption of exchangeability with distance dependent CRPs can provide a better fi to sequential data and network data. We also show that the distance dependent CRP representation of the traditional CRP mixture leads to a faster-mixing Gibbs sampling algorithm than the one based on the original formulation. © 2011 David M. Blei and Peter I. Frazier.},
	journal = {Journal of Machine Learning Research},
	author = {Blei, David M. and Frazier, Peter I.},
	year = {2011},
	note = {arXiv: 0910.1022},
	keywords = {Bayesian nonparametrics, Chinese restaurant processes},
	pages = {2461--2488},
}

@article{Li2019a,
	title = {A tutorial on {Dirichlet} process mixture modeling},
	volume = {91},
	issn = {10960880},
	url = {https://doi.org/10.1016/j.jmp.2019.04.004},
	doi = {10.1016/j.jmp.2019.04.004},
	abstract = {Bayesian nonparametric (BNP) models are becoming increasingly important in psychology, both as theoretical models of cognition and as analytic tools. However, existing tutorials tend to be at a level of abstraction largely impenetrable by non-technicians. This tutorial aims to help beginners understand key concepts by working through important but often omitted derivations carefully and explicitly, with a focus on linking the mathematics with a practical computation solution for a Dirichlet Process Mixture Model (DPMM)—one of the most widely used BNP methods. Abstract concepts are made explicit and concrete to non-technical readers by working through the theory that gives rise to them. A publicly accessible computer program written in the statistical language R is explained line-by-line to help readers understand the computation algorithm. The algorithm is also linked to a construction method called the Chinese Restaurant Process in an accessible tutorial in this journal (Gershman and Blei, 2012). The overall goals are to help readers understand more fully the theory and application so that they may apply BNP methods in their own work and leverage the technical details in this tutorial to develop novel methods.},
	journal = {Journal of Mathematical Psychology},
	author = {Li, Yuelin and Schofield, Elizabeth and Gönen, Mithat},
	year = {2019},
	note = {Publisher: Elsevier Inc.},
	keywords = {Bayesian nonparametric, Chinese Restaurant Process, Dirichlet process, Gibbs sampling, Mixture model},
	pages = {128--144},
}

@article{Gong2015,
	title = {Hashtag recommendation using dirichlet process mixture models incorporating types of hashtags},
	doi = {10.18653/v1/d15-1046},
	abstract = {In recent years, the task of recommending hashtags for microblogs has been given increasing attention. Various methods have been proposed to study the problem from different aspects. However, most of the recent studies have not considered the differences in the types or uses of hashtags. In this paper, we introduce a novel nonparametric Bayesian method for this task. Based on the Dirichlet Process Mixture Models (DPMM), we incorporate the type of hashtag as a hidden variable. The results of experiments on the data collected from a real world microblogging service demonstrate that the proposed method outperforms stateof-the-art methods that do not consider these aspects. By taking these aspects into consideration, the relative improvement of the proposed method over the state-of-theart methods is around 12.2\% in Fl-score.},
	journal = {Conference Proceedings - EMNLP 2015: Conference on Empirical Methods in Natural Language Processing},
	author = {Gong, Yeyun and Zhang, Qi and Huang, Xuanjing},
	year = {2015},
	note = {ISBN: 9781941643327},
	pages = {401--410},
}

@article{Hsieh2017,
	title = {Collaborative metric learning},
	doi = {10.1145/3038912.3052639},
	abstract = {Metric learning algorithms produce distance metrics that capture the important relationships among data. In this work, we study the connection between metric learning and collaborative filtering. We propose Collaborative Metric Learning (CML) which learns a joint metric space to encode not only users’ preferences but also the user-user and item-item similarity. The proposed algorithm outperforms state-of-the-art collaborative filtering algorithms on a wide range of recommendation tasks and uncovers the underlying spectrum of users’ fine-grained preferences. CML also achieves significant speedup for Top-K recommendation tasks using off-the-shelf, approximate nearest-neighbor search, with negligible accuracy reduction.},
	journal = {26th International World Wide Web Conference, WWW 2017},
	author = {Hsieh, Cheng Kang and Yang, Longqi and Cui, Yin and Lin, Tsung Yi and Belongie, Serge and Estrin, Deborah},
	year = {2017},
	note = {ISBN: 9781450349130},
	pages = {193--201},
}

@article{Eidea,
	title = {{FINAL} {DRAFT} 15.04: {Bayesian} {Sequential} {Slate} {Recommender} {Systems} with {Thompson} {Sampling} {Bandits}},
	author = {Eide, Simen and Leslie, David S and Frigessi, Arnoldo},
	pages = {1--29},
}

@article{Tran2019,
	title = {Improving collaborative metric learning with efficient negative sampling},
	doi = {10.1145/3331184.3331337},
	abstract = {Distance metric learning based on triplet loss has been applied with success in a wide range of applications such as face recognition, image retrieval, speaker change detection and recently recommendation with the Collaborative Metric Learning (CML) model. However, as we show in this article, CML requires large batches to work reasonably well because of a too simplistic uniform negative sampling strategy for selecting triplets. Due to memory limitations, this makes it difficult to scale in high-dimensional scenarios. To alleviate this problem, we propose here a 2-stage negative sampling strategy which finds triplets that are highly informative for learning. Our strategy allows CML to work effectively in terms of accuracy and popularity bias, even when the batch size is an order of magnitude smaller than what would be needed with the default uniform sampling. We demonstrate the suitability of the proposed strategy for recommendation and exhibit consistent positive results across various datasets.},
	journal = {SIGIR 2019 - Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Tran, Viet Anh and Hennequin, Romain and Royo-Letelier, Jimena and Moussallam, Manuel},
	year = {2019},
	note = {arXiv: 1909.10912
ISBN: 9781450361729},
	keywords = {Collaborative Filtering, Metric Learning, Recommender Systems, Triplet Loss},
	pages = {1201--1204},
}

@article{Zhang2007,
	title = {Efficient bayesian hierarchical user modeling for recommendation system},
	doi = {10.1145/1277741.1277752},
	abstract = {A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user's interest. A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model. Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive. The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications. This paper proposes a new fast learning technique to learn a large number of individual user profiles. The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens. Copyright 2007 ACM.},
	journal = {Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR'07},
	author = {Zhang, Yi and Koren, Jonathan},
	year = {2007},
	note = {ISBN: 1595935975},
	keywords = {Bayesian hierarchical models, EM algorithm, Information filtering, Personalization, Recommender systems},
	pages = {47--54},
}

@article{lu_graph-based_2019,
	title = {Graph-based {Multilingual} {Product} {Retrieval} in {E}-{Commerce} {Search}},
	author = {Lu, Hanqing and Wu, Tony and Yin, Bing},
	year = {2019},
}

@article{Maddox2021,
	title = {Fast {Adaptation} with {Linearized} {Neural} {Networks}},
	volume = {130},
	url = {http://arxiv.org/abs/2103.01439},
	abstract = {The inductive biases of trained neural networks are difficult to understand and, consequently, to adapt to new settings. We study the inductive biases of linearizations of neural networks, which we show to be surprisingly good summaries of the full network functions. Inspired by this finding, we propose a technique for embedding these inductive biases into Gaussian processes through a kernel designed from the Jacobian of the network. In this setting, domain adaptation takes the form of interpretable posterior inference, with accompanying uncertainty estimation. This inference is analytic and free of local optima issues found in standard techniques such as fine-tuning neural network weights to a new task. We develop significant computational speed-ups based on matrix multiplies, including a novel implementation for scalable Fisher vector products. Our experiments on both image classification and regression demonstrate the promise and convenience of this framework for transfer learning, compared to neural network fine-tuning. Code is available at https://github.com/amzn/xfer/tree/master/finite\_ntk.},
	author = {Maddox, Wesley J. and Tang, Shuai and Moreno, Pablo Garcia and Wilson, Andrew Gordon and Damianou, Andreas},
	year = {2021},
	note = {arXiv: 2103.01439},
}

@article{Ma2020,
	title = {Off-policy {Learning} in {Two}-stage {Recommender} {Systems}},
	doi = {10.1145/3366423.3380130},
	abstract = {Many real-world recommender systems need to be highly scalable: matching millions of items with billions of users, with milliseconds latency. The scalability requirement has led to widely used two-stage recommender systems, consisting of efficient candidate generation model(s) in the first stage and a more powerful ranking model in the second stage. Logged user feedback, e.g., user clicks or dwell time, are often used to build both candidate generation and ranking models for recommender systems. While it's easy to collect large amount of such data, they are inherently biased because the feedback can only be observed on items recommended by the previous systems. Recently, off-policy correction on such biases have attracted increasing interest in the field of recommender system research. However, most existing work either assumed that the recommender system is a single-stage system or only studied how to apply off-policy correction to the candidate generation stage of the system without explicitly considering the interactions between the two stages. In this work, we propose a two-stage off-policy policy gradient method, and showcase that ignoring the interaction between the two stages leads to a sub-optimal policy in two-stage recommender systems. The proposed method explicitly takes into account the ranking model when training the candidate generation model, which helps improve the performance of the whole system. We conduct experiments on real-world datasets with large item space and demonstrate the effectiveness of our proposed method.},
	number = {May},
	journal = {The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020},
	author = {Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Yang, Ji and Chen, Minmin and Tang, Jiaxi and Hong, Lichan and Chi, Ed H.},
	year = {2020},
	note = {ISBN: 9781450370233},
	keywords = {Neural Networks, Off-policy Learning, Recommender Systems, Two-stage Systems},
	pages = {463--473},
}

@article{Saito2020,
	title = {A {Large}-scale {Open} {Dataset} for {Bandit} {Algorithms}},
	issn = {23318422},
	abstract = {We build and publicize the Open Bandit Dataset and Pipeline to facilitate scalable and reproducible research on bandit algorithms. They are especially suitable for off-policy evaluation (OPE), which attempts to predict the performance of hypothetical algorithms using data generated by a different algorithm. We construct the dataset based on experiments and implementations on a large-scale fashion e-commerce platform, ZOZOTOWN. The data contain the ground-truth about the performance of several bandit policies and enable the fair comparisons of different OPE estimators. We also provide a pipeline to make its implementation easy and consistent. As a proof of concept, we use the dataset and pipeline to implement and evaluate OPE estimators. First, we find that a well-established estimator fails, suggesting that it is critical to choose an appropriate estimator. We then select a well-performing estimator and use it to improve the platform’s fashion item recommendation. Our analysis succeeds in finding a counterfactual policy that significantly outperforms the historical ones. Our open data and pipeline will allow researchers and practitioners to easily evaluate and compare their bandit algorithms and OPE estimators with others in a large, real-world setting.},
	journal = {arXiv},
	author = {Saito, Yuta and Matsutani, Megumi and Aihara, Shunsuke and Narita, Yusuke},
	year = {2020},
}

@article{Rounce2020,
	title = {Quantifying parameter uncertainty in a large-scale glacier evolution model using {Bayesian} inference: {Application} to {High} {Mountain} {Asia}},
	volume = {66},
	issn = {00221430},
	doi = {10.1017/jog.2019.91},
	abstract = {Abstract The response of glaciers to climate change has major implications for sea-level change and water resources around the globe. Large-scale glacier evolution models are used to project glacier runoff and mass loss, but are constrained by limited observations, which result in models being over-parameterized. Recent systematic geodetic mass-balance observations provide an opportunity to improve the calibration of glacier evolution models. In this study, we develop a calibration scheme for a glacier evolution model using a Bayesian inverse model and geodetic mass-balance observations, which enable us to quantify model parameter uncertainty. The Bayesian model is applied to each glacier in High Mountain Asia using Markov chain Monte Carlo methods. After 10,000 steps, the chains generate a sufficient number of independent samples to estimate the properties of the model parameters from the joint posterior distribution. Their spatial distribution shows a clear orographic effect indicating the resolution of climate data is too coarse to resolve temperature and precipitation at high altitudes. Given the glacier evolution model is over-parameterized, particular attention is given to identifiability and the need for future work to integrate additional observations in order to better constrain the plausible sets of model parameters.},
	number = {256},
	journal = {Journal of Glaciology},
	author = {Rounce, David R. and Khurana, Tushar and Short, Margaret B. and Hock, Regine and Shean, David E. and Brinkerhoff, Douglas J.},
	year = {2020},
	keywords = {High Mountain Asia, Key wordsBayesian model, Markov chain Monte Carlo, glaciers, mass change, parameter uncertainty},
	pages = {175--187},
}

@article{Abdollahpouri2017,
	title = {Controlling popularity bias in learning-to-rank recommendation},
	doi = {10.1145/3109859.3109912},
	abstract = {Many recommendation algorithms su.er from popularity bias in their output: popular items are recommended frequently and less popular ones rarely, if at all. However, less popular, long-tail items are precisely those that are often desirable recommendations. In this paper, we introduce a flexible regularization-based framework to enhance the long-tail coverage of recommendation lists in a learning-to-rank algorithm. We show that regularization provides a tunable mechanism for controlling the trade-off between accuracy and coverage. Moreover, the experimental results using two data sets show that it is possible to improve coverage of long tail items without substantial loss of ranking performance.},
	journal = {RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems},
	author = {Abdollahpouri, Himan and Burke, Robin and Mobasher, Bamshad},
	year = {2017},
	note = {ISBN: 9781450346528},
	keywords = {Coverage, Learning to rank, Long-tail, Recommendation evaluation, Recommender systems},
	pages = {42--46},
}

@article{Simpson2017,
	title = {Penalising model component complexity: {A} principled, practical approach to constructing priors},
	volume = {32},
	issn = {08834237},
	doi = {10.1214/16-STS576},
	abstract = {In this paper, we introduce a new concept for constructing prior distributions. We exploit the natural nested structure inherent to many model components, which defines the model component to be a flexible extension of a base model. Proper priors are defined to penalise the complexity induced by deviating from the simpler base model and are formulated after the input of a user-defined scaling parameter for that model component, both in the univariate and the multivariate case. These priors are invariant to reparameterisations, have a natural connection to Jeffreys' priors, are designed to support Occam's razor and seem to have excellent robustness properties, all which are highly desirable and allow us to use this approach to define default prior distributions. Through examples and theoretical results, we demonstrate the appropriateness of this approach and how it can be applied in various situations.},
	number = {1},
	journal = {Statistical Science},
	author = {Simpson, Daniel and Rue, Håvard and Riebler, Andrea and Martins, Thiago G. and Sørbye, Sigrunn H.},
	year = {2017},
	note = {arXiv: 1403.4630},
	keywords = {Bayesian theory, Disease mapping, Hierarchical models, Information geometry, Interpretable prior distributions, Prior on correlation matrices},
	pages = {1--28},
}

@inproceedings{Salakhutdinov2008,
	address = {New York, New York, USA},
	title = {Bayesian probabilistic matrix factorization using {Markov} chain {Monte} {Carlo}},
	isbn = {978-1-60558-205-4},
	url = {http://portal.acm.org/citation.cfm?doid=1390156.1390267},
	doi = {10.1145/1390156.1390267},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning - {ICML} '08},
	publisher = {ACM Press},
	author = {Salakhutdinov, Ruslan and Mnih, Andriy},
	year = {2008},
	pmid = {1990511},
	note = {arXiv: 1705.05355
ISSN: 1049-5258},
	pages = {880--887},
}

@article{Russo2017,
	title = {A {Tutorial} on {Thompson} {Sampling}},
	volume = {11},
	issn = {1935-8237},
	url = {http://www.nowpublishers.com/article/Details/MAL-070},
	doi = {10.1561/2200000070},
	abstract = {Thompson sampling is an algorithm for online decision problems where actions are taken sequentially in a manner that must balance between exploiting what is known to maximize immediate performance and investing to accumulate new information that may improve future performance. The algorithm addresses a broad range of problems in a computationally efficient manner and is therefore enjoying wide use. This tutorial covers the algorithm and its application, illustrating concepts through a range of examples, including Bernoulli bandit problems, shortest path problems, dynamic pricing, recommendation, active learning with neural networks, and reinforcement learning in Markov decision processes. Most of these problems involve complex information structures, where information revealed by taking an action informs beliefs about other actions. We will also discuss when and why Thompson sampling is or is not effective and relations to alternative algorithms.},
	number = {1},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Russo, Daniel J. and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng},
	year = {2018},
	note = {arXiv: 1707.02038
ISBN: 9781680833683},
	pages = {1--96},
}

@inproceedings{Rendle2009,
	title = {{BPR}: {Bayesian} {Personalized} {Ranking} from {Implicit} {Feedback}},
	url = {https://dl.acm.org/doi/10.5555/1795114.1795167},
	abstract = {Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive k-nearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of per-sonalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion.},
	urldate = {2018-11-12},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	author = {Rendle, Steffen and Freudenthaler, Christoph and Gantner, Zeno and Schmidt-Thieme, Lars},
	year = {2009},
	pages = {452--461},
}

@article{Ludewig2018,
	title = {Evaluation of session-based recommendation algorithms},
	volume = {28},
	issn = {0924-1868},
	url = {http://arxiv.org/abs/1803.09587},
	doi = {10.1007/s11257-018-9209-6},
	abstract = {Recommender systems help users find relevant items of interest, for example on e-commerce or media streaming sites. Most academic research is concerned with approaches that personalize the recommendations according to long-term user profiles. In many real-world applications, however, such long-term profiles often do not exist and recommendations therefore have to be made solely based on the observed behavior of a user during an ongoing session. Given the high practical relevance of the problem, an increased interest in this problem can be observed in recent years, leading to a number of proposals for session-based recommendation algorithms that typically aim to predict the user's immediate next actions. In this work, we present the results of an in-depth performance comparison of a number of such algorithms, using a variety of datasets and evaluation measures. Our comparison includes the most recent approaches based on recurrent neural networks like GRU4REC, factorized Markov model approaches such as FISM or Fossil, as well as more simple methods based, e.g., on nearest neighbor schemes. Our experiments reveal that algorithms of this latter class, despite their sometimes almost trivial nature, often perform equally well or significantly better than today's more complex approaches based on deep neural networks. Our results therefore suggest that there is substantial room for improvement regarding the development of more sophisticated session-based recommendation algorithms.},
	number = {4-5},
	urldate = {2018-08-21},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Ludewig, Malte and Jannach, Dietmar},
	month = dec,
	year = {2018},
	note = {arXiv: 1803.09587},
	pages = {331--390},
}

@misc{criteo,
	title = {Criteo {1TB} {Click} {Logs} dataset},
	url = {https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/},
	author = {{Criteo}},
	year = {2020},
}

@article{Balandat2020,
	title = {{BoTorch}: {A} {Framework} for {Efficient} {Monte}-{Carlo} {Bayesian} {Optimization}},
	volume = {33},
	url = {http://arxiv.org/abs/1910.06403},
	abstract = {Bayesian optimization provides sample-efficient global optimization for a broad range of applications, including automatic machine learning, engineering, physics, and experimental design. We introduce BoTorch, a modern programming framework for Bayesian optimization that combines Monte-Carlo (MC) acquisition functions, a novel sample average approximation optimization approach, auto-differentiation, and variance reduction techniques. BoTorch's modular design facilitates flexible specification and optimization of probabilistic models written in PyTorch, simplifying implementation of new acquisition functions. Our approach is backed by novel theoretical convergence results and made practical by a distinctive algorithmic foundation that leverages fast predictive distributions, hardware acceleration, and deterministic optimization. We also propose a novel "one-shot" formulation of the Knowledge Gradient, enabled by a combination of our theoretical and software contributions. In experiments, we demonstrate the improved sample efficiency of BoTorch relative to other popular libraries.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Balandat, Maximilian and Karrer, Brian and Jiang, Daniel R. and Daulton, Samuel and Letham, Benjamin and Wilson, Andrew Gordon and Bakshy, Eytan},
	month = oct,
	year = {2020},
	note = {arXiv: 1910.06403},
	pages = {21524--21538},
}

@inproceedings{Cho2014,
	address = {Stroudsburg, PA, USA},
	title = {Learning {Phrase} {Representations} using {RNN} {Encoder}–{Decoder} for {Statistical} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1406.1078},
	doi = {10.3115/v1/D14-1179},
	abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
	urldate = {2019-06-05},
	booktitle = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {arXiv: 1406.1078},
	pages = {1724--1734},
}

@inproceedings{Eide2018,
	address = {New York, NY, USA},
	title = {Deep neural network marketplace recommenders in online experiments},
	isbn = {978-1-4503-5901-6},
	url = {https://dl.acm.org/doi/10.1145/3240323.3240387},
	doi = {10.1145/3240323.3240387},
	abstract = {© 2018 Copyright held by the owner/author(s). Recommendations are broadly used in marketplaces to match users with items relevant to their interests and needs. To understand user intent and tailor recommendations to their needs, we use deep learning to explore various heterogeneous data available in marketplaces. This paper focuses on the challenge of measuring recommender performance and summarizes the online experiment results with several promising types of deep neural network recommenders - hybrid item representation models combining features from user engagement and content, sequence-based models, and multi-armed bandit models that optimize user engagement by re-ranking proposals from multiple submodels. The recommenders are currently running in production at the leading Norwegian marketplace FINN.no and serves over one million visitors everyday.},
	booktitle = {Proceedings of the 12th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Eide, Simen and Zhou, Ning},
	month = sep,
	year = {2018},
	keywords = {Deep learning, Marketplace, Recommendation system},
	pages = {387--391},
}

@incollection{Edwards2018,
	title = {Diversity as a {Response} to {User} {Preference} {Uncertainty}},
	url = {https://www.worldscientific.com/doi/abs/10.1142/9781786345400_0004},
	abstract = {JAE: I've not rewritten this. This paper considers the problem of choosing a set of website elements to present to a user. An often desirable property of such a set is that it is diverse, that is that the elements are not all similar to one another. Often this is presented as being a separate objective from that of choosing elements that match the user in some way and which are therefore more likely to clicked. We present a range of simple and intuitive models based on uncertainty about user preferences that show how diversity emerges naturally as a result of seeking to maximise the probability that the user will click on an element. As such we give an argument as to why diversity is desirable which avoids the need for it as a separate objective. The exact model used a↵ects the diversity of sets chosen as well as the likelihood that the user will click on an element.},
	booktitle = {Statistical {Data} {Science}},
	publisher = {WORLD SCIENTIFIC (EUROPE)},
	author = {Edwards, James and Leslie, David},
	month = jul,
	year = {2018},
	doi = {10.1142/9781786345400_0004},
	pages = {55--68},
}

@article{Yi2018,
	title = {Model-based reinforcement learning: {A} survey},
	volume = {2018-Decem},
	issn = {16830040},
	abstract = {Reinforcement learning is an important branch of machine learning and artificial intelligence. Compared with traditional reinforcement learning, model-based reinforcement learning obtains the action of the next state by the model that has been learned, and then optimizes the policy, which greatly improves data efficiency. Based on the present status of research on model-based reinforcement learning at home and abroad, this paper comprehensively reviews the key techniques of model-based reinforcement learning, summarizes the characteristics, advantages and defects of each technology, and analyzes the application of model-based reinforcement learning in games, robotics and brain science.},
	journal = {Proceedings of the International Conference on Electronic Business (ICEB)},
	author = {Yi, Fengji and Fu, Wenlong and Liang, Huan},
	year = {2018},
	note = {arXiv: 2006.16712},
	keywords = {Data efficiency, Dynamic models, Optimizing, Reinforcement learning, Value function approximation},
	pages = {421--429},
}

@article{Xin2020a,
	title = {Self-{Supervised} {Reinforcement} {Learning} for {Recommender} {Systems}},
	doi = {10.1145/3397271.3401147},
	abstract = {In session-based or sequential recommendation, it is important to consider a number of factors like long-term user engagement, multiple types of user-item interactions such as clicks, purchases etc. The current state-of-the-art supervised approaches fail to model them appropriately. Casting sequential recommendation task as a reinforcement learning (RL) problem is a promising direction. A major component of RL approaches is to train the agent through interactions with the environment. However, it is often problematic to train a recommender in an on-line fashion due to the requirement to expose users to irrelevant recommendations. As a result, learning the policy from logged implicit feedback is of vital importance, which is challenging due to the pure off-policy setting and lack of negative rewards (feedback). In this paper, we propose self-supervised reinforcement learning for sequential recommendation tasks. Our approach augments standard recommendation models with two output layers: one for self-supervised learning and the other for RL. The RL part acts as a regularizer to drive the supervised layer focusing on specific rewards (e.g., recommending items which may lead to purchases rather than clicks) while the self-supervised layer with cross-entropy loss provides strong gradient signals for parameter updates. Based on such an approach, we propose two frameworks namely Self-Supervised Q-learning (SQN) and Self-Supervised Actor-Critic (SAC). We integrate the proposed frameworks with four state-of-the-art recommendation models. Experimental results on two real-world datasets demonstrate the effectiveness of our approach.},
	journal = {SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Xin, Xin and Karatzoglou, Alexandros and Arapakis, Ioannis and Jose, Joemon M.},
	year = {2020},
	note = {arXiv: 2006.05779
ISBN: 9781450380164},
	keywords = {Q-learning, reinforcement learning, self-supervised learning, sequential recommendation, session-based recommendation},
	pages = {931--940},
}

@article{VanDenOord2017,
	title = {Neural discrete representation learning},
	volume = {2017-Decem},
	issn = {10495258},
	abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" - where the latents are ignored when they are paired with a powerful autoregressive decoder - typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
	number = {Nips},
	journal = {Advances in Neural Information Processing Systems},
	author = {Van Den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
	year = {2017},
	note = {arXiv: 1711.00937},
	pages = {6307--6316},
}

@article{Sun2019,
	title = {Functional variational {Bayesian} neural networks},
	issn = {23318422},
	abstract = {Variational Bayesian neural networks (BNNs) perform variational inference over weights, but it is difficult to specify meaningful priors and approximate posteriors in a high-dimensional weight space. We introduce functional variational Bayesian neural networks (fBNNs), which maximize an Evidence Lower BOund (ELBO) defined directly on stochastic processes, i.e. distributions over functions. We prove that the KL divergence between stochastic processes equals the supremum of marginal KL divergences over all finite sets of inputs. Based on this, we introduce a practical training objective which approximates the functional ELBO using finite measurement sets and the spectral Stein gradient estimator. With fBNNs, we can specify priors entailing rich structures, including Gaussian processes and implicit stochastic processes. Empirically, we find fBNNs extrapolate well using various structured priors, provide reliable uncertainty estimates, and scale to large datasets.},
	journal = {arXiv},
	author = {Sun, Shengyang and Zhang, Guodong and Shi, Jiaxin and Grosse, Roger},
	year = {2019},
	note = {arXiv: 1903.05779},
	pages = {1--22},
}

@article{Nagabandi2018,
	title = {Neural {Network} {Dynamics} for {Model}-{Based} {Deep} {Reinforcement} {Learning} with {Model}-{Free} {Fine}-{Tuning}},
	issn = {10504729},
	doi = {10.1109/ICRA.2018.8463189},
	abstract = {Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5times on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.},
	journal = {Proceedings - IEEE International Conference on Robotics and Automation},
	author = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S. and Levine, Sergey},
	year = {2018},
	note = {arXiv: 1708.02596
ISBN: 9781538630815},
	pages = {7579--7586},
}

@article{Liu2020,
	title = {Kalman filtering attention for user behavior modeling in {CTR} prediction},
	issn = {23318422},
	abstract = {Click-through rate (CTR) prediction is one of the fundamental tasks for e-commerce search engines. As search becomes more personalized, it is necessary to capture the user interest from rich behavior data. Existing user behavior modeling algorithms develop different attention mechanisms to emphasize query-relevant behaviors and suppress irrelevant ones. Despite being extensively studied, these attentions still suffer from two limitations. First, conventional attentions mostly limit the attention field only to a single user’s behaviors, which is not suitable in e-commerce where users often hunt for new demands that are irrelevant to any historical behaviors. Second, these attentions are usually biased towards frequent behaviors, which is unreasonable since high frequency does not necessarily indicate great importance. To tackle the two limitations, we propose a novel attention mechanism, termed Kalman Filtering Attention (KFAtt), that considers the weighted pooling in attention as a maximum a posteriori (MAP) estimation. By incorporating a priori, KFAtt resorts to global statistics when few user behaviors are relevant. Moreover, a frequency capping mechanism is incorporated to correct the bias towards frequent behaviors. Offline experiments on both benchmark and a 10 billion scale real production dataset, together with an Online A/B test, show that KFAtt outperforms all compared state-of-the-arts. KFAtt has been deployed in the ranking system of JD.com, one of the largest B2C e-commerce websites in China, serving the main traffic of hundreds of millions of active users.},
	number = {NeurIPS},
	journal = {arXiv},
	author = {Liu, Hu and Lu, Jing and Zhao, Xiwei and Xu, Sulong and Peng, Hao and Liu, Yutong and Zhang, Zehua and Li, Jian and Jin, Junsheng and Bao, Yongjun and Yan, Weipeng},
	year = {2020},
	note = {arXiv: 2010.00985},
}

@article{Liang2016c,
	title = {Modeling user exposure in recommendation},
	doi = {10.1145/2872427.2883090},
	abstract = {Collaborative -ltering analyzes user preferences for items (e.g., books, movies, restaurants, academic papers) by exploiting the similarity patterns across users. In implicit feedback settings, all the items, including the ones that a user did not consume, are taken into consideration. But this assumption does not accord with the common sense understanding that users have a limited scope and awareness of items. For example, a user might not have heard of a certain paper, or might live too far away from a restaurant to experience it. In the language of causal analysis [9], the assignment mechanism (i.e., the items that a user is exposed to) is a latent variable that may change for various user/item combinations. In this paper, we propose a new probabilistic approach that directly incorporates user exposure to items into collaborative ffltering. The exposure is modeled as a latent variable and the model infers its value from data. In doing so, we recover one of the most successful state-of-Theart approaches as a special case of our model [8], and provide a plug-in method for conditioning exposure on various forms of exposure covariates (e.g., topics in text, venue locations). We show that our scalable inference algorithm outperforms existing benchmarks in four difierent domains both with and without exposure covariates.},
	journal = {25th International World Wide Web Conference, WWW 2016},
	author = {Liang, Dawen and Charlin, Laurent and McInerney, James and Blei, David M.},
	year = {2016},
	note = {arXiv: 1510.07025
ISBN: 9781450341431},
	keywords = {Collaborative filtering, Matrix factorization, Recommender systems},
	pages = {951--961},
}

@article{gal_improving_nodate,
	title = {Improving {PILCO} with {Bayesian} {Neural} {Network} {Dynamics} {Models}},
	author = {Gal, Yarin and Mcallister, Rowan Thomas and Rasmussen, Carl Edward},
}

@article{kamronn_disentangled_nodate,
	title = {A {Disentangled} {Recognition} and {Nonlinear} {Dynamics} {Model} for {Unsupervised} {Learning}},
	number = {section 5},
	author = {Kamronn, Simon},
	note = {arXiv: 1710.05741v2},
}

@article{Freeman2019,
	title = {Learning to predictwithout looking ahead: world modelswithout forward prediction},
	issn = {23318422},
	abstract = {Much of model-based reinforcement learning involves learning a model of an agent's world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware-e.g., a brain-arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we introduce a modification to traditional reinforcement learning which we call observational dropout, whereby we limit the agents ability to observe the real environment at each timestep. In doing so, we can coerce an agent into learning a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment. Videos of our results available at https://learningtopredict.github.io/.},
	number = {9},
	journal = {arXiv},
	author = {Freeman, C. Daniel and Metz, Luke and Ha, David},
	year = {2019},
	note = {arXiv: 1910.13038},
	pages = {1--17},
}

@article{Chen2014a,
	title = {Stochastic gradient {Hamiltonian} {Monte} {Carlo}},
	volume = {5},
	abstract = {Hamiltonian Monte Carlo (HMC) sampling methods provide a mechanism for defining distant proposals with high acceptance probabilities in a Metropolis-Hastings framework, enabling more efficient exploration of the state space than standard random-walk proposals. The popularity of such methods has grown significantly in recen-t years. However, a limitation of HMC methods is the required gradient computation for simulation of the Hamiltonian dynamical system - such computation is infeasible in problems involving a large sample size or streaming data. Instead, we must rely on a noisy gradient estimate computed from a subset of the data. In this paper, we explore the properties of such a stochastic gradient HMC approach. Surprisingly, the natural implementation of the stochastic approximation can be arbitrarily bad. To address this problem we introduce a variant that uses second-order Langevin dynamics with a friction term that counteracts the effects of the noisy gradient, maintaining the desired target distribution as the invariant distribution. Results on simulated data validate our theory. We also provide an application of our methods to a classification task using neural networks and to online Bayesian matrix factorization.},
	journal = {31st International Conference on Machine Learning, ICML 2014},
	author = {Chen, Tianqi and Fox, Emily B. and Guestrin, Carlos},
	year = {2014},
	note = {arXiv: 1402.4102
ISBN: 9781634393973},
	pages = {3663--3676},
}

@article{Aas2016a,
	title = {The climatic mass balance of {Svalbard} glaciers: {A} 10-year simulation with a coupled atmosphere-glacier mass balance model},
	volume = {10},
	issn = {19940424},
	doi = {10.5194/tc-10-1089-2016},
	abstract = {In this study we simulate the climatic mass balance of Svalbard glaciers with a coupled atmosphere-glacier model with 3 km grid spacing, from September 2003 to September 2013. We find a mean specific net mass balance of -257mmw.e. yr-1, corresponding to a mean annual mass loss of about 8.7 Gt, with large interannual variability. Our results are compared with a comprehensive set of mass balance, meteorological, and satellite measurements. Model temperature biases of 0.19 and -1.9 °C are found at two glacier automatic weather station sites. Simulated climatic mass balance is mostly within about 100mmw.e. yr-1 of stake measurements, and simulated winter accumulation at the Austfonna ice cap shows mean absolute errors of 47 and 67mmw.e. yr-1 when compared to radar-derived values for the selected years 2004 and 2006. Comparison of modeled surface height changes from 2003 to 2008, and satellite altimetry reveals good agreement in both mean values and regional differences. The largest deviations from observations are found for winter accumulation at Hansbreen (up to around 1000mmw.e. yr-1), a site where sub-grid topography and wind redistribution of snow are important factors. Comparison with simulations using 9 km grid spacing reveal considerable differences on regional and local scales. In addition, 3 km grid spacing allows for a much more detailed comparison with observations than what is possible with 9 km grid spacing. Further decreasing the grid spacing to 1 km appears to be less significant, although in general precipitation amounts increase with resolution. Altogether, the model compares well with observations and offers possibilities for studying glacier climatic mass balance on Svalbard both historically as well as based on climate projections.},
	number = {3},
	journal = {Cryosphere},
	author = {Aas, Kjetil S. and Dunse, Thorben and Collier, Emily and Schuler, Thomas V. and Berntsen, Terje K. and Kohler, Jack and Luks, Bartłomiej},
	year = {2016},
	pages = {1089--1104},
}

@article{Finn2016,
	title = {Guided cost learning: {Deep} inverse optimal control via policy optimization},
	volume = {1},
	abstract = {Reinforcement learning can acquire complex behaviors from high-level specifications. However, defining a cost function that can be optimized effectively and encodes the correct task is challenging in practice. We explore how inverse optimal control (IOC) can be used to learn behaviors from demonstrations, with applications to torque control of high-dimensional robotic systems. Our method addresses two key challenges in inverse optimal control: first, the need for informative features and effective regularization to impose structure on the cost, and second, the difficulty of learning the cost function under unknown dynamics for high-dimensional continuous systems. To address the former challenge, we present an algorithm capable of learning arbitrary nonlinear cost functions, such as neural networks, without meticulous feature engineering. To address the latter challenge, we formulate an efficient sample-based approximation for MaxEnt IOC. We evaluate our method on a series of simulated tasks and real-world robotic manipulation problems, demonstrating substantial improvement over prior methods both in terms of task complexity and sample efficiency.},
	journal = {33rd International Conference on Machine Learning, ICML 2016},
	author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
	year = {2016},
	note = {arXiv: 1603.00448
ISBN: 9781510829008},
	pages = {95--107},
}

@article{as_orgnr_2020,
	title = {Org.nr. 919 251 344 mva - arctic datalab as krav på forsinkelsesrenter},
	author = {As, Arctic Datalab},
	year = {2020},
	note = {ISBN: 5876940518},
}

@misc{finn-recsys-slate-dataset,
	title = {{FINN}.no {Recommender} {System} {Slate} {Dataset}},
	url = {https://github.com/finn-no/recsys-slates-dataset},
	author = {Eide, Simen},
	year = {2021},
}

@article{Ying2018a,
	title = {Sequential recommender system based on hierarchical attention network},
	volume = {2018-July},
	issn = {10450823},
	doi = {10.24963/ijcai.2018/546},
	abstract = {With a large amount of user activity data accumulated, it is crucial to exploit user sequential behavior for sequential recommendations. Conventionally, user general taste and recent demand are combined to promote recommendation performances. However, existing methods often neglect that user long-term preference keep evolving over time, and building a static representation for user general taste may not adequately reflect the dynamic characters. Moreover, they integrate user-item or itemitem interactions through a linear way which limits the capability of model. To this end, in this paper, we propose a novel two-layer hierarchical attention network, which takes the above properties into account, to recommend the next item user might be interested. Specifically, the first attention layer learns user long-term preferences based on the historical purchased item representation, while the second one outputs final user representation through coupling user long-term and short-term preferences. The experimental study demonstrates the superiority of our method compared with other state-of-the-art ones.},
	number = {July},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	author = {Ying, Haochao and Zhuang, Fuzhen and Zhang, Fuzheng and Liu, Yanchi and Xu, Guandong and Xie, Xing and Xiong, Hui and Wu, Jian},
	year = {2018},
	note = {ISBN: 9780999241127},
	keywords = {Machine Learning: Data Mining, Multidisciplinary Topics and Applications: Recomme},
	pages = {3926--3932},
}

@article{Mandt2016,
	title = {Variational tempering},
	volume = {41},
	abstract = {Variational inference (VI) combined with data subsampling enables approximate posterior inference over large data sets, but suffers from poor local optima. We first formulate a deterministic annealing approach for the generic class of conditionally conjugate exponential family models. This approach uses a decreasing temperature parameter which deterministically deforms the objective during the course of the optimization. A well-known drawback to this annealing approach is the choice of the cooling schedule. We therefore introduce variational tempering, a variational algorithm that introduces a temperature latent variable to the model. In contrast to related work in the Markov chain Monte Carlo literature, this algorithm results in adaptive annealing schedules. Lastly, we develop local variational tempering, which assigns a latent temperature to each data point; this allows for dynamic annealing that varies across data. Compared to the traditional VI, all proposed approaches find improved predictive likelihoods on held-out data.},
	journal = {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, AISTATS 2016},
	author = {Mandt, Stephan and McInerney, James and Abrol, Farhan and Ranganath, Rajesh and Blei, David},
	year = {2016},
	note = {arXiv: 1411.1810},
	pages = {704--712},
}

@article{Bello,
	title = {{Seq2Slate}: {Re}-ranking and slate optimization with {RNNs}},
	issn = {23318422},
	abstract = {Ranking is a central task in machine learning and information retrieval. In this task, it is especially important to present the user with a slate of items that is appealing as a whole. This in turn requires taking into account interactions between items, since intuitively, placing an item on the slate affects the decision of which other items should be placed alongside it. In this work, we propose a sequence-to-sequence model for ranking called seq2slate. At each step, the model predicts the next “best” item to place on the slate given the items already selected. The sequential nature of the model allows complex dependencies between the items to be captured directly in a flexible and scalable way. We show how to learn the model end-to-end from weak supervision in the form of easily obtained click-through data. We further demonstrate the usefulness of our approach in experiments on standard ranking benchmarks as well as in a real-world recommendation system.},
	urldate = {2019-04-09},
	journal = {arXiv},
	author = {Bello, Irwan and Kulkarni, Sayali and Jain, Sagar and Boutilier, Craig and Chi, Ed and Eban, Elad and Luo, Xiyang and Mackey, Alan},
	year = {2018},
	note = {arXiv: 1810.02019},
}

@book{Chan2009a,
	title = {Quantitative {Trading} - {How} to {Build} {Your} {Own} {Algorithmic} {Trading} {Business}},
	isbn = {978-0-470-28488-9},
	author = {Chan, Ernest P.},
	year = {2009},
}

@book{Sataloff,
	title = {Machine {Trading} - {Deploying} computer algorithms to conquer the markets},
	isbn = {978-1-62623-977-7},
	author = {Chan, Ernest P.},
}

@article{Linden2003,
	title = {Amazon.com recommendations: {Item}-to-item collaborative filtering},
	volume = {7},
	issn = {10897801},
	doi = {10.1109/MIC.2003.1167344},
	abstract = {Recommendation algorithms are best known for their use on e-commerce Web sites. It provides an effective form of targeted marketing by creating a personalized shopping experience for each customer. Amazon.com uses them to personalize the online store for each customer. Most of these algorithms start by finding a set of customers whose purchased and rated items overlap the user's purchased and rated items.},
	number = {1},
	journal = {IEEE Internet Computing},
	author = {Linden, Greg and Smith, Brent and York, Jeremy},
	year = {2003},
	pages = {76--80},
}

@inproceedings{hidasi2016,
	title = {Session-based recommendations with recurrent neural networks},
	abstract = {We apply recurrent neural networks (RNN) on a new domain, namely recommender systems. Real-life recommender systems often face the problem of having to base recommendations only on short session-based data (e.g. a small sportsware website) instead of long user histories (as in the case of Netflix). In this situation the frequently praised matrix factorization approaches are not accurate. This problem is usually overcome in practice by resorting to item-to-item recommendations, i.e. recommending similar items. We argue that by modeling the whole session, more accurate recommendations can be provided. We therefore propose an RNN-based approach for session-based recommendations. Our approach also considers practical aspects of the task and introduces several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem. Experimental results on two data-sets show marked improvements over widely used approaches.},
	booktitle = {4th {International} {Conference} on {Learning} {Representations}, {ICLR} 2016 - {Conference} {Track} {Proceedings}},
	author = {Hidasi, Balázs and Karatzoglou, Alexandros and Baltrunas, Linas and Tikk, Domonkos},
	year = {2016},
	note = {arXiv: 1511.06939},
}

@article{Polson2017,
	title = {Deep learning: {A} {Bayesian} perspective},
	volume = {12},
	issn = {19316690},
	doi = {10.1214/17-BA1082},
	abstract = {Deep learning is a form of machine learning for nonlinear high dimensional pattern matching and prediction. By taking a Bayesian probabilistic perspective, we provide a number of insights into more efficient algorithms for optimisation and hyper-parameter tuning. Traditional high-dimensional data reduction techniques, such as principal component analysis (PCA), partial least squares (PLS), reduced rank regression (RRR), projection pursuit regression (PPR) are all shown to be shallow learners. Their deep learning counterparts exploit multiple deep layers of data reduction which provide predictive performance gains. Stochastic gradient descent (SGD) training optimisation and Dropout (DO) regularization provide estimation and variable selection. Bayesian regularization is central to finding weights and connections in networks to optimize the predictive bias-variance trade-off. To illustrate our methodology, we provide an analysis of international bookings on Airbnb. Finally, we conclude with directions for future research.},
	number = {4},
	journal = {Bayesian Analysis},
	author = {Polson, Nicholas G. and Sokolov, Vadim},
	year = {2017},
	note = {arXiv: 1706.00473},
	keywords = {Artificial Intelligence, Bayesian hierarchical models, Deep learning, LSTM models, Machine learning, Pattern matching, Prediction, TensorFlow},
	pages = {1275--1304},
}

@article{Ie2019a,
	title = {{SLateq}: {A} tractable decomposition for reinforcement learning with recommendation sets},
	volume = {2019-Augus},
	issn = {10450823},
	doi = {10.24963/ijcai.2019/360},
	abstract = {Reinforcement learning (RL) methods for recommender systems optimize recommendations for long-term user engagement. However, since users are often presented with slates of multiple items-which may have interacting effects on user choice-methods are required to deal with the combinatorics of the RL action space. We develop SLATEQ, a decomposition of value-based temporal-difference and Q-learning that renders RL tractable with slates. Under mild assumptions on user choice behavior, we show that the long-term value (LTV) of a slate can be decomposed into a tractable function of its component item-wise LTVs. We demonstrate our methods in simulation, and validate the scalability and effectiveness of decomposed TD-learning on YouTube.},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	author = {Ie, Eugene and Jain, Vihan and Wang, Jing and Narvekar, Sanmit and Agarwal, Ritesh and Wu, Rui and Cheng, Heng Tze and Chandra, Tushar and Boutilier, Craig},
	year = {2019},
	note = {ISBN: 9780999241141},
	pages = {2592--2599},
}

@article{Bottou2013,
	title = {Counterfactual reasoning and learning systems: {The} example of computational advertising},
	volume = {14},
	issn = {15324435},
	abstract = {This work shows how to leverage causal inference to understand the behavior of complex learning systems interacting with their environment and predict the consequences of changes to the system. Such predictions allow both humans and algorithms to select the changes that would have improved the system performance. This work is illustrated by experiments on the ad placement system associated with the Bing search engine. © 2013 Léon Bottou, Jonas Peters, Joaquin Quiñonero-Candela, Denis X. Charles, D. Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard and Ed Snelson.},
	journal = {Journal of Machine Learning Research},
	author = {Bottou, Léon and Peters, Jonas and Quiñonero-Candela, Joaquin and Charles, Denis X. and Chickering, D. Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
	year = {2013},
	keywords = {Causation, Computational advertising, Counterfactual reasoning},
	pages = {3207--3260},
}

@article{Chaney2017,
	title = {How algorithmic confounding in recommendation systems increases homogeneity and decreases utility},
	issn = {23318422},
	doi = {10.1145/3240323.3240370},
	abstract = {Recommendation systems are ubiquitous and impact many domains; they have the potential to infuence product consumption, individuals' perceptions of the world, and life-altering decisions. These systems are often evaluated or trained with data from users already exposed to algorithmic recommendations; this creates a pernicious feedback loop. Using simulations, we demonstrate how using data confounded in this way homogenizes user behavior without increasing utility.},
	journal = {arXiv},
	author = {Chaney, Allison J.B. and Stewart, Brandon M. and Engelhardt, Barbara E.},
	year = {2017},
	note = {arXiv: 1710.11214
ISBN: 9781450359016},
	keywords = {Algorithmic confounding, Recommendation systems},
}

@inproceedings{Guo,
	address = {New York, NY, USA},
	title = {Deep {Bayesian} {Bandits}: {Exploring} in {Online} {Personalized} {Recommendations}},
	isbn = {978-1-4503-7583-2},
	url = {https://arxiv.org/abs/2008.00727},
	doi = {10.1145/3383313.3412214},
	abstract = {Recommender systems trained in a continuous learning fashion are plagued by the feedback loop problem, also known as algorithmic bias. This causes a newly trained model to act greedily and favor items that have already been engaged by users. This behavior is particularly harmful in personalised ads recommendations, as it can also cause new campaigns to remain unexplored. Exploration aims to address this limitation by providing new information about the environment, which encompasses user preference, and can lead to higher long-term reward. In this work, we formulate a display advertising recommender as a contextual bandit and implement exploration techniques that require sampling from the posterior distribution of click-through-rates in a computationally tractable manner. Traditional large-scale deep learning models do not provide uncertainty estimates by default. We approximate these uncertainty measurements of the predictions by employing a bootstrapped model with multiple heads and dropout units. We benchmark a number of different models in an offline simulation environment using a publicly available dataset of user-ads engagements. We test our proposed deep Bayesian bandits algorithm in the offline simulation and online AB setting with large-scale production traffic, where we demonstrate a positive gain of our exploration model.},
	booktitle = {Fourteenth {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Guo, Dalin and Ktena, Sofia Ira and Myana, Pranay Kumar and Huszar, Ferenc and Shi, Wenzhe and Tejani, Alykhan and Kneier, Michael and Das, Sourav},
	month = sep,
	year = {2020},
	note = {arXiv: 2008.00727},
	pages = {456--461},
}

@article{Choi2018,
	title = {Reinforcement {Learning} based {Recommender} {System} using {Biclustering} {Technique}},
	url = {https://doi.org/10.475/123_4},
	abstract = {A recommender system aims to recommend items that a user is interested in among many items. The need for the recommender system has been expanded by the information explosion. Various approaches have been suggested for providing meaningful recommendations to users. One of the proposed approaches is to consider a recommender system as a Markov decision process (MDP) problem and try to solve it using reinforcement learning (RL). However, existing RL-based methods have an obvious drawback. To solve an MDP in a recommender system, they encountered a problem with the large number of discrete actions that bring RL to a larger class of problems. In this paper, we propose a novel RL-based recommender system. We formulate a recommender system as a gridworld game by using a biclustering technique that can reduce the state and action space significantly. Using biclustering not only reduces space but also improves the recommendation quality effectively handling the cold-start problem. In addition, our approach can provide users with some explanation why the system recommends certain items. Lastly, we examine the proposed algorithm on a real-world dataset and achieve a better performance than the widely used recommendation algorithm.},
	urldate = {2018-04-25},
	author = {Choi, Sungwoon and Ha, Heonseok and Hwang, Uiwon and Kim, Chanju and Ha, Jung-Woo and Yoon, Sungroh},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.05532
ISBN: 1234567245},
	keywords = {Biclustering, KEYWORDS Recommender System, Markov Decision Process, Reinforcement Learning},
}

@article{Kula2015,
	title = {Metadata {Embeddings} for {User} and {Item} {Cold}-start {Recommendations}},
	volume = {1448},
	issn = {16130073},
	url = {http://arxiv.org/abs/1507.08439},
	abstract = {I present a hybrid matrix factorisation model representing users and items as linear combinations of their content features' latent factors. The model outperforms both collaborative and content-based models in cold-start or sparse interaction data scenarios (using both user and item metadata), and performs at least as well as a pure collaborative matrix factorisation model where interaction data is abundant. Additionally, feature embeddings produced by the model encode semantic information in a way reminiscent of word embedding approaches, making them useful for a range of related tasks such as tag recommendations.},
	journal = {CEUR Workshop Proceedings},
	author = {Kula, Maciej},
	month = jul,
	year = {2015},
	note = {arXiv: 1507.08439},
	keywords = {Cold-start, Matrix Factorization, Recommender Systems},
	pages = {14--21},
}

@article{Gonen2014a,
	title = {Kernelized {Bayesian} transfer learning},
	volume = {3},
	abstract = {Transfer learning considers related but distinct tasks defined on heterogenous domains and tries to transfer knowledge between these tasks to improve generalization performance. It is particularly useful when we do not have sufficient amount of labeled training data in some tasks, which may be very costly, laborious, or even infeasible to obtain. Instead, learning the tasks jointly enables us to effectively increase the amount of labeled training data. In this paper, we formulate a kernelized Bayesian transfer learning framework that is a principled combination of kernel-based dimensionality reduction models with task-specific projection matrices to find a shared subspace and a coupled classification model for all of the tasks in this subspace. Our two main contributions are: (i) two novel probabilistic models for binary and multiclass classification, and (ii) very efficient variational approximation procedures for these models. We illustrate the generalization performance of our algorithms on two different applications. In computer vision experiments, our method outperforms the state-of-the-art algorithms on nine out of 12 benchmark supervised domain adaptation experiments defined on two object recognition data sets. In cancer biology experiments, we use our algorithm to predict mutation status of important cancer genes from gene expression profiles using two distinct cancer populations, namely, patient-derived primary tumor data and in-vitro-derived cancer cell line data. We show that we can increase our generalization performance on primary tumors using cell lines as an auxiliary data source.},
	number = {2011},
	journal = {Proceedings of the National Conference on Artificial Intelligence},
	author = {Gönen, Mehmet and Margolin, Adam A.},
	year = {2014},
	note = {ISBN: 9781577356790},
	keywords = {Novel Machine Learning Algorithms},
	pages = {1831--1839},
}

@article{Liang2018,
	title = {Variational autoencoders for collaborative filtering},
	doi = {10.1145/3178876.3186150},
	abstract = {We extend variational autoencoders (VAEs) to collaborative filtering for implicit feedback. This non-linear probabilistic model enables us to go beyond the limited modeling capacity of linear factor models which still largely dominate collaborative filtering research.We introduce a generative model with multinomial likelihood and use Bayesian inference for parameter estimation. Despite widespread use in language modeling and economics, the multinomial likelihood receives less attention in the recommender systems literature. We introduce a different regularization parameter for the learning objective, which proves to be crucial for achieving competitive performance. Remarkably, there is an efficient way to tune the parameter using annealing. The resulting model and learning algorithm has information-theoretic connections to maximum entropy discrimination and the information bottleneck principle. Empirically, we show that the proposed approach significantly outperforms several state-of-the-art baselines, including two recently-proposed neural network approaches, on several real-world datasets. We also provide extended experiments comparing the multinomial likelihood with other commonly used likelihood functions in the latent factor collaborative filtering literature and show favorable results. Finally, we identify the pros and cons of employing a principled Bayesian inference approach and characterize settings where it provides the most significant improvements.},
	journal = {The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018},
	author = {Liang, Dawen and Krishnan, Rahul G. and Hoffman, Matthew D. and Jebara, Tony},
	year = {2018},
	note = {arXiv: 1802.05814
ISBN: 9781450356398},
	keywords = {Bayesian models, Collaborative filtering, Implicit feedback, Recommender systems, Variational autoencoder},
	pages = {689--698},
}

@article{Ramachandran2007,
	title = {Bayesian inverse reinforcement learning},
	issn = {10450823},
	abstract = {Inverse Reinforcement Learning (IRL) is the problem of learning the reward function underlying a Markov Decision Process given the dynamics of the system and the behaviour of an expert. IRL is motivated by situations where knowledge of the rewards is a goal by itself (as in preference elicitation) and by the task of apprenticeship learning (learning policies from an expert). In this paper we show how to combine prior knowledge and evidence from the expert's actions to derive a probability distribution over the space of reward functions. We present efficient algorithms that find solutions for the reward learning and apprenticeship learning tasks that generalize well over these distributions. Experimental results show strong improvement for our methods over previous heuristic-based approaches.},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	author = {Ramachandran, Deepak and Amir, Eyal},
	year = {2007},
	keywords = {Markov-decision processes, reinforcement learning},
	pages = {2586--2591},
}

@article{Ritter2018,
	title = {Online structured laplace approximations for overcoming catastrophic forgetting},
	volume = {2018-Decem},
	issn = {10495258},
	abstract = {We introduce the Kronecker factored online Laplace approximation for overcoming catastrophic forgetting in neural networks. The method is grounded in a Bayesian online learning framework, where we recursively approximate the posterior after every task with a Gaussian, leading to a quadratic penalty on changes to the weights. The Laplace approximation requires calculating the Hessian around a mode, which is typically intractable for modern architectures. In order to make our method scalable, we leverage recent block-diagonal Kronecker factored approximations to the curvature. Our algorithm achieves over 90\% test accuracy across a sequence of 50 instantiations of the permuted MNIST dataset, substantially outperforming related methods for overcoming catastrophic forgetting.},
	number = {NeurIPS},
	journal = {Advances in Neural Information Processing Systems},
	author = {Ritter, Hippolyt and Botev, Aleksandar and Barber, David},
	year = {2018},
	note = {arXiv: 1805.07810},
	pages = {3738--3748},
}

@article{Pinder2020,
	title = {Stein {Variational} {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/2009.12141},
	abstract = {We show how to use Stein variational gradient descent (SVGD) to carry out inference in Gaussian process (GP) models with non-Gaussian likelihoods and large data volumes. Markov chain Monte Carlo (MCMC) is extremely computationally intensive for these situations, but the parametric assumptions required for efficient variational inference (VI) result in incorrect inference when they encounter the multi-modal posterior distributions that are common for such models. SVGD provides a non-parametric alternative to variational inference which is substantially faster than MCMC but unhindered by parametric assumptions. We prove that for GP models with Lipschitz gradients the SVGD algorithm monotonically decreases the Kullback-Leibler divergence from the sampling distribution to the true posterior. Our method is demonstrated on benchmark problems in both regression and classification, and a real air quality example with 11440 spatiotemporal observations, showing substantial performance improvements over MCMC and VI.},
	author = {Pinder, Thomas and Nemeth, Christopher and Leslie, David},
	year = {2020},
	note = {arXiv: 2009.12141},
	pages = {1--25},
}

@article{Kirkpatrick2017,
	title = {Overcoming catastrophic forgetting in neural networks},
	volume = {114},
	issn = {10916490},
	doi = {10.1073/pnas.1611835114},
	abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially.},
	number = {13},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
	year = {2017},
	pmid = {28292907},
	note = {arXiv: 1612.00796},
	keywords = {Artificial intelligence, Continual learning, Deep learning, Stability plasticity, Synaptic consolidation},
	pages = {3521--3526},
}

@article{levine_inverse_nodate,
	title = {Inverse {Reinforcement} {Learning} {CS} 285},
	author = {Levine, Instructor Sergey},
}

@article{Jordan1999a,
	title = {Variational {MCMC}},
	author = {{Freitas}},
	year = {1999},
}

@article{agassi_against_2017,
	title = {Against method : {Outline} of an anarchistic theory of knowledge},
	doi = {10.1007/BF02383263},
	number = {August},
	author = {Agassi, Joseph},
	year = {2017},
}

@misc{eide_five_2018,
	title = {Five lessons from building a deep neural network recommender for marketplaces},
	abstract = {Copyright © 2018, arXiv, All rights reserved. Recommendation algorithms are widely adopted in marketplaces to help users find the items they are looking for. The sparsity of the items by user matrix and the cold-start issue in marketplaces pose challenges for the off-the-shelf matrix factorization based recommender systems. To understand user intent and tailor recommendations to their needs, we use deep learning to explore various heterogeneous data available in marketplaces. This paper summarizes five lessons we learned from experimenting with stateof-the-art deep learning recommenders at the leading Norwegian marketplace FINN.no.We design a hybrid recommender system that takes the user-generated content of a marketplace (including text, images and meta attributes) and combines it with user behavior data such as page views and messages to provide recommendations for marketplace items. Among various tactics we experimented with, the following five show the best impact: Staged training instead of end-to-end training, leveraging rich user behaviors beyond page views, using user behaviors as noisy labels to train embeddings, using transfer learning to solve the unbalanced data problem, and using attention mechanisms in the hybrid model. This system is currently running with around 20\% click-through-rate in production at FINN.no and serves over one million visitors everyday.},
	author = {Eide, S. and Øygard, A.M. and Zhou, N.},
	year = {2018},
	note = {Publication Title: arXiv},
	keywords = {Deep learning, Marketplace, Recommender system},
}

@article{Bonner2018,
	title = {Causal embeddings for recommendation},
	doi = {10.1145/3240323.3240360},
	abstract = {Many current applications use recommendations in order to modify the natural user behavior, such as to increase the number of sales or the time spent on a website. This results in a gap between the final recommendation objective and the classical setup where recommendation candidates are evaluated by their coherence with past user behavior, by predicting either the missing entries in the user-item matrix, or the most likely next event. To bridge this gap, we optimize a recommendation policy for the task of increasing the desired outcome versus the organic user behavior. We show this is equivalent to learning to predict recommendation outcomes under a fully random recommendation policy. To this end, we propose a new domain adaptation algorithm that learns from logged data containing outcomes from a biased recommendation policy and predicts recommendation outcomes according to random exposure. We compare our method against state-of-the-art factorization methods, in addition to new approaches of causal recommendation and show significant improvements.},
	journal = {RecSys 2018 - 12th ACM Conference on Recommender Systems},
	author = {Bonner, Stephen and Vasile, Flavian},
	year = {2018},
	note = {arXiv: 1706.07639
ISBN: 9781450359016},
	keywords = {Causality, Counterfactual Inference, Embeddings, Neural Networks, Recommender Systems},
	pages = {104--112},
}

@article{Hoffman2017,
	title = {Learning {Deep} {Latent} {Gaussian} {Models} with {Markov} {Chain} {Monte} {Carlo}},
	author = {Hoffman, Matthew D},
	year = {2017},
}

@article{Vahdat2020,
	title = {{NVAE}: {A} {Deep} {Hierarchical} {Variational} {Autoencoder}},
	url = {http://arxiv.org/abs/2007.03898},
	abstract = {Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ as shown in Fig. 1. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256\${\textbackslash}times\$256 pixels.},
	author = {Vahdat, Arash and Kautz, Jan},
	year = {2020},
	note = {arXiv: 2007.03898},
	pages = {1--20},
}

@article{Zhang2019,
	title = {Cyclical {Stochastic} {Gradient} {MCMC} for {Bayesian} {Deep} {Learning}},
	url = {http://arxiv.org/abs/1902.03932},
	abstract = {The posteriors over neural network weights are high dimensional and multimodal. Each mode typically characterizes a meaningfully different representation of the data. We develop Cyclical Stochastic Gradient MCMC (SG-MCMC) to automatically explore such distributions. In particular, we propose a cyclical stepsize schedule, where larger steps discover new modes, and smaller steps characterize each mode. We also prove non-asymptotic convergence of our proposed algorithm. Moreover, we provide extensive experimental results, including ImageNet, to demonstrate the scalability and effectiveness of cyclical SG-MCMC in learning complex multimodal distributions, especially for fully Bayesian inference with modern deep neural networks.},
	number = {2017},
	author = {Zhang, Ruqi and Li, Chunyuan and Zhang, Jianyi and Chen, Changyou and Wilson, Andrew Gordon},
	year = {2019},
	note = {arXiv: 1902.03932},
	pages = {1--28},
}

@article{Lucas2019,
	title = {Understanding posterior collapse in generative latent variable models},
	abstract = {Posterior collapse in Variational Autoencoders (VAEs) arises when the variational distribution closely matches the uninformative prior for a subset of latent variables. This paper presents a simple and intuitive explanation for posterior collapse through the analysis of linear VAEs and their direct correspondence with Probabilistic PCA (pPCA). We identify how local maxima can emerge from the marginal log-likelihood of pPCA, which yields similar local maxima for the evidence lower bound (ELBO). We show that training a linear VAE with variational inference recovers a uniquely identifiable global maximum corresponding to the principal component directions. We provide empirical evidence that the presence of local maxima causes posterior collapse in non-linear VAEs. Our findings help to explain a wide range of heuristic approaches in the literature that attempt to diminish the effect of the KL term in the ELBO to alleviate posterior collapse.},
	journal = {Deep Generative Models for Highly Structured Data, DGS@ICLR 2019 Workshop},
	author = {Lucas, James and Tucker, George and Grosse, Roger and Norouzi, Mohammad},
	year = {2019},
	pages = {1--16},
}

@techreport{Quadrana2018,
	title = {Sequence-{Aware} {Recommender} {Systems}},
	url = {http://arxiv.org/abs/1802.08452},
	abstract = {Recommender systems are one of the most successful applications of data mining and machine learning technology in practice. Academic research in the field is historically often based on the matrix completion problem formulation, where for each user-item-pair only one interaction (e.g., a rating) is considered. In many application domains, however, multiple user-item interactions of different types can be recorded over time. And, a number of recent works have shown that this information can be used to build richer individual user models and to discover additional behavioral patterns that can be leveraged in the recommendation process. In this work we review existing works that consider information from such sequentially-ordered user- item interaction logs in the recommendation process. Based on this review, we propose a categorization of the corresponding recommendation tasks and goals, summarize existing algorithmic solutions, discuss methodological approaches when benchmarking what we call sequence-aware recommender systems, and outline open challenges in the area.},
	urldate = {2018-12-16},
	author = {Quadrana, Massimo and Cremonesi, Paolo and Jannach, Dietmar},
	year = {2018},
	note = {arXiv: 1802.08452},
	keywords = {Additional Key Words and Phrases: sequence, sessio, CCS Concepts: • Information systems → Recommender, Collaborative filtering, • Computing methodologies → Learning from implicit},
}

@article{Resources2016,
	title = {{TOWARDS} {AN} {IMPROVED} {EUROPEAN} {AUXILIARY} {MATRIX} {FOR} {ASSESSING}},
	number = {October},
	author = {Resources, Norwegian Water and Directorate, Energy and Mitterer, Christoph},
	year = {2016},
	pages = {1--4},
}

@article{Shi2018,
	title = {Gradient {Boosting} {With} {Piece}-{Wise} {Linear} {Regression} {Trees}},
	abstract = {Gradient boosting using decision trees as base learners, so called Gradient Boosted Decision Trees (GBDT), is a very successful ensemble learning algorithm widely used across a variety of applications. Recently, various GDBT construction algorithms and implementation have been designed and heavily optimized in some very popular open sourced toolkits such as XGBoost and LightGBM. In this paper, we show that both the accuracy and efficiency of GBDT can be further enhanced by using more complex base learners. Specifically, we extend gradient boosting to use piecewise linear regression trees (PL Trees), instead of piecewise constant regression trees. We show PL Trees can accelerate convergence of GBDT. Moreover, our new algorithm fits better to modern computer architectures with powerful Single Instruction Multiple Data (SIMD) parallelism. We propose optimization techniques to speedup our algorithm. The experimental results show that GBDT with PL Trees can provide very competitive testing accuracy with comparable or less training time. Our algorithm also produces much concise tree ensembles, thus can often reduce testing time costs.},
	author = {Shi, Yu and Li, Jian and Li, Zhize},
	year = {2018},
	note = {arXiv: 1802.05640},
}

@techreport{Akaike,
	title = {On the {Likelihood} of a {Time} {Series} {Model}},
	urldate = {2019-04-08},
	author = {Akaike, Hirotugu},
	note = {Publication Title: Source: Journal of the Royal Statistical Society. Series D (The Statistician)
Volume: 27
Issue: 4},
	pages = {217--235},
}

@article{Ngaffo2020,
	title = {A {Bayesian} {Inference} {Based} {Hybrid} {Recommender} {System}},
	volume = {8},
	issn = {21693536},
	doi = {10.1109/ACCESS.2020.2998824},
	abstract = {The large mass of various products/services accessible on the Internet has motivated the development of recommender systems to refine the selection of items aligned with users' expectations. Recommender systems have been developed to tackle the item targeting problem. They are crucial tools that quickly target items fitting users' needs, thus allowing them to easily identify the items that fit their tastes and preferences. Following state-of-the-art methods, a distinction is made between content-based recommender approaches and collaborative filtering-based recommender approaches. Collaborative filtering-based recommender approaches are the most widely adopted methods. They are divided into memory-based methods that show the advantage of their easy-understandability, and model-based methods that are data sparsity resilient and high-accurate. In this paper, we propose a hybrid model-based recommendation approach, a combination of a user-based approach and an item-based approach. Our method estimates the probability with which a user would rate an item. It performs a Bayesian inference of future end-user interests and shows the advantage of the easy-understandability of memory-based methods and the effectiveness of model-based methods. Experiments are conducted on real-world datasets and show that our method outperforms several state-of-the-art recommendation methods regarding the prediction accuracy and the recommendation quality.},
	journal = {IEEE Access},
	author = {Ngaffo, Armielle Noulapeu and Ayeb, Walid El and Choukair, Zied},
	year = {2020},
	keywords = {Bayesian inference, Dirichlet distribution, collaborative filtering, maximum a posteriori estimation, recommender system},
	pages = {101682--101701},
}

@article{Park2013,
	title = {Hierarchical {Bayesian} matrix factorization with side information},
	issn = {10450823},
	abstract = {Bayesian treatment of matrix factorization has been successfully applied to the problem of collaborative prediction, where unknown ratings are determined by the predictive distribution, inferring posterior distributions over user and item factor matrices that are used to approximate the user-item matrix as their product. In practice, however, Bayesian matrix factorization suffers from cold-start problems, where inferences are required for users or items about which a sufficient number of ratings are not gathered. In this paper we present a method for Bayesian matrix factorization with side information, to handle cold-start problems. To this end, we place Gaussian-Wishart priors on mean vectors and precision matrices of Gaussian user and item factor matrices, such that mean of each prior distribution is regressed on corresponding side information. We develop variational inference algorithms to approximately compute posterior distributions over user and item factor matrices. In addition, we provide Bayesian Cramér-Rao Bound for our model, showing that the hierarchical Bayesian matrix factorization with side information improves the reconstruction over the standard Bayesian matrix factorization where the side information is not used. Experiments on MovieLens data demonstrate the useful behavior of our model in the case of cold-start problems.},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	author = {Park, Sunho and Kim, Yong Deok and Choi, Seungjin},
	year = {2013},
	note = {ISBN: 9781577356332},
	keywords = {Machine Learning},
	pages = {1593--1599},
}

@article{Okada2019,
	title = {Variational {Inference} {MPC} for {Bayesian} {Model}-based {Reinforcement} {Learning}},
	number = {CoRL},
	author = {Okada, Masashi},
	year = {2019},
	note = {arXiv: 1907.04202v2},
	keywords = {model predictive control, model-based rein-, variational inference},
	pages = {1--15},
}

@article{Ghavamzadeh2016,
	title = {Bayesian {Reinforcement} {Learning}: {A} {Survey}},
	url = {http://arxiv.org/abs/1609.04436},
	doi = {10.1561/2200000049},
	abstract = {Bayesian methods for machine learning have been widely investigated, yielding principled methods for incorporating prior information into inference algorithms. In this survey, we provide an in-depth review of the role of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian reasoning in RL are: 1) it provides an elegant approach to action-selection (exploration/exploitation) as a function of the uncertainty in learning; and 2) it provides a machinery to incorporate prior knowledge into the algorithms. We first discuss models and methods for Bayesian inference in the simple single-step Bandit model. We then review the extensive recent literature on Bayesian methods for model-based RL, where prior information can be expressed on the parameters of the Markov model. We also present Bayesian methods for model-free RL, where priors are expressed over the value function or policy class. The objective of the paper is to provide a comprehensive survey on Bayesian RL algorithms and their theoretical and empirical properties.},
	urldate = {2019-05-04},
	author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.04436},
}

@techreport{Leslie2019,
	title = {Building blocks of reinforcement learning: teaching notes},
	abstract = {Caveat: These are notes used to teach from. They are neither carefully constructed nor comprehensive. These notes were the backbone of a day-long session with objective to introduce people to the basic building blocks of reinforcement learning. This was the theory part, while Jupyter notebooks were provided to help people experiment with the methods. The standard start-point for RL is Sutton and Barto (1998). 1 Basic bandit algorithms At each time t ∈ N a decision-maker selects an action/arm a t in a finite set A, then receives a reward R t ∼ ν at with expected value r(a t). Rewards are independent across time steps, and all rewards from action a are identically distributed (ie no temporal dependence). The decision-maker does not know ν a or r(a) in advance. The objective is to maximise the cumulative reward. It is necessary for the decision-maker to trade off exploring, to find out information about the reward distributions, with explointing, selecting actions which are known to perform well in order to gain reward. This is a fundamental problem in all online learning/acting frameworks, and the bandit problem is a simple framework in which to investigate the explore-exploit dilemna. At time t, a natural estimator of r(a) is the average reward received so far when action a has been played. Let N t (a) = t s=1 I as=a denote the number of times action a has been played up to time t, and let Q t (a) = N t (a) −1 t s=1 I at=a R t be the average reward. (Probably) every policy discussed here will use the Q t (a) values to select an action at time t + 1. Note that these can be maintained in an online fashion, so that the full history need not be retained: basic algebraic manipulations show that Q t (a) = Q t−1 (a) + I at=a 1 N t (a) \{R t − Q t−1 (a)\}. A very poor policy is the greedy policy, for which a t+1 ∈ argmax a Q t (a). This policy performs no exploration at all, and if the optimal action happens to give a poor reward on the first try it may never get selected ever again. A slight improvement is the-greedy algorithm, which on each time step selects the greedy action with probability 1 − , and otherwise selects an action uniformly at random.-greedy carries out sufficient exploration to ensure that eventually the greedy action is indeed the optimal action (i.e. argmax a r(a)). However there is always a fixed probability of playing an arbitrary suboptimal action, so action selection can never converge to the optimal.},
	author = {Leslie, David S},
	year = {2019},
}

@article{Ekeli,
	title = {Ytringsfrihet og terrorisme {Bør} liberale demokratier forby oppfordringer til terrorisme? {Selv} om det finnes interessante argumenter for å forby slike oppfordringer, argumenterer forfatte-ren i denne artikkelen mot et forbud},
	issn = {0029-1943},
	author = {Ekeli, Kristian Skagen},
}

@article{Blundell2015,
	title = {Weight uncertainty in neural networks},
	volume = {2},
	abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
	journal = {32nd International Conference on Machine Learning, ICML 2015},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	year = {2015},
	note = {arXiv: 1505.05424
ISBN: 9781510810587},
	pages = {1613--1622},
}

@article{Wingate2013a,
	title = {Automated {Variational} {Inference} in {Probabilistic} {Programming}},
	url = {http://arxiv.org/abs/1301.1299},
	abstract = {We present a new algorithm for approximate inference in probabilistic programs, based on a stochastic gradient for variational programs. This method is efficient without restrictions on the probabilistic program; it is particularly practical for distributions which are not analytically tractable, including highly structured distributions that arise in probabilistic programs. We show how to automatically derive mean-field probabilistic programs and optimize them, and demonstrate that our perspective improves inference efficiency over other algorithms.},
	author = {Wingate, David and Weber, Theophane},
	year = {2013},
	note = {arXiv: 1301.1299},
	pages = {1--7},
}

@article{Bingham2018,
	title = {Pyro: {Deep} universal probabilistic programming},
	volume = {20},
	issn = {15337928},
	abstract = {Pyro is a probabilistic programming language built on Python as a platform for developing advanced probabilistic models in AI research. To scale to large data sets and high-dimensional models, Pyro uses stochastic variational inference algorithms and probability distributions built on top of PyTorch, a modern GPU-accelerated deep learning framework. To accommodate complex or model-specific algorithmic behavior, Pyro leverages Poutine, a library of composable building blocks for modifying the behavior of probabilistic programs.},
	number = {Xxxx},
	journal = {Journal of Machine Learning Research},
	author = {Bingham, Eli and Chen, Jonathan P. and Jankowiak, Martin and Obermeyer, F. and Pradhan, Neeraj and Karaletsos, Theofanis and Singh, Rohit and Szerlip, Paul and Horsfall, Paul and Goodman, Noah D.},
	year = {2018},
	note = {arXiv: 1810.09538},
	keywords = {Approximate Bayesian inference, Deep learning, Generative models, Graphical models, Probabilistic programming},
	pages = {0--5},
}

@article{Dacrema2019,
	title = {Are {We} {Really} {Making} {Much} {Progress}? {A} {Worrying} {Analysis} of {Recent} {Neural} {Recommendation} {Approaches}},
	url = {http://arxiv.org/abs/1907.06902},
	doi = {10.1145/3298689.3347058},
	abstract = {Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general, it has, as a result, become difficult to keep track of what represents the state-of-the-art at the moment, e.g., for top-n recommendation tasks. At the same time, several recent publications point out problems in today's research practice in applied machine learning, e.g., in terms of the reproducibility of the results or the choice of the baselines when proposing new models. In this work, we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifically, we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable effort. For these methods, it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods, e.g., based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall, our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientific practices in this area. Source code of our experiments and full results are available at: https://github.com/MaurizioFD/RecSys2019\_DeepLearning\_Evaluation.},
	author = {Dacrema, Maurizio Ferrari and Cremonesi, Paolo and Jannach, Dietmar},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.06902},
}

@techreport{Li,
	title = {Online {Learning} to {Rank} with {Features}},
	abstract = {We introduce a new model for online ranking in which the click probability factors into an examination and attractiveness function and the attractiveness function is a linear function of a feature vector and an unknown parameter. Only relatively mild assumptions are made on the examination function. A novel algorithm for this setup is analysed , showing that the dependence on the number of items is replaced by a dependence on the dimension , allowing the new algorithm to handle a large number of items. When reduced to the orthogonal case, the regret of the algorithm improves on the state-of-the-art.},
	urldate = {2019-06-21},
	author = {Li, Shuai and Lattimore, Tor and Szepesvári, Csaba},
	note = {arXiv: 1810.02567v2
ISBN: 1810.02567v2},
}

@article{Zhao,
	title = {Model-{Based} {Reinforcement} {Learning} for {Whole}-{Chain} {Recommendations}},
	url = {https://doi.org/10.1145/3219819.3219886},
	doi = {10.1145/3219819.3219886},
	abstract = {With the recent prevalence of Reinforcement Learning (RL), there have been tremendous interests in developing RL-based recom-mender systems, which enjoy two major advantages-(i) they can continuously improve their recommendation strategies based on users' real-time feedback, and (ii) the optimal recommendation strategies aim to maximize the cumulative reward from users in the long run, e.g., the total revenue of a recommendation session. In practical recommendation sessions, users will sequentially access multiple scenarios, such as the entrance pages and the item detail pages, and each scenario has its own recommendation strategy. However, the majority of existing RL-based recommender systems focus on separately optimizing each strategy, which could lead to sub-optimal overall performance, because independently optimizing each scenario (i) overlooks the sequential correlation among scenarios, (ii) ignores users' behavior data from other scenarios, and (iii) only optimizes its own objective but neglects the overall objective of a session. Therefore, in this paper, we study the recommendation problem with multiple (consecutive) scenarios, i.e., whole-chain recommendations. We propose a multi-agent reinforcement learning based approach (DeepChain), which can capture the sequential correlation among different scenarios and jointly optimize multiple recommendation strategies. To be specific, all recommender agents share the same memory of users' historical behaviors, and they work collaboratively to maximize the overall reward of a session. Note that optimizing multiple recommendation strategies jointly faces two challenges-(i) it requires huge amounts of user behavior data, and (ii) the distribution of reward (users' feedback) are extremely unbalanced. In this paper, we introduce model-based reinforcement learning techniques to reduce the training data requirement and execute more accurate strategy updates. The experimental results based on data from a real e-commerce platform demonstrate the effectiveness of the proposed framework.},
	urldate = {2019-04-09},
	author = {Zhao, Xiangyu and Xia, Long and Zhao, Yihong and Yin, Dawei and Tang, Jiliang},
	note = {arXiv: 1902.03987v1
Publisher: ACM
ISBN: 9781450355520},
	pages = {10},
}

@article{Hron2020,
	title = {Exact posterior distributions of wide {Bayesian} neural networks},
	url = {http://arxiv.org/abs/2006.10541},
	abstract = {Recent work has shown that the prior over functions induced by a deep Bayesian neural network (BNN) behaves as a Gaussian process (GP) as the width of all layers becomes large. However, many BNN applications are concerned with the BNN function space posterior. While some empirical evidence of the posterior convergence was provided in the original works of Neal (1996) and Matthews et al. (2018), it is limited to small datasets or architectures due to the notorious difficulty of obtaining and verifying exactness of BNN posterior approximations. We provide the missing theoretical proof that the exact BNN posterior converges (weakly) to the one induced by the GP limit of the prior. For empirical validation, we show how to generate exact samples from a finite BNN on a small dataset via rejection sampling.},
	author = {Hron, Jiri and Bahri, Yasaman and Novak, Roman and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
	year = {2020},
	note = {arXiv: 2006.10541},
}

@techreport{Neumann,
	title = {{THEORY} {OF} {GAMES} {AND} {ECONOMIC} {BEHAVIOR}},
	author = {Neumann, John Yon and Princeton, Oskar Morgenstern},
}

@article{Gopalan2013,
	title = {Scalable {Recommendation} with {Poisson} {Factorization}},
	issn = {01451707},
	doi = {10.1002/jae},
	abstract = {We develop a Bayesian Poisson matrix factorization model for forming recommendations from sparse user behavior data. These data are large user/item matrices where each user has provided feedback on only a small subset of items, ei- ther explicitly (e.g., through star ratings) or implicitly (e.g., through views or purchases). In contrast to traditional matrix factorization approaches, Poisson factorization implicitly models each user's limited attention to consume items. Moreover, because of the mathematical form of the Poisson likelihood, the model needs only to explicitly consider the observed entries in the matrix, leading to both scalable computation and good predictive performance. We develop a variational inference algorithm for approximate posterior inference that scales up to massive data sets. This is an efficient algorithm that iterates over the observed entries and adjusts an approximate posterior over the user/item representations. We apply our method to large real-world user data containing users rating movies, users listening to songs, and users reading scientific papers. In all these settings, Bayesian Poisson factorization outperforms state-of-the-art matrix factorization methods.},
	journal = {arXiv preprint},
	author = {Gopalan, Prem and Hofman, Jake M and Blei, David M},
	year = {2013},
	pmid = {15003161},
	note = {arXiv: 1311.1704v2
ISBN: 9780000000002},
	pages = {1--10},
}

@article{Li2019,
	title = {{HHMF}: hidden hierarchical matrix factorization for recommender systems},
	volume = {33},
	issn = {1573756X},
	url = {https://doi.org/10.1007/s10618-019-00632-4},
	doi = {10.1007/s10618-019-00632-4},
	abstract = {Matrix factorization (MF) is one of the most powerful techniques used in recommender systems. MF models the (user, item) interactions behind historical explicit or implicit ratings. Standard MF does not capture the hierarchical structural correlations, such as publisher and advertiser in advertisement recommender systems, or the taxonomy (e.g., tracks, albums, artists, genres) in music recommender systems. There are a few hierarchical MF approaches, but they require the hierarchical structures to be known beforehand. In this paper, we propose a Hidden Hierarchical Matrix Factorization (HHMF) technique, which learns the hidden hierarchical structure from the user-item rating records. HHMF does not require the prior knowledge of hierarchical structure; hence, as opposed to existing hierarchical MF methods, HHMF can be applied when this information is either explicit or implicit. According to our extensive experiments, HHMF outperforms existing methods, demonstrating that the discovery of latent hierarchical structures indeed improves the quality of recommendation.},
	number = {6},
	journal = {Data Mining and Knowledge Discovery},
	author = {Li, Hui and Liu, Yu and Qian, Yuqiu and Mamoulis, Nikos and Tu, Wenting and Cheung, David W.},
	year = {2019},
	note = {Publisher: Springer US},
	keywords = {Collaborative filtering, Hierarchical matrix factorization, Recommender systems},
	pages = {1548--1582},
}

@article{Jun2014,
	title = {The possibility of using search traffic information to explore consumer product attitudes and forecast consumer preference},
	volume = {86},
	issn = {00401625},
	url = {http://dx.doi.org/10.1016/j.techfore.2013.10.021},
	doi = {10.1016/j.techfore.2013.10.021},
	abstract = {In recent years, many researchers have devoted their attention to using search traffic information gathered from Google Insights to carry out consumer attitude research. The purpose of this study is to assess the effectiveness of using search traffic information to analyze actual consumer attitudes regarding a product. By comparing the results of conventional survey-based attitude research with the results of search traffic information, this study reveals that search traffic information indicates consumers' level of interest regarding a product, the product attributes that they are considering, and the importance of each attribute to them. Also, it demonstrates the potential benefits of search traffic analysis, which can be useful for forecasting consumer preferences regarding products. Focusing on the Prius, a hybrid car, this study shows that search traffic information serves as an accurate indicator of consumer attitudes, and even succeeds in identifying consumers' hidden attitudes toward the Prius, which can be explained by cognitive dissonance theory. Finally, this study utilizes search traffic information to forecast changes in consumer attitudes and to develop an econometric model of consumer demand for the Prius by incorporating environmental variables such as the WTI (West Texas Intermediate) price. This study concludes that search traffic information offers new potential advantages, in that it not only overcomes the limitations imposed by the high cost of conducting surveys, in terms of money and time, but also helps to reduce the distortions caused by conscious or unconscious errors committed by survey respondents. © 2013 Elsevier Inc.},
	journal = {Technological Forecasting and Social Change},
	author = {Jun, Seung Pyo and Park, Do Hyung and Yeom, Jaeho},
	year = {2014},
	note = {Publisher: Elsevier Inc.},
	keywords = {Attribute in selection, Big data, Consumer attitude, Consumer search index, Demand forecasting, Google Insights, Search traffic},
	pages = {237--253},
}

@article{Daian2019,
	title = {Flash {Boys} 2.0: {Frontrunning}, {Transaction} {Reordering}, and {Consensus} {Instability} in {Decentralized} {Exchanges}},
	url = {http://arxiv.org/abs/1904.05234},
	abstract = {Blockchains, and specifically smart contracts, have promised to create fair and transparent trading ecosystems. Unfortunately, we show that this promise has not been met. We document and quantify the widespread and rising deployment of arbitrage bots in blockchain systems, specifically in decentralized exchanges (or "DEXes"). Like high-frequency traders on Wall Street, these bots exploit inefficiencies in DEXes, paying high transaction fees and optimizing network latency to frontrun, i.e., anticipate and exploit, ordinary users' DEX trades. We study the breadth of DEX arbitrage bots in a subset of transactions that yield quantifiable revenue to these bots. We also study bots' profit-making strategies, with a focus on blockchain-specific elements. We observe bots engage in what we call priority gas auctions (PGAs), competitively bidding up transaction fees in order to obtain priority ordering, i.e., early block position and execution, for their transactions. PGAs present an interesting and complex new continuous-time, partial-information, game-theoretic model that we formalize and study. We release an interactive web portal, http://frontrun.me/, to provide the community with real-time data on PGAs. We additionally show that high fees paid for priority transaction ordering poses a systemic risk to consensus-layer security. We explain that such fees are just one form of a general phenomenon in DEXes and beyond---what we call miner extractable value (MEV)---that poses concrete, measurable, consensus-layer security risks. We show empirically that MEV poses a realistic threat to Ethereum today. Our work highlights the large, complex risks created by transaction-ordering dependencies in smart contracts and the ways in which traditional forms of financial-market exploitation are adapting to and penetrating blockchain economies.},
	author = {Daian, Philip and Goldfeder, Steven and Kell, Tyler and Li, Yunqi and Zhao, Xueyuan and Bentov, Iddo and Breidenbach, Lorenz and Juels, Ari},
	year = {2019},
	note = {arXiv: 1904.05234},
}

@article{Turner2011,
	title = {Two problems with variational expectation maximisation for time series models},
	volume = {9780521196},
	doi = {10.1017/CBO9780511984679.006},
	abstract = {Variational methods are a key component of the approximate inference and learning toolbox. These methods fill an important middle ground, retaining distributional information about uncertainty in latent variables, unlike maximum a posteriori methods, and yet generally requiring less computational time than Markov chain Monte Carlo methods. In particular the variational expectation maximisation (vEM) and variational Bayes algorithms, both involving variational optimisation of a free-energy, are widely used in time series modelling. Here, we investigate the success of vEM in simple probabilistic time series models. First we consider the inference step of vEM, and show that a consequence of the well-known compactness property of variational inference is a failure to propagate uncertainty in time, thus limiting the usefulness of the retained distributional information. In particular, the uncertainty may appear to be smallest precisely when the approximation is poorest. Second, we consider parameter learning and analytically reveal systematic biases in the parameters found by vEM. Surprisingly, simpler variational approximations (such as mean-field) can lead to less bias than more complicated structured approximations. The variational approach. We begin this chapter with a brief theoretical review of the variational expectation maximisation algorithm, before illustrating the important concepts with a simple example in the next section. The vEM algorithm is an approximate version of the expectation maximisation (EM) algorithm [4]. Expectation maximisation is a standard approach to finding maximum likelihood (ML) parameters for latent variable models, including hidden Markov models and linear or non-linear state space models (SSMs) for time series.},
	number = {3},
	journal = {Bayesian Time Series Models},
	author = {Turner, Richard Eric and Sahani, Maneesh},
	year = {2011},
	note = {ISBN: 9780511984679},
	pages = {104--124},
}

@article{Li2016a,
	title = {Rényi divergence variational inference},
	issn = {10495258},
	abstract = {This paper introduces the variational Rényi bound (VR) that extends traditional vari-ational inference to Rényi's α-divergences. This new family of variational methods unifies a number of existing approaches, and enables a smooth interpolation from the evidence lower-bound to the log (marginal) likelihood that is controlled by the value of α that parametrises the divergence. The reparameterization trick, Monte Carlo approximation and stochastic optimisation methods are deployed to obtain a tractable and unified framework for optimisation. We further consider negative α values and propose a novel variational inference method as a new special case in the proposed framework. Experiments on Bayesian neural networks and variational auto-encoders demonstrate the wide applicability of the VR bound.},
	number = {Nips},
	journal = {Advances in Neural Information Processing Systems},
	author = {Li, Yingzhen and Turner, Richard E.},
	year = {2016},
	pages = {1081--1089},
}

@article{Rossi2019,
	title = {Good initializations of variational bayes for deep models},
	volume = {2019-June},
	abstract = {Stochastic variational inference is an established way to carry out approximate Bayesian inference for deep models flexibly and at scale. While there have been effective proposals for good initializations for loss minimization in deep learning, far less attention has been devoted to the issue of initialization of stochastic variational inference. We address this by proposing a novel layer-wise initialization strategy based on Bayesian linear models. The proposed method is extensively validated on regression and classification tasks, including Bayesian Deep Nets and Conv Nets, showing faster and better convergence compared to alternatives inspired by the literature on initializations for loss minimization.},
	journal = {36th International Conference on Machine Learning, ICML 2019},
	author = {Rossi, Simone and Michiardi, Pietro and Filippone, Maurizio},
	year = {2019},
	note = {arXiv: 1810.08083
ISBN: 9781510886988},
	pages = {9659--9669},
}

@article{Xiao2019,
	title = {Dynamic collaborative recurrent learning},
	doi = {10.1145/3357384.3357901},
	abstract = {In this paper, we provide a unified learning algorithm, dynamic collaborative recurrent learning, DCRL, of two directions of recommendations: temporal recommendations focusing on tracking the evolution of users' long-term preference and sequential recommendations focusing on capturing short-term preferences given a short time window. Our DCRL builds based on RNN and Sate Space Model (SSM), and thus it is not only able to collaboratively capture users' short-term and long-term preferences as in sequential recommendations, but also can dynamically track the evolution of users' long-term preferences as in temporal recommendations in a unified framework. In addition, we introduce two smoothing and filtering scalable inference algorithms for DCRL's offline and online learning, respectively, based on amortized variational inference, allowing us to effectively train the model jointly over all time. Experiments demonstrate DCRL outperforms the temporal and sequential recommender models, and does capture users' short-term preferences and track the evolution of long-term preferences.},
	number = {2},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	author = {Xiao, Teng and Liang, Shangsong and Meng, Zaiqiao},
	year = {2019},
	note = {ISBN: 9781450369763},
	keywords = {Deep generative model, Sequential recommendation, Temporal recommendation},
	pages = {1151--1160},
}

@article{Ma2019,
	title = {Sampling can be faster than optimization},
	volume = {116},
	issn = {10916490},
	doi = {10.1073/pnas.1820003116},
	abstract = {Optimization algorithms and Monte Carlo sampling algorithms have provided the computational foundations for the rapid growth in applications of statistical machine learning in recent years. There is, however, limited theoretical understanding of the relationships between these 2 kinds of methodology, and limited understanding of relative strengths and weaknesses. Moreover, existing results have been obtained primarily in the setting of convex functions (for optimization) and log-concave functions (for sampling). In this setting, where local properties determine global properties, optimization algorithms are unsurprisingly more efficient computationally than sampling algorithms. We instead examine a class of nonconvex objective functions that arise in mixture modeling and multistable systems. In this nonconvex setting, we find that the computational complexity of sampling algorithms scales linearly with the model dimension while that of optimization algorithms scales exponentially.},
	number = {42},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Ma, Yi An and Chen, Yuansi and Jin, Chi and Flammarion, Nicolas and Jordan, Michael I.},
	year = {2019},
	note = {ISBN: 1820003116},
	keywords = {Computational complexity, Langevin Monte Carlo, Nonconvex optimization},
	pages = {20881--20885},
}

@article{Yao2018,
	title = {Yes, but did it work?: {Evaluating} variational inference},
	volume = {12},
	abstract = {While it's always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation". We propose two diagnostic algorithms to alleviate this problem. The Paretosmoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulationbased calibration (VSBC) assesses the average performance of point estimates.},
	journal = {35th International Conference on Machine Learning, ICML 2018},
	author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
	year = {2018},
	note = {arXiv: 1802.02538
ISBN: 9781510867963},
	pages = {8887--8895},
}

@article{ODonoghue2020,
	title = {Making {Sense} of {Reinforcement} {Learning} and {Probabilistic} {Inference}},
	url = {http://arxiv.org/abs/2001.00805},
	abstract = {Reinforcement learning (RL) combines a control problem with statistical estimation: the system dynamics are not known to the agent, but can be learned through experience. A recent line of research casts `RL as inference' and suggests a particular framework to generalize the RL problem as probabilistic inference. Our paper surfaces a key shortcoming in that approach, and clarifies the sense in which RL can be coherently cast as an inference problem. In particular, an RL agent must consider the effects of its actions upon future rewards and observations: the exploration-exploitation tradeoff. In all but the most simple settings, the resulting inference is computationally intractable so that practical RL algorithms must resort to approximation. We demonstrate that the popular `RL as inference' approximation can perform poorly in even very basic problems. However, we show that with a small modification the framework does yield algorithms that can provably perform well, and we show that the resulting algorithm is equivalent to the recently proposed K-learning, which we further connect with Thompson sampling.},
	author = {O'Donoghue, Brendan and Osband, Ian and Ionescu, Catalin},
	year = {2020},
	note = {arXiv: 2001.00805},
	pages = {1--16},
}

@book{HastieTrevor;TibshiraniRobert;Friedman2009,
	title = {The elements of statistical learning : data mining, inference, and prediction},
	isbn = {978-0-387-84857-0},
	url = {http://ucl-primo.hosted.exlibrisgroup.com/primo_library/libweb/action/display.do;jsessionid=078607CD6BD74BEB05E0179C6387A2E2?tabs=detailsTab&ct=display&fn=search&doc=UCL_LMS_DS001238326&indx=1&recIds=UCL_LMS_DS001238326&recIdxs=0&elementId=0&renderMode=po},
	author = {Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome;},
	year = {2009},
	pmid = {15512507},
	doi = {10.1007/BF02985802},
	note = {Publication Title: 2009
ISSN: 0343-6993},
}

@article{Levine2018,
	title = {Reinforcement {Learning} and {Control} as {Probabilistic} {Inference}: {Tutorial} and {Review}},
	url = {http://arxiv.org/abs/1805.00909},
	abstract = {The framework of reinforcement learning or optimal control provides a mathematical formalization of intelligent decision making that is powerful and broadly applicable. While the general form of the reinforcement learning problem enables effective reasoning about uncertainty, the connection between reinforcement learning and inference in probabilistic models is not immediately obvious. However, such a connection has considerable value when it comes to algorithm design: formalizing a problem as probabilistic inference in principle allows us to bring to bear a wide array of approximate inference tools, extend the model in flexible and powerful ways, and reason about compositionality and partial observability. In this article, we will discuss how a generalization of the reinforcement learning or optimal control problem, which is sometimes termed maximum entropy reinforcement learning, is equivalent to exact probabilistic inference in the case of deterministic dynamics, and variational inference in the case of stochastic dynamics. We will present a detailed derivation of this framework, overview prior work that has drawn on this and related ideas to propose new reinforcement learning and control algorithms, and describe perspectives on future research.},
	author = {Levine, Sergey},
	year = {2018},
	note = {arXiv: 1805.00909},
}

@article{Duan2017,
	title = {R {Einforcement} {L} {Earning}},
	author = {Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter and Science, Computer},
	year = {2017},
	note = {arXiv: 1611.02779v2},
	pages = {1--14},
}

@article{Depeweg2016,
	title = {Learning and {Policy} {Search} in {Stochastic} {Dynamical} {Systems} with {Bayesian} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1605.07127},
	abstract = {We present an algorithm for model-based reinforcement learning that combines Bayesian neural networks (BNNs) with random roll-outs and stochastic optimization for policy learning. The BNNs are trained by minimizing \${\textbackslash}alpha\$-divergences, allowing us to capture complicated statistical patterns in the transition dynamics, e.g. multi-modality and heteroskedasticity, which are usually missed by other common modeling approaches. We illustrate the performance of our method by solving a challenging benchmark where model-based approaches usually fail and by obtaining promising results in a real-world scenario for controlling a gas turbine.},
	author = {Depeweg, Stefan and Hernández-Lobato, José Miguel and Doshi-Velez, Finale and Udluft, Steffen},
	year = {2016},
	note = {arXiv: 1605.07127},
	pages = {1--14},
}

@article{Chua2018,
	title = {Deep {Reinforcement} {Learning} in a {Handful} of {Trials} using {Probabilistic} {Dynamics} {Models}},
	volume = {2018-Decem},
	issn = {10495258},
	abstract = {Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).},
	number = {NeurIPS},
	journal = {Advances in Neural Information Processing Systems},
	author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
	year = {2018},
	note = {arXiv: 1805.12114},
	pages = {4754--4765},
}

@article{DanielFreeman2019,
	title = {Learning to {Predict} {Without} {Looking} {Ahead}: {World} {Models} {Without} {Forward} {Prediction}},
	abstract = {Much of model-based reinforcement learning (RL) involves learning a model of an agent's world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware-e.g., a brain-arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we provide an example modification to traditional reinforcement learning we call observational dropout, whereby we artificially constrain the probability that an agent is allowed to observe its real environment at each step. In doing so, we can coerce an agent into learning a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment.},
	number = {9},
	author = {Daniel Freeman, C and Metz, Luke and Ha, David},
	year = {2019},
	note = {arXiv: 1910.13038v1},
	pages = {1--17},
}

@article{Razavi2019,
	title = {Generating {Diverse} {High}-{Fidelity} {Images} with {VQ}-{VAE}-2},
	url = {http://arxiv.org/abs/1906.00446},
	abstract = {We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before. We use simple feed-forward encoder and decoder networks, making our model an attractive candidate for applications where the encoding and/or decoding speed is critical. Additionally, VQ-VAE requires sampling an autoregressive model only in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN's known shortcomings such as mode collapse and lack of diversity.},
	author = {Razavi, Ali and Oord, Aaron van den and Vinyals, Oriol},
	year = {2019},
	note = {arXiv: 1906.00446},
}

@article{Hoffman2013,
	title = {Stochastic {Variational} {Inference}},
	volume = {14},
	abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
	urldate = {2019-02-26},
	journal = {Journal of Machine Learning Research},
	author = {Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John and Edu, Jpaisley@berkeley and Jaakkola, Tommi},
	year = {2013},
	keywords = {Bayesian inference, Bayesian nonparametrics, stochastic optimization, topic models, variational inference},
	pages = {1303--1347},
}

@article{Fraccaro2017,
	title = {A disentangled recognition and nonlinear dynamics model for unsupervised learning},
	volume = {2017-Decem},
	issn = {10495258},
	abstract = {This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks.},
	number = {section 5},
	journal = {Advances in Neural Information Processing Systems},
	author = {Fraccaro, Marco and Kamronn, Simon and Paquet, Ulrich and Winther, Ole},
	year = {2017},
	note = {arXiv: 1710.05741},
	pages = {3602--3611},
}

@techreport{Pike-Burke2018,
	title = {Recovering {Bandits}},
	abstract = {We study a variant of the non-stationary stochastic K-armed bandit problem which we call recovering bandits. In this problem, the expected reward of each arm changes depending on the time since the arm was last played according to some unknown recovery function. This problem arises in many settings, for example in product recommendation when after a user makes a purchase, we wish to wait before suggesting the same product again. In the recovering bandits problem, the reward at time t depends on all previous actions, so finding the optimal sequence of T actions would be infeasible. In this paper, we discuss alternative strategies which perform well theoretically and experimentally. Specifically, we assume the recovery functions take the form of a Gaussian process and present UCB and Thompson Sampling algorithms which achieve high instantaneous reward (reward from the played arm) and lookahead reward (total reward from the next d arms).},
	author = {Pike-Burke, Ciara and Grünewälder, Steffen},
	year = {2018},
	note = {Publication Title: European Workshop on Reinforcement Learning
Volume: 14},
}

@article{Li2016,
	title = {Collaborative {Filtering} {Bandits}},
	issn = {9781450321389},
	doi = {10.1145/2911451.2911548},
	abstract = {Classical collaborative filtering, and content-based filtering methods try to learn a static recommendation model given training data. These approaches are far from ideal in highly dynamic recommendation domains such as news recommen-dation and computational advertisement, where the set of items and users is very fluid. In this work, we investigate an adaptive clustering technique for content recommenda-tion based on exploration-exploitation strategies in contex-tual multi-armed bandit settings. Our algorithm takes into account the collaborative effects that arise due to the inter-action of the users with the items, by dynamically grouping users based on the items under consideration and, at the same time, grouping items based on the similarity of the clusterings induced over the users. The resulting algorithm thus takes advantage of preference patterns in the data in a way akin to collaborative filtering methods. We provide an empirical analysis on medium-size real-world datasets, showing scalability and increased prediction performance (as measured by click-through rate) over state-of-the-art meth-ods for clustering bandits. We also provide a regret analysis within a standard linear stochastic noise setting.},
	journal = {Sigir},
	author = {Li, Shuai and Karatzoglou, Alexandros and Gentile, Claudio},
	year = {2016},
	pmid = {21526112},
	note = {arXiv: 1502.03473
ISBN: 9781450340694},
	keywords = {bandits, clustering, collaborative filtering, computational advertising, filtering and recommending, line learning, on-, recommender systems, regret},
	pages = {539--548},
}

@article{Zhang2018,
	title = {Advances in {Variational} {Inference}},
	issn = {19393539},
	abstract = {Many modern unsupervised or semi-supervised machine learning algorithms rely on Bayesian probabilistic models. These models are usually intractable and thus require approximate inference. Variational inference (VI) lets us approximate a high-dimensional Bayesian posterior with a simpler variational distribution by solving an optimization problem. This approach has been successfully used in various models and large-scale applications. In this review, we give an overview of recent trends in variational inference. We first introduce standard mean field variational inference, then review recent advances focusing on the following aspects: (a) scalable VI, which includes stochastic approximations, (b) generic VI, which extends the applicability of VI to a large class of otherwise intractable models, such as non-conjugate models, (c) accurate VI, which includes variational models beyond the mean field approximation or with atypical divergences, and (d) amortized VI, which implements the inference over local latent variables with inference networks. Finally, we provide a summary of promising future research directions.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zhang, Cheng and Butepage, Judith and Kjellstrom, Hedvig and Mandt, Stephan},
	year = {2018},
	doi = {10.1109/TPAMI.2018.2889774},
	note = {Publisher: IEEE Computer Society},
	keywords = {Approximate Bayesian Inference, Bayes methods, Computational modeling, Hidden Markov models, Inference Networks, Market research, Optimization, Probabilistic logic, Reparameterization Gradients, Scalable Inference, Stochastic processes, Structured Variational Approximations, Variational Inference},
}

@article{Zhang,
	title = {A {Comparative} {Analysis} of {Feature} {Selection} {Methods} for {Biomarker} {Discovery} in {Study} of {Toxicant}-treated {Atlantic} {Cod} ( {Gadus} morhua ) {Liver}},
	author = {Zhang, Xiaokang and Jonassen, Inge},
	keywords = {biomarker discovery, classification, feature selection, machine learning, stability},
}

@article{Krishnan2016,
	title = {Structured {Inference} {Networks} for {Nonlinear} {State} {Space} {Models}},
	url = {http://arxiv.org/abs/1609.09869},
	abstract = {Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood.},
	urldate = {2019-05-03},
	author = {Krishnan, Rahul G. and Shalit, Uri and Sontag, David},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.09869},
}

@article{Jiang2019,
	title = {B {Eyond} {G} {Reedy} {R} {Anking} : {S} {Late} {O} {Ptimization} {Via} {L} {Ist} -{Cvae}},
	author = {Jiang, Ray and Rezende, Danilo J},
	year = {2019},
	pages = {1--12},
}

@article{Liang2016,
	title = {Causal {Inference} for {Recommendation}},
	url = {http://arxiv.org},
	abstract = {Abstract We develop a causal inference approach to recommender systems. Observational recommendation data contains two sources of information: which items each user decided to look at and which of those items each user liked. We assume these two types of ...{\textbackslash}n},
	journal = {Conference on Uncertainty in Artificial Intelligence},
	author = {Liang, Dawen and Charlin, Laurent and Blei, David M},
	year = {2016},
}

@article{Hessel2017,
	title = {Rainbow: {Combining} {Improvements} in {Deep} {Reinforcement} {Learning}},
	issn = {15205126},
	url = {http://arxiv.org/abs/1710.02298},
	doi = {10.1021/ja00048a049},
	abstract = {The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.},
	author = {Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
	year = {2017},
	note = {arXiv: 1710.02298
ISBN: 1710.02298v1},
}

@article{Kendall,
	title = {Learning to {Drive} in a {Day}},
	url = {http://arxiv.org/abs/1807.00412},
	abstract = {We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.},
	author = {Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
	year = {2018},
	note = {arXiv: 1807.00412},
	keywords = {Autonomous Vehicles, Deep Reinforcement Learning},
}

@inproceedings{Sui2015,
	title = {Safe {Exploration} for {Optimization} with {Gaussian} {Processes}},
	volume = {37},
	isbn = {978-3-319-23461-8 978-3-319-23460-1},
	url = {http://jmlr.org/proceedings/papers/v37/sui15.html},
	doi = {10.1007/978-3-s319-23461-8},
	abstract = {We consider sequential decision problems under uncertainty, where we seek to optimize an unknown function from noisy samples. This requires balancing exploration (learning about the objective) and exploitation (localizing the maximum), a problem well-studied in the multi-armed bandit literature. In many applications, however, we require that the sampled function values exceed some prespecified " safety " thresh-old, a requirement that existing algorithms fail to meet. Examples include medical applications where patient comfort must be guaranteed, recommender systems aiming to avoid user dissatisfaction, and robotic control, where one seeks to avoid controls causing physical harm to the platform. We tackle this novel, yet rich, set of problems under the assumption that the unknown function satisfies regularity conditions expressed via a Gaussian process prior. We develop an efficient algorithm called SAFEOPT, and theoretically guarantee its convergence to a natural notion of optimum reachable under safety constraints. We evaluate SAFEOPT on synthetic data, as well as two real applications: movie recommendation, and therapeutic spinal cord stimulation. Proceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W\&CP volume 37. Copy-right 2015 by the author(s).},
	urldate = {2018-06-22},
	booktitle = {{ICML}},
	author = {Sui, Yanan and Gotovos, Alkis and Burdick, Joel and Krause, Andreas},
	year = {2015},
	note = {ISSN: 16113349 03029743},
	pages = {997--1005},
}

@article{Bubeck2014,
	title = {Convex {Optimization}: {Algorithms} and {Complexity}},
	volume = {8},
	issn = {1935-8237},
	url = {http://arxiv.org/abs/1405.4980},
	doi = {10.1561/2200000049},
	abstract = {This monograph presents the main complexity theorems in convex optimization and their corresponding algorithms. Starting from the fundamental theory of black-box optimization, the material progresses towards recent advances in structural optimization and stochastic optimization. Our presentation of black-box optimization, strongly influenced by Nesterov's seminal book and Nemirovski's lecture notes, includes the analysis of cutting plane methods, as well as (accelerated) gradient descent schemes. We also pay special attention to non-Euclidean settings (relevant algorithms include Frank-Wolfe, mirror descent, and dual averaging) and discuss their relevance in machine learning. We provide a gentle introduction to structural optimization with FISTA (to optimize a sum of a smooth and a simple non-smooth term), saddle-point mirror prox (Nemirovski's alternative to Nesterov's smoothing), and a concise description of interior point methods. In stochastic optimization we discuss stochastic gradient descent, mini-batches, random coordinate descent, and sublinear algorithms. We also briefly touch upon convex relaxation of combinatorial problems and the use of randomness to round solutions, as well as random walks based methods.},
	number = {5},
	journal = {Foundations and Trends R in Machine Learning},
	author = {Bubeck, Sébastien},
	year = {2014},
	pmid = {18255791},
	note = {arXiv: 1405.4980
ISBN: 978-1-68083-089-7},
	pages = {6--359},
}

@article{Zebell2015,
	title = {Cell-{Cycle} {Regulators} and {Cell} {Death} in {Immunity}},
	volume = {18},
	issn = {19346069},
	doi = {10.1016/j.chom.2015.10.001},
	abstract = {Various cell death mechanisms are integral to host defense in both plants and mammals. Plant defense against biotrophic pathogens is associated with programmed cell death (PCD) of the infected cell. This effector-triggered PCD is partly analogous to pyroptosis, an inflammatory host cell death process that plays a crucial role in defense against microbial infections in mammals. Plant effector-triggered PCD also shares with mammalian apoptosis the involvement of cell-cycle regulators as signaling components. Here we explore the similarities between these different cell death programs as they relate to host defense and their relationship to the cell cycle.},
	number = {4},
	urldate = {2018-06-17},
	journal = {Cell Host and Microbe},
	author = {Zebell, Sophia G. and Dong, Xinnian},
	year = {2015},
	pmid = {26468745},
	note = {arXiv: 1003.0146v2
ISBN: 1934-6069 (Electronic){\textbackslash}r1931-3128 (Linking)},
	keywords = {()},
	pages = {402--407},
}

@article{May2000,
	title = {{OPTIMISTIC} {BAYESIAN} {SAMPLING} {IN} {CONTEXTUAL}-{BANDIT} {PROBLEMS}},
	abstract = {In sequential decision problems in an unknown environment, the decision maker often faces a dilemma over whether to explore to discover more about the environment, or to exploit current knowledge. We address the exploration-exploitation dilemma in a general setting encompassing both standard and contextualised bandit problems. The contextual bandit problem has recently resurfaced in attempts to maximise click-through rates in web based applications, a task with significant commercial interest. In this article we consider an approach of Thompson (1933) which makes use of samples from the posterior distributions for the instantaneous value of each action. We extend the approach by introducing a new algorithm, Optimistic Bayesian Sampling (OBS), in which the probability of playing an action increases with the uncertainty in the estimate of the action value. This results in better directed exploratory behaviour. We prove that, under unrestrictive assumptions, both approaches result in optimal behaviour with respect to the average reward criterion of Yang and Zhu (2002). We implement OBS and measure its performance in simulated Bernoulli bandit and linear regression domains, and also when tested with the task of personalised news article recommendation on a Yahoo! Front Page Today Module data set. We find that OBS performs competitively when compared to recently proposed benchmark algorithms and outperforms Thompson's method throughout. © 2012 Benedict C. May, Nathan Korda, Anthony Lee and David S. Leslie.},
	journal = {Annals of Applied Probability},
	author = {May, By Benedict C and Korda, Nathan and Lee, Anthony and Leslie, S},
	year = {2000},
	keywords = {Thompson sampling, contextual bandits, exploration-exploitation, multi-armed bandits, sequential alloca-tion},
	pages = {1--24},
}

@techreport{Aas,
	title = {Pair-copula constructions of multiple dependence {Projektpartner} {Pair}-copula constructions of multiple dependence},
	abstract = {Building on the work of Bedford, Cooke and Joe, we show how multivariate data, which exhibit complex patterns of dependence in the tails, can be modelled using a cascade of pair-copulae, acting on two variables at a time. We use the pair-copula decomposition of a general multivariate distribution and propose a method to perform inference. The model construction is hierarchical in nature, the various levels corresponding to the incorporation of more variables in the conditioning sets, using pair-copulae as simple building blocs. Pair-copula decomposed models also represent a very ¤exible way to construct higher-dimensional coplulae. We apply the methodology to a £nancial data set. Our approach represents the £rst step towards developing of an unsupervised algorithm that explores the space of possible pair-copula models, that also can be applied to huge data sets automatically.},
	urldate = {2018-06-17},
	author = {Aas, Kjersti and Czado, Claudia and Frigessi, Arnoldo},
	year = {2006},
	note = {Publication Title: Discussion paper
Volume: 487},
}

@article{Ying2018,
	title = {Graph {Convolutional} {Neural} {Networks} for {Web}-{Scale} {Recommender} {Systems}},
	volume = {10},
	url = {https://doi.org/10.1145/3219819.3219890},
	doi = {10.1145/3219819.3219890},
	abstract = {Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains a challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm PinSage, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We deploy PinSage at Pinterest and train it on 7.5 billion exam-ples on a graph with 3 billion nodes representing pins and boards, and 18 billion edges. According to offline metrics, user studies and A/B tests, PinSage generates higher-quality recommendations than comparable deep learning and graph-based alternatives. To our knowledge, this is the largest application of deep graph embed-dings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.},
	urldate = {2018-06-12},
	author = {Ying, Rex and He, Ruining and Chen, Kaifeng and Eksombatchai, Pong and Hamilton, William L and Leskovec, Jure},
	year = {2018},
	note = {Publisher: ACM},
}

@article{Pearl2010,
	title = {The {International} {Journal} of {Biostatistics} {An} {Introduction} to {Causal} {Inference} {An} {Introduction} to {Causal} {Inference} ∗},
	volume = {6},
	issn = {1557-4679},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2836213&tool=pmcentrez&rendertype=abstract},
	doi = {10.2202/1557-4679.1203},
	abstract = {This paper summarizes recent advances in causal inference and underscores the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underlie all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: those about (1) the effects of potential interventions, (2) probabilities of counterfactuals, and (3) direct and indirect effects (also known as "mediation"). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both. The tools are demonstrated in the analyses of mediation, causes of effects, and probabilities of causation.},
	number = {2},
	journal = {The international journal of biostatistics},
	author = {Pearl, Judea},
	year = {2010},
	pmid = {20305706},
	keywords = {Algorithms, Causality, Confounding Factors (Epidemiology), Humans, Models, Research Design, Statistical},
	pages = {Article 7},
}

@article{Nichol2018,
	title = {On {First}-{Order} {Meta}-{Learning} {Algorithms}},
	url = {http://arxiv.org/abs/1803.02999},
	abstract = {This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution. We analyze a family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only first-order derivatives for the meta-learning updates. This family includes and generalizes first-order MAML, an approximation to MAML obtained by ignoring second-order derivatives. It also includes Reptile, a new algorithm that we introduce here, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task. We expand on the results from Finn et al. showing that first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification, and we provide theoretical analysis aimed at understanding why these algorithms work.},
	urldate = {2018-04-07},
	author = {Nichol, Alex and Achiam, Joshua and Schulman, John},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.02999},
}

@article{Silver,
	title = {Alpha {Go} {Zero}},
	issn = {0028-0836},
	doi = {10.1038/nature24270},
	abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, su-perhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated posi-tions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here, we introduce an algorithm based solely on reinforcement learning, without hu-man data, guidance, or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of tree search, re-sulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating AlphaGo. Much progress towards artificial intelligence has been made using supervised learning sys-tems that are trained to replicate the decisions of human experts 1–4 . However, expert data is often expensive, unreliable, or simply unavailable. Even when reliable data is available it may impose a ceiling on the performance of systems trained in this manner 5 . In contrast, reinforcement learn-ing systems are trained from their own experience, in principle allowing them to exceed human capabilities, and to operate in domains where human expertise is lacking. Recently, there has been rapid progress towards this goal, using deep neural networks trained by reinforcement learning. These systems have outperformed humans in computer games such as Atari 6, 7 and 3D virtual en-vironments 8–10 . However, the most challenging domains in terms of human intellect – such as the 1},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and Van Den Driessche, George and Graepel, Thore and Hassabis, Demis},
	pmid = {29052630},
	note = {ISBN: 3013372370},
}

@article{Vitelli2014,
	title = {Probabilistic preference learning with the {Mallows} rank model},
	url = {http://arxiv.org/abs/1405.7945},
	abstract = {Ranking and comparing items is crucial for collecting information about preferences in many areas, from marketing to politics. The Mallows rank model is among the most successful approaches to analyse rank data, but its computational complexity has limited its use to a particular form based on Kendall distance. We develop new computationally tractable methods for Bayesian inference in Mallows models that work with any right-invariant distance. Our method performs inference on the consensus ranking of the items, also when based on partial rankings, such as top-k items or pairwise comparisons. We prove that items that none of the assessors has ranked do not influence the maximum a posteriori consensus ranking, and can therefore be ignored. When assessors are many or heterogeneous, we propose a mixture model for clustering them in homogeneous subgroups, with cluster-specific consensus rankings. We develop approximate stochastic algorithms that allow a fully probabilistic analysis, leading to coherent quantifications of uncertainties. We make probabilistic predictions on the class membership of assessors based on their ranking of just some items, and predict missing individual preferences, as needed in recommendation systems. We test our approach using several experimental and benchmark datasets.},
	author = {Vitelli, Valeria and Sørensen, Øystein and Crispino, Marta and Frigessi, Arnoldo and Arjas, Elja},
	year = {2014},
	note = {arXiv: 1405.7945},
	keywords = {Incomplete Rankings, Markov Chain Monte Carlo, Pairwise Comparisons, Preference Learning with uncertainty, Recommendation Systems},
}

@article{Guo2017,
	title = {Long {Text} {Generation} via {Adversarial} {Training} with {Leaked} {Information}},
	url = {http://arxiv.org/abs/1709.08624},
	abstract = {Automatically generating coherent and semantically meaningful text has many applications in machine translation, dialogue systems, image captioning, etc. Recently, by combining with policy gradient, Generative Adversarial Nets (GAN) that use a discriminative model to guide the training of the generative model as a reinforcement learning policy has shown promising results in text generation. However, the scalar guiding signal is only available after the entire text has been generated and lacks intermediate information about text structure during the generative process. As such, it limits its success when the length of the generated text samples is long (more than 20 words). In this paper, we propose a new framework, called LeakGAN, to address the problem for long text generation. We allow the discriminative net to leak its own high-level extracted features to the generative net to further help the guidance. The generator incorporates such informative signals into all generation steps through an additional Manager module, which takes the extracted features of current generated words and outputs a latent vector to guide the Worker module for next-word generation. Our extensive experiments on synthetic data and various real-world tasks with Turing test demonstrate that LeakGAN is highly effective in long text generation and also improves the performance in short text generation scenarios. More importantly, without any supervision, LeakGAN would be able to implicitly learn sentence structures only through the interaction between Manager and Worker.},
	urldate = {2017-11-28},
	author = {Guo, Jiaxian and Lu, Sidi and Cai, Han and Zhang, Weinan and Yu, Yong and Wang, Jun},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.08624},
}

@article{Choi2017,
	title = {{StarGAN}: {Unified} {Generative} {Adversarial} {Networks} for {Multi}-{Domain} {Image}-to-{Image} {Translation}},
	issn = {0717-6163},
	url = {http://arxiv.org/abs/1711.09020},
	doi = {10.1016/J.PHYSLETB.2017.12.053},
	abstract = {Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.},
	urldate = {2017-11-28},
	author = {Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
	month = nov,
	year = {2017},
	pmid = {172668},
	note = {arXiv: 1711.09020
ISBN: 9781467398947},
}

@article{Orabona2017,
	title = {Training {Deep} {Networks} without {Learning} {Rates} {Through} {Coin} {Betting}},
	issn = {1054-139X},
	url = {http://arxiv.org/abs/1705.07795},
	doi = {10.1016/j.jadohealth.2010.10.003},
	abstract = {Deep learning methods achieve state-of-the-art performance in many application scenarios. Yet, these methods require a significant amount of hyperparameters tuning in order to achieve the best results. In particular, tuning the learning rates in the stochastic optimization process is still one of the main bottlenecks. In this paper, we propose a new stochastic gradient descent procedure for deep networks that does not require any learning rate setting. Contrary to previous methods, we do not adapt the learning rates nor we make use of the assumed curvature of the objective function. Instead, we reduce the optimization process to a game of betting on a coin and propose a learning-rate-free optimal algorithm for this scenario. Theoretical convergence is proven for convex and quasi-convex functions and empirical evidence shows the advantage of our algorithm over popular stochastic gradient algorithms.},
	urldate = {2017-11-27},
	author = {Orabona, Francesco and Tommasi, Tatiana},
	month = may,
	year = {2017},
	note = {arXiv: 1705.07795},
}

@article{SaraSabourNicholasFrosst2015,
	title = {Dynamic {Routing} {Between} {Capsules} {Sara}},
	volume = {23},
	issn = {18647790},
	doi = {10.3354/ab00617},
	abstract = {We provide first data on the life span, growth and seasonal aspects of the life history of Black Sea bottlenose dolphins Tursiops truncatus in the wild and compare these with historical data and conspecific populations in other geographical regions. Average life span is 20 to 32 yr; the oldest record is 41 yr. The reproductive season lasts at least from February to September or October and includes the coldest months of the year (February and March). Average adult body lengths are 240 ± 14 cm for females and 255 ± 10 cm for males. Rapid early body growth ceases by 3 to 4 yr. Two morphs, one large (offshore) and one small (coastal), possibly co-exist in the Black Sea. The larger morph may include winter-breeding migrants or immigrants from the Mediterran- ean Sea. The small coastal form is similar in body size and growth patterns to coastal populations in the eastern Mediterranean region and the Gulf of Mexico, but is characterized by early growth to maturity and small asymptotic body size. Small-sized dolphin populations in enclosed water bodies can be treated as an example of the ‘island rule’, and their dwarfism may hypothetically be explained as an effect of smaller prey size.},
	number = {2},
	journal = {Aquatic Biology},
	author = {Sara Sabour, Nicholas Frosst, Geoffrey E. Hinton},
	year = {2015},
	pmid = {26338992},
	note = {arXiv: 1710.09829v1
ISBN: 1864-7790},
	keywords = {Black sea, Bottlenose dolphin, Dwarfism, Island rule, Life history},
	pages = {159--166},
}

@techreport{Paquim,
	title = {Learning {Depth} from {Single} {Monocular} {Images} {Using} {Stereo} {Supervisory} {Input}},
	abstract = {Stereo vision systems are often employed in robotics as a means for obstacle avoidance and navigation. These systems have inherent depth-sensing limitations, with significant problems in occluded and untextured regions, leading to sparse depth maps. We propose using a monocular depth estimation algorithm to tackle these problems, in a Self-Supervised Learning (SSL) framework. The algorithm learns online from the sparse depth map generated by a stereo vision system, producing a dense depth map. The algorithm is designed to be computationally efficient, for implementation onboard resource-constrained mobile robots and unmanned aerial vehicles. Within that context, it can be used to provide both reliability against a stereo camera failure, as well as more accurate depth perception, by filling in missing depth information, in occluded and low texture regions. This in turn allows the use of more efficient sparse stereo vision algorithms. We test the algorithm offline on a new, high resolution, stereo dataset, of scenes shot in indoor environments, and processed using both sparse and dense stereo matching algorithms. It is shown that the algorithm's performance doesn't deteriorate, and in fact sometimes improves, when learning only from sparse, high confidence regions rather than from the computationally expensive, dense, occlusion-filled and highly post-processed dense depth maps. This makes the approach very promising for self-supervised learning on autonomous robots.},
	urldate = {2017-10-18},
	author = {Paquim, João and De Croon, Guido},
	note = {Publication Title: Index Terms—Depth Estimation, Conditional Random Field},
	keywords = {Index Terms-Monocular depth estimation, robotics, self-supervised learning, stereo vision},
}

@misc{noauthor_convolutional_nodate,
	title = {Convolutional {Methods} for {Text} – {Tal} {Perry} – {Medium}},
	url = {https://medium.com/@TalPerry/convolutional-methods-for-text-d5260fd5675f},
	urldate = {2017-08-25},
}

@article{Blei2017,
	title = {Variational {Inference}: {A} {Review} for {Statisticians}},
	issn = {1537274X},
	doi = {10.1080/01621459.2017.1285773},
	abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
	journal = {Journal of the American Statistical Association},
	author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
	year = {2017},
	pmid = {303902},
	note = {arXiv: 1601.00670v9
ISBN: 1601.00670},
	keywords = {Algorithms, Computationally intensive methods, Statistical computing},
}

@article{Sachdeva,
	title = {Sequential {Variational} {Autoencoders} for {Collaborative} {Filtering}},
	url = {http://arxiv.org/abs/1811.09975},
	doi = {10.1145/3178876.3186150},
	abstract = {Variational autoencoders were proven successful in domains such as computer vision and speech processing. Their adoption for modeling user preferences is still unexplored, although recently it is starting to gain attention in the current literature. In this work, we propose a model which extends variational autoencoders by exploiting the rich information present in the past preference history. We introduce a recurrent version of the VAE, where instead of passing a subset of the whole history regardless of temporal dependencies, we rather pass the consumption sequence subset through a recurrent neural network. At each time-step of the RNN, the sequence is fed through a series of fully-connected layers, the output of which models the probability distribution of the most likely future preferences. We show that handling temporal information is crucial for improving the accuracy of the VAE: In fact, our model beats the current state-of-the-art by valuable margins because of its ability to capture temporal dependencies among the user-consumption sequence using the recurrent encoder still keeping the fundamentals of variational autoencoders intact.},
	urldate = {2019-02-15},
	author = {Sachdeva, Noveen and Manco, Giuseppe and Ritacco, Ettore and Pudi, Vikram},
	year = {2018},
	note = {arXiv: 1811.09975
ISBN: 9781450356398},
	keywords = {CCS CONCEPTS • Information systems → Collaborative, KEYWORDS Variational Autoencoders, Latent variable models, Neural networks, Ranking, Recommender systems, Recurrent Networks, Sequence modeling, • Computing methodologies → Supervised learn-ing},
}

@article{Krishnan,
	title = {Ethics considerations in global mobile phone-based surveys of noncommunicable diseases:{A} conceptual exploration},
	volume = {19},
	issn = {14388871},
	url = {www.aaai.org},
	doi = {10.2196/jmir.7326},
	abstract = {Mobile phone coverage has grown, particularly within low- and middle-income countries (LMICs), presenting an opportunity to augment routine health surveillance programs. Several LMICs and global health partners are seeking opportunities to launch basic mobile phone-based surveys of noncommunicable diseases (NCDs). The increasing use of such technology in LMICs brings forth a cluster of ethical challenges; however, much of the existing literature regarding the ethics of mobile or digital health focuses on the use of technologies in high-income countries and does not consider directly the specific ethical issues associated with the conduct of mobile phone surveys (MPS) for NCD risk factor surveillance in LMICs. In this paper, we explore conceptually several of the central ethics issues in this domain, which mainly track the three phases of the MPS process: predata collection, during data collection, and postdata collection. These include identifying the nature of the activity; stakeholder engagement; appropriate design; anticipating and managing potential harms and benefits; consent; reaching intended respondents; data ownership, access and use; and ensuring LMIC sustainability. We call for future work to develop an ethics framework and guidance for the use of mobile phones for disease surveillance globally.},
	number = {5},
	urldate = {2019-02-01},
	journal = {Journal of Medical Internet Research},
	author = {Ali, Joseph and Labrique, Alain B. and Gionfriddo, Kara and Pariyo, George and Gibson, Dustin G. and Pratt, Bridget and Deutsch-Feldman, Molly and Hyder, Adnan A.},
	year = {2017},
	note = {arXiv: 1609.09869v2
ISBN: 1609.09869v2},
	keywords = {Bioethics, Ethics, Mhealth, Mobile phone survey, Noncommunicable diseases, Research ethics},
}

@article{Liu2017,
	title = {{PBODL} : {Parallel} {Bayesian} {Online} {Deep} {Learning} for {Click}-{Through} {Rate} {Prediction} in {Tencent} {Advertising} {System}},
	issn = {0098-7484},
	doi = {10.1001/jama.268.12.1581},
	abstract = {We describe a parallel bayesian online deep learning framework (PBODL) for click-through rate (CTR) prediction within today's Tencent advertising system, which provides quick and accurate learning of user preferences. We first explain the framework with a deep probit regression model, which is trained with probabilistic back-propagation in the mode of assumed Gaussian density filtering. Then we extend the model family to a variety of bayesian online models with increasing feature embedding capabilities, such as Sparse-MLP, FM-MLP and FFM-MLP. Finally, we implement a parallel training system based on a stream computing infrastructure and parameter servers. Experiments with public available datasets and Tencent industrial datasets show that models within our framework perform better than several common online models, such as AdPredictor, FTRL-Proximal and MatchBox. Online A/B test within Tencent advertising system further proves that our framework could achieve CTR and CPM lift by learning more quickly and accurately.},
	author = {Liu, Xun and Xue, Wei and Xiao, Lei and Zhang, Bo},
	year = {2017},
	note = {arXiv: 1707.00802},
}

@article{Scott2010,
	title = {A modern {Bayesian} look at the multi-armed bandit},
	volume = {26},
	issn = {15241904},
	doi = {10.1002/asmb.874},
	abstract = {A multi-armed bandit is an experiment with the goal of accumulating rewards from a payoff distribution with unknown parameters that are to be learned sequentially. This article describes a heuristic for managing multi-armed bandits called randomized probability matching, which randomly allocates observations to arms according the Bayesian posterior probability that each arm is optimal. Advances in Bayesian computation have made randomized probability matching easy to apply to virtually any payoff distribution. This flexibility frees the experimenter to work with payoff distributions that correspond to certain classical experimental designs that have the potential to outperform methods that are ‘optimal’ in simpler contexts. I summarize the relationships between randomized probability matching and several related heuristics that have been used in the reinforcement learning literature. Copyright},
	number = {6},
	journal = {Applied Stochastic Models in Business and Industry},
	author = {Scott, Steven L},
	year = {2010},
	keywords = {Bayesian adaptive design, exploration vs exploitation, probability matching, sequential design},
	pages = {639--658},
}

@techreport{Hidasi,
	title = {Organization {Workshop} chairs {Program} committee},
	author = {Hidasi, Balázs and Sar-Shalom, Oren and Vasile, Flavian and Dieleman, Criteo Sander and Quadrana, Massimo and Usa, Pandora and Mcauley, Julian},
}

@article{P-rom,
	title = {Leitevegen 71},
	author = {P-rom, Einebustad},
}

@inproceedings{Bansal2016,
	title = {Ask the {GRU}},
	isbn = {978-1-4503-4035-9},
	doi = {10.1145/2959100.2959180},
	abstract = {In a variety of application domains the content to be recommended to users is associated with text. This includes research papers, movies with associated plot summaries, news articles, blog posts, etc. Recommendation approaches based on latent factor models can be extended naturally to leverage text by employing an explicit mapping from text to factors. This enables recommendations for new, unseen content, and may generalize better, since the factors for all items are produced by a compactly-parametrized model. Previous work has used topic models or averages of word embeddings for this mapping. In this paper we present a method leveraging deep recurrent neural networks to encode the text sequence into a latent vector, specifically gated recurrent units (GRUs) trained end-to-end on the collaborative filtering task. For the task of scientific paper recommendation, this yields models with significantly higher accuracy. In cold-start scenarios, we beat the previous state-of-the-art, all of which ignore word order. Performance is further improved by multi-task learning, where the text encoder network is trained for a combination of content recommendation and item metadata prediction. This regularizes the collaborative filtering model, ameliorating the problem of sparsity of the observed rating matrix.},
	author = {Bansal, Trapit and Belanger, David and McCallum, Andrew},
	year = {2016},
	note = {arXiv: 1609.02116},
	pages = {107--114},
}

@article{Busa-Fekete2018,
	title = {Preference-based {Online} {Learning} with {Dueling} {Bandits}: {A} {Survey}},
	url = {http://arxiv.org/abs/1807.11398},
	abstract = {In machine learning, the notion of multi-armed bandits refers to a class of online learning problems, in which an agent is supposed to simultaneously explore and exploit a given set of choice alternatives in the course of a sequential decision process. In the standard setting, the agent learns from stochastic feedback in the form of real-valued rewards. In many applications, however, numerical reward signals are not readily available -- instead, only weaker information is provided, in particular relative preferences in the form of qualitative comparisons between pairs of alternatives. This observation has motivated the study of variants of the multi-armed bandit problem, in which more general representations are used both for the type of feedback to learn from and the target of prediction. The aim of this paper is to provide a survey of the state of the art in this field, referred to as preference-based multi-armed bandits or dueling bandits. To this end, we provide an overview of problems that have been considered in the literature as well as methods for tackling them. Our taxonomy is mainly based on the assumptions made by these methods about the data-generating process and, related to this, the properties of the preference-based feedback.},
	urldate = {2018-08-21},
	author = {Busa-Fekete, Robert and Hüllermeier, Eyke and Mesaoudi-Paul, Adil El},
	year = {2018},
	note = {arXiv: 1807.11398},
	keywords = {Multi-armed bandits, PAC learning, cumulative regret, exploration/exploitation, online learning, preference learning, ranking, sample complexity, top-k selection},
}

@inproceedings{Graepel2010,
	title = {Web-{Scale} {Bayesian} {Click}-{Through} {Rate} {Prediction} for {Sonsored} {Search} {Advertising} in {Microsofts}'s {Bing} {Search} {Engine}},
	isbn = {978-1-60558-907-7},
	doi = {10.1016/j.bbr.2012.06.005},
	abstract = {We describe a new Bayesian click-through rate (CTR) prediction algorithm used for Sponsored Search in Microsofts Bing search engine. The algorithm is based on a probit regression model that maps discrete or real-valued input features to probabilities. It maintains Gaussian beliefs over weights of the model and performs Gaussian online updates derived from approximate message passing. Scalability of the algorithm is ensured through a principled weight pruning procedure and an approximate parallel implementation. We discuss the challenges arising from evaluating and tuning the predictor as part of the complex system of sponsored search where the predictions made by the algorithm decide about future training sample composition. Finally, we show experimental results from the production system and compare to a calibrated Naïve Bayes algorithm.},
	urldate = {2018-09-11},
	booktitle = {{ICML}},
	author = {Graepel, Thore and Candela, Joaquin Quinonero and Bochert, Thomas and Herbrich, Ralf and Com, Rherb Microsoft},
	year = {2010},
	pmid = {22705860},
	note = {Issue: April 2009
ISSN: 1872-7549},
	pages = {13--20},
}

@inproceedings{Beutel2018,
	title = {Latent {Cross}},
	isbn = {978-1-4503-5581-0},
	url = {https://doi.org/10.1145/3159652.3159727},
	doi = {10.1145/3159652.3159727},
	abstract = {The success of recommender systems often depends on their ability to understand and make use of the context of the recommenda- tion request. Signi cant research has focused on how time, loca- tion, interfaces, and a plethora of other contextual features a ect recommendations. However, in using deep neural networks for recommender systems, researchers often ignore these contexts or incorporate them as ordinary features in the model. In this paper, we study how to e ectively treat contextual data in neural recommender systems. We begin with an empirical analysis of the conventional approach to context as features in feed-forward recommenders and demonstrate that this approach is ine cient in capturing common feature crosses. We apply this insight to de- sign a state-of-the-art RNN recommender system. We rst describe our RNN-based recommender system in use at YouTube. Next, we o er “Latent Cross,” an easy-to-use technique to incorporate con- textual data in the RNN by embedding the context feature rst and then performing an element-wise product of the context embed- ding with model’s hidden states. We demonstrate the improvement in performance by using this Latent Cross technique in multiple experimental settings.},
	urldate = {2018-08-27},
	author = {Jain, Sagar and Gatto, Vince and Li, Jia and Xu, Can and Chi, Ed H and Covington, Paul and Beutel, Alex},
	year = {2018},
	pages = {46--54},
}

@article{Dimakopoulou2018,
	title = {Scalable {Coordinated} {Exploration} in {Concurrent} {Reinforcement} {Learning}},
	issn = {20452322},
	url = {http://arxiv.org/abs/1805.08948},
	doi = {10.1038/s41598-017-09968-7},
	abstract = {We consider a team of reinforcement learning agents that concurrently operate in a common environment, and we develop an approach to efficient coordinated exploration that is suitable for problems of practical scale. Our approach builds on seed sampling (Dimakopoulou and Van Roy, 2018) and randomized value function learning (Osband et al., 2016). We demonstrate that, for simple tabular contexts, the approach is competitive with previously proposed tabular model learning methods (Dimakopoulou and Van Roy, 2018). With a higher-dimensional problem and a neural network value function representation, the approach learns quickly with far fewer agents than alternative exploration schemes.},
	author = {Dimakopoulou, Maria and Osband, Ian and Van Roy, Benjamin},
	year = {2018},
	pmid = {25130058},
	note = {arXiv: 1805.08948
ISBN: 0262042088},
}

@article{Brukhim2018,
	title = {Predict and {Constrain}: {Modeling} {Cardinality} in {Deep} {Structured} {Prediction}},
	url = {http://arxiv.org/abs/1802.04721},
	abstract = {Many machine learning problems require the prediction of multi-dimensional labels. Such structured prediction models can benefit from modeling dependencies between labels. Recently, several deep learning approaches to structured prediction have been proposed. Here we focus on capturing cardinality constraints in such models. Namely, constraining the number of non-zero labels that the model outputs. Such constraints have proven very useful in previous structured prediction approaches, but it is a challenge to introduce them into a deep learning framework. Here we show how to do this via a novel deep architecture. Our approach outperforms strong baselines, achieving state-of-the-art results on multi-label classification benchmarks.},
	author = {Brukhim, Nataly and Globerson, Amir},
	year = {2018},
	note = {arXiv: 1802.04721},
}

@article{Farajtabar2018,
	title = {More {Robust} {Doubly} {Robust} {Off}-policy {Evaluation}},
	issn = {1938-7228},
	url = {http://arxiv.org/abs/1802.03493},
	abstract = {We study the problem of off-policy evaluation (OPE) in reinforcement learning (RL), where the goal is to estimate the performance of a policy from the data generated by another policy(ies). In particular, we focus on the doubly robust (DR) estimators that consist of an importance sampling (IS) component and a performance model, and utilize the low (or zero) bias of IS and low variance of the model at the same time. Although the accuracy of the model has a huge impact on the overall performance of DR, most of the work on using the DR estimators in OPE has been focused on improving the IS part, and not much on how to learn the model. In this paper, we propose alternative DR estimators, called more robust doubly robust (MRDR), that learn the model parameter by minimizing the variance of the DR estimator. We first present a formulation for learning the DR model in RL. We then derive formulas for the variance of the DR estimator in both contextual bandits and RL, such that their gradients w.r.t.{\textasciitilde}the model parameters can be estimated from the samples, and propose methods to efficiently minimize the variance. We prove that the MRDR estimators are strongly consistent and asymptotically optimal. Finally, we evaluate MRDR in bandits and RL benchmark problems, and compare its performance with the existing methods.},
	author = {Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
	year = {2018},
	note = {arXiv: 1802.03493
ISBN: 9781510867963},
}

@inproceedings{Azizzadenesheli2018,
	title = {Efficient exploration through {Bayesian} deep {Q}-networks},
	isbn = {978-1-72810-124-8},
	doi = {10.1109/ITA.2018.8503252},
	abstract = {We propose Bayesian Deep Q-Networks (BDQN), a Thompson sampling approach for Deep Reinforcement Learning (DRL) in Markov decision processes (MDP). BDQN is an efficient exploration-exploitation algorithm which combines Thompson sampling with deep-Q networks (DQN) and directly incorporates uncertainty over the Q-value in the last layer of the DQN, on the feature representation layer. This allows us to efficiently carry out Thompson sampling through Gaussian sampling and Bayesian Linear Regression (BLR), which has fast closed-form updates. We apply our method to a wide range of Atari games and compare BDQN to a powerful baseline: the double deep Q-network (DDQN). Since BDQN carries out more efficient exploration, it is able to reach higher rewards substantially faster: in less than 5M-+1M interactions for almost half of the games to reach DDQN scores. We also establish theoretical guarantees for the special case when the feature representation is d-dimensional and fixed. We provide the Bayesian regret of posterior sampling RL (PSRL) and frequentist regret of the optimism in the face of uncertainty (OFU) for episodic MDPs.},
	urldate = {2018-07-10},
	booktitle = {2018 {Information} {Theory} and {Applications} {Workshop}, {ITA} 2018},
	author = {Azizzadenesheli, Kamyar and Brunskill, Emma and Anandkumar, Animashree},
	year = {2018},
	note = {arXiv: 1802.04412v1},
}

@article{Liu2018,
	title = {When {Simple} {Exploration} is {Sample} {Efficient}: {Identifying} {Sufficient} {Conditions} for {Random} {Exploration} to {Yield} {PAC} {RL} {Algorithms}},
	abstract = {Efficient exploration is one of the key challenges for reinforcement learning (RL) algorithms. Most traditional sample efficiency bounds require strategic exploration. Recently many deep RL algorithm with simple heuristic exploration strategies that have few formal guarantees, achieve surprising success in many domains. These results pose an important question about understand-ing these exploration strategies such as e-greedy, as well as understanding what characterize the difficulty of exploration in MDPs. In this work we propose problem specific sample complexity bounds of Q learning with random walk exploration that rely on several structural properties. We also link our theoretical results to some empirical benchmark domains, to illustrate if our bound gives polynomial sample complexity or not in these domains and how that is related with the empirical performance in these domains.},
	urldate = {2018-06-17},
	author = {Liu, Yao and Brunskill, Emma},
	year = {2018},
}

@article{Li2010a,
	title = {Unbiased {Offline} {Evaluation} of {Contextual}-bandit-based {News} {Article} {Recommendation} {Algorithms}},
	issn = {1450304931},
	url = {http://arxiv.org/abs/1003.5956%0Ahttp://dx.doi.org/10.1145/1935826.1935878},
	doi = {10.1145/1935826.1935878},
	abstract = {Contextual bandit algorithms have become popular for online recommendation systems such as Digg, Yahoo! Buzz, and news recommendation in general. {\textbackslash}emph\{Offline\} evaluation of the effectiveness of new algorithms in these applications is critical for protecting online user experiences but very challenging due to their "partial-label" nature. Common practice is to create a simulator which simulates the online environment for the problem at hand and then run an algorithm against this simulator. However, creating simulator itself is often difficult and modeling bias is usually unavoidably introduced. In this paper, we introduce a {\textbackslash}emph\{replay\} methodology for contextual bandit algorithm evaluation. Different from simulator-based approaches, our method is completely data-driven and very easy to adapt to different applications. More importantly, our method can provide provably unbiased evaluations. Our empirical results on a large-scale news article recommendation dataset collected from Yahoo! Front Page conform well with our theoretical results. Furthermore, comparisons between our offline replay and online bucket evaluation of several contextual bandit algorithms show accuracy and effectiveness of our offline evaluation method.},
	author = {Li, Lihong and Chu, Wei and Langford, John and Wang, Xuanhui},
	year = {2010},
	note = {arXiv: 1003.5956
ISBN: 9781450304931},
}

@article{Leslie2012,
	title = {Recommending {Mallows}},
	volume = {13},
	abstract = {In a recommendation setting, one might assume that each individual has a ranking over the possible items that could be recommended. For example, of the available items on an auction site, each individual might have a preference order for these items. The Mallows model provides a distribution over rankings, based on some distance from a (population) consensus ranking ρ (a location), and a scale parameter α indicating how variable the population is. Individuals j in a population are each assumed to have a personal ranking R j ∼ Mallows(ρ, α), although even the R j are probably not fully observed. Learning either ρ or individual rankings R j allows one to recommend highly ranked items to individuals from the population. Frigessi's research team have developed a Bayesian Mallows model for preference learning (e.g. [1]), and associated MCMC schemes to infer the parameters, when the data are partial observations of R j 's, such as pairwise preferences, partial rankings, or even simply clicks on sufficiently high-ranked items. However, to date, the focus of effort has been to infer parameters of the model conditional on fixed data, and little effort has been made to consider the online learning challenge, in which one must balance exploration and exploitation. We are interested in quickly improving our knowledge to lead to better recommendations. A simple framework is as follows. Suppose that we wish to recommend items to a sequence of individuals j = 1, 2, . . ., each of whom has a personal ranking R j ∼ Mallows(ρ, α). The recommender's action j is an item a j recommended to user j. The system receives reward equal to the actual ranking by individual j of action a j , and updates the beliefs about ρ. The objective is to try to minimise the cumulative ranking (small rank numbers are good). This is a simple objective, and the inference is easy, although the data assumptions are unrealistic; the next step might well be a slightly more complicated model in which the system receives 0/1 reward indicating whether the recommended item was " good enough " for the user. A greedy policy will always take the action currently believed to be best, but may well result in insufficient information gain. In this setting, the greedy action is the a which minimises E[R j,a {\textbar} History] = n r=1 rp(R j,a = r {\textbar} ρ, α)p(ρ {\textbar} History). A Thompson sampling [2] approach will not integrate out all this uncertainty. Instead it will draw a singl ρ from the belief distribution p(ρ {\textbar} History) then choose a to minimise E[R j,a ρ, α] = n r=1 rp(R j,a = r ρ, α). This additional randomness in Thompson sampling will ensure that if the belief distribution p(ρ {\textbar} History) is not particularly focused, exploratory actions are taken which will hopefully improve knowledge about ρ. Note however one of the critical gaps with Thompson sampling: it is far from clear whether the action selected will indeed be the most informative. We believe that if some of the distributions involved in the Mallows inference can be explicitly dealt with then further approaches such as UCB or knowledge gradient may well be easily implemented, and this is one direction we could follow if a more theoretical project appealed. You will test your developed approach using several experimental and benchmark datasets, building on examples already constructed by Frigessi's team. If you are successful, we will also test the methods in an on-line industrial framework in which scalability issues, when either the number of users or items become large, will need to be carefully considered. Skills required: You will be working with MCMC, so will need to be comfortable with computer programming. You will be doing Bayesian stats, and thinking about decision-making. A theoretical slant on the project would involve some advanced probability, whereas a practical slant would be more computational.},
	number = {1},
	journal = {Journal of Machine Learning Research, forthcoming. Journal of Machine Learning Research},
	author = {Leslie, David and Frigessi, Arnoldo},
	year = {2012},
	pages = {2069--2106},
}

@article{Chen2016,
	title = {Exploiting meta features for dependency parsing and part-of-speech tagging},
	volume = {230},
	issn = {00043702},
	doi = {10.1016/j.artint.2015.09.002},
	abstract = {In recent years, discriminative methods have achieved much progress in natural language processing tasks, such as parsing, part-of-speech tagging, and word segmentation. For these methods, conventional features in a relatively high dimensional feature space may suffer from sparseness and thus exhibit less discriminative power on unseen data. This article presents a learning framework of feature transformation, addressing the sparseness problem by transforming sparse conventional base features into less sparse high-level features (i.e. meta features) with the help of a large amount of automatically annotated data. The meta features are derived by bucketing similar base features according to the frequency in large data, and used together with base features in our final system. We apply the framework to part-of-speech tagging and dependency parsing. Experimental results show that our systems perform better than the baseline systems in both tasks on standard evaluation. For the dependency parsing task, our parsers achieve state-of-the-art accuracy on the Chinese data and comparable accuracy with the best known systems on the English data. Further analysis indicates that our proposed approach is effective in processing unseen data and features.},
	journal = {Artificial Intelligence},
	author = {Chen, Wenliang and Zhang, Min and Zhang, Yue and Duan, Xiangyu},
	year = {2016},
	pmid = {26150344},
	note = {arXiv: 1509.06461
ISBN: 0004-3702},
	keywords = {Dependency parsing, Meta-features, Natural language processing, Part-of-speech tagging, Semi-supervised approach},
	pages = {173--191},
}

@article{Heinrich2015,
	title = {Fictitious {Self}-{Play} in {Extensive}-{Form} {Games}},
	issn = {1938-7228},
	abstract = {Fictitious play is a popular game-theoretic model of learning in games. However, it has received little attention in practical applications to large problems. This paper introduces two variants of fictitious play that are implemented in be-havioural strategies of an extensive-form game. The first variant is a full-width process that is re-alization equivalent to its normal-form counter-part and therefore inherits its convergence guar-antees. However, its computational requirements are linear in time and space rather than exponen-tial. The second variant, Fictitious Self-Play, is a machine learning framework that implements fictitious play in a sample-based fashion. Ex-periments in imperfect-information poker games compare our approaches and demonstrate their convergence to approximate Nash equilibria.},
	journal = {ICML'15 Proceedings of the 32nd International Conference on International Conference on Machine Learning},
	author = {Heinrich, Johannes and Lanctot, Marc and Silver, David},
	year = {2015},
	note = {ISBN: 9781510810587},
}

@article{Haarnoja2018,
	title = {Soft {Actor}-{Critic}: {Off}-{Policy} {Maximum} {Entropy} {Deep} {Reinforcement} {Learning} with a {Stochastic} {Actor}},
	url = {http://arxiv.org/abs/1801.01290},
	doi = {arXiv:1801.01290v2},
	abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	year = {2018},
	pmid = {11032563},
	note = {arXiv: 1801.01290
ISBN: 0264-410X (Print){\textbackslash}r0264-410X (Linking)},
}

@article{Lillicrap,
	title = {{CONTINUOUS} {CONTROL} {WITH} {DEEP} {REINFORCEMENT} {LEARNING}},
	abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the de-terministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our al-gorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is com-petitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies " end-to-end " : directly from raw pixel in-puts.},
	author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
}

@article{Kannan2016,
	title = {Smart {Reply}: {Automated} {Response} {Suggestion} for {Email}},
	issn = {0146-4833},
	url = {http://arxiv.org/abs/1606.04870},
	doi = {10.475/123},
	abstract = {In this paper we propose and investigate a novel end-to-end method for automatically generating short email responses, called Smart Reply. It generates semantically diverse suggestions that can be used as complete email responses with just one tap on mobile. The system is currently used in Inbox by Gmail and is responsible for assisting with 10\% of all mobile responses. It is designed to work at very high throughput and process hundreds of millions of messages daily. The system exploits state-of-the-art, large-scale deep learning. We describe the architecture of the system as well as the challenges that we faced while building it, like response diversity and scalability. We also introduce a new method for semantic clustering of user-generated content that requires only a modest amount of explicitly labeled data.},
	author = {Kannan, Anjuli and Kurach, Karol and Ravi, Sujith and Kaufmann, Tobias and Tomkins, Andrew and Miklos, Balint and Corrado, Greg and Lukacs, Laszlo and Ganea, Marina and Young, Peter and Ramavajjala, Vivek},
	year = {2016},
	pmid = {6239336},
	note = {arXiv: 1606.04870
ISBN: 9781450335423},
}

@incollection{Francis2014,
	title = {Depth {Map} {Prediction} from a {Single} {Image} using a {Multi}-{Scale} {Deep} {Network}},
	isbn = {978-1-139-34267-4},
	abstract = {What use can the brain make of the massive flow of sensory information that occurs without any associated rewards or punishments? This question is reviewed in the light of connectionist models of unsupervised learning and some older ideas, namely the cognitive maps and working models of Tolman and Craik, and the idea that redundancy is important for understanding perception (Attneave 1954), the physiology of sensory pathways (Barlow 1959), and pattern recognition (Watanabe 1960). It is argued that (1) The redundancy of sensory messages provides the knowledge incorporated in the maps or models. (2) Some of this knowledge can be obtained by observations of mean, variance, and covariance of sensory messages, and perhaps also by a method called “minimum entropy coding.” (3) Such knowledge may be incorporated in a model of “what usually happens” with which incoming messages are automatically compared, enabling unexpected discrepancies to be immediately identified. (4) Knowledge of the sort incorporated into su...},
	author = {Francis, Louise},
	year = {2014},
	pmid = {20879316},
	doi = {10.1017/CBO9781139342674.012},
	note = {arXiv: 1512.00567
ISSN: 16137736},
	keywords = {Finance and accountancy, Finance and insurance, Statistics for econometrics},
	pages = {280--312},
}

@inproceedings{Redmon2016,
	title = {{YOLO9000}: {Better}, faster, stronger},
	volume = {2017-Janua},
	isbn = {978-1-5386-0457-1},
	url = {http://arxiv.org/abs/1612.08242},
	doi = {10.1109/CVPR.2017.690},
	abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
	urldate = {2017-08-21},
	booktitle = {Proceedings - 30th {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, {CVPR} 2017},
	author = {Redmon, Joseph and Farhadi, Ali},
	month = dec,
	year = {2017},
	note = {arXiv: 1612.08242},
	pages = {6517--6525},
}

@article{Li2010,
	title = {Improving one-class collaborative filtering by incorporating rich user information},
	abstract = {One-Class Collaborative Filtering (OCCF) is an emerging setup in collaborative filtering in which only positive exam-ples or implicit feedback can be observed. Compared with the traditional collaborative filtering setting where the data has ratings, OCCF is more realistic in many scenarios when no ratings are available. In this paper, we propose to im-prove OCCF accuracy by exploiting the rich user informa-tion that is often naturally available in community-based interactive information systems, including a user's search query history, purchasing and browsing activities. We pro-pose two ways to incorporate such user information into the OCCF models: one is to linearly combine scores from dif-ferent sources and the other is to embed user information into collaborative filtering. Experimental results on a large-scale retail data set from a major e-commerce company show that the proposed methods are effective and can improve the performance of the One-Class Collaborative Filtering over baseline methods through leveraging rich user information.},
	journal = {Proceedings of the 19th ACM international conference on Information and knowledge management - CIKM '10},
	author = {Li, Yanen and Hu, Jia and Zhai, ChengXiang and Chen, Ye},
	year = {2010},
}

@inproceedings{Hidasi2018,
	title = {Recurrent {Neural} {Net}-works with {Top}-k {Gains} for {Session}-based {Recommendations}},
	isbn = {978-1-4503-6014-2},
	url = {https://dl.acm.org/citation.cfm?id=3271761},
	doi = {10.1145/3269206.3271761},
	abstract = {RNNs have been shown to be excellent models for sequential data and in particular for data that is generated by users in an session-based manner. The use of RNNs provides impressive performance benefits over classical methods in session-based recommendations. In this work we introduce novel ranking loss functions tailored to RNNs in the recommendation setting. The improved performance of these losses over alternatives, along with further tricks and refinements described in this work, allow for an overall improvement of up to 35\% in terms of MRR and Recall@20 over previous session-based RNN solutions and up to 53\% over classical collaborative filtering approaches. Unlike data augmentation-based improvements, our method does not increase training times significantly. We further demonstrate the performance gain of the RNN over baselines in an online A/B test.},
	urldate = {2019-01-27},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Hidasi, Balázs and Karatzoglou, Alexandros},
	year = {2018},
	note = {arXiv: 1706.03847v3},
	keywords = {loss function, ranking, recommender systems, recurrent neural networks, session-based recommendation},
	pages = {10},
}

@inproceedings{Hidasi2016,
	title = {Parallel {Recurrent} {Neural} {Network} {Architectures} for {Feature}-rich {Session}-based {Recommendations}},
	isbn = {978-1-4503-4035-9},
	doi = {10.1145/2959100.2959167},
	abstract = {Reallife recommender systems often face the daunting task of providing recommendations based only on the clicks of a user session. Methods that rely on user profiles – such as matrix factorization – perform very poorly in this setting, thus itemtoitem recommendations are used most of the time. However the items typically have rich feature representations such as pictures and text descriptions that can be used to model the sessions. Here we investigate how these features can be exploited in Recurrent Neural Network based session models using deep learning. We show that obvious approaches do not leverage these data sources. We thus introduce a number of parallel RNN (pRNN) architectures to model sessions based on the clicks and the features (images and text) of the clicked items. We also propose alternative training strategies for pRNNs that suit them better than standard training. We show that pRNN architectures with proper training have significant performance improvements over featureless session models while all sessionbased models outperform the itemtoitem type baseline.},
	booktitle = {Proceedings of the 10th {ACM} {Conference} on {Recommender} {Systems} - {RecSys} '16},
	author = {Hidasi, Balázs and Quadrana, Massimo and Karatzoglou, Alexandros and Tikk, Domonkos},
	year = {2016},
	note = {ISSN: 00030007},
	pages = {241--248},
}

@inproceedings{Belletti2018,
	title = {Factorized {Recurrent} {Neural} {Architectures} for {Longer} {Range} {Dependence}},
	volume = {84},
	url = {https://ai.google/research/pubs/pub46850},
	abstract = {The ability to capture Long Range Dependence (LRD) in a stochastic process is of prime im-portance in the context of predictive models. A sequential model with a longer-term mem-ory is better able contextualize recent observa-tions. In this article, we apply the theory of LRD stochastic processes to modern recurrent archi-tectures, such as LSTMs and GRUs, and prove they do not provide LRD under assumptions suf-ficient for gradients to vanish. Motivated by an information-theoretic analysis, we provide a modified recurrent neural architecture that miti-gates the issue of faulty memory through redun-dancy while keeping the compute time constant. Experimental results on a synthetic copy task, the Youtube-8m video classification task and a recommender system show that we enable better memorization and longer-term memory.},
	urldate = {2018-12-20},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Belletti, Francois and Chi, Ed H. and Beutel, Alex and Jain, Sagar and Chi, Ed H.},
	year = {2018},
	pages = {1522--1530},
}

@article{Mackay,
	title = {intro\_gausian\_processes},
	urldate = {2018-12-02},
	author = {Mackay, David J.C.},
}

@article{Opper1997,
	title = {A {Bayesian} {Approach} to {On}-line {Learning}},
	url = {https://www.cambridge.org/core/product/identifier/CBO9780511569920A023/type/book_part},
	doi = {10.1017/CBO9780511569920.017},
	abstract = {Online learning is discussed from the viewpoint of Bayesian statistical inference. By replacing the true posterior distribution with a simpler parametric distribution, one can define an online algorithm by a repetition of two steps: An update of the approximate posterior, when a new example arrives, and an optimal projection into the parametric family. Choosing this family to be Gaussian, we show that the algorithm achieves asymptotic efficiency. An application to learning in single layer neural networks is given.},
	journal = {On-Line Learning in Neural Networks},
	author = {Opper, Manfred},
	year = {1997},
	note = {ISBN: 0262194163},
	pages = {363--378},
}

@article{Nickel2018,
	title = {Learning {Continuous} {Hierarchies} in the {Lorentz} {Model} of {Hyperbolic} {Geometry}},
	url = {http://arxiv.org/abs/1806.03417},
	abstract = {We are concerned with the discovery of hierarchical relationships from large-scale unstructured similarity scores. For this purpose, we study different models of hyperbolic space and find that learning embeddings in the Lorentz model is substantially more efficient than in the Poincar{\textbackslash}'e-ball model. We show that the proposed approach allows us to learn high-quality embeddings of large taxonomies which yield improvements over Poincar{\textbackslash}'e embeddings, especially in low dimensions. Lastly, we apply our model to discover hierarchies in two real-world datasets: we show that an embedding in hyperbolic space can reveal important aspects of a company's organizational structure as well as reveal historical relationships between language families.},
	author = {Nickel, Maximilian and Kiela, Douwe},
	year = {2018},
	note = {arXiv: 1806.03417},
}

@article{Shani2005,
	title = {An {MDP}-{Based} {Recommender} {System}},
	volume = {1216--1220},
	issn = {1560-4292},
	doi = {arXiv:1301.0600},
	abstract = {This appendix provides suggestions for organisation of a research dissertation or thesis in the areas of applied linguistics and language learning research. They are not intended as a strait-jacket and in general it is a good idea to identify exemplary studies in your specific area of research and examine carefully how they are organised. The University at which you are studying may have its own guidelines on organising a dissertation or thesis, which do of course take precedence over these.},
	number = {3},
	urldate = {2018-06-17},
	journal = {Journal of Machine Learning Research},
	author = {Shani, Guy and Heckerman, David and Brafman, Ronen I.},
	year = {2005},
	note = {arXiv: 1301.0600
ISBN: 92-5-104902-5},
	keywords = {- recommender system, Data mining, Data stream clustering, Divide-and-conquer, Vector space model, assembly, augmented reality, commercial applications, constraint-based, data mining, data stream clustering, divide-and-, e-learning, education, intelligent tutoring system, interface, learning, maintenance, markov decision processes, recommender systems, similarity, vector space model},
	pages = {1--11},
}

@article{Gilotte2018,
	title = {Offline {A}/{B} testing for {Recommender} {Systems}},
	url = {http://arxiv.org/abs/1801.07030%0Ahttp://dx.doi.org/10.1145/3159652.3159687},
	doi = {10.1145/3159652.3159687},
	abstract = {Before A/B testing online a new version of a recommender system, it is usual to perform some offline evaluations on historical data. We focus on evaluation methods that compute an estimator of the potential uplift in revenue that could generate this new technology. It helps to iterate faster and to avoid losing money by detecting poor policies. These estimators are known as counterfactual or off-policy estimators. We show that traditional counterfactual estimators such as capped importance sampling and normalised importance sampling are experimentally not having satisfying bias-variance compromises in the context of personalised product recommendation for online advertising. We propose two variants of counterfactual estimates with different modelling of the bias that prove to be accurate in real-world conditions. We provide a benchmark of these estimators by showing their correlation with business metrics observed by running online A/B tests on a commercial recommender system.},
	author = {Gilotte, Alexandre and Calauzènes, Clément and Nedelec, Thomas and Abraham, Alexandre and Dollé, Simon},
	year = {2018},
	note = {arXiv: 1801.07030
ISBN: 9781450355810},
}

@article{Grave2016,
	title = {Efficient softmax approximation for {GPUs}},
	issn = {1938-7228},
	url = {http://arxiv.org/abs/1609.04309},
	doi = {10.1002/pbc.20795},
	abstract = {We propose an approximate strategy to efficiently train neural network based language models over very large vocabularies. Our approach, called adaptive softmax, circumvents the linear dependency on the vocabulary size by exploiting the unbalanced word distribution to form clusters that explicitly minimize the expectation of computation time. Our approach further reduces the computational time by exploiting the specificities of modern architectures and matrix-matrix vector operations, making it particularly suited for graphical processing units. Our experiments carried out on standard benchmarks, such as EuroParl and One Billion Word, show that our approach brings a large gain in efficiency over standard approximations while achieving an accuracy close to that of the full softmax. The code of our method is available at https://github.com/facebookresearch/adaptive-softmax.},
	author = {Grave, Edouard and Joulin, Armand and Cissé, Moustapha and Grangier, David and Jégou, Hervé},
	year = {2016},
	pmid = {2407808},
	note = {arXiv: 1609.04309
ISBN: 9781510855144},
}

@techreport{noauthor_recommendations_2018,
	title = {Recommendations as {Reinforcement} {Learning}},
	year = {2018},
}

@book{Gelman,
	title = {Bayesian {Data} {Analysis} {Third} {Edition}},
	url = {https://the-eye.eu/public/Books/qt.vidyagam.es/library/Monitoring and Analysis/Bayesian Data Analysis%2C Third Edition/Bayesian Data Analysis%2C Third Edition - Andrew Gelman %26 John B. Carlin %26 Hal S. Stern %26 David B. Dunson %26 Aki Vehtari %26 Dona},
	urldate = {2018-08-18},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubon, Donald B.},
}

@article{Ag,
	title = {Research paper of {swissQuant} {Group} {AG} {Probability} {Unbiased} {Value}-at-{Risk} {Estimators} {Probability}-unbiased {Value}-at-{Risk} {Estimators}},
	author = {Ag, Group},
}

@article{Osband,
	title = {Generalization and {Exploration} via {Randomized} {Value} {Functions}},
	abstract = {We propose randomized least-squares value iteration (RLSVI)-a new reinforcement learning algorithm designed to explore and generalize efficiently via linearly parameterized value functions. We explain why versions of least-squares value iteration that use Boltzmann or-greedy exploration can be highly inefficient, and we present computational results that demonstrate dramatic efficiency gains enjoyed by RLSVI. Further, we establish an upper bound on the expected regret of RLSVI that demonstrates near-optimality in a tabula rasa learning context. More broadly, our results suggest that random-ized value functions offer a promising approach to tackling a critical challenge in reinforcement learning: synthesizing efficient exploration and effective generalization.},
	author = {Osband, Ian and Roy, Benjamin Van and Wen, Zheng},
	note = {arXiv: 1402.0635v3},
}

@article{Dabney2017,
	title = {Distributional {Reinforcement} {Learning} with {Quantile} {Regression}},
	url = {http://arxiv.org/abs/1710.10044},
	abstract = {In reinforcement learning an agent interacts with the environment by taking actions and observing the next state and reward. When sampled probabilistically, these state transitions, rewards, and actions can all induce randomness in the observed long-term return. Traditionally, reinforcement learning algorithms average over this randomness to estimate the value function. In this paper, we build on recent work advocating a distributional approach to reinforcement learning in which the distribution over returns is modeled explicitly instead of only estimating the mean. That is, we examine methods of learning the value distribution instead of the value function. We give results that close a number of gaps between the theoretical and algorithmic results given by Bellemare, Dabney, and Munos (2017). First, we extend existing results to the approximate distribution setting. Second, we present a novel distributional reinforcement learning algorithm consistent with our theoretical formulation. Finally, we evaluate this new algorithm on the Atari 2600 games, observing that it significantly outperforms many of the recent improvements on DQN, including the related distributional algorithm C51.},
	urldate = {2018-07-21},
	author = {Dabney, Will and Rowland, Mark and Bellemare, Marc G. and Munos, Rémi},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.10044},
}

@article{Dabney,
	title = {Implicit {Quantile} {Networks} for {Distributional} {Reinforcement} {Learning}},
	abstract = {In this work, we build on recent advances in dis-tributional reinforcement learning to give a gener-ally applicable, flexible, and state-of-the-art dis-tributional variant of DQN. We achieve this by using quantile regression to approximate the full quantile function for the state-action return distri-bution. By reparameterizing a distribution over the sample space, this yields an implicitly defined return distribution and gives rise to a large class of risk-sensitive policies. We demonstrate improved performance on the 57 Atari 2600 games in the ALE, and use our algorithm's implicitly defined distributions to study the effects of risk-sensitive policies in Atari games.},
	author = {Dabney, Will and Ostrovski, Georg and Silver, David and Munos, Rémi},
}

@article{Covington2016,
	title = {Deep {Neural} {Networks} for {YouTube} {Recommendations}},
	url = {http://dl.acm.org/citation.cfm?doid=2959100.2959190},
	doi = {10.1145/2959100.2959190},
	abstract = {YouTube represents one of the largest scale and most sophis-ticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and fo-cus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a sepa-rate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintain-ing a massive recommendation system with enormous user-facing impact.},
	journal = {Proceedings of the 10th ACM Conference on Recommender Systems - RecSys '16},
	author = {Covington, Paul and Adams, Jay and Sargin, Emre},
	year = {2016},
	note = {ISBN: 9781450340359},
	keywords = {deep learning, recommender system, scalability},
	pages = {191--198},
}

@article{Silver2017,
	title = {Article {Mastering} the game of {Go} without human knowledge},
	volume = {550},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/nature24270},
	doi = {10.1038/nature24270},
	number = {7676},
	journal = {Nature Publishing Group},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent},
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	pages = {354--359},
}

@article{DeBoom2017,
	title = {Large-{Scale} {User} {Modeling} with {Recurrent} {Neural} {Networks} for {Music} {Discovery} on {Multiple} {Time} {Scales}},
	url = {http://arxiv.org/abs/1708.06520},
	doi = {10.1007/s11042-017-5121-z},
	abstract = {The amount of content on online music streaming platforms is immense, and most users only access a tiny fraction of this content. Recommender systems are the application of choice to open up the collection to these users. Collaborative filtering has the disadvantage that it relies on explicit ratings, which are often unavailable, and generally disregards the temporal nature of music consumption. On the other hand, item co-occurrence algorithms, such as the recently introduced word2vec-based recommenders, are typically left without an effective user representation. In this paper, we present a new approach to model users through recurrent neural networks by sequentially processing consumed items, represented by any type of embeddings and other context features. This way we obtain semantically rich user representations, which capture a user's musical taste over time. Our experimental analysis on large-scale user data shows that our model can be used to predict future songs a user will likely listen to, both in the short and long term.},
	urldate = {2017-08-24},
	author = {De Boom, Cedric and Agrawal, Rohan and Hansen, Samantha and Kumar, Esh and Yon, Romain and Chen, Ching-Wei and Demeester, Thomas and Dhoedt, Bart},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.06520},
}

@article{Schulman2017,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	url = {http://arxiv.org/abs/1707.06347},
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	urldate = {2017-08-12},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.06347},
}

@article{Zhang2016a,
	title = {{StackGAN}: {Text} to {Photo}-realistic {Image} {Synthesis} with {Stacked} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1612.03242},
	abstract = {Synthesizing photo-realistic images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing text-to-image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose stacked Generative Adversarial Networks (StackGAN) to generate photo-realistic images conditioned on text descriptions. The Stage-I GAN sketches the primitive shape and basic colors of the object based on the given text description, yielding Stage-I low resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high resolution images with photo-realistic details. The Stage-II GAN is able to rectify defects and add compelling details with the refinement process. Samples generated by StackGAN are more plausible than those generated by existing approaches. Importantly, our StackGAN for the first time generates realistic 256 x 256 images conditioned on only text descriptions, while state-of-the-art methods can generate at most 128 x 128 images. To demonstrate the effectiveness of the proposed StackGAN, extensive experiments are conducted on CUB and Oxford-102 datasets, which contain enough object appearance variations and are widely-used for text-to-image generation analysis.},
	journal = {arXiv preprint},
	author = {Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Huang, Xiaolei and Wang, Xiaogang and Metaxas, Dimitris},
	year = {2016},
	note = {arXiv: 1612.03242},
}

@article{Rezende2016,
	title = {One-{Shot} {Generalization} in {Deep} {Generative} {Models}},
	volume = {48},
	url = {http://proceedings.mlr.press/v48/rezende16.html},
	abstract = {Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples—having seen new examples just once—providing an important class of general-purpose models for one-shot machine learning.},
	number = {5},
	journal = {Proceedings of The 33rd International Conference on Machine Learning},
	author = {Rezende, Danilo and {Shakir} and Danihelka, Ivo and Gregor, Karol and Wierstra, Daan},
	year = {2016},
	note = {arXiv: 1603.05106
ISBN: 9781510829008},
	pages = {1521--1529},
}

@article{Kim2015,
	title = {Deep {Neural} {Network} for {Real}-{Time} {Autonomous} {Indoor} {Navigation}},
	url = {http://arxiv.org/abs/1511.04668},
	abstract = {Autonomous indoor navigation of Micro Aerial Vehicles (MAVs) possesses many challenges. One main reason is that GPS has limited precision in indoor environments. The additional fact that MAVs are not able to carry heavy weight or power consuming sensors, such as range finders, makes indoor autonomous navigation a challenging task. In this paper, we propose a practical system in which a quadcopter autonomously navigates indoors and finds a specific target, i.e., a book bag, by using a single camera. A deep learning model, Convolutional Neural Network (ConvNet), is used to learn a controller strategy that mimics an expert pilot's choice of action. We show our system's performance through real-time experiments in diverse indoor locations. To understand more about our trained network, we use several visualization techniques.},
	journal = {arXiv},
	author = {Kim, Dong Ki and Chen, Tsuhan},
	year = {2015},
	note = {arXiv: 1511.04668},
}

@article{Tramer2016,
	title = {Stealing {Machine} {Learning} {Models} via {Prediction} {APIs}},
	issn = {2469-9985},
	url = {http://arxiv.org/abs/1609.02943},
	doi = {10.1103/PhysRevC.94.034301},
	abstract = {Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service ("predictive analytics") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis.   The tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., "steal") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.},
	number = {Ml},
	author = {Tramèr, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K. and Ristenpart, Thomas},
	year = {2016},
	note = {arXiv: 1609.02943
ISBN: 9781931971324},
	pages = {19},
}

@article{Maurya2012,
	title = {Running , {Iterate} from {Plan} {A} to a {Plan} {That} {Works}},
	url = {http://shop.oreilly.com/product/0636920020141.do},
	author = {Maurya, Ash},
	year = {2012},
	note = {ISBN: 978-1-4493-0517-8},
	pages = {240},
}

@book{Harrel2001,
	title = {Springer {Series} in {Statistics} {Springer} {Series} in {Statistics}},
	isbn = {978-1-4419-2918-1},
	author = {Harrel, Jr. F. E.},
	year = {2001},
	pmid = {15772297},
	doi = {10.1007/978-0-387-98135-2},
	note = {arXiv: 1011.1669v3
ISSN: 01727397},
}

@article{McMahan2013,
	title = {Ad click prediction: a view from the trenches},
	issn = {9781450321747},
	doi = {10.1145/2487575.2488200},
	abstract = {Predicting ad click--through rates (CTR) is a massive-scale learning problem that is central to the multi-billion dollar online advertising industry. We present a selection of case studies and topics drawn from recent experiments in the setting of a deployed CTR prediction system. These include improvements in the context of traditional supervised learning based on an FTRL-Proximal online learning algorithm (which has excellent sparsity and convergence properties) and the use of per-coordinate learning rates. We also explore some of the challenges that arise in a real-world system that may appear at first to be outside the domain of traditional machine learning research. These include useful tricks for memory savings, methods for assessing and visualizing performance, practical methods for providing confidence estimates for predicted probabilities, calibration methods, and methods for automated management of features. Finally, we also detail several directions that did not turn out to be beneficial for us, despite promising results elsewhere in the literature. The goal of this paper is to highlight the close relationship between theoretical advances and practical engineering in this industrial setting, and to show the depth of challenges that appear when applying traditional machine learning methods in a complex dynamic system.},
	journal = {Kdd},
	author = {McMahan, H Brendan and Holt, Gary and Sculley, D and Young, Michael and Ebner, Dietmar and Grady, Julian and Nie, Lan and Phillips, Todd and Davydov, Eugene and Golovin, Daniel and Chikkerur, Sharat and Liu, Dan and Wattenberg, Martin and Hrafnkelsson, Arnar Mar and Boulos, Tom and Kubica, Jeremy},
	year = {2013},
	note = {arXiv: 1301.3781v2
ISBN: 9781450321747},
	keywords = {data mining, large-scale learning, online advertising},
	pages = {1222--1230},
}

@article{Chen2017,
	title = {Improving sentiment analysis via sentence type classification using {BiLSTM}-{CRF} and {CNN}},
	volume = {72},
	issn = {09574174},
	doi = {10.1016/j.eswa.2016.10.065},
	abstract = {Different types of sentences express sentiment in very different ways. Traditional sentence-level sentiment classification research focuses on one-technique-fits-all solution or only centers on one special type of sentences. In this paper, we propose a divide-and-conquer approach which first classifies sentences into different types, then performs sentiment analysis separately on sentences from each type. Specifically, we find that sentences tend to be more complex if they contain more sentiment targets. Thus, we propose to first apply a neural network based sequence model to classify opinionated sentences into three types according to the number of targets appeared in a sentence. Each group of sentences is then fed into a one-dimensional convolutional neural network separately for sentiment classification. Our approach has been evaluated on four sentiment classification datasets and compared with a wide range of baselines. Experimental results show that: (1) sentence type classification can improve the performance of sentence-level sentiment analysis; (2) the proposed approach achieves state-of-the-art results on several benchmarking datasets.},
	number = {Dl},
	journal = {Expert Systems with Applications},
	author = {Chen, Tao and Xu, Ruifeng and He, Yulan and Wang, Xuan},
	year = {2017},
	pmid = {19932002},
	note = {arXiv: 1404.7828
ISBN: 0925-2312},
	keywords = {Deep neural network, Natural language processing, Sentiment analysis},
	pages = {221--230},
}

@article{Koren2009,
	title = {Matrix factorization techniques for recommender systems},
	volume = {42},
	issn = {00189162},
	doi = {10.1109/MC.2009.263},
	abstract = {As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.},
	number = {8},
	journal = {Computer},
	author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
	year = {2009},
	pmid = {17255001},
	note = {arXiv: ISSN 0018-9162
ISBN: 0018-9162},
	pages = {30--37},
}

@misc{Riedmiller,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	author = {Riedmiller, Volodymyr Mnih Koray Kavukcuoglu David Silver Alex Graves Ioannis Antonoglou DaanWierstra Martin},
}

@article{Rendle2010,
	title = {Factorization machines},
	issn = {15504786},
	doi = {10.1109/ICDM.2010.127},
	abstract = {In this paper, we introduce Factorization Machines (FM) which are a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models. Like SVMs, FMs are a general predictor working with any real valued feature vector. In contrast to SVMs, FMs model all interactions between variables using factorized parameters. Thus they are able to estimate interactions even in problems with huge sparsity (like recommender systems) where SVMs fail. We show that the model equation of FMs can be calculated in linear time and thus FMs can be optimized directly. So unlike nonlinear SVMs, a transformation in the dual form is not necessary and the model parameters can be estimated directly without the need of any support vector in the solution. We show the relationship to SVMs and the advantages of FMs for parameter estimation in sparse settings. On the other hand there are many different factorization models like matrix factorization, parallel factor analysis or specialized models like SVD++, PITF or FPMC. The drawback of these models is that they are not applicable for general prediction tasks but work only with special input data. Furthermore their model equations and optimization algorithms are derived individually for each task. We show that FMs can mimic these models just by specifying the input data (i.e. the feature vectors). This makes FMs easily applicable even for users without expert knowledge in factorization models.},
	journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
	author = {Rendle, Steffen},
	year = {2010},
	pmid = {1530748},
	note = {ISBN: 9780769542560},
	keywords = {Factorization machine, Sparse data, Support vector machine, Tensor factorization},
	pages = {995--1000},
}

@article{Frank2000,
	title = {Technical note: {Naive} {Bayes} for regression},
	volume = {41},
	issn = {08856125},
	doi = {10.1023/A:1007670802811},
	abstract = {Despite its simplicity, the naive Bayes learning scheme performs well on most classification tasks, and is often significantly more accurate than more sophisticated methods. Although the probability estimates that it produces can be inaccurate, it often assigns maximum probability to the correct class. This suggests that its good performance might be restricted to situations where the output is categorical. It is therefore interesting to see how it performs in domains where the predicted value is numeric, because in this case, predictions are more sensitive to inaccurate probability estimates.{\textbackslash}r{\textbackslash}nThis paper shows how to apply the naive Bayes methodology to numeric prediction (i.e., regression) tasks by modeling the probability distribution of the target value with kernel density estimators, and compares it to linear regression, locally weighted linear regression, and a method that produces “model trees”—decision trees with linear regression functions at the leaves. Although we exhibit an artificial dataset for which naive Bayes is the method of choice, on real-world datasets it is almost uniformly worse than locally weighted linear regression and model trees. The comparison with linear regression depends on the error measure: for one measure naive Bayes performs similarly, while for another it is worse. We also show that standard naive Bayes applied to regression problems by discretizing the target value performs similarly badly. We then present empirical evidence that isolates naive Bayes' independence assumption as the culprit for its poor performance in the regression setting. These results indicate that the simplistic statistical assumption that naive Bayes makes is indeed more restrictive for regression than for classification.},
	number = {1},
	journal = {Machine Learning},
	author = {Frank, Eibe and Trigg, Leonard and Holmes, Geoffrey and Witten, Ian H.},
	year = {2000},
	note = {ISBN: 0885-6125},
	keywords = {linear regression, locally weighted regression, model trees, naive bayes, regression},
	pages = {5--25},
}

@article{Statnikov2005,
	title = {A comprehensive evaluation of multicategory classification methods for microarray gene expression cancer diagnosis},
	volume = {21},
	issn = {13674803},
	doi = {10.1093/bioinformatics/bti033},
	abstract = {Cancer diagnosis is one of the most important emerging clinical applications of gene expression microarray technology. We are seeking to develop a computer system for powerful and reliable cancer diagnostic model creation based on microarray data. To keep a realistic perspective on clinical applications we focus on multicategory diagnosis. To equip the system with the optimum combination of classifier, gene selection and cross-validation methods, we performed a systematic and comprehensive evaluation of several major algorithms for multicategory classification, several gene selection methods, multiple ensemble classifier methods and two cross-validation designs using 11 datasets spanning 74 diagnostic categories and 41 cancer types and 12 normal tissue types.},
	number = {5},
	journal = {Bioinformatics},
	author = {Statnikov, Alexander and Aliferis, Constantin F. and Tsamardinos, Ioannis and Hardin, Douglas and Levy, Shawn},
	year = {2005},
	pmid = {15374862},
	note = {ISBN: 1367-4803},
	pages = {631--643},
}

@article{Gunther2010,
	title = {neuralnet: {Training} of {Neural} {Networks}},
	volume = {2},
	issn = {2073-4859},
	doi = {10.1109/SP.2010.25},
	abstract = {Artificial neural networks are applied in many situations. neuralnet is built to train multi-layer perceptrons in the context of regres- sion analyses, i.e. to approximate functional rela- tionships between covariates and response vari- ables. Thus, neural networks are used as exten- sions of generalized linear models. neuralnet is a very flexible package. The back- propagation algorithm and three versions of re- silient backpropagation are implemented and it provides a custom-choice of activation and er- ror function. An arbitrary number of covariates and response variables as well as of hidden lay- ers can theoretically be included. The paper gives a brief introduction to multi- layer perceptrons and resilient backpropagation and demonstrates the application of neuralnet using the data set infert, which is contained in the R distribution.},
	number = {1},
	journal = {The R Journal},
	author = {Günther, Frauke and Fritsch, Stefan},
	year = {2010},
	pmid = {22057480},
	note = {arXiv: file:///home/spikeh/Dropbox/chp\%253A10.1007\%252F11553595\_10.pdf
ISBN: 0-387-95457-0},
	pages = {30--38},
}

@article{Deng2013,
	title = {Deep {Learning}: {Methods} and {Applications}},
	volume = {7},
	issn = {09598138},
	doi = {10.1136/bmj.319.7209.0a},
	abstract = {This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning. In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme. In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.},
	number = {3-4},
	journal = {Foundations and Trends® in Signal Processing},
	author = {Deng, Li and Yu, Dong},
	year = {2013},
	pmid = {10463930},
	note = {arXiv: 1309.1501
ISBN: 9781405161251},
	pages = {197--387},
}

@techreport{Ruiz2018,
	title = {Augment and {Reduce}: {Stochastic} {Inference} for {Large} {Categorical} {Distributions}},
	abstract = {Categorical distributions are ubiquitous in machine learning, e.g., in classification, language models, and recommendation systems. However, when the number of possible outcomes is very large, using categorical distributions becomes computationally expensive, as the complexity scales linearly with the number of outcomes. To address this problem, we propose augment and reduce (A\&R), a method to alleviate the computational complexity. A\&R uses two ideas: latent variable augmentation and stochastic variational inference. It maximizes a lower bound on the marginal likelihood of the data. Unlike existing methods which are specific to softmax, A\&R is more general and is amenable to other categorical models, such as multinomial probit. On several large-scale classification problems, we show that A\&R provides a tighter bound on the marginal likelihood and has better predictive performance than existing approaches.},
	urldate = {2019-01-14},
	author = {Ruiz, Francisco J R and Titsias, Michalis K and Dieng, Adji B and Blei, David M},
	year = {2018},
}

@article{Wua,
	title = {Recurrent {Recommender} {Networks}},
	url = {http://dx.doi.org/10.1145/3018661.3018689},
	doi = {10.1145/3018661.3018689},
	abstract = {Recommender systems traditionally assume that user profiles and movie attributes are static. Temporal dynamics are purely reactive, that is, they are inferred after they are observed , e.g. after a user's taste has changed or based on hand-engineered temporal bias corrections for movies. We propose Recurrent Recommender Networks (RRN) that are able to predict future behavioral trajectories. This is achieved by endowing both users and movies with a Long Short-Term Memory (LSTM) [14] autoregressive model that captures dynamics, in addition to a more traditional low-rank factor-ization. On multiple real-world datasets, our model offers excellent prediction accuracy and it is very compact, since we need not learn latent state but rather just the state transition function.},
	urldate = {2018-08-27},
	author = {Wu, Chao-Yuan and Ahmed, Amr and Beutel, Alex and Smola, Alexander J and Jing, How},
}

@article{Bai2018,
	title = {An {Empirical} {Evaluation} of {Generic} {Convolutional} and {Recurrent} {Networks} for {Sequence} {Modeling}},
	abstract = {For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .},
	author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
	year = {2018},
	note = {arXiv: 1803.01271},
}

@article{Rabinowitz,
	title = {Machine {Theory} of {Mind}},
	abstract = {Theory of mind (ToM; Premack \& Woodruff, 1978) broadly refers to humans' ability to rep-resent the mental states of others, including their desires, beliefs, and intentions. We propose to train a machine to build such models too. We de-sign a Theory of Mind neural network – a ToM-net – which uses meta-learning to build models of the agents it encounters, from observations of their behaviour alone. Through this process, it acquires a strong prior model for agents' be-haviour, as well as the ability to bootstrap to richer predictions about agents' characteristics and mental states using only a small number of behavioural observations. We apply the ToM-net to agents behaving in simple gridworld en-vironments, showing that it learns to model ran-dom, algorithmic, and deep reinforcement learn-ing agents from varied populations, and that it passes classic ToM tasks such as the " Sally-Anne " test (Wimmer \& Perner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold false beliefs about the world. We argue that this system – which autonomously learns how to model other agents in its world – is an impor-tant step forward for developing multi-agent AI systems, for building intermediating technology for machine-human interaction, and for advanc-ing the progress on interpretable AI.},
	author = {Rabinowitz, Neil C and Perbet, Frank and Song, H Francis and Zhang, Chiyuan and Eslami, Ali and Botvinick, Matthew},
}

@article{Zhang2016,
	title = {Deep {Reinforcement} {Learning} in {Large} {Discrete} {Action} {Spaces}},
	issn = {15729974},
	doi = {10.1007/s10614-015-9490-y},
	author = {Zhang, Jin and Maringer, Dietmar},
	year = {2016},
	note = {arXiv: 1512.07679
ISBN: 9781450335423},
	keywords = {Algorithmic trading, Artificial intelligence, Genetic algorithm, Indicator selection, Recurrent reinforcement learning, Sharpe ratio},
}

@article{Mnih2016,
	title = {Asynchronous methods for deep reinforcement learning},
	volume = {48},
	issn = {1938-7228},
	url = {http://arxiv.org/abs/1602.01783},
	abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task involving finding rewards in random 3D mazes using a visual input.},
	number = {arXiv:1602.01783v1 [cs.LG]},
	journal = {arXiv preprint},
	author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	year = {2016},
	pmid = {1000272564},
	note = {arXiv: 1602.01783
ISBN: 9781510829008},
	pages = {1--28},
}

@misc{HowJing,
	title = {Neural {Survival} {Recommender} {How}},
	author = {{How Jing} and Smola, Alexander J},
}

@article{Maas2012,
	title = {Recurrent {Neural} {Networks} for {Noise} {Reduction} in {Robust} {ASR}.},
	issn = {1558-7916},
	doi = {10.1016/j.patcog.2005.01.025},
	abstract = {Recent work on deep neural networks as acoustic mod- els for automatic speech recognition (ASR) have demon- strated substantial performance improvements. We intro- duce a model which uses a deep recurrent auto encoder neural network to denoise input features for robust ASR. The model is trained on stereo (noisy and clean) audio features to predict clean features given noisy input. The model makes no assumptions about how noise affects the signal, nor the existence of distinct noise environments. Instead, the model can learn to model any type of distor- tion or additive noise given sufficient training data. We demonstrate the model is competitive with existing fea- ture denoising approaches on the Aurora2 task, and out- performs a tandem approach where deep networks are used to predict phoneme posteriors directly.},
	journal = {Interspeech},
	author = {Maas, Andrew L. and Le, Quoc V. and O'Neil, Tyler M. and Vinyals, Oriol and Nguyen, Patrick and Ng, Andrew Y.},
	year = {2012},
	pmid = {18557655},
	note = {ISBN: 9781622767595},
	pages = {3--6},
}

@article{Izadinia2016,
	title = {{Im2Cad}},
	url = {http://arxiv.org/abs/1608.05137},
	abstract = {Given a single photo of a room and a large database of furniture CAD models, our goal is to reconstruct a scene that is as similar as possible to the scene depicted in the photograph, and composed of objects drawn from the database. We present a completely automatic system to address this IM2CAD problem that produces high quality results on challenging imagery from interior home design and remodeling websites. Our approach iteratively optimizes the placement and scale of objects in the room to best match scene renderings to the input photo, using image comparison metrics trained via deep convolutional neural nets. By operating jointly on the full scene at once, we account for inter-object occlusions. We also show the applicability of our method in standard scene understanding benchmarks where we obtain significant improvement.},
	author = {Izadinia, Hamid and Shan, Qi and Seitz, Steven M.},
	year = {2016},
	note = {arXiv: 1608.05137},
}

@article{TensorFlow2015,
	title = {What is candidate sampling},
	author = {{TensorFlow}},
	year = {2015},
}

@article{Levine2016,
	title = {Learning {Hand}-{Eye} {Coordination} for {Robotic} {Grasping} with {Deep} {Learning} and {Large}-{Scale} {Data} {Collection}},
	issn = {00032999},
	doi = {10.1145/2835776.2835844},
	abstract = {We describe a learning-based approach to hand-eye coordination for robotic grasping from monocular images. To learn hand-eye coordination for grasping, we trained a large convolutional neural network to predict the probability that task-space motion of the gripper will result in successful grasps, using only monocular camera images and independently of camera calibration or the current robot pose. This requires the network to observe the spatial relationship between the gripper and objects in the scene, thus learning hand-eye coordination. We then use this network to servo the gripper in real time to achieve successful grasps. To train our network, we collected over 800,000 grasp attempts over the course of two months, using between 6 and 14 robotic manipulators at any given time, with differences in camera placement and hardware. Our experimental evaluation demonstrates that our method achieves effective real-time control, can successfully grasp novel objects, and corrects mistakes by continuous servoing.},
	journal = {arXiv},
	author = {Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Quillen, Deirdre},
	year = {2016},
	pmid = {21156984},
	note = {arXiv: 1603.02199
ISBN: 978-1-4503-3716-8},
	pages = {1--1},
}

@article{Wang2016,
	title = {Stacked {Approximated} {Regression} {Machine}: {A} {Simple} {Deep} {Learning} {Approach}},
	volume = {1},
	url = {http://arxiv.org/abs/1608.04062},
	abstract = {This paper proposes the Stacked Approximated Regression Machine (SARM), a novel, simple yet powerful deep learning (DL) baseline. We start by discussing the relationship between regularized regression models and feed-forward networks, with emphasis on the non-negative sparse coding and convolutional sparse coding models. We demonstrate how these models are naturally converted into a unified feed-forward network structure, which coincides with popular DL components. SARM is constructed by stacking multiple unfolded and truncated regression models. Compared to the PCANet, whose feature extraction layers are completely linear, SARM naturally introduces non-linearities, by embedding sparsity regularization. The parameters of SARM are easily obtained, by solving a series of light-weight problems, e.g., PCA or KSVD. Extensive experiments are conducted, which show that SARM outperforms the existing simple deep baseline, PCANet, and is on par with many state-of-the-art deep models, but with much lower computational loads.},
	number = {3},
	journal = {Advances in Neural Information Processing Systems 29 (NIPS 2016)},
	author = {Wang, Zhangyang and Chang, Shiyu and Ling, Qing and Huang, Shuai and Hu, Xia and Shi, Honghui and Huang, Thomas S.},
	year = {2016},
	note = {arXiv: 1608.04062},
}

@article{Vuurens2016,
	title = {Exploring {Deep} {Space}: {Learning} {Personalized} {Ranking} in a {Semantic} {Space}},
	url = {http://arxiv.org/abs/1608.00276%5Cnhttp://dl.acm.org/citation.cfm?doid=2988450.2988457},
	doi = {10.1145/2988450.2988457},
	abstract = {Recommender systems leverage both content and user interactions to generate recommendations that fit users' preferences. The recent surge of interest in deep learning presents new opportunities for exploiting these two sources of information. To recommend items we propose to first learn a user-independent high-dimensional semantic space in which items are positioned according to their substitutability, and then learn a user-specific transformation function to transform this space into a ranking according to the user's past preferences. An advantage of the proposed architecture is that it can be used to effectively recommend items using either content that describes the items or user-item ratings. We show that this approach significantly outperforms state-of-the-art recommender systems on the MovieLens 1M dataset.},
	journal = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems - DLRS 2016},
	author = {Vuurens, Jeroen B. P. and Larson, Martha and de Vries, Arjen P.},
	year = {2016},
	note = {arXiv: 1608.00276
ISBN: 9781450347952},
	pages = {23--28},
}

@article{Marquez2013,
	title = {Proceedings of the {Sixth} {International} {Conference} on {Management} {Science} and {Engineering} {Management}},
	volume = {185},
	issn = {18761100},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867697326&partnerID=tZOtx3y1},
	doi = {10.1007/978-1-4471-4600-1},
	abstract = {This paper describes a real case study has been considered. It presents a dual optimization problem that consists in finding the optimal routes in the called principal and capillary routes. The problem has been considered as a travel salesman problem with time windows (TSPTW). The restrictions of Miller et al. have been used in order to reduce the computational cost [56]. A recurrent neural network approach is employed, which involves not just unsupervised learning to train neurons, but an integrated approach where Genetic Algorithm is utilized for training neurons so as to obtain a model with the least error. © 2013 Springer-Verlag.},
	journal = {Lecture Notes in Electrical Engineering},
	author = {Márquez, Fausto Pedro García and Nieto, Marta Ramos Martín},
	year = {2013},
	note = {ISBN: 978-1-4471-4599-8},
	keywords = {Genetic algorithm, Logistics, Recurrent neural network, Travelling salesman problem},
	pages = {23--37},
}

@article{Echeverria2017,
	title = {Multimodal collaborative workgroup dataset and challenges},
	volume = {1828},
	issn = {16130073},
	doi = {10.475/123},
	journal = {CEUR Workshop Proceedings},
	author = {Echeverria, Vanessa and Falcones, Gabriel and Castells, Jaime and Granda, Roger and Chiluiza, Katherine},
	year = {2017},
	note = {arXiv: 1602.05561v1
ISBN: 9781450335423},
	keywords = {Collaboration, Collocated spaces, Group work, Multimodal learning analytics},
	pages = {94--98},
}

@article{Wu,
	title = {Using {Navigation} to {Improve}},
	number = {5},
	author = {Wu, Chao-yuan},
	note = {ISBN: 9781450340359},
}

@article{Silver2016,
	title = {Mastering the game of {Go} with deep neural networks and tree search},
	volume = {529},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/nature16961},
	doi = {10.1038/nature16961},
	abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
	number = {7587},
	journal = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	year = {2016},
	pmid = {26819042},
	note = {arXiv: 1610.00633
Publisher: Nature Publishing Group
ISBN: 1476-4687 (Electronic){\textbackslash}r0028-0836 (Linking)},
	pages = {484--489},
}

@misc{Barto2015,
	title = {Reinforcement {Learning}: {An} {Introduction}},
	author = {Barto, Richard S. Sutton {and} Andrew G.},
	year = {2015},
}

@article{Ren2017,
	title = {Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}},
	volume = {39},
	issn = {01628828},
	doi = {10.1109/TPAMI.2016.2577031},
	abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [7] and Fast R-CNN [5] have reduced the running time of these detection networks, exposing region pro-posal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. RPNs are trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. With a simple alternating optimization, RPN and Fast R-CNN can be trained to share convolu-tional features. For the very deep VGG-16 model [18], our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007 (73.2\% mAP) and 2012 (70.4\% mAP) using 300 proposals per image. The code will be released.},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	year = {2017},
	pmid = {27295650},
	note = {arXiv: 1506.01497v1
ISBN: 0162-8828 VO - PP},
	keywords = {Object detection, convolutional neural network, region proposal},
	pages = {1137--1149},
}

@article{Heinrich2016,
	title = {Deep {Reinforcement} {Learning} from {Self}-{Play} in {Imperfect}-{Information} {Games}},
	abstract = {Many real-world applications can be described as large-scale games of imperfect information. To deal with these challenging domains, prior work has focused on computing Nash equilib-ria in a handcrafted abstraction of the domain. In this paper we introduce the first scalable end-to-end approach to learning approximate Nash equilibria without any prior knowledge. Our method combines fictitious self-play with deep reinforcement learning. When applied to Leduc poker, Neural Fictitious Self-Play (NFSP) ap-proached a Nash equilibrium, whereas common reinforcement learning methods diverged. In Limit Texas Hold'em, a poker game of real-world scale, NFSP learnt a competitive strategy that approached the performance of human ex-perts and state-of-the-art methods.},
	journal = {Arxiv},
	author = {Heinrich, Johannes and Silver, David},
	year = {2016},
	note = {arXiv: 1603.01121},
}

@book{Bogers2009,
	title = {Collaborative and content-based filtering for item recommendation on social bookmarking websites},
	volume = {532},
	isbn = {978-0-387-85819-7},
	abstract = {Social bookmarking websites allow users to store, organize, and search bookmarks of web pages. Users of these services can an- notate their bookmarks by using informal tags and other metadata, such as titles, descriptions, etc. In this paper, we focus on the task of item recommendation for social bookmarking websites, i.e. pre- dicting which unseen bookmarks a user might like based on his or her profile. We examine how we can incorporate the tags and other metadata into a nearest-neighbor collaborative filtering (CF) algo- rithm, by replacing the traditional usage-based similarity metrics by tag overlap, and by fusing tag-based similarity with usage-based similarity. In addition, we perform experiments with content-based filtering by using the metadata content to recommend interesting items. We generate recommendations directly based on Kullback- Leibler divergence of the metadata language models, and we ex- plore the use of this metadata in calculating user and item simi- larities. We perform our experiments on three data sets from two different domains: Delicious, CiteULike and BibSonomy.},
	author = {Bogers, Toine and Van Den Bosch, Antal},
	year = {2009},
	pmid = {21607264},
	doi = {10.1007/978-0-387-85820-3},
	note = {arXiv: 1011.1669v3
Publication Title: CEUR Workshop Proceedings
ISSN: 16130073},
	keywords = {Collaborative filtering, Content-based filtering, Folksonomies, Recommender systems, Social bookmarking},
}

@article{He2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	volume = {7},
	issn = {1664-1078},
	doi = {10.3389/fpsyg.2013.00124},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn- ing residual functions with reference to the layer inputs, in- stead of learning unreferenced functions. We provide com- prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complex- ity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex- tremely deep representations, we obtain a 28\% relative im- provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet local- ization, COCO detection, and COCO segmentation.},
	number = {3},
	journal = {arXiv preprint arXiv:1512.03385v1},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2015},
	pmid = {23554596},
	note = {arXiv: 1512.03385
ISBN: 978-1-4673-6964-0},
	keywords = {deep learning, denoising auto-encoder, image denoising},
	pages = {171--180},
}

@article{Koren2009a,
	title = {Collaborative filtering with temporal dynamics},
	issn = {00010782},
	url = {http://dx.doi.org/10.1145/1557019.1557072},
	doi = {10.1145/1557019.1557072},
	abstract = {Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset.},
	journal = {Proc. of KDD '09},
	author = {Koren, Yehuda},
	year = {2009},
	pmid = {9659936},
	note = {ISBN: 978-1-60558-495-9},
	keywords = {online},
	pages = {447--456},
}

@article{Hummer2000,
	title = {Summary questions},
	volume = {10},
	issn = {10630198},
	number = {3},
	journal = {HortTechnology},
	author = {Hummer, K. E. and Sniezko, R.},
	year = {2000},
	pages = {570},
}

@article{Cheng2016,
	title = {Wide \& {Deep} {Learning} for {Recommender} {Systems}},
	url = {http://arxiv.org/abs/1606.07792},
	doi = {10.1145/2988450.2988454},
	abstract = {Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide \& Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide \& Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.},
	journal = {arXiv preprint},
	author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
	year = {2016},
	note = {arXiv: 1606.07792
ISBN: 9781450347952},
	keywords = {deep learning, recommender systems, wide},
	pages = {1--4},
}

@article{Szegedy2016,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	issn = {08866236},
	url = {http://arxiv.org/abs/1512.00567%5Cnhttp://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.html},
	doi = {10.1002/2014GB005021},
	abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible. We benchmark our methods on the ILSVRC 2012 classification challenge validation set and demonstrate substantial gains over the state of the art via to carefully factorized convolutions and aggressive regularization: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters.},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
	year = {2016},
	pmid = {8190083},
	note = {arXiv: 1512.00567
ISBN: 9781617796029},
	pages = {2818--2826},
}

@article{Amatriain2014,
	title = {Recommender {Systems} - {Collaborative} {Filtering} and other approaches},
	url = {http://de.slideshare.net/xamat/recommender-systems-machine-learning-summer-school-2014-cmu/17},
	abstract = {Insights on Recommender Systems at Netflix for the Machine Learning Summer School 2014 at CMU},
	number = {July},
	journal = {Mlss},
	author = {Amatriain, Xavier Research (Engineering Director Netflix)},
	year = {2014},
	pages = {248},
}

@article{Girshick2012,
	title = {Rich feature hierarchies for accu- rate object detection and semantic segmentation},
	journal = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	year = {2012},
	keywords = {Ross Girshick Jeff Donahue Trevor Darrell Jitendra},
	pages = {580--587},
}

@article{Viola2001,
	title = {Robust real-time object detection},
	volume = {57},
	issn = {09205691},
	url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Robust+Real-time+Object+Detection#0},
	doi = {http://dx.doi.org/10.1023/B:VISI.0000013087.49260.fb},
	abstract = {This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [6]. The third contribution is a method for combining classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performace comparable to the best previous systems [18, 13, 16, 12, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second.},
	number = {2},
	journal = {International Journal of Computer Vision},
	author = {Viola, Paul and Jones, Michael},
	year = {2001},
	pmid = {7143246},
	note = {ISBN: 1094670599130},
	pages = {137--154},
}

@article{Rice2014,
	title = {Bayesian {Statistics} (a very brief introduction)},
	author = {Rice, Ken},
	year = {2014},
}

@article{Moravcik2017,
	title = {{DeepStack}: {Expert}-{Level} {Artificial} {Intelligence} in {No}-{Limit} {Poker}},
	volume = {6960},
	issn = {0036-8075},
	doi = {10.1126/science.aam6960},
	abstract = {Artificial intelligence has seen a number of breakthroughs in recent years, with games often serving as significant milestones. A common feature of games with these successes is that they involve information symmetry among the players, where all players have identical information. This property of perfect information, though, is far more common in games than in real-world problems. Poker is the quintessential game of imperfect information, and it has been a longstanding challenge problem in artificial intelligence. In this paper we introduce DeepStack, a new algorithm for imperfect information settings such as poker. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition about arbitrary poker situations that is automatically learned from self-play games using deep learning. In a study involving dozens of participants and 44,000 hands of poker, DeepStack becomes the first computer program to beat professional poker players in heads-up no-limit Texas hold'em. Furthermore, we show this approach dramatically reduces worst-case exploitability compared to the abstraction paradigm that has been favored for over a decade.},
	number = {February},
	author = {Moravčík, Matej and Schmid, Martin and Burch, Neil and Lisý, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
	year = {2017},
	pmid = {28254783},
	note = {arXiv: 1701.01724},
	pages = {1--32},
}

@article{Kostøl,
	title = {Kabler i arbeidsmarkedet : {Hvordan} kan stillingsannonser fra {FINN} brukes for å lære om ( fremtidens ) jobber ?},
	author = {Kostøl, Andreas},
	pages = {1--4},
}

@article{Tamar2016,
	title = {Value {Iteration} {Networks}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1602.02867},
	abstract = {We introduce the value iteration network: a fully differentiable neural network with a `planning module' embedded within. Value iteration networks are suitable for making predictions about outcomes that involve planning-based reasoning, such as predicting a desired trajectory from an observation of a map. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate our value iteration networks on the task of predicting optimal obstacle-avoiding trajectories from an image of a landscape, both on synthetic data, and on challenging raw images of the Mars terrain.},
	journal = {arXiv},
	author = {Tamar, Aviv and Levine, Sergey and Abbeel, Pieter},
	year = {2016},
	pmid = {172808},
	note = {arXiv: 1602.02867},
	pages = {1--14},
}

@article{Tibshirani2011,
	title = {Regression shrinkage and selection via the lasso: {A} retrospective},
	volume = {73},
	abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. SUMMARY We propose a new method for estimation in linear models. The 'lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
	number = {3},
	journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
	author = {Tibshirani, Robert},
	year = {2011},
	keywords = {Penalization, Regularization, l1-penalty},
	pages = {273--282},
}

@misc{noauthor_1-s2.0-s0888613x10000460-main.pdf_nodate,
	title = {1-s2.0-{S0888613X10000460}-main.pdf},
}

@misc{noauthor_kubectl_nodate,
	title = {kubectl {Cheat} {Sheet} - {Kubernetes}},
	url = {https://kubernetes.io/docs/user-guide/kubectl-cheatsheet/},
	urldate = {2017-08-12},
}
