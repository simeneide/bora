@misc{1s20S0888613X10000460mainPdf,
  title = {1-S2.0-{{S0888613X10000460-main}}.Pdf},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/77UU5EXR/Unknown - Unknown - 1-s2.0-S0888613X10000460-main.pdf.pdf}
}

@report{Aas,
  title = {Pair-Copula Constructions of Multiple Dependence {{Projektpartner Pair-copula}} Constructions of Multiple Dependence},
  author = {Aas, Kjersti and Czado, Claudia and Frigessi, Arnoldo},
  date = {2006},
  journaltitle = {Discussion paper},
  volume = {487},
  abstract = {Building on the work of Bedford, Cooke and Joe, we show how multivariate data, which exhibit complex patterns of dependence in the tails, can be modelled using a cascade of pair-copulae, acting on two variables at a time. We use the pair-copula decomposition of a general multivariate distribution and propose a method to perform inference. The model construction is hierarchical in nature, the various levels corresponding to the incorporation of more variables in the conditioning sets, using pair-copulae as simple building blocs. Pair-copula decomposed models also represent a very ¤exible way to construct higher-dimensional coplulae. We apply the methodology to a £nancial data set. Our approach represents the £rst step towards developing of an unsupervised algorithm that explores the space of possible pair-copula models, that also can be applied to huge data sets automatically.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/V6DLP7DS/m-api-74dac006-7f66-f7bf-7b01-696285534d58.pdf}
}

@article{Aas2016a,
  title = {The Climatic Mass Balance of {{Svalbard}} Glaciers: {{A}} 10-Year Simulation with a Coupled Atmosphere-Glacier Mass Balance Model},
  author = {Aas, Kjetil S. and Dunse, Thorben and Collier, Emily and Schuler, Thomas V. and Berntsen, Terje K. and Kohler, Jack and Luks, Bartłomiej},
  date = {2016},
  journaltitle = {Cryosphere},
  volume = {10},
  number = {3},
  pages = {1089--1104},
  issn = {19940424},
  doi = {10.5194/tc-10-1089-2016},
  abstract = {In this study we simulate the climatic mass balance of Svalbard glaciers with a coupled atmosphere-glacier model with 3 km grid spacing, from September 2003 to September 2013. We find a mean specific net mass balance of -257mmw.e. yr-1, corresponding to a mean annual mass loss of about 8.7 Gt, with large interannual variability. Our results are compared with a comprehensive set of mass balance, meteorological, and satellite measurements. Model temperature biases of 0.19 and -1.9 °C are found at two glacier automatic weather station sites. Simulated climatic mass balance is mostly within about 100mmw.e. yr-1 of stake measurements, and simulated winter accumulation at the Austfonna ice cap shows mean absolute errors of 47 and 67mmw.e. yr-1 when compared to radar-derived values for the selected years 2004 and 2006. Comparison of modeled surface height changes from 2003 to 2008, and satellite altimetry reveals good agreement in both mean values and regional differences. The largest deviations from observations are found for winter accumulation at Hansbreen (up to around 1000mmw.e. yr-1), a site where sub-grid topography and wind redistribution of snow are important factors. Comparison with simulations using 9 km grid spacing reveal considerable differences on regional and local scales. In addition, 3 km grid spacing allows for a much more detailed comparison with observations than what is possible with 9 km grid spacing. Further decreasing the grid spacing to 1 km appears to be less significant, although in general precipitation amounts increase with resolution. Altogether, the model compares well with observations and offers possibilities for studying glacier climatic mass balance on Svalbard both historically as well as based on climate projections.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TTQ3YG66/Aas et al. - 2016 - The climatic mass balance of Svalbard glaciers A 10-year simulation with a coupled atmosphere-glacier mass balance m.pdf}
}

@article{Abdollahpouri2017,
  title = {Controlling Popularity Bias in Learning-to-Rank Recommendation},
  author = {Abdollahpouri, Himan and Burke, Robin and Mobasher, Bamshad},
  date = {2017},
  journaltitle = {RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems},
  pages = {42--46},
  doi = {10.1145/3109859.3109912},
  abstract = {Many recommendation algorithms su.er from popularity bias in their output: popular items are recommended frequently and less popular ones rarely, if at all. However, less popular, long-tail items are precisely those that are often desirable recommendations. In this paper, we introduce a flexible regularization-based framework to enhance the long-tail coverage of recommendation lists in a learning-to-rank algorithm. We show that regularization provides a tunable mechanism for controlling the trade-off between accuracy and coverage. Moreover, the experimental results using two data sets show that it is possible to improve coverage of long tail items without substantial loss of ranking performance.},
  isbn = {9781450346528},
  keywords = {Coverage,Learning to rank,Long-tail,Recommendation evaluation,Recommender systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/JG44EPZL/Abdollahpouri, Burke, Mobasher - 2017 - Controlling popularity bias in learning-to-rank recommendation.pdf}
}

@article{adamsSurveyInverseReinforcement2022,
  title = {A Survey of Inverse Reinforcement Learning},
  author = {Adams, Stephen and Cody, Tyler and Beling, Peter A.},
  date = {2022-08-01},
  journaltitle = {Artificial Intelligence Review},
  shortjournal = {Artif Intell Rev},
  volume = {55},
  number = {6},
  pages = {4307--4346},
  issn = {1573-7462},
  doi = {10.1007/s10462-021-10108-x},
  url = {https://doi.org/10.1007/s10462-021-10108-x},
  urldate = {2023-08-27},
  abstract = {Learning from demonstration, or imitation learning, is the process of learning to act in an environment from examples provided by a teacher. Inverse reinforcement learning (IRL) is a specific form of learning from demonstration that attempts to estimate the reward function of a Markov decision process from examples provided by the teacher. The reward function is often considered the most succinct description of a task. In simple applications, the reward function may be known or easily derived from properties of the system and hard coded into the learning process. However, in complex applications, this may not be possible, and it may be easier to learn the reward function by observing the actions of the teacher. This paper provides a comprehensive survey of the literature on IRL. This survey outlines the differences between IRL and two similar methods - apprenticeship learning and inverse optimal control. Further, this survey organizes the IRL literature based on the principal method, describes applications of IRL algorithms, and provides areas of future research.},
  langid = {english},
  keywords = {Apprenticeship learning,Inverse optimal control,Inverse reinforcement learning,Learning from demonstration,Reinforcement learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZAXIHK2T/s10462-021-10108-x.pdf}
}

@article{afsarReinforcementLearningBased2022,
  title = {Reinforcement {{Learning}} Based {{Recommender Systems}}: {{A Survey}}},
  shorttitle = {Reinforcement {{Learning}} Based {{Recommender Systems}}},
  author = {Afsar, M. Mehdi and Crump, Trafford and Far, Behrouz},
  date = {2022-12-15},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {55},
  number = {7},
  pages = {145:1--145:38},
  issn = {0360-0300},
  doi = {10.1145/3543846},
  url = {https://doi.org/10.1145/3543846},
  urldate = {2022-12-27},
  abstract = {Recommender systems (RSs) have become an inseparable part of our everyday lives. They help us find our favorite items to purchase, our friends on social networks, and our favorite movies to watch. Traditionally, the recommendation problem was considered to be a classification or prediction problem, but it is now widely agreed that formulating it as a sequential decision problem can better reflect the user-system interaction. Therefore, it can be formulated as a Markov decision process (MDP) and be solved by reinforcement learning (RL) algorithms. Unlike traditional recommendation methods, including collaborative filtering and content-based filtering, RL is able to handle the sequential, dynamic user-system interaction and to take into account the long-term user engagement. Although the idea of using RL for recommendation is not new and has been around for about two decades, it was not very practical, mainly because of scalability problems of traditional RL algorithms. However, a new trend has emerged in the field since the introduction of deep reinforcement learning (DRL), which made it possible to apply RL to the recommendation problem with large state and action spaces. In this paper, a survey on reinforcement learning based recommender systems (RLRSs) is presented. Our aim is to present an outlook on the field and to provide the reader with a fairly complete knowledge of key concepts of the field. We first recognize and illustrate that RLRSs can be generally classified into RL- and DRL-based methods. Then, we propose an RLRS framework with four components, i.e., state representation, policy optimization, reward formulation, and environment building, and survey RLRS algorithms accordingly. We highlight emerging topics and depict important trends using various graphs and tables. Finally, we discuss important aspects and challenges that can be addressed in the future.},
  keywords = {Recommender systems,reinforcement learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/58MCIY4R/Afsar et al. - 2022 - Reinforcement Learning based Recommender Systems .pdf}
}

@article{Ag,
  title = {Research Paper of {{swissQuant Group AG Probability Unbiased Value-at-Risk Estimators Probability-unbiased Value-at-Risk Estimators}}},
  author = {Ag, Group},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/6S5CWU7P/Ag - Unknown - Research paper of swissQuant Group AG Probability Unbiased Value-at-Risk Estimators Probability-unbiased Value-at-Risk Es.pdf}
}

@article{agassiMethodOutlineAnarchistic2017,
  title = {Against Method : {{Outline}} of an Anarchistic Theory of Knowledge},
  author = {Agassi, Joseph},
  date = {2017},
  doi = {10.1007/BF02383263},
  issue = {August},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/WVX4THNG/Agassi - 2017 - Against method Outline of an anarchistic theory of knowledge.pdf}
}

@online{ainslieCoLT5FasterLongRange2023,
  title = {{{CoLT5}}: {{Faster Long-Range Transformers}} with {{Conditional Computation}}},
  shorttitle = {{{CoLT5}}},
  author = {Ainslie, Joshua and Lei, Tao and family=Jong, given=Michiel, prefix=de, useprefix=true and Ontañón, Santiago and Brahma, Siddhartha and Zemlyanskiy, Yury and Uthus, David and Guo, Mandy and Lee-Thorp, James and Tay, Yi and Sung, Yun-Hsuan and Sanghai, Sumit},
  date = {2023-03-16},
  eprint = {2303.09752},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.09752},
  url = {http://arxiv.org/abs/2303.09752},
  urldate = {2023-03-21},
  abstract = {Many natural language processing tasks benefit from long inputs, but processing long documents with Transformers is expensive -- not only due to quadratic attention complexity but also from applying feedforward and projection layers to every token. However, not all tokens are equally important, especially for longer documents. We propose CoLT5, a long-input Transformer model that builds on this intuition by employing conditional computation, devoting more resources to important tokens in both feedforward and attention layers. We show that CoLT5 achieves stronger performance than LongT5 with much faster training and inference, achieving SOTA on the long-input SCROLLS benchmark. Moreover, CoLT5 can effectively and tractably make use of extremely long inputs, showing strong gains up to 64k input length.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9H5JQ8ED/Ainslie et al. - 2023 - CoLT5 Faster Long-Range Transformers with Conditi.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/FZ3UABR3/2303.html}
}

@unpublished{aitchisonStatisticalTheoryCold2020,
  title = {A Statistical Theory of Cold Posteriors in Deep Neural Networks},
  author = {Aitchison, Laurence},
  date = {2020},
  eprint = {2008.05912},
  eprinttype = {arXiv},
  pages = {1--15},
  url = {http://arxiv.org/abs/2008.05912},
  abstract = {To get Bayesian neural networks to perform comparably to standard neural networks it is usually necessary to artificially reduce uncertainty using a "tempered" or "cold" posterior. This is extremely concerning: if the prior is accurate, Bayes inference/decision theory is optimal, and any artificial changes to the posterior should harm performance. While this suggests that the prior may be at fault, here we argue that in fact, BNNs for image classification use the wrong likelihood. In particular, standard image benchmark datasets such as CIFAR-10 are carefully curated. We develop a generative model describing curation which gives a principled Bayesian account of cold posteriors, because the likelihood under this new generative model closely matches the tempered likelihoods used in past work.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BSKLL587/Aitchison - 2020 - A statistical theory of cold posteriors in deep neural networks.pdf}
}

@report{Akaike,
  title = {On the {{Likelihood}} of a {{Time Series Model}}},
  author = {Akaike, Hirotugu},
  journaltitle = {Source: Journal of the Royal Statistical Society. Series D (The Statistician)},
  volume = {27},
  number = {4},
  pages = {217--235},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/K5JA7D68/m-api-62e0cf92-f832-eb67-5dd4-471ddf6b69c0.pdf}
}

@article{Amatriain2014,
  title = {Recommender {{Systems}} - {{Collaborative Filtering}} and Other Approaches},
  author = {Amatriain, Xavier Research (Engineering Director Netflix)},
  date = {2014},
  journaltitle = {Mlss},
  pages = {248},
  url = {http://de.slideshare.net/xamat/recommender-systems-machine-learning-summer-school-2014-cmu/17},
  abstract = {Insights on Recommender Systems at Netflix for the Machine Learning Summer School 2014 at CMU},
  issue = {July},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3WQFJWQ2/Amatriain - 2014 - Recommender Systems - Collaborative Filtering and other approaches.pdf}
}

@article{andrieuTutorialAdaptiveMCMC2008,
  title = {A Tutorial on Adaptive {{MCMC}}},
  author = {Andrieu, Christophe and Thoms, Johannes},
  date = {2008},
  pages = {343--373},
  doi = {10.1007/s11222-008-9110-y},
  issue = {December},
  keywords = {adaptive mcmc,also denoted π,assumed for simplicity to,controlled,from which,have a density with,markov chain,mcmc,measure,r n x,re-,spect to the lebesgue,stochastic approximation,x},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3KH7LHZV/Andrieu, Thoms - 2008 - A tutorial on adaptive MCMC.pdf}
}

@online{andTensorFlowLargeScaleMachine2005,
  title = {{{TensorFlow}}: {{Large-Scale Machine Learning}} on {{Heterogeneous Distributed Systems}}},
  author = {And, Mart\textbackslash '\{i\}n\textasciitilde Abadi and And, Ashish\textasciitilde Agarwal and And, Paul\textasciitilde Barham and And, Eugene\textasciitilde Brevdo and And, Zhifeng\textasciitilde Chen and And, Craig\textasciitilde Citro and And, Greg\textasciitilde S.\textasciitilde Corrado and And, Andy\textasciitilde Davis and And, Jeffrey\textasciitilde Dean and And, Matthieu\textasciitilde Devin and And, Sanjay\textasciitilde Ghemawat and And, Ian\textasciitilde Goodfellow and And, Andrew\textasciitilde Harp and And, Geoffrey\textasciitilde Irving and And, Michael\textasciitilde Isard and And, Yangqing Jia and And, Rafal\textasciitilde Jozefowicz and And, Lukasz\textasciitilde Kaiser and And, Manjunath\textasciitilde Kudlur and And, Josh\textasciitilde Levenberg and And, Dandelion\textasciitilde Man\textbackslash '\{e\} and And, Rajat\textasciitilde Monga and And, Sherry\textasciitilde Moore and And, Derek\textasciitilde Murray and And, Chris\textasciitilde Olah and And, Mike\textasciitilde Schuster and And, Jonathon\textasciitilde Shlens and And, Benoit\textasciitilde Steiner and And, Ilya\textasciitilde Sutskever and And, Kunal\textasciitilde Talwar and And, Paul\textasciitilde Tucker and And, Vincent\textasciitilde Vanhoucke and And, Vijay\textasciitilde Vasudevan and And, Fernanda\textasciitilde Vi\textbackslash '\{e\}gas and And, Oriol\textasciitilde Vinyals and And, Pete\textasciitilde Warden and And, Martin\textasciitilde Wattenberg and And, Martin\textasciitilde Wicke and And, Yuan\textasciitilde Yu and {Xiaoqiang\textasciitilde Zheng}},
  date = {2005},
  eprint = {16411492},
  eprinttype = {pmid},
  issn = {0954898X},
  doi = {10.1080/09548980500300507},
  url = {tensorflow.org},
  abstract = {TensorFlow [1] is an interface for expressing machine lea},
  organization = {Network: Computation in Neural Systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/8KT8ETZP/Rucci, Casile - 2005 - Fixational instability and natural image statistics Implications for early visual representations.pdf}
}

@article{asOrgNr9192020,
  title = {Org.Nr. 919 251 344 Mva - Arctic Datalab as Krav På Forsinkelsesrenter},
  author = {As, Arctic Datalab},
  date = {2020},
  isbn = {5876940518},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/95P29GG6/As - 2020 - Org.nr. 919 251 344 mva - arctic datalab as krav på forsinkelsesrenter.pdf}
}

@inproceedings{Azizzadenesheli2018,
  title = {Efficient Exploration through {{Bayesian}} Deep {{Q-networks}}},
  booktitle = {2018 {{Information Theory}} and {{Applications Workshop}}, {{ITA}} 2018},
  author = {Azizzadenesheli, Kamyar and Brunskill, Emma and Anandkumar, Animashree},
  date = {2018},
  eprint = {1802.04412v1},
  eprinttype = {arXiv},
  doi = {10.1109/ITA.2018.8503252},
  abstract = {We propose Bayesian Deep Q-Networks (BDQN), a Thompson sampling approach for Deep Reinforcement Learning (DRL) in Markov decision processes (MDP). BDQN is an efficient exploration-exploitation algorithm which combines Thompson sampling with deep-Q networks (DQN) and directly incorporates uncertainty over the Q-value in the last layer of the DQN, on the feature representation layer. This allows us to efficiently carry out Thompson sampling through Gaussian sampling and Bayesian Linear Regression (BLR), which has fast closed-form updates. We apply our method to a wide range of Atari games and compare BDQN to a powerful baseline: the double deep Q-network (DDQN). Since BDQN carries out more efficient exploration, it is able to reach higher rewards substantially faster: in less than 5M-+1M interactions for almost half of the games to reach DDQN scores. We also establish theoretical guarantees for the special case when the feature representation is d-dimensional and fixed. We provide the Bayesian regret of posterior sampling RL (PSRL) and frequentist regret of the optimism in the face of uncertainty (OFU) for episodic MDPs.},
  isbn = {978-1-72810-124-8},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/P2L6TKJS/m-api-301fe22a-4728-d685-59dc-5a4af527c044.pdf}
}

@unpublished{Bai2018,
  title = {An {{Empirical Evaluation}} of {{Generic Convolutional}} and {{Recurrent Networks}} for {{Sequence Modeling}}},
  author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
  date = {2018},
  eprint = {1803.01271},
  eprinttype = {arXiv},
  abstract = {For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YXGLLPUG/Bai, Kolter, Koltun - 2018 - An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling.pdf}
}

@article{Balandat2020,
  title = {{{BoTorch}}: {{A Framework}} for {{Efficient Monte-Carlo Bayesian Optimization}}},
  author = {Balandat, Maximilian and Karrer, Brian and Jiang, Daniel R. and Daulton, Samuel and Letham, Benjamin and Wilson, Andrew Gordon and Bakshy, Eytan},
  date = {2020-10-14},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  eprint = {1910.06403},
  eprinttype = {arXiv},
  pages = {21524--21538},
  url = {http://arxiv.org/abs/1910.06403},
  abstract = {Bayesian optimization provides sample-efficient global optimization for a broad range of applications, including automatic machine learning, engineering, physics, and experimental design. We introduce BoTorch, a modern programming framework for Bayesian optimization that combines Monte-Carlo (MC) acquisition functions, a novel sample average approximation optimization approach, auto-differentiation, and variance reduction techniques. BoTorch's modular design facilitates flexible specification and optimization of probabilistic models written in PyTorch, simplifying implementation of new acquisition functions. Our approach is backed by novel theoretical convergence results and made practical by a distinctive algorithmic foundation that leverages fast predictive distributions, hardware acceleration, and deterministic optimization. We also propose a novel "one-shot" formulation of the Knowledge Gradient, enabled by a combination of our theoretical and software contributions. In experiments, we demonstrate the improved sample efficiency of BoTorch relative to other popular libraries.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/2CTQ6IGM/Balandat et al. - 2019 - BoTorch Programmable Bayesian Optimization in PyTorch.pdf}
}

@inproceedings{Bansal2016,
  title = {Ask the {{GRU}}},
  author = {Bansal, Trapit and Belanger, David and McCallum, Andrew},
  date = {2016},
  eprint = {1609.02116},
  eprinttype = {arXiv},
  pages = {107--114},
  doi = {10.1145/2959100.2959180},
  abstract = {In a variety of application domains the content to be recommended to users is associated with text. This includes research papers, movies with associated plot summaries, news articles, blog posts, etc. Recommendation approaches based on latent factor models can be extended naturally to leverage text by employing an explicit mapping from text to factors. This enables recommendations for new, unseen content, and may generalize better, since the factors for all items are produced by a compactly-parametrized model. Previous work has used topic models or averages of word embeddings for this mapping. In this paper we present a method leveraging deep recurrent neural networks to encode the text sequence into a latent vector, specifically gated recurrent units (GRUs) trained end-to-end on the collaborative filtering task. For the task of scientific paper recommendation, this yields models with significantly higher accuracy. In cold-start scenarios, we beat the previous state-of-the-art, all of which ignore word order. Performance is further improved by multi-task learning, where the text encoder network is trained for a combination of content recommendation and item metadata prediction. This regularizes the collaborative filtering model, ameliorating the problem of sparsity of the observed rating matrix.},
  isbn = {978-1-4503-4035-9},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7TIMFVTC/Bansal et al. - 2016 - Ask the GRU.pdf}
}

@article{barnesImprovingSentimentAnalysis2021,
  title = {Improving {{Sentiment Analysis}} with {{Multi-task Learning}} of {{Negation}}},
  author = {Barnes, Jeremy and Velldal, Erik and Øvrelid, Lilja},
  date = {2021-03},
  journaltitle = {Natural Language Engineering},
  shortjournal = {Nat. Lang. Eng.},
  volume = {27},
  number = {2},
  eprint = {1906.07610},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {249--269},
  issn = {1351-3249, 1469-8110},
  doi = {10.1017/S1351324920000510},
  url = {http://arxiv.org/abs/1906.07610},
  urldate = {2024-02-12},
  abstract = {Sentiment analysis is directly affected by compositional phenomena in language that act on the prior polarity of the words and phrases found in the text. Negation is the most prevalent of these phenomena and in order to correctly predict sentiment, a classifier must be able to identify negation and disentangle the effect that its scope has on the final polarity of a text. This paper proposes a multi-task approach to explicitly incorporate information about negation in sentiment analysis, which we show outperforms learning negation implicitly in a data-driven manner. We describe our approach, a cascading neural architecture with selective sharing of LSTM layers, and show that explicitly training the model with negation as an auxiliary task helps improve the main task of sentiment analysis. The effect is demonstrated across several different standard English-language data sets for both tasks and we analyze several aspects of our system related to its performance, varying types and amounts of input data and different multi-task setups.},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/47FBMX7R/1906.07610.pdf}
}

@misc{Barto2015,
  title = {Reinforcement {{Learning}}: {{An Introduction}}},
  author = {Barto, Richard S. Sutton {and} Andrew G.},
  date = {2015},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/S6AXSF3U/Barto - 2015 - Reinforcement Learning An Introduction.pdf}
}

@inproceedings{Belletti2018,
  title = {Factorized {{Recurrent Neural Architectures}} for {{Longer Range Dependence}}},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Belletti, Francois and Chi, Ed H. and Beutel, Alex and Jain, Sagar and Chi, Ed H.},
  date = {2018},
  volume = {84},
  pages = {1522--1530},
  url = {https://ai.google/research/pubs/pub46850},
  urldate = {2018-12-20},
  abstract = {The ability to capture Long Range Dependence (LRD) in a stochastic process is of prime im-portance in the context of predictive models. A sequential model with a longer-term mem-ory is better able contextualize recent observa-tions. In this article, we apply the theory of LRD stochastic processes to modern recurrent archi-tectures, such as LSTMs and GRUs, and prove they do not provide LRD under assumptions suf-ficient for gradients to vanish. Motivated by an information-theoretic analysis, we provide a modified recurrent neural architecture that miti-gates the issue of faulty memory through redun-dancy while keeping the compute time constant. Experimental results on a synthetic copy task, the Youtube-8m video classification task and a recommender system show that we enable better memorization and longer-term memory.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GU598XUM/full-text.pdf}
}

@article{Bello,
  title = {{{Seq2Slate}}: {{Re-ranking}} and Slate Optimization with {{RNNs}}},
  author = {Bello, Irwan and Kulkarni, Sayali and Jain, Sagar and Boutilier, Craig and Chi, Ed and Eban, Elad and Luo, Xiyang and Mackey, Alan},
  date = {2018},
  journaltitle = {arXiv},
  eprint = {1810.02019},
  eprinttype = {arXiv},
  issn = {23318422},
  abstract = {Ranking is a central task in machine learning and information retrieval. In this task, it is especially important to present the user with a slate of items that is appealing as a whole. This in turn requires taking into account interactions between items, since intuitively, placing an item on the slate affects the decision of which other items should be placed alongside it. In this work, we propose a sequence-to-sequence model for ranking called seq2slate. At each step, the model predicts the next “best” item to place on the slate given the items already selected. The sequential nature of the model allows complex dependencies between the items to be captured directly in a flexible and scalable way. We show how to learn the model end-to-end from weak supervision in the form of easily obtained click-through data. We further demonstrate the usefulness of our approach in experiments on standard ranking benchmarks as well as in a real-world recommendation system.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SNSES5UP/m-api-14c9f01f-c203-7fd9-3b63-4217c9ee5410.pdf}
}

@article{beluchPowerEnsemblesActive2018,
  title = {The {{Power}} of {{Ensembles}} for {{Active Learning}} in {{Image Classification}}},
  author = {Beluch, William H. and Genewein, Tim and Nürnberger, Andreas and Köhler, Jan M.},
  date = {2018},
  journaltitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages = {9368--9377},
  issn = {10636919},
  doi = {10.1109/CVPR.2018.00976},
  abstract = {Deep learning methods have become the de-facto standard for challenging image processing tasks such as image classification. One major hurdle of deep learning approaches is that large sets of labeled data are necessary, which can be prohibitively costly to obtain, particularly in medical image diagnosis applications. Active learning techniques can alleviate this labeling effort. In this paper we investigate some recently proposed methods for active learning with high-dimensional data and convolutional neural network classifiers. We compare ensemble-based methods against Monte-Carlo Dropout and geometric approaches. We find that ensembles perform better and lead to more calibrated predictive uncertainties, which are the basis for many active learning algorithms. To investigate why Monte-Carlo Dropout uncertainties perform worse, we explore potential differences in isolation in a series of experiments. We show results for MNIST and CIFAR-10, on which we achieve a test set accuracy of 90\% with roughly 12,200 labeled images, and initial results on ImageNet. Additionally, we show results on a large, highly class-imbalanced diabetic retinopathy dataset. We observe that the ensemble-based active learning effectively counteracts this imbalance during acquisition.},
  isbn = {9781538664209},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LMRS3J6L/Beluch et al. - 2018 - The Power of Ensembles for Active Learning in Image Classification.pdf}
}

@inproceedings{bendadaCarouselPersonalizationMusic2020,
  title = {Carousel {{Personalization}} in {{Music Streaming Apps}} with {{Contextual Bandits}}},
  booktitle = {Fourteenth {{ACM Conference}} on {{Recommender Systems}}},
  author = {Bendada, Walid and Salha, Guillaume and Bontempelli, Théo},
  date = {2020-09-22},
  eprint = {2009.06546},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  pages = {420--425},
  doi = {10.1145/3383313.3412217},
  url = {http://arxiv.org/abs/2009.06546},
  urldate = {2023-01-02},
  abstract = {Media services providers, such as music streaming platforms, frequently leverage swipeable carousels to recommend personalized content to their users. However, selecting the most relevant items (albums, artists, playlists...) to display in these carousels is a challenging task, as items are numerous and as users have different preferences. In this paper, we model carousel personalization as a contextual multi-armed bandit problem with multiple plays, cascade-based updates and delayed batch feedback. We empirically show the effectiveness of our framework at capturing characteristics of real-world carousels by addressing a large-scale playlist recommendation task on a global music streaming mobile app. Along with this paper, we publicly release industrial data from our experiments, as well as an open-source environment to simulate comparable carousel personalization learning problems.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7XKQSMIS/Bendada et al. - 2020 - Carousel Personalization in Music Streaming Apps w.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/2XUWXHKB/2009.html}
}

@inproceedings{Beutel2018,
  title = {Latent {{Cross}}},
  author = {Jain, Sagar and Gatto, Vince and Li, Jia and Xu, Can and Chi, Ed H and Covington, Paul and Beutel, Alex},
  date = {2018},
  pages = {46--54},
  doi = {10.1145/3159652.3159727},
  url = {https://doi.org/10.1145/3159652.3159727},
  urldate = {2018-08-27},
  abstract = {The success of recommender systems often depends on their ability to understand and make use of the context of the recommenda- tion request. Signi cant research has focused on how time, loca- tion, interfaces, and a plethora of other contextual features a ect recommendations. However, in using deep neural networks for recommender systems, researchers often ignore these contexts or incorporate them as ordinary features in the model. In this paper, we study how to e ectively treat contextual data in neural recommender systems. We begin with an empirical analysis of the conventional approach to context as features in feed-forward recommenders and demonstrate that this approach is ine cient in capturing common feature crosses. We apply this insight to de- sign a state-of-the-art RNN recommender system. We rst describe our RNN-based recommender system in use at YouTube. Next, we o er “Latent Cross,” an easy-to-use technique to incorporate con- textual data in the RNN by embedding the context feature rst and then performing an element-wise product of the context embed- ding with model’s hidden states. We demonstrate the improvement in performance by using this Latent Cross technique in multiple experimental settings.},
  isbn = {978-1-4503-5581-0},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/EYJGBXLW/full-text.pdf}
}

@article{Bingham2018,
  title = {Pyro: {{Deep}} Universal Probabilistic Programming},
  author = {Bingham, Eli and Chen, Jonathan P. and Jankowiak, Martin and Obermeyer, F. and Pradhan, Neeraj and Karaletsos, Theofanis and Singh, Rohit and Szerlip, Paul and Horsfall, Paul and Goodman, Noah D.},
  date = {2018},
  journaltitle = {Journal of Machine Learning Research},
  volume = {20},
  eprint = {1810.09538},
  eprinttype = {arXiv},
  pages = {0--5},
  issn = {15337928},
  abstract = {Pyro is a probabilistic programming language built on Python as a platform for developing advanced probabilistic models in AI research. To scale to large data sets and high-dimensional models, Pyro uses stochastic variational inference algorithms and probability distributions built on top of PyTorch, a modern GPU-accelerated deep learning framework. To accommodate complex or model-specific algorithmic behavior, Pyro leverages Poutine, a library of composable building blocks for modifying the behavior of probabilistic programs.},
  issue = {Xxxx},
  keywords = {Approximate Bayesian inference,Deep learning,Generative models,Graphical models,Probabilistic programming},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BZ9TFZUW/Bingham et al. - 2018 - Pyro Deep universal probabilistic programming.pdf}
}

@article{blackP0VisionLanguageActionFlow,
  title = {Π0: {{A Vision-Language-Action Flow Model}} for {{General Robot Control}}},
  author = {Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and Jakubczak, Szymon and Jones, Tim and Ke, Liyiming and Levine, Sergey and Li-Bell, Adrian and Mothukuri, Mohith and Nair, Suraj and Pertsch, Karl and Shi, Lucy Xiaoyang and Tanner, James and Vuong, Quan and Walling, Anna and Wang, Haohuan and Zhilinsky, Ury},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DNTR26VH/Black et al. - π0 A Vision-Language-Action Flow Model for Genera.pdf}
}

@article{Blei2011,
  title = {Distance Dependent {{Chinese}} Restaurant Processes},
  author = {Blei, David M. and Frazier, Peter I.},
  date = {2011},
  journaltitle = {Journal of Machine Learning Research},
  volume = {12},
  eprint = {0910.1022},
  eprinttype = {arXiv},
  pages = {2461--2488},
  issn = {15324435},
  abstract = {We develop the distance dependent Chinese restaurant process, a flxible class of distributions over partitions that allows for dependencies between the elements. This class can be used to model many kinds of dependencies between data in infinit clustering models, including dependencies arising from time, space, and network connectivity. We examine the properties of the distance dependent CRP, discuss its connections to Bayesian nonparametric mixture models, and derive a Gibbs sampler for both fully observed and latent mixture settings. We study its empirical performance with three text corpora. We show that relaxing the assumption of exchangeability with distance dependent CRPs can provide a better fi to sequential data and network data. We also show that the distance dependent CRP representation of the traditional CRP mixture leads to a faster-mixing Gibbs sampling algorithm than the one based on the original formulation. © 2011 David M. Blei and Peter I. Frazier.},
  keywords = {Bayesian nonparametrics,Chinese restaurant processes},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/EJQ5FBEZ/Blei, Frazier - 2011 - Distance dependent Chinese restaurant processes.pdf}
}

@article{Blei2017,
  title = {Variational {{Inference}}: {{A Review}} for {{Statisticians}}},
  author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
  date = {2017},
  journaltitle = {Journal of the American Statistical Association},
  eprint = {303902},
  eprinttype = {pmid},
  issn = {1537274X},
  doi = {10.1080/01621459.2017.1285773},
  abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
  isbn = {1601.00670},
  keywords = {Algorithms,Computationally intensive methods,Statistical computing},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GZGIL82H/1601.00670.pdf}
}

@article{Blundell2015,
  title = {Weight Uncertainty in Neural Networks},
  author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  date = {2015},
  journaltitle = {32nd International Conference on Machine Learning, ICML 2015},
  volume = {2},
  eprint = {1505.05424},
  eprinttype = {arXiv},
  pages = {1613--1622},
  abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
  isbn = {9781510810587},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ENZETQZF/Blundell et al. - 2015 - Weight uncertainty in neural networks.pdf}
}

@book{Bogers2009,
  title = {Collaborative and Content-Based Filtering for Item Recommendation on Social Bookmarking Websites},
  author = {Bogers, Toine and Van Den Bosch, Antal},
  date = {2009},
  journaltitle = {CEUR Workshop Proceedings},
  volume = {532},
  eprint = {21607264},
  eprinttype = {pmid},
  issn = {16130073},
  doi = {10.1007/978-0-387-85820-3},
  abstract = {Social bookmarking websites allow users to store, organize, and search bookmarks of web pages. Users of these services can an- notate their bookmarks by using informal tags and other metadata, such as titles, descriptions, etc. In this paper, we focus on the task of item recommendation for social bookmarking websites, i.e. pre- dicting which unseen bookmarks a user might like based on his or her profile. We examine how we can incorporate the tags and other metadata into a nearest-neighbor collaborative filtering (CF) algo- rithm, by replacing the traditional usage-based similarity metrics by tag overlap, and by fusing tag-based similarity with usage-based similarity. In addition, we perform experiments with content-based filtering by using the metadata content to recommend interesting items. We generate recommendations directly based on Kullback- Leibler divergence of the metadata language models, and we ex- plore the use of this metadata in calculating user and item simi- larities. We perform our experiments on three data sets from two different domains: Delicious, CiteULike and BibSonomy.},
  isbn = {978-0-387-85819-7},
  pagetotal = {9-16},
  keywords = {Collaborative filtering,Content-based filtering,Folksonomies,Recommender systems,Social bookmarking},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/VW55GGW5/Bogers, Van Den Bosch - 2009 - Collaborative and content-based filtering for item recommendation on social bookmarking websites.pdf}
}

@article{Bonner2018,
  title = {Causal Embeddings for Recommendation},
  author = {Bonner, Stephen and Vasile, Flavian},
  date = {2018},
  journaltitle = {RecSys 2018 - 12th ACM Conference on Recommender Systems},
  eprint = {1706.07639},
  eprinttype = {arXiv},
  pages = {104--112},
  doi = {10.1145/3240323.3240360},
  abstract = {Many current applications use recommendations in order to modify the natural user behavior, such as to increase the number of sales or the time spent on a website. This results in a gap between the final recommendation objective and the classical setup where recommendation candidates are evaluated by their coherence with past user behavior, by predicting either the missing entries in the user-item matrix, or the most likely next event. To bridge this gap, we optimize a recommendation policy for the task of increasing the desired outcome versus the organic user behavior. We show this is equivalent to learning to predict recommendation outcomes under a fully random recommendation policy. To this end, we propose a new domain adaptation algorithm that learns from logged data containing outcomes from a biased recommendation policy and predicts recommendation outcomes according to random exposure. We compare our method against state-of-the-art factorization methods, in addition to new approaches of causal recommendation and show significant improvements.},
  isbn = {9781450359016},
  keywords = {Causality,Counterfactual Inference,Embeddings,Neural Networks,Recommender Systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SI9LV73B/Bonner, Vasile - 2018 - Causal embeddings for recommendation.pdf}
}

@article{Bottou2013,
  title = {Counterfactual Reasoning and Learning Systems: {{The}} Example of Computational Advertising},
  author = {Bottou, Léon and Peters, Jonas and Quiñonero-Candela, Joaquin and Charles, Denis X. and Chickering, D. Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  date = {2013},
  journaltitle = {Journal of Machine Learning Research},
  volume = {14},
  pages = {3207--3260},
  issn = {15324435},
  abstract = {This work shows how to leverage causal inference to understand the behavior of complex learning systems interacting with their environment and predict the consequences of changes to the system. Such predictions allow both humans and algorithms to select the changes that would have improved the system performance. This work is illustrated by experiments on the ad placement system associated with the Bing search engine. © 2013 Léon Bottou, Jonas Peters, Joaquin Quiñonero-Candela, Denis X. Charles, D. Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard and Ed Snelson.},
  keywords = {Causation,Computational advertising,Counterfactual reasoning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/8NPRCJSQ/Bottou et al. - 2013 - Counterfactual reasoning and learning systems The example of computational advertising.pdf}
}

@online{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  date = {2020-07-22},
  eprint = {2005.14165},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.14165},
  url = {http://arxiv.org/abs/2005.14165},
  urldate = {2023-01-15},
  abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  pubstate = {prepublished},
  version = {4},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DKEV6DEQ/NeurIPS-2020-language-models-are-few-shot-learners-Paper.pdf}
}

@unpublished{Brukhim2018,
  title = {Predict and {{Constrain}}: {{Modeling Cardinality}} in {{Deep Structured Prediction}}},
  author = {Brukhim, Nataly and Globerson, Amir},
  date = {2018},
  eprint = {1802.04721},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1802.04721},
  abstract = {Many machine learning problems require the prediction of multi-dimensional labels. Such structured prediction models can benefit from modeling dependencies between labels. Recently, several deep learning approaches to structured prediction have been proposed. Here we focus on capturing cardinality constraints in such models. Namely, constraining the number of non-zero labels that the model outputs. Such constraints have proven very useful in previous structured prediction approaches, but it is a challenge to introduce them into a deep learning framework. Here we show how to do this via a novel deep architecture. Our approach outperforms strong baselines, achieving state-of-the-art results on multi-label classification benchmarks.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/W45L2C2N/1802.04721.pdf}
}

@article{Bubeck2014,
  title = {Convex {{Optimization}}: {{Algorithms}} and {{Complexity}}},
  author = {Bubeck, Sébastien},
  date = {2014},
  journaltitle = {Foundations and Trends R in Machine Learning},
  volume = {8},
  number = {5},
  eprint = {18255791},
  eprinttype = {pmid},
  pages = {6--359},
  issn = {1935-8237},
  doi = {10.1561/2200000049},
  url = {http://arxiv.org/abs/1405.4980},
  abstract = {This monograph presents the main complexity theorems in convex optimization and their corresponding algorithms. Starting from the fundamental theory of black-box optimization, the material progresses towards recent advances in structural optimization and stochastic optimization. Our presentation of black-box optimization, strongly influenced by Nesterov's seminal book and Nemirovski's lecture notes, includes the analysis of cutting plane methods, as well as (accelerated) gradient descent schemes. We also pay special attention to non-Euclidean settings (relevant algorithms include Frank-Wolfe, mirror descent, and dual averaging) and discuss their relevance in machine learning. We provide a gentle introduction to structural optimization with FISTA (to optimize a sum of a smooth and a simple non-smooth term), saddle-point mirror prox (Nemirovski's alternative to Nesterov's smoothing), and a concise description of interior point methods. In stochastic optimization we discuss stochastic gradient descent, mini-batches, random coordinate descent, and sublinear algorithms. We also briefly touch upon convex relaxation of combinatorial problems and the use of randomness to round solutions, as well as random walks based methods.},
  isbn = {978-1-68083-089-7},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/K3VYNF9M/1609.04436.pdf}
}

@unpublished{Busa-Fekete2018,
  title = {Preference-Based {{Online Learning}} with {{Dueling Bandits}}: {{A Survey}}},
  author = {Busa-Fekete, Robert and Hüllermeier, Eyke and Mesaoudi-Paul, Adil El},
  date = {2018},
  eprint = {1807.11398},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1807.11398},
  urldate = {2018-08-21},
  abstract = {In machine learning, the notion of multi-armed bandits refers to a class of online learning problems, in which an agent is supposed to simultaneously explore and exploit a given set of choice alternatives in the course of a sequential decision process. In the standard setting, the agent learns from stochastic feedback in the form of real-valued rewards. In many applications, however, numerical reward signals are not readily available -- instead, only weaker information is provided, in particular relative preferences in the form of qualitative comparisons between pairs of alternatives. This observation has motivated the study of variants of the multi-armed bandit problem, in which more general representations are used both for the type of feedback to learn from and the target of prediction. The aim of this paper is to provide a survey of the state of the art in this field, referred to as preference-based multi-armed bandits or dueling bandits. To this end, we provide an overview of problems that have been considered in the literature as well as methods for tackling them. Our taxonomy is mainly based on the assumptions made by these methods about the data-generating process and, related to this, the properties of the preference-based feedback.},
  keywords = {cumulative regret,exploration/exploitation,Multi-armed bandits,online learning,PAC learning,preference learning,ranking,sample complexity,top-k selection},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5SKFVSXP/m-api-63392d3e-8f58-e10d-4416-f0c55de56530.pdf}
}

@unpublished{buzzicottiInferringTurbulentParameters2022,
  title = {Inferring {{Turbulent Parameters}} via {{Machine Learning}}},
  author = {Buzzicotti, Michele and Bonaccorso, Fabio and Biferale, Luca},
  date = {2022},
  number = {3},
  eprint = {2201.00732},
  eprinttype = {arXiv},
  pages = {1--13},
  url = {http://arxiv.org/abs/2201.00732},
  abstract = {We design a machine learning technique to solve the general problem of inferring physical parameters from the observation of turbulent flows, a relevant exercise in many theoretical and applied fields, from engineering to earth observation and astrophysics. Our approach is to train the machine learning system to regress the rotation frequency of the flow's reference frame, from the observation of the flow's velocity amplitude on a 2d plane extracted from the 3d domain. The machine learning approach consists of a Deep Convolutional Neural Network (DCNN) of the same kind developed in computer vision. The training and validation datasets are produced by means of fully resolved direct numerical simulations. This study shows interesting results from two different points of view. From the machine learning point of view it shows the potential of DCNN, reaching good results on such a particularly complex problem that goes well outside the limits of human vision. Second, from the physics point of view, it provides an example on how machine learning can be exploited in data analysis to infer information that would be inaccessible otherwise. Indeed, by comparing DCNN with the other possible Bayesian approaches, we find that DCNN yields to a much higher inference accuracy in all the examined cases.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZZFKGE6Q/Buzzicotti, Bonaccorso, Biferale - 2022 - Inferring Turbulent Parameters via Machine Learning.pdf}
}

@article{Cami2019,
  title = {User Preferences Modeling Using Dirichlet Process Mixture Model for a Content-Based Recommender System},
  author = {Cami, Bagher Rahimpour and Hassanpour, Hamid and Mashayekhi, Hoda},
  date = {2019-01-01},
  journaltitle = {Knowledge-Based Systems},
  volume = {163},
  pages = {644--655},
  publisher = {Elsevier B.V.},
  issn = {09507051},
  doi = {10.1016/j.knosys.2018.09.028},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705118304799},
  urldate = {2021-04-08},
  abstract = {Recommender systems have been developed to assist users in retrieving relevant resources. Collaborative and content-based filtering are two basic approaches that are used in recommender systems. The former employs the feedback of users with similar interests, while the latter is based on the feature of the selected resources by each user. Recommender systems can consider users’ behavior to more accurately estimate their preferences via a list of recommendations. However, the existing approaches rarely consider both interests and preferences of the users. Also, the dynamic nature of user behavior poses an additional challenge for recommender systems. In this paper, we consider the interactions of each individual user, and analyze them to propose a user model and capture user's interests. We construct the user model based on a Bayesian nonparametric framework, called the Dirichlet Process Mixture Model. The proposed model evolves following the dynamic nature of user behavior to adapt both the user interests and preferences. We implemented the proposed model and evaluated it using both the MovieLens dataset, and a real-world dataset that contains news tweets from five news channels (New York Times, BBC, CNN, Reuters and Associated Press). The experimental results and comparisons with several recently developed approaches show the superiority in accuracy of the proposed approach, and its ability to adapt with user behavior over time.},
  keywords = {Temporal content-based recommender systems,User behavior modeling,User preferences modeling},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/2B2EHZZN/Cami, Hassanpour, Mashayekhi - 2019 - User preferences modeling using dirichlet process mixture model for a content-based recommender sy.pdf}
}

@unpublished{caoAutomaticSelectionTSNE2017,
  title = {Automatic {{Selection}} of T-{{SNE Perplexity}}},
  author = {Cao, Yanshuai and Wang, Luyu},
  date = {2017},
  eprint = {1708.03229},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1708.03229},
  abstract = {t-Distributed Stochastic Neighbor Embedding (t-SNE) is one of the most widely used dimensionality reduction methods for data visualization, but it has a perplexity hyperparameter that requires manual selection. In practice, proper tuning of t-SNE perplexity requires users to understand the inner working of the method as well as to have hands-on experience. We propose a model selection objective for t-SNE perplexity that requires negligible extra computation beyond that of the t-SNE itself. We empirically validate that the perplexity settings found by our approach are consistent with preferences elicited from human experts across a number of datasets. The similarities of our approach to Bayesian information criteria (BIC) and minimum description length (MDL) are also analyzed.},
  issue = {September},
  keywords = {bayesian information criteria,hyperparameter tuning,perplexity,t-sne},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/PF9ISZN4/Cao, Wang - 2017 - Automatic Selection of t-SNE Perplexity.pdf}
}

@article{carboneRobustnessBayesianNeural2020,
  title = {Robustness of {{Bayesian}} Neural Networks to Gradient-Based Attacks},
  author = {Carbone, Ginevra and Wicker, Matthew and Laurenti, Luca and Patane, Andrea and Bortolussi, Luca and Sanguinetti, Guido},
  date = {2020},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {2020-Decem},
  eprint = {2002.04359},
  eprinttype = {arXiv},
  issn = {10495258},
  abstract = {Vulnerability to adversarial attacks is one of the principal hurdles to the adoption of deep learning in safety-critical applications. Despite significant efforts, both practical and theoretical, the problem remains open. In this paper, we analyse the geometry of adversarial attacks in the large-data, overparametrized limit for Bayesian Neural Networks (BNNs). We show that, in the limit, vulnerability to gradient-based attacks arises as a result of degeneracy in the data distribution, i.e., when the data lies on a lower-dimensional submanifold of the ambient space. As a direct consequence, we demonstrate that in the limit BNN posteriors are robust to gradient-based adversarial attacks. Experimental results on the MNIST and Fashion MNIST datasets, representing the finite data regime, with BNNs trained with Hamiltonian Monte Carlo and Variational Inference support this line of argument, showing that BNNs can display both high accuracy and robustness to gradient based adversarial attacks.},
  issue = {February},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/UADR46WZ/Carbone et al. - 2020 - Robustness of Bayesian neural networks to gradient-based attacks.pdf}
}

@unpublished{carlssonThompsonSamplingBandits2021,
  title = {Thompson {{Sampling}} for {{Bandits}} with {{Clustered Arms}}},
  author = {Carlsson, Emil and Dubhashi, Devdatt and Johansson, Fredrik D.},
  date = {2021},
  eprint = {2109.01656},
  eprinttype = {arXiv},
  pages = {2212--2218},
  doi = {10.24963/ijcai.2021/305},
  abstract = {We propose algorithms based on a multi-level Thompson sampling scheme, for the stochastic multi-armed bandit and its contextual variant with linear expected rewards, in the setting where arms are clustered. We show, both theoretically and empirically, how exploiting a given cluster structure can significantly improve the regret and computational cost compared to using standard Thompson sampling. In the case of the stochastic multi-armed bandit we give upper bounds on the expected cumulative regret showing how it depends on the quality of the clustering. Finally, we perform an empirical evaluation showing that our algorithms perform well compared to previously proposed algorithms for bandits with clustered arms.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZX9GU4H3/Carlsson, Dubhashi, Johansson - 2021 - Thompson Sampling for Bandits with Clustered Arms.pdf}
}

@article{caruanaMultitaskLearning1997,
  title = {Multitask {{Learning}}},
  author = {Caruana, Rich},
  date = {1997},
  journaltitle = {Machine learning 28},
  pages = {41--75},
  doi = {10.1023k},
  url = {https://link.springer.com/article/10.1023/A:1007379606734},
  abstract = {Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FXTZU4AM/Caruana - Multitask Learning.pdf}
}

@book{Chan2009a,
  title = {Quantitative {{Trading}} - {{How}} to {{Build Your Own Algorithmic Trading Business}}},
  author = {Chan, Ernest P.},
  date = {2009},
  isbn = {978-0-470-28488-9},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/A8AVG3Z7/Chan - 2009 - E R N E S T P . C H a N.pdf}
}

@article{Chaney2017,
  title = {How Algorithmic Confounding in Recommendation Systems Increases Homogeneity and Decreases Utility},
  author = {Chaney, Allison J.B. and Stewart, Brandon M. and Engelhardt, Barbara E.},
  date = {2017},
  journaltitle = {arXiv},
  eprint = {1710.11214},
  eprinttype = {arXiv},
  issn = {23318422},
  doi = {10.1145/3240323.3240370},
  abstract = {Recommendation systems are ubiquitous and impact many domains; they have the potential to infuence product consumption, individuals' perceptions of the world, and life-altering decisions. These systems are often evaluated or trained with data from users already exposed to algorithmic recommendations; this creates a pernicious feedback loop. Using simulations, we demonstrate how using data confounded in this way homogenizes user behavior without increasing utility.},
  isbn = {9781450359016},
  keywords = {Algorithmic confounding,Recommendation systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3SIMN46N/Chaney, Stewart, Engelhardt - 2017 - How algorithmic confounding in recommendation systems increases homogeneity and decreases utility.pdf}
}

@article{Chen2014a,
  title = {Stochastic Gradient {{Hamiltonian Monte Carlo}}},
  author = {Chen, Tianqi and Fox, Emily B. and Guestrin, Carlos},
  date = {2014},
  journaltitle = {31st International Conference on Machine Learning, ICML 2014},
  volume = {5},
  eprint = {1402.4102},
  eprinttype = {arXiv},
  pages = {3663--3676},
  abstract = {Hamiltonian Monte Carlo (HMC) sampling methods provide a mechanism for defining distant proposals with high acceptance probabilities in a Metropolis-Hastings framework, enabling more efficient exploration of the state space than standard random-walk proposals. The popularity of such methods has grown significantly in recen-t years. However, a limitation of HMC methods is the required gradient computation for simulation of the Hamiltonian dynamical system - such computation is infeasible in problems involving a large sample size or streaming data. Instead, we must rely on a noisy gradient estimate computed from a subset of the data. In this paper, we explore the properties of such a stochastic gradient HMC approach. Surprisingly, the natural implementation of the stochastic approximation can be arbitrarily bad. To address this problem we introduce a variant that uses second-order Langevin dynamics with a friction term that counteracts the effects of the noisy gradient, maintaining the desired target distribution as the invariant distribution. Results on simulated data validate our theory. We also provide an application of our methods to a classification task using neural networks and to online Bayesian matrix factorization.},
  isbn = {9781634393973},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/V3XGJUN4/Chen, Fox, Guestrin - 2014 - Stochastic gradient Hamiltonian Monte Carlo.pdf}
}

@article{Chen2016,
  title = {Exploiting Meta Features for Dependency Parsing and Part-of-Speech Tagging},
  author = {Chen, Wenliang and Zhang, Min and Zhang, Yue and Duan, Xiangyu},
  date = {2016},
  journaltitle = {Artificial Intelligence},
  volume = {230},
  eprint = {26150344},
  eprinttype = {pmid},
  pages = {173--191},
  issn = {00043702},
  doi = {10.1016/j.artint.2015.09.002},
  abstract = {In recent years, discriminative methods have achieved much progress in natural language processing tasks, such as parsing, part-of-speech tagging, and word segmentation. For these methods, conventional features in a relatively high dimensional feature space may suffer from sparseness and thus exhibit less discriminative power on unseen data. This article presents a learning framework of feature transformation, addressing the sparseness problem by transforming sparse conventional base features into less sparse high-level features (i.e. meta features) with the help of a large amount of automatically annotated data. The meta features are derived by bucketing similar base features according to the frequency in large data, and used together with base features in our final system. We apply the framework to part-of-speech tagging and dependency parsing. Experimental results show that our systems perform better than the baseline systems in both tasks on standard evaluation. For the dependency parsing task, our parsers achieve state-of-the-art accuracy on the Chinese data and comparable accuracy with the best known systems on the English data. Further analysis indicates that our proposed approach is effective in processing unseen data and features.},
  isbn = {0004-3702},
  keywords = {Dependency parsing,Meta-features,Natural language processing,Part-of-speech tagging,Semi-supervised approach},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5J87HF67/Chen et al. - 2016 - Exploiting meta features for dependency parsing an.pdf}
}

@article{Chen2017,
  title = {Improving Sentiment Analysis via Sentence Type Classification Using {{BiLSTM-CRF}} and {{CNN}}},
  author = {Chen, Tao and Xu, Ruifeng and He, Yulan and Wang, Xuan},
  date = {2017},
  journaltitle = {Expert Systems with Applications},
  volume = {72},
  eprint = {19932002},
  eprinttype = {pmid},
  pages = {221--230},
  issn = {09574174},
  doi = {10.1016/j.eswa.2016.10.065},
  abstract = {Different types of sentences express sentiment in very different ways. Traditional sentence-level sentiment classification research focuses on one-technique-fits-all solution or only centers on one special type of sentences. In this paper, we propose a divide-and-conquer approach which first classifies sentences into different types, then performs sentiment analysis separately on sentences from each type. Specifically, we find that sentences tend to be more complex if they contain more sentiment targets. Thus, we propose to first apply a neural network based sequence model to classify opinionated sentences into three types according to the number of targets appeared in a sentence. Each group of sentences is then fed into a one-dimensional convolutional neural network separately for sentiment classification. Our approach has been evaluated on four sentiment classification datasets and compared with a wide range of baselines. Experimental results show that: (1) sentence type classification can improve the performance of sentence-level sentiment analysis; (2) the proposed approach achieves state-of-the-art results on several benchmarking datasets.},
  isbn = {0925-2312},
  issue = {Dl},
  keywords = {Deep neural network,Natural language processing,Sentiment analysis},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/4V3WYG9N/Chen et al. - 2017 - Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN.pdf}
}

@article{Chen2019,
  title = {Top-k off-Policy Correction for a Reinforce Recommender System},
  author = {Chen, Minmin and Beutel, Alex and Covington, Paul and Jain, Sagar and Belletti, Francois and Chi, Ed H.},
  date = {2019},
  journaltitle = {WSDM 2019 - Proceedings of the 12th ACM International Conference on Web Search and Data Mining},
  eprint = {1812.02353},
  eprinttype = {arXiv},
  pages = {456--464},
  doi = {10.1145/3289600.3290999},
  abstract = {Industrial recommender systems deal with extremely large action spaces - many millions of items to recommend. Moreover, they need to serve billions of users, who are unique at any point in time, making a complex user state space. Luckily, huge quantities of logged implicit feedback (e.g., user clicks, dwell time) are available for learning. Learning from the logged feedback is however subject to biases caused by only observing feedback on recommendations selected by the previous versions of the recommender. In this work, we present a general recipe of addressing such biases in a production top-K recommender system at YouTube, built with a policy-gradient-based algorithm, i.e. REINFORCE [48]. The contributions of the paper are: (1) scaling REINFORCE to a production recommender system with an action space on the orders of millions; (2) applying off-policy correction to address data biases in learning from logged feedback collected from multiple behavior policies; (3) proposing a novel top-K off-policy correction to account for our policy recommending multiple items at a time; (4) showcasing the value of exploration. We demonstrate the efficacy of our approaches through a series of simulations and multiple live experiments on YouTube.},
  isbn = {9781450359405},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DUUW3F8Z/Chen et al. - 2019 - Top-k off-policy correction for a reinforce recommender system.pdf}
}

@online{chenChatGPTOneyearAnniversary2023,
  title = {{{ChatGPT}}'s {{One-year Anniversary}}: {{Are Open-Source Large Language Models Catching}} Up?},
  shorttitle = {{{ChatGPT}}'s {{One-year Anniversary}}},
  author = {Chen, Hailin and Jiao, Fangkai and Li, Xingxuan and Qin, Chengwei and Ravaut, Mathieu and Zhao, Ruochen and Xiong, Caiming and Joty, Shafiq},
  date = {2023-11-29},
  eprint = {2311.16989},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2311.16989},
  urldate = {2023-12-02},
  abstract = {Upon its release in late 2022, ChatGPT has brought a seismic shift in the entire landscape of AI, both in research and commerce. Through instruction-tuning a large language model (LLM) with supervised fine-tuning and reinforcement learning from human feedback, it showed that a model could answer human questions and follow instructions on a broad panel of tasks. Following this success, interests in LLMs have intensified, with new LLMs flourishing at frequent interval across academia and industry, including many start-ups focused on LLMs. While closedsource LLMs (e.g., OpenAI’s GPT, Anthropic’s Claude) generally outperform their open-source counterparts, the progress on the latter has been rapid with claims of achieving parity or even better on certain tasks. This has crucial implications not only on research but also on business. In this work, on the first anniversary of ChatGPT, we provide an exhaustive overview of this success, surveying all tasks where an open-source LLM has claimed to be on par or better than ChatGPT.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LEZW2MMF/Chen et al. - 2023 - ChatGPT's One-year Anniversary Are Open-Source La.pdf}
}

@online{chenF5TTSFairytalerThat2024,
  title = {F5-{{TTS}}: {{A Fairytaler}} That {{Fakes Fluent}} and {{Faithful Speech}} with {{Flow Matching}}},
  shorttitle = {F5-{{TTS}}},
  author = {Chen, Yushen and Niu, Zhikang and Ma, Ziyang and Deng, Keqi and Wang, Chunhui and Zhao, Jian and Yu, Kai and Chen, Xie},
  date = {2024-10-15},
  eprint = {2410.06885},
  eprinttype = {arXiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2410.06885},
  url = {http://arxiv.org/abs/2410.06885},
  urldate = {2024-11-25},
  abstract = {This paper introduces F5-TTS, a fully non-autoregressive text-to-speech system based on flow matching with Diffusion Transformer (DiT). Without requiring complex designs such as duration model, text encoder, and phoneme alignment, the text input is simply padded with filler tokens to the same length as input speech, and then the denoising is performed for speech generation, which was originally proved feasible by E2 TTS. However, the original design of E2 TTS makes it hard to follow due to its slow convergence and low robustness. To address these issues, we first model the input with ConvNeXt to refine the text representation, making it easy to align with the speech. We further propose an inference-time Sway Sampling strategy, which significantly improves our model’s performance and efficiency. This sampling strategy for flow step can be easily applied to existing flow matching based models without retraining. Our design allows faster training and achieves an inference RTF of 0.15, which is greatly improved compared to state-of-the-art diffusion-based TTS models. Trained on a public 100K hours multilingual dataset, our Fairytaler Fakes Fluent and Faithful speech with Flow matching (F5-TTS) exhibits highly natural and expressive zero-shot ability, seamless code-switching capability, and speed control efficiency. Demo samples can be found at https://SWivid.github.io/F5-TTS. We release all code and checkpoints to promote community development2.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IWCMQJGF/Chen et al. - 2024 - F5-TTS A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching.pdf}
}

@article{Cheng2016,
  title = {Wide \& {{Deep Learning}} for {{Recommender Systems}}},
  author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
  date = {2016},
  journaltitle = {arXiv preprint},
  eprint = {1606.07792},
  eprinttype = {arXiv},
  pages = {1--4},
  doi = {10.1145/2988450.2988454},
  url = {http://arxiv.org/abs/1606.07792},
  abstract = {Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide \& Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide \& Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.},
  isbn = {9781450347952},
  keywords = {deep learning,recommender systems,wide},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/S2EC2DUG/Cheng et al. - 2016 - Wide & Deep Learning for Recommender Systems.pdf}
}

@online{chenNeuralOrdinaryDifferential2019,
  title = {Neural {{Ordinary Differential Equations}}},
  author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  date = {2019-12-13},
  eprint = {1806.07366},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1806.07366},
  url = {http://arxiv.org/abs/1806.07366},
  urldate = {2023-02-19},
  abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/A6A6HGW6/Chen et al. - 2019 - Neural Ordinary Differential Equations.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/KGQ8YFPG/1806.html}
}

@online{chenUnderstandingMixtureExperts2022,
  title = {Towards {{Understanding Mixture}} of {{Experts}} in {{Deep Learning}}},
  author = {Chen, Zixiang and Deng, Yihe and Wu, Yue and Gu, Quanquan and Li, Yuanzhi},
  date = {2022-08-04},
  eprint = {2208.02813},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2208.02813},
  urldate = {2023-12-09},
  abstract = {The Mixture-of-Experts (MoE) layer, a sparsely-activated model controlled by a router, has achieved great success in deep learning. However, the understanding of such architecture remains elusive. In this paper, we formally study how the MoE layer improves the performance of neural network learning and why the mixture model will not collapse into a single model. Our empirical results suggest that the cluster structure of the underlying problem and the non-linearity of the expert are pivotal to the success of MoE. To further understand this, we consider a challenging classification problem with intrinsic cluster structures, which is hard to learn using a single expert. Yet with the MoE layer, by choosing the experts as two-layer nonlinear convolutional neural networks (CNNs), we show that the problem can be learned successfully. Furthermore, our theory shows that the router can learn the cluster-center features, which helps divide the input complex problem into simpler linear classification sub-problems that individual experts can conquer. To our knowledge, this is the first result towards formally understanding the mechanism of the MoE layer for deep learning.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/XV9KFWRN/Chen et al. - 2022 - Towards Understanding Mixture of Experts in Deep L.pdf}
}

@article{chiangChatGPTBlurryJPEG2023,
  entrysubtype = {magazine},
  title = {{{ChatGPT Is}} a {{Blurry JPEG}} of the {{Web}}},
  author = {Chiang, Ted},
  date = {2023-02-09},
  journaltitle = {The New Yorker},
  issn = {0028-792X},
  url = {https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web},
  urldate = {2023-03-19},
  abstract = {OpenAI’s chatbot offers paraphrases, whereas Google offers quotes. Which do we prefer?},
  langid = {american},
  keywords = {algorithms,artificial intelligence (a.i.),images,internet,technology,writing},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ULXP7VBX/chatgpt-is-a-blurry-jpeg-of-the-web.html}
}

@inproceedings{chiDiffusionPolicyVisuomotor2023,
  title = {Diffusion {{Policy}}: {{Visuomotor Policy Learning}} via {{Action Diffusion}}},
  shorttitle = {Diffusion {{Policy}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
  date = {2023-07-10},
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2023.XIX.026},
  url = {http://www.roboticsproceedings.org/rss19/p026.pdf},
  urldate = {2024-09-27},
  eventtitle = {Robotics: {{Science}} and {{Systems}} 2023},
  isbn = {978-0-9923747-9-2},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/NW6CG8Z7/diffusion_policy_ijrr.pdf}
}

@article{chipmanBayesianEnsembleLearning2007,
  title = {Bayesian Ensemble Learning},
  author = {Chipman, Hugh A. and George, Edward I. and McCulloch, Robert E.},
  date = {2007},
  journaltitle = {Advances in Neural Information Processing Systems},
  pages = {265--272},
  issn = {10495258},
  doi = {10.7551/mitpress/7503.003.0038},
  abstract = {We develop a Bayesian "sum-of-trees" model, named BART, where each tree is constrained by a prior to be a weak learner. Fitting and inference are accomplished via an iterative backfitting MCMC algorithm. This model is motivated by ensemble methods in general, and boosting algorithms in particular. Like boosting, each weak learner (i.e., each weak tree) contributes a small amount to the overall model. However, our procedure is defined by a statistical model: a prior and a likelihood, while boosting is defined by an algorithm. This model-based approach enables a full and accurate assessment of uncertainty in model predictions, while remaining highly competitive in terms of predictive accuracy.},
  isbn = {9780262195683},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/UTX3RFDI/Chipman, George, McCulloch - 2007 - Bayesian ensemble learning.pdf}
}

@inproceedings{Cho2014,
  title = {Learning {{Phrase Representations}} Using {{RNN Encoder}}–{{Decoder}} for {{Statistical Machine Translation}}},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Cho, Kyunghyun and family=Merrienboer, given=Bart, prefix=van, useprefix=true and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  date = {2014-06-03},
  eprint = {1406.1078},
  eprinttype = {arXiv},
  pages = {1724--1734},
  publisher = {Association for Computational Linguistics},
  location = {Stroudsburg, PA, USA},
  doi = {10.3115/v1/D14-1179},
  url = {http://arxiv.org/abs/1406.1078},
  urldate = {2019-06-05},
  abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/G95TMR2C/full-text.pdf}
}

@unpublished{Choi2017,
  title = {{{StarGAN}}: {{Unified Generative Adversarial Networks}} for {{Multi-Domain Image-to-Image Translation}}},
  author = {Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
  date = {2017-11-24},
  eprint = {172668},
  eprinttype = {pmid},
  issn = {0717-6163},
  doi = {10.1016/J.PHYSLETB.2017.12.053},
  url = {http://arxiv.org/abs/1711.09020},
  urldate = {2017-11-28},
  abstract = {Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.},
  isbn = {9781467398947},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YXV77BJT/Choi et al. - 2017 - StarGAN Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation.pdf}
}

@unpublished{Choi2018,
  title = {Reinforcement {{Learning}} Based {{Recommender System}} Using {{Biclustering Technique}}},
  author = {Choi, Sungwoon and Ha, Heonseok and Hwang, Uiwon and Kim, Chanju and Ha, Jung-Woo and Yoon, Sungroh},
  date = {2018-01-16},
  eprint = {1801.05532},
  eprinttype = {arXiv},
  url = {https://doi.org/10.475/123_4},
  urldate = {2018-04-25},
  abstract = {A recommender system aims to recommend items that a user is interested in among many items. The need for the recommender system has been expanded by the information explosion. Various approaches have been suggested for providing meaningful recommendations to users. One of the proposed approaches is to consider a recommender system as a Markov decision process (MDP) problem and try to solve it using reinforcement learning (RL). However, existing RL-based methods have an obvious drawback. To solve an MDP in a recommender system, they encountered a problem with the large number of discrete actions that bring RL to a larger class of problems. In this paper, we propose a novel RL-based recommender system. We formulate a recommender system as a gridworld game by using a biclustering technique that can reduce the state and action space significantly. Using biclustering not only reduces space but also improves the recommendation quality effectively handling the cold-start problem. In addition, our approach can provide users with some explanation why the system recommends certain items. Lastly, we examine the proposed algorithm on a real-world dataset and achieve a better performance than the widely used recommendation algorithm.},
  isbn = {1234567245},
  keywords = {Biclustering,KEYWORDS Recommender System,Markov Decision Process,Reinforcement Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AWYEU2R4/Choi et al. - 2018 - Reinforcement Learning based Recommender System using Biclustering Technique.pdf}
}

@unpublished{chowdheryPaLMScalingLanguage2022,
  title = {{{PaLM}}: {{Scaling Language Modeling}} with {{Pathways}}},
  author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  date = {2022},
  eprint = {2204.02311},
  eprinttype = {arXiv},
  pages = {1--83},
  url = {http://arxiv.org/abs/2204.02311},
  abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/33LSDM87/Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf}
}

@article{Chua2018,
  title = {Deep {{Reinforcement Learning}} in a {{Handful}} of {{Trials}} Using {{Probabilistic Dynamics Models}}},
  author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  date = {2018},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {2018-Decem},
  eprint = {1805.12114},
  eprinttype = {arXiv},
  pages = {4754--4765},
  issn = {10495258},
  abstract = {Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).},
  issue = {NeurIPS},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/26LW68F7/Chua et al. - 2018 - Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models.pdf}
}

@article{clearyCalibrateEmulateSample2021,
  title = {Calibrate, Emulate, Sample},
  author = {Cleary, Emmet and Garbuno-Inigo, Alfredo and Lan, Shiwei and Schneider, Tapio and Stuart, Andrew M.},
  date = {2021},
  journaltitle = {Journal of Computational Physics},
  volume = {424},
  eprint = {2001.03689},
  eprinttype = {arXiv},
  pages = {1--27},
  issn = {10902716},
  doi = {10.1016/j.jcp.2020.109716},
  abstract = {Many parameter estimation problems arising in applications can be cast in the framework of Bayesian inversion. This allows not only for an estimate of the parameters, but also for the quantification of uncertainties in the estimates. Often in such problems the parameter-to-data map is very expensive to evaluate, and computing derivatives of the map, or derivative-adjoints, may not be feasible. Additionally, in many applications only noisy evaluations of the map may be available. We propose an approach to Bayesian inversion in such settings that builds on the derivative-free optimization capabilities of ensemble Kalman inversion methods. The overarching approach is to first use ensemble Kalman sampling (EKS) to calibrate the unknown parameters to fit the data; second, to use the output of the EKS to emulate the parameter-to-data map; third, to sample from an approximate Bayesian posterior distribution in which the parameter-to-data map is replaced by its emulator. This results in a principled approach to approximate Bayesian inference that requires only a small number of evaluations of the (possibly noisy approximation of the) parameter-to-data map. It does not require derivatives of this map, but instead leverages the documented power of ensemble Kalman methods. Furthermore, the EKS has the desirable property that it evolves the parameter ensemble towards the regions in which the bulk of the parameter posterior mass is located, thereby locating them well for the emulation phase of the methodology. In essence, the EKS methodology provides a cheap solution to the design problem of where to place points in parameter space to efficiently train an emulator of the parameter-to-data map for the purposes of Bayesian inversion.},
  keywords = {Approximate Bayesian inversion,Ensemble Kalman sampling,Experimental design,Gaussian process emulation,Uncertainty quantification},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BNASZVLL/Cleary et al. - 2021 - Calibrate, emulate, sample.pdf}
}

@online{CodeLlamaOpen,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}} | {{Research}} - {{AI}} at {{Meta}}},
  url = {https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/},
  urldate = {2024-01-23},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/P4KPLIFN/code-llama-open-foundation-models-for-code.html}
}

@online{ConvolutionalMethodsText,
  title = {Convolutional {{Methods}} for {{Text}} – {{Tal Perry}} – {{Medium}}},
  url = {https://medium.com/@TalPerry/convolutional-methods-for-text-d5260fd5675f},
  urldate = {2017-08-25}
}

@article{Covington2016,
  title = {Deep {{Neural Networks}} for {{YouTube Recommendations}}},
  author = {Covington, Paul and Adams, Jay and Sargin, Emre},
  date = {2016},
  journaltitle = {Proceedings of the 10th ACM Conference on Recommender Systems - RecSys '16},
  pages = {191--198},
  doi = {10.1145/2959100.2959190},
  url = {http://dl.acm.org/citation.cfm?doid=2959100.2959190},
  abstract = {YouTube represents one of the largest scale and most sophis-ticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and fo-cus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a sepa-rate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintain-ing a massive recommendation system with enormous user-facing impact.},
  isbn = {9781450340359},
  keywords = {deep learning,recommender system,scalability},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/6FGPA4ZT/Covington, Adams, Sargin - 2016 - Deep Neural Networks for YouTube Recommendations.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/7SA7N2JX/45530.pdf}
}

@online{criteo,
  title = {Criteo {{1TB Click Logs}} Dataset},
  author = {{Criteo}},
  date = {2020},
  url = {https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/}
}

@article{Dabney,
  title = {Implicit {{Quantile Networks}} for {{Distributional Reinforcement Learning}}},
  author = {Dabney, Will and Ostrovski, Georg and Silver, David and Munos, Rémi},
  abstract = {In this work, we build on recent advances in dis-tributional reinforcement learning to give a gener-ally applicable, flexible, and state-of-the-art dis-tributional variant of DQN. We achieve this by using quantile regression to approximate the full quantile function for the state-action return distri-bution. By reparameterizing a distribution over the sample space, this yields an implicitly defined return distribution and gives rise to a large class of risk-sensitive policies. We demonstrate improved performance on the 57 Atari 2600 games in the ALE, and use our algorithm's implicitly defined distributions to study the effects of risk-sensitive policies in Atari games.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TYP686KP/1806.06923.pdf}
}

@unpublished{Dabney2017,
  title = {Distributional {{Reinforcement Learning}} with {{Quantile Regression}}},
  author = {Dabney, Will and Rowland, Mark and Bellemare, Marc G. and Munos, Rémi},
  date = {2017-10-27},
  eprint = {1710.10044},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1710.10044},
  urldate = {2018-07-21},
  abstract = {In reinforcement learning an agent interacts with the environment by taking actions and observing the next state and reward. When sampled probabilistically, these state transitions, rewards, and actions can all induce randomness in the observed long-term return. Traditionally, reinforcement learning algorithms average over this randomness to estimate the value function. In this paper, we build on recent work advocating a distributional approach to reinforcement learning in which the distribution over returns is modeled explicitly instead of only estimating the mean. That is, we examine methods of learning the value distribution instead of the value function. We give results that close a number of gaps between the theoretical and algorithmic results given by Bellemare, Dabney, and Munos (2017). First, we extend existing results to the approximate distribution setting. Second, we present a novel distributional reinforcement learning algorithm consistent with our theoretical formulation. Finally, we evaluate this new algorithm on the Atari 2600 games, observing that it significantly outperforms many of the recent improvements on DQN, including the related distributional algorithm C51.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/CKNX5N93/full-text.pdf}
}

@unpublished{Dacrema2019,
  title = {Are {{We Really Making Much Progress}}? {{A Worrying Analysis}} of {{Recent Neural Recommendation Approaches}}},
  author = {Dacrema, Maurizio Ferrari and Cremonesi, Paolo and Jannach, Dietmar},
  date = {2019-07-16},
  eprint = {1907.06902},
  eprinttype = {arXiv},
  doi = {10.1145/3298689.3347058},
  url = {http://arxiv.org/abs/1907.06902},
  abstract = {Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general, it has, as a result, become difficult to keep track of what represents the state-of-the-art at the moment, e.g., for top-n recommendation tasks. At the same time, several recent publications point out problems in today's research practice in applied machine learning, e.g., in terms of the reproducibility of the results or the choice of the baselines when proposing new models. In this work, we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifically, we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable effort. For these methods, it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods, e.g., based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall, our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientific practices in this area. Source code of our experiments and full results are available at: https://github.com/MaurizioFD/RecSys2019\_DeepLearning\_Evaluation.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/JPDU624I/1907.06902.pdf}
}

@unpublished{Daian2019,
  title = {Flash {{Boys}} 2.0: {{Frontrunning}}, {{Transaction Reordering}}, and {{Consensus Instability}} in {{Decentralized Exchanges}}},
  author = {Daian, Philip and Goldfeder, Steven and Kell, Tyler and Li, Yunqi and Zhao, Xueyuan and Bentov, Iddo and Breidenbach, Lorenz and Juels, Ari},
  date = {2019},
  eprint = {1904.05234},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1904.05234},
  abstract = {Blockchains, and specifically smart contracts, have promised to create fair and transparent trading ecosystems. Unfortunately, we show that this promise has not been met. We document and quantify the widespread and rising deployment of arbitrage bots in blockchain systems, specifically in decentralized exchanges (or "DEXes"). Like high-frequency traders on Wall Street, these bots exploit inefficiencies in DEXes, paying high transaction fees and optimizing network latency to frontrun, i.e., anticipate and exploit, ordinary users' DEX trades. We study the breadth of DEX arbitrage bots in a subset of transactions that yield quantifiable revenue to these bots. We also study bots' profit-making strategies, with a focus on blockchain-specific elements. We observe bots engage in what we call priority gas auctions (PGAs), competitively bidding up transaction fees in order to obtain priority ordering, i.e., early block position and execution, for their transactions. PGAs present an interesting and complex new continuous-time, partial-information, game-theoretic model that we formalize and study. We release an interactive web portal, http://frontrun.me/, to provide the community with real-time data on PGAs. We additionally show that high fees paid for priority transaction ordering poses a systemic risk to consensus-layer security. We explain that such fees are just one form of a general phenomenon in DEXes and beyond---what we call miner extractable value (MEV)---that poses concrete, measurable, consensus-layer security risks. We show empirically that MEV poses a realistic threat to Ethereum today. Our work highlights the large, complex risks created by transaction-ordering dependencies in smart contracts and the ways in which traditional forms of financial-market exploitation are adapting to and penetrating blockchain economies.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BI3B3U7J/Daian et al. - 2019 - Flash Boys 2.0 Frontrunning, Transaction Reordering, and Consensus Instability in Decentralized Exchanges.pdf}
}

@unpublished{DanielFreeman2019,
  title = {Learning to {{Predict Without Looking Ahead}}: {{World Models Without Forward Prediction}}},
  author = {Daniel Freeman, C and Metz, Luke and Ha, David},
  date = {2019},
  number = {9},
  eprint = {1910.13038v1},
  eprinttype = {arXiv},
  pages = {1--17},
  abstract = {Much of model-based reinforcement learning (RL) involves learning a model of an agent's world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware-e.g., a brain-arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we provide an example modification to traditional reinforcement learning we call observational dropout, whereby we artificially constrain the probability that an agent is allowed to observe its real environment at each step. In doing so, we can coerce an agent into learning a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/PGFZ2HE8/Daniel Freeman, Metz, Ha - 2019 - Learning to Predict Without Looking Ahead World Models Without Forward Prediction.pdf}
}

@unpublished{DeBoom2017,
  title = {Large-{{Scale User Modeling}} with {{Recurrent Neural Networks}} for {{Music Discovery}} on {{Multiple Time Scales}}},
  author = {De Boom, Cedric and Agrawal, Rohan and Hansen, Samantha and Kumar, Esh and Yon, Romain and Chen, Ching-Wei and Demeester, Thomas and Dhoedt, Bart},
  date = {2017-08-22},
  eprint = {1708.06520},
  eprinttype = {arXiv},
  doi = {10.1007/s11042-017-5121-z},
  url = {http://arxiv.org/abs/1708.06520},
  urldate = {2017-08-24},
  abstract = {The amount of content on online music streaming platforms is immense, and most users only access a tiny fraction of this content. Recommender systems are the application of choice to open up the collection to these users. Collaborative filtering has the disadvantage that it relies on explicit ratings, which are often unavailable, and generally disregards the temporal nature of music consumption. On the other hand, item co-occurrence algorithms, such as the recently introduced word2vec-based recommenders, are typically left without an effective user representation. In this paper, we present a new approach to model users through recurrent neural networks by sequentially processing consumed items, represented by any type of embeddings and other context features. This way we obtain semantically rich user representations, which capture a user's musical taste over time. Our experimental analysis on large-scale user data shows that our model can be used to predict future songs a user will likely listen to, both in the short and long term.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LBN54VQ7/De Boom et al. - 2017 - Large-Scale User Modeling with Recurrent Neural Networks for Music Discovery on Multiple Time Scales.pdf}
}

@article{Deisenroth2011,
  title = {{{PILCO}}: {{A}} Model-Based and Data-Efficient Approach to Policy Search},
  author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward},
  date = {2011},
  journaltitle = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
  pages = {465--472},
  abstract = {In this paper, we introduce PILCO, a practical, data-efficient model-based policy search method. PILCO reduces model bias, one of the key problems of model-based reinforcement learning, in a principled way. By learning a probabilistic dynamics model and explicitly incorporating model uncertainty into long-term planning, PILCO can cope with very little data and facilitates learning from scratch in only a few trials. Policy evaluation is performed in closed form using state-of-the-art approximate inference. Furthermore, policy gradients are computed analytically for policy improvement. We report unprecedented learning efficiency on challenging and high-dimensional control tasks. Copyright 2011 by the author(s)/owner(s).},
  isbn = {9781450306195},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FXVEVS3D/Deisenroth, Rasmussen - 2011 - PILCO A model-based and data-efficient approach to policy search.pdf}
}

@unpublished{deldjooSurveyResearchFair2022,
  title = {A {{Survey}} of {{Research}} on {{Fair Recommender Systems}}},
  author = {Deldjoo, Yashar and Jannach, Dietmar and Bellogin, Alejandro and Diffonzo, Alessandro and Zanzonelli, Dario},
  date = {2022},
  eprint = {2205.11127},
  eprinttype = {arXiv},
  pages = {1--35},
  url = {http://arxiv.org/abs/2205.11127},
  abstract = {Recommender systems can strongly influence which information we see online, e.g, on social media, and thus impact our beliefs, decisions, and actions. At the same time, these systems can create substantial business value for different stakeholders. Given the growing potential impact of such AI-based systems on individuals, organizations, and society, questions of fairness have gained increased attention in recent years. However, research on fairness in recommender systems is still a developing area. In this survey, we first review the fundamental concepts and notions of fairness that were put forward in the area in the recent past. Afterward, we provide a survey of how research in this area is currently operationalized, for example, in terms of the general research methodology, fairness metrics, and algorithmic approaches. Overall, our analysis of recent works points to certain research gaps. In particular, we find that in many research works in computer science very abstract problem operationalizations are prevalent, which circumvent the fundamental and important question of what represents a fair recommendation in the context of a given application.},
  keywords = {fairness,recommender systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/XY3PMCM4/Deldjoo et al. - 2022 - A Survey of Research on Fair Recommender Systems.pdf}
}

@article{Deng2013,
  title = {Deep {{Learning}}: {{Methods}} and {{Applications}}},
  author = {Deng, Li and Yu, Dong},
  date = {2013},
  journaltitle = {Foundations and Trends® in Signal Processing},
  volume = {7},
  number = {3-4},
  eprint = {10463930},
  eprinttype = {pmid},
  pages = {197--387},
  issn = {09598138},
  doi = {10.1136/bmj.319.7209.0a},
  abstract = {This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning. In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme. In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.},
  isbn = {9781405161251},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7Q6JNFML/Deng, Yu - 2013 - Deep Learning Methods and Applications.pdf}
}

@unpublished{Depeweg2016,
  title = {Learning and {{Policy Search}} in {{Stochastic Dynamical Systems}} with {{Bayesian Neural Networks}}},
  author = {Depeweg, Stefan and Hernández-Lobato, José Miguel and Doshi-Velez, Finale and Udluft, Steffen},
  date = {2016},
  eprint = {1605.07127},
  eprinttype = {arXiv},
  pages = {1--14},
  url = {http://arxiv.org/abs/1605.07127},
  abstract = {We present an algorithm for model-based reinforcement learning that combines Bayesian neural networks (BNNs) with random roll-outs and stochastic optimization for policy learning. The BNNs are trained by minimizing \$\textbackslash alpha\$-divergences, allowing us to capture complicated statistical patterns in the transition dynamics, e.g. multi-modality and heteroskedasticity, which are usually missed by other common modeling approaches. We illustrate the performance of our method by solving a challenging benchmark where model-based approaches usually fail and by obtaining promising results in a real-world scenario for controlling a gas turbine.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LABIUCMS/Depeweg et al. - 2016 - Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks.pdf}
}

@unpublished{Dimakopoulou2018,
  title = {Scalable {{Coordinated Exploration}} in {{Concurrent Reinforcement Learning}}},
  author = {Dimakopoulou, Maria and Osband, Ian and Van Roy, Benjamin},
  date = {2018},
  eprint = {25130058},
  eprinttype = {pmid},
  issn = {20452322},
  doi = {10.1038/s41598-017-09968-7},
  url = {http://arxiv.org/abs/1805.08948},
  abstract = {We consider a team of reinforcement learning agents that concurrently operate in a common environment, and we develop an approach to efficient coordinated exploration that is suitable for problems of practical scale. Our approach builds on seed sampling (Dimakopoulou and Van Roy, 2018) and randomized value function learning (Osband et al., 2016). We demonstrate that, for simple tabular contexts, the approach is competitive with previously proposed tabular model learning methods (Dimakopoulou and Van Roy, 2018). With a higher-dimensional problem and a neural network value function representation, the approach learns quickly with far fewer agents than alternative exploration schemes.},
  isbn = {0262042088},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AZPSJIH5/1802.01282.pdf}
}

@unpublished{Duan2017,
  title = {R {{Einforcement L Earning}}},
  author = {Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter and Science, Computer},
  date = {2017},
  eprint = {1611.02779v2},
  eprinttype = {arXiv},
  pages = {1--14},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/K5PJUMIK/Duan et al. - 2017 - R Einforcement L Earning(2).pdf}
}

@unpublished{duran-martinEfficientOnlineBayesian2021,
  title = {Efficient {{Online Bayesian Inference}} for {{Neural Bandits}}},
  author = {Duran-Martin, Gerardo and Kara, Aleyna and Murphy, Kevin},
  date = {2021},
  eprint = {2112.00195},
  eprinttype = {arXiv},
  pages = {1--23},
  url = {http://arxiv.org/abs/2112.00195},
  abstract = {In this paper we present a new algorithm for online (sequential) inference in Bayesian neural networks, and show its suitability for tackling contextual bandit problems. The key idea is to combine the extended Kalman filter (which locally linearizes the likelihood function at each time step) with a (learned or random) low-dimensional affine subspace for the parameters; the use of a subspace enables us to scale our algorithm to models with \$\textbackslash sim 1M\$ parameters. While most other neural bandit methods need to store the entire past dataset in order to avoid the problem of "catastrophic forgetting", our approach uses constant memory. This is possible because we represent uncertainty about all the parameters in the model, not just the final linear layer. We show good results on the "Deep Bayesian Bandit Showdown" benchmark, as well as MNIST and a recommender system.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/33966QXC/Duran-martin, Kara, Murphy - 2021 - Efficient Online Bayesian Inference for Neural Bandits.pdf}
}

@article{Echeverria2017,
  title = {Multimodal Collaborative Workgroup Dataset and Challenges},
  author = {Echeverria, Vanessa and Falcones, Gabriel and Castells, Jaime and Granda, Roger and Chiluiza, Katherine},
  date = {2017},
  journaltitle = {CEUR Workshop Proceedings},
  volume = {1828},
  eprint = {1602.05561v1},
  eprinttype = {arXiv},
  pages = {94--98},
  issn = {16130073},
  doi = {10.475/123},
  isbn = {9781450335423},
  keywords = {Collaboration,Collocated spaces,Group work,Multimodal learning analytics},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IYPXKDZ5/Echeverria et al. - 2017 - Multimodal collaborative workgroup dataset and challenges.pdf}
}

@incollection{Edwards2018,
  title = {Diversity as a {{Response}} to {{User Preference Uncertainty}}},
  booktitle = {Statistical {{Data Science}}},
  author = {Edwards, James and Leslie, David},
  date = {2018-07},
  pages = {55--68},
  publisher = {WORLD SCIENTIFIC (EUROPE)},
  doi = {10.1142/9781786345400_0004},
  url = {https://www.worldscientific.com/doi/abs/10.1142/9781786345400_0004},
  abstract = {JAE: I've not rewritten this. This paper considers the problem of choosing a set of website elements to present to a user. An often desirable property of such a set is that it is diverse, that is that the elements are not all similar to one another. Often this is presented as being a separate objective from that of choosing elements that match the user in some way and which are therefore more likely to clicked. We present a range of simple and intuitive models based on uncertainty about user preferences that show how diversity emerges naturally as a result of seeking to maximise the probability that the user will click on an element. As such we give an argument as to why diversity is desirable which avoids the need for it as a separate objective. The exact model used a↵ects the diversity of sets chosen as well as the likelihood that the user will click on an element.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Y44598TE/Stat_Data_Science_draft-DSL.pdf}
}

@article{edwardsSelectingMultipleWeb2020,
  title = {Selecting Multiple Web Adverts: {{A}} Contextual Multi-Armed Bandit with State Uncertainty},
  author = {Edwards, James A. and Leslie, David S.},
  date = {2020},
  journaltitle = {Journal of the Operational Research Society},
  volume = {71},
  number = {1},
  pages = {100--116},
  publisher = {Taylor \& Francis},
  issn = {14769360},
  doi = {10.1080/01605682.2018.1546650},
  url = {https://doi.org/10.1080/01605682.2018.1546650},
  abstract = {We present a method to solve the problem of choosing a set of adverts to display to each of a sequence of web users. The objective is to maximise user clicks over time and to do so we must learn about the quality of each advert in an online manner by observing user clicks. We formulate the problem as a novel variant of a contextual combinatorial multi-armed bandit problem. The context takes the form of a probability distribution over the user's latent topic preference, and rewards are a particular nonlinear function of the selected set and the context. These features ensure that optimal sets of adverts are appropriately diverse. We give a flexible solution method which combines submodular optimisation with existing bandit index policies. User state uncertainty creates ambiguity in interpreting user feedback which prohibits exact Bayesian updating, but we give an approximate method that is shown to work well.},
  keywords = {contextual bandits,diverse recommendation,Multi-armed bandits,statistical learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ITYIPXHC/Edwards, Leslie - 2020 - Selecting multiple web adverts A contextual multi-armed bandit with state uncertainty.pdf}
}

@inproceedings{Eide2018,
  title = {Deep Neural Network Marketplace Recommenders in Online Experiments},
  booktitle = {Proceedings of the 12th {{ACM Conference}} on {{Recommender Systems}}},
  author = {Eide, Simen and Zhou, Ning},
  date = {2018-09-27},
  pages = {387--391},
  publisher = {ACM},
  location = {New York, NY, USA},
  doi = {10.1145/3240323.3240387},
  url = {https://dl.acm.org/doi/10.1145/3240323.3240387},
  abstract = {© 2018 Copyright held by the owner/author(s). Recommendations are broadly used in marketplaces to match users with items relevant to their interests and needs. To understand user intent and tailor recommendations to their needs, we use deep learning to explore various heterogeneous data available in marketplaces. This paper focuses on the challenge of measuring recommender performance and summarizes the online experiment results with several promising types of deep neural network recommenders - hybrid item representation models combining features from user engagement and content, sequence-based models, and multi-armed bandit models that optimize user engagement by re-ranking proposals from multiple submodels. The recommenders are currently running in production at the leading Norwegian marketplace FINN.no and serves over one million visitors everyday.},
  isbn = {978-1-4503-5901-6},
  keywords = {Deep learning,Marketplace,Recommendation system}
}

@article{Eidea,
  title = {{{FINAL DRAFT}} 15.04: {{Bayesian Sequential Slate Recommender Systems}} with {{Thompson Sampling Bandits}}},
  author = {Eide, Simen and Leslie, David S and Frigessi, Arnoldo},
  pages = {1--29},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/QSQ45JGW/Eide, Leslie, Frigessi - Unknown - Bayesian Sequential Slate Recommender Systems with Thompson Sampling Bandits.pdf}
}

@article{eideBayesianSequentialSlate,
  title = {Bayesian {{Sequential Slate Recommender Systems}} with {{Thompson Sampling Bandits}}},
  author = {Eide, Simen and Leslie, David S and Frigessi, Arnoldo},
  pages = {1--29},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/94LCUGRM/Eide, Leslie, Frigessi - Unknown - Bayesian Sequential Slate Recommender Systems with Thompson Sampling Bandits.pdf}
}

@article{eideDraftDynamicSlate,
  title = {Draft: {{Dynamic Slate Recommendation}} with {{Gated Recurrent Units}} and {{Thompson Sampling}}},
  author = {Eide, Simen and Leslie, David S and Frigessi, Arnoldo},
  pages = {1--30},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/PCZIPZH9/Eide, Leslie, Frigessi - 2021 - Dynamic Slate Recommendation with Gated Recurrent Units and Thompson Sampling.pdf}
}

@article{eideFINNNoSlates2021,
  title = {{{FINN}} . No {{Slates Dataset}} : {{A}} New {{Sequential Dataset Logging Interactions}} , All {{Viewed Items}} and {{Click Responses}} / {{No-Click}} for {{Recommender Systems}}},
  author = {Eide, Simen and Frigessi, Arnoldo and Jenssen, Helge and Leslie, David S. and Rishaug, Joakim and Verrewaere, Sofie},
  date = {2021},
  journaltitle = {Fifteenth ACM Conference on Recommender Systems (RecSys '21), September 27-October 1, 2021, Amsterdam, Netherlands},
  volume = {1},
  number = {1},
  pages = {1--5},
  publisher = {Association for Computing Machinery},
  doi = {10.1145/3460231.3474607},
  keywords = {bandit,candidate sampling,item attributes,marketplace data,off-policy,reinforcement learning,search result,slate recommendations search result candidate sa},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/XUQ7UT2B/Leslie, Kingdom, Rishaug - 2021 - FINN . no Slates Dataset A new Sequential Dataset Logging Interactions , all Viewed Items and Click R.pdf}
}

@misc{eideFiveLessonsBuilding2018,
  title = {Five Lessons from Building a Deep Neural Network Recommender for Marketplaces},
  author = {Eide, S. and Øygard, A.M. and Zhou, N.},
  date = {2018},
  journaltitle = {arXiv},
  abstract = {Copyright © 2018, arXiv, All rights reserved. Recommendation algorithms are widely adopted in marketplaces to help users find the items they are looking for. The sparsity of the items by user matrix and the cold-start issue in marketplaces pose challenges for the off-the-shelf matrix factorization based recommender systems. To understand user intent and tailor recommendations to their needs, we use deep learning to explore various heterogeneous data available in marketplaces. This paper summarizes five lessons we learned from experimenting with stateof-the-art deep learning recommenders at the leading Norwegian marketplace FINN.no.We design a hybrid recommender system that takes the user-generated content of a marketplace (including text, images and meta attributes) and combines it with user behavior data such as page views and messages to provide recommendations for marketplace items. Among various tactics we experimented with, the following five show the best impact: Staged training instead of end-to-end training, leveraging rich user behaviors beyond page views, using user behaviors as noisy labels to train embeddings, using transfer learning to solve the unbalanced data problem, and using attention mechanisms in the hybrid model. This system is currently running with around 20\% click-through-rate in production at FINN.no and serves over one million visitors everyday.},
  keywords = {Deep learning,Marketplace,Recommender system}
}

@report{eideMidasMarginModel2016,
  title = {Midas {{Margin Model SIX}} X-Clear {{Ltd}}},
  author = {Eide, Simen},
  date = {2016},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/PAGKAB9M/Eide - 2016 - Midas Margin Model SIX x-clear Ltd.pdf}
}

@article{eideSimenEide2021,
  title = {Simen Eide},
  author = {Eide, Simen},
  date = {2021},
  volume = {2},
  pages = {2021},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/UJ4N942A/Eide - 2021 - Simen eide.pdf}
}

@article{Ekeli,
  title = {Ytringsfrihet Og Terrorisme {{Bør}} Liberale Demokratier Forby Oppfordringer Til Terrorisme? {{Selv}} Om Det Finnes Interessante Argumenter for å Forby Slike Oppfordringer, Argumenterer Forfatte-Ren i Denne Artikkelen Mot et Forbud},
  author = {Ekeli, Kristian Skagen},
  issn = {0029-1943},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/UZ2JALCN/Ekeli - NFT-14.pdf}
}

@article{ekgrenGPTSW3AutoregressiveLanguage,
  title = {{{GPT-SW3}}: {{An Autoregressive Language Model}} for the {{Scandinavian Languages}}},
  author = {Ekgren, Ariel and Gyllensten, Amaru Cuba and Stollenwerk, Felix and Öhman, Joey and Isbister, Tim and Gogoulou, Evangelia and Carlsson, Fredrik and Casademont, Judit and Sahlgren, Magnus},
  abstract = {This paper details the process of developing the first native large generative language model for the North Germanic languages, GPT-SW3. We cover all parts of the development process, from data collection and processing, training configuration and instruction finetuning, to evaluation, applications, and considerations for release strategies. We discuss pros and cons of developing large language models for smaller languages and in relatively peripheral regions of the globe, and we hope that this paper can serve as a guide and reference for other researchers that undertake the development of large generative models for smaller languages.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/APYMWXWQ/Ekgren et al. - GPT-SW3 An Autoregressive Language Model for the .pdf}
}

@unpublished{el-kishkyKNNEmbedLocallySmoothed2022,
  title = {{{kNN-Embed}}: {{Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval}}},
  author = {El-Kishky, Ahmed and Markovich, Thomas and Leung, Kenny and Portman, Frank and Haghighi, Aria},
  date = {2022},
  volume = {1},
  number = {1},
  eprint = {2205.06205},
  eprinttype = {arXiv},
  publisher = {Association for Computing Machinery},
  url = {http://arxiv.org/abs/2205.06205},
  abstract = {Candidate generation is the first stage in recommendation systems, where a light-weight system is used to retrieve potentially relevant items for an input user. These candidate items are then ranked and pruned in later stages of recommender systems using a more complex ranking model. Since candidate generation is the top of the recommendation funnel, it is important to retrieve a high-recall candidate set to feed into downstream ranking models. A common approach for candidate generation is to leverage approximate nearest neighbor (ANN) search from a single dense query embedding; however, this approach this can yield a low-diversity result set with many near duplicates. As users often have multiple interests, candidate retrieval should ideally return a diverse set of candidates reflective of the user's multiple interests. To this end, we introduce kNN-Embed, a general approach to improving diversity in dense ANN-based retrieval. kNN-Embed represents each user as a smoothed mixture over learned item clusters that represent distinct `interests' of the user. By querying each of a user's mixture component in proportion to their mixture weights, we retrieve a high-diversity set of candidates reflecting elements from each of a user's interests. We experimentally compare kNN-Embed to standard ANN candidate retrieval, and show significant improvements in overall recall and improved diversity across three datasets. Accompanying this work, we open source a large Twitter follow-graph dataset, to spur further research in graph-mining and representation learning for recommender systems.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/JPXE7QCW/El-Kishky et al. - 2022 - kNN-Embed Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval.pdf}
}

@article{ethayarajhHumanCenteredLossFunctions,
  title = {Human-{{Centered Loss Functions}} ({{HALOs}})},
  author = {Ethayarajh, Kawin and Xu, Winnie and Ai, Contextual and Jurafsky, Dan and Kiela, Douwe},
  journaltitle = {Technical Report},
  abstract = {From Kahneman \& Tversky’s seminal work on prospect theory (1992), we know that humans perceive random variables in a systematically distorted manner; for example, they are more sensitive to losses than gains of the same magnitude. We show that existing methods for aligning LLMs with human feedback implicitly model some of these distortions, making them human-centered loss functions (HALOs). However, the utility functions these methods impute to humans still differ in some ways from those in the prospect theory literature. By bridging this gap, we derive a HALO that directly maximizes the utility of LLM generations instead of maximizing the log-likelihood of preferences, as current methods do. We call our approach Kahneman-Tversky Optimization (KTO). KTO matches or exceeds the performance of direct preference optimization methods at scales from 1B to 30B. Moreover, because KTO does not need preference pairs—only knowledge of whether an output is desirable or undesirable for a given input—it is much easier to deploy in the real world, where the latter kind of data is far more abundant.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Y8BD2J5N/Ethayarajh et al. - Human-Centered Loss Functions (HALOs).pdf}
}

@online{Facebook,
  title = {Facebook},
  url = {https://www.facebook.com/},
  urldate = {2023-12-20},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LAIYPLRY/www.facebook.com.html}
}

@article{fangLearningHowActive2017,
  title = {Learning How to Active Learn: {{A}} Deep Reinforcement Learning Approach},
  author = {Fang, Meng and Li, Yuan and Cohn, Trevor},
  date = {2017},
  journaltitle = {EMNLP 2017 - Conference on Empirical Methods in Natural Language Processing, Proceedings},
  eprint = {1708.02383},
  eprinttype = {arXiv},
  pages = {595--605},
  doi = {10.18653/v1/d17-1063},
  abstract = {Active learning aims to select a small subset of data for annotation such that a classifier learned on the data is highly accurate. This is usually done using heuristic selection methods, however the effectiveness of such methods is limited and moreover, the performance of heuristics varies between datasets. To address these shortcomings, we introduce a novel formulation by re-framing the active learning as a reinforcement learning problem and explicitly learning a data selection policy, where the policy takes the role of the active learning heuristic. Importantly, our method allows the selection policy learned using simulation on one language to be transferred to other languages. We demonstrate our method using cross-lingual named entity recognition, observing uniform improvements over traditional active learning.},
  isbn = {9781945626838},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LP5ICGBB/Fang, Li, Cohn - 2017 - Learning how to active learn A deep reinforcement learning approach.pdf}
}

@online{fangTransformerbasedConditionalVariational2021,
  title = {Transformer-Based {{Conditional Variational Autoencoder}} for {{Controllable Story Generation}}},
  author = {Fang, Le and Zeng, Tao and Liu, Chaochun and Bo, Liefeng and Dong, Wen and Chen, Changyou},
  date = {2021-07-08},
  eprint = {2101.00828},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2101.00828},
  url = {http://arxiv.org/abs/2101.00828},
  urldate = {2023-01-17},
  abstract = {We investigate large-scale latent variable models (LVMs) for neural story generation -- an under-explored application for open-domain long text -- with objectives in two threads: generation effectiveness and controllability. LVMs, especially the variational autoencoder (VAE), have achieved both effective and controllable generation through exploiting flexible distributional latent representations. Recently, Transformers and its variants have achieved remarkable effectiveness without explicit latent representation learning, thus lack satisfying controllability in generation. In this paper, we advocate to revive latent variable modeling, essentially the power of representation learning, in the era of Transformers to enhance controllability without hurting state-of-the-art generation effectiveness. Specifically, we integrate latent representation vectors with a Transformer-based pre-trained architecture to build conditional variational autoencoder (CVAE). Model components such as encoder, decoder and the variational posterior are all built on top of pre-trained language models -- GPT2 specifically in this paper. Experiments demonstrate state-of-the-art conditional generation ability of our model, as well as its excellent representation learning capability and controllability.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DH5IMQAH/Fang et al. - 2021 - Transformer-based Conditional Variational Autoenco.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/M6Q2N9CY/2101.html}
}

@online{fanHierarchicalNeuralStory2018,
  title = {Hierarchical {{Neural Story Generation}}},
  author = {Fan, Angela and Lewis, Mike and Dauphin, Yann},
  date = {2018-05-13},
  eprint = {1805.04833},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1805.04833},
  url = {http://arxiv.org/abs/1805.04833},
  urldate = {2023-01-15},
  abstract = {We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AJ59TWYK/Fan et al. - 2018 - Hierarchical Neural Story Generation.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/W87I42BW/1805.html}
}

@unpublished{Farajtabar2018,
  title = {More {{Robust Doubly Robust Off-policy Evaluation}}},
  author = {Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  date = {2018},
  eprint = {1802.03493},
  eprinttype = {arXiv},
  issn = {1938-7228},
  url = {http://arxiv.org/abs/1802.03493},
  abstract = {We study the problem of off-policy evaluation (OPE) in reinforcement learning (RL), where the goal is to estimate the performance of a policy from the data generated by another policy(ies). In particular, we focus on the doubly robust (DR) estimators that consist of an importance sampling (IS) component and a performance model, and utilize the low (or zero) bias of IS and low variance of the model at the same time. Although the accuracy of the model has a huge impact on the overall performance of DR, most of the work on using the DR estimators in OPE has been focused on improving the IS part, and not much on how to learn the model. In this paper, we propose alternative DR estimators, called more robust doubly robust (MRDR), that learn the model parameter by minimizing the variance of the DR estimator. We first present a formulation for learning the DR model in RL. We then derive formulas for the variance of the DR estimator in both contextual bandits and RL, such that their gradients w.r.t.\textasciitilde the model parameters can be estimated from the samples, and propose methods to efficiently minimize the variance. We prove that the MRDR estimators are strongly consistent and asymptotically optimal. Finally, we evaluate MRDR in bandits and RL benchmark problems, and compare its performance with the existing methods.},
  isbn = {9781510867963},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/77769QSI/1802.03493.pdf}
}

@online{finn-recsys-slate-dataset,
  title = {{{FINN}}.No {{Recommender System Slate Dataset}}},
  author = {Eide, Simen},
  date = {2021},
  url = {https://github.com/finn-no/recsys-slates-dataset}
}

@article{Finn2016,
  title = {Guided Cost Learning: {{Deep}} Inverse Optimal Control via Policy Optimization},
  author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  date = {2016},
  journaltitle = {33rd International Conference on Machine Learning, ICML 2016},
  volume = {1},
  eprint = {1603.00448},
  eprinttype = {arXiv},
  pages = {95--107},
  abstract = {Reinforcement learning can acquire complex behaviors from high-level specifications. However, defining a cost function that can be optimized effectively and encodes the correct task is challenging in practice. We explore how inverse optimal control (IOC) can be used to learn behaviors from demonstrations, with applications to torque control of high-dimensional robotic systems. Our method addresses two key challenges in inverse optimal control: first, the need for informative features and effective regularization to impose structure on the cost, and second, the difficulty of learning the cost function under unknown dynamics for high-dimensional continuous systems. To address the former challenge, we present an algorithm capable of learning arbitrary nonlinear cost functions, such as neural networks, without meticulous feature engineering. To address the latter challenge, we formulate an efficient sample-based approximation for MaxEnt IOC. We evaluate our method on a series of simulated tasks and real-world robotic manipulation problems, demonstrating substantial improvement over prior methods both in terms of task complexity and sample efficiency.},
  isbn = {9781510829008},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7BCIAZ6C/Finn, Levine, Abbeel - 2016 - Guided cost learning Deep inverse optimal control via policy optimization.pdf}
}

@report{FortunatoDeepMind,
  title = {{{BAYESIAN RECURRENT NEURAL NETWORKS}}},
  author = {Fortunato DeepMind, Meire and Blundell DeepMind, Charles and Vinyals DeepMind, Oriol},
  eprint = {1704.02798v3},
  eprinttype = {arXiv},
  abstract = {In this work we explore a straightforward variational Bayes scheme for Recurrent Neural Networks. Firstly, we show that a simple adaptation of truncated backpropagation through time can yield good quality uncertainty estimates and superior regularisation at only a small extra computational cost during training, also reducing the amount of parameters by 80\%. Secondly, we demonstrate how a novel kind of posterior approximation yields further improvements to the performance of Bayesian RNNs. We incorporate local gradient information into the approximate posterior to sharpen it around the current batch statistics. We show how this technique is not exclusive to recurrent neural networks and can be applied more widely to train Bayesian neural networks. We also empirically demonstrate how Bayesian RNNs are superior to traditional RNNs on a language modelling benchmark and an image captioning task, as well as showing how each of these methods improve our model over a variety of other schemes for training them. We also introduce a new benchmark for studying uncertainty for language models so future methods can be easily compared.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YBBXVMC3/m-api-66d53b80-6100-de15-5aa1-fb50917ee008.pdf}
}

@article{Fraccaro2017,
  title = {A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning},
  author = {Fraccaro, Marco and Kamronn, Simon and Paquet, Ulrich and Winther, Ole},
  date = {2017},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {2017-Decem},
  eprint = {1710.05741},
  eprinttype = {arXiv},
  pages = {3602--3611},
  issn = {10495258},
  abstract = {This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks.},
  issue = {section 5},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/KPVDYIS5/Fraccaro et al. - 2017 - A disentangled recognition and nonlinear dynamics model for unsupervised learning.pdf}
}

@incollection{Francis2014,
  title = {Depth {{Map Prediction}} from a {{Single Image}} Using a {{Multi-Scale Deep Network}}},
  author = {Francis, Louise},
  date = {2014},
  eprint = {20879316},
  eprinttype = {pmid},
  pages = {280--312},
  issn = {16137736},
  doi = {10.1017/CBO9781139342674.012},
  abstract = {What use can the brain make of the massive flow of sensory information that occurs without any associated rewards or punishments? This question is reviewed in the light of connectionist models of unsupervised learning and some older ideas, namely the cognitive maps and working models of Tolman and Craik, and the idea that redundancy is important for understanding perception (Attneave 1954), the physiology of sensory pathways (Barlow 1959), and pattern recognition (Watanabe 1960). It is argued that (1) The redundancy of sensory messages provides the knowledge incorporated in the maps or models. (2) Some of this knowledge can be obtained by observations of mean, variance, and covariance of sensory messages, and perhaps also by a method called “minimum entropy coding.” (3) Such knowledge may be incorporated in a model of “what usually happens” with which incoming messages are automatically compared, enabling unexpected discrepancies to be immediately identified. (4) Knowledge of the sort incorporated into su...},
  isbn = {978-1-139-34267-4},
  keywords = {Finance and accountancy,Finance and insurance,Statistics for econometrics},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/NHIILU7P/Eigen, Puhrsch, Fergus - 2014 - Depth Map Prediction from a Single Image using a Multi-Scale Deep Network.pdf}
}

@article{Frank2000,
  title = {Technical Note: {{Naive Bayes}} for Regression},
  author = {Frank, Eibe and Trigg, Leonard and Holmes, Geoffrey and Witten, Ian H.},
  date = {2000},
  journaltitle = {Machine Learning},
  volume = {41},
  number = {1},
  pages = {5--25},
  issn = {08856125},
  doi = {10.1023/A:1007670802811},
  abstract = {Despite its simplicity, the naive Bayes learning scheme performs well on most classification tasks, and is often significantly more accurate than more sophisticated methods. Although the probability estimates that it produces can be inaccurate, it often assigns maximum probability to the correct class. This suggests that its good performance might be restricted to situations where the output is categorical. It is therefore interesting to see how it performs in domains where the predicted value is numeric, because in this case, predictions are more sensitive to inaccurate probability estimates.\textbackslash r\textbackslash nThis paper shows how to apply the naive Bayes methodology to numeric prediction (i.e., regression) tasks by modeling the probability distribution of the target value with kernel density estimators, and compares it to linear regression, locally weighted linear regression, and a method that produces “model trees”—decision trees with linear regression functions at the leaves. Although we exhibit an artificial dataset for which naive Bayes is the method of choice, on real-world datasets it is almost uniformly worse than locally weighted linear regression and model trees. The comparison with linear regression depends on the error measure: for one measure naive Bayes performs similarly, while for another it is worse. We also show that standard naive Bayes applied to regression problems by discretizing the target value performs similarly badly. We then present empirical evidence that isolates naive Bayes' independence assumption as the culprit for its poor performance in the regression setting. These results indicate that the simplistic statistical assumption that naive Bayes makes is indeed more restrictive for regression than for classification.},
  isbn = {0885-6125},
  keywords = {linear regression,locally weighted regression,model trees,naive bayes,regression},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/6AFNLYHG/Frank et al. - 2000 - Technical note Naive Bayes for regression.pdf}
}

@article{Freeman2019,
  title = {Learning to Predictwithout Looking Ahead: World Modelswithout Forward Prediction},
  author = {Freeman, C. Daniel and Metz, Luke and Ha, David},
  date = {2019},
  journaltitle = {arXiv},
  number = {9},
  eprint = {1910.13038},
  eprinttype = {arXiv},
  pages = {1--17},
  issn = {23318422},
  abstract = {Much of model-based reinforcement learning involves learning a model of an agent's world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware-e.g., a brain-arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we introduce a modification to traditional reinforcement learning which we call observational dropout, whereby we limit the agents ability to observe the real environment at each timestep. In doing so, we can coerce an agent into learning a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment. Videos of our results available at https://learningtopredict.github.io/.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7JXIWQR7/Freeman, Metz, Ha - 2019 - Learning to predictwithout looking ahead world modelswithout forward prediction.pdf}
}

@article{galDeepBayesianActive2017,
  title = {Deep {{Bayesian}} Active Learning with Image Data},
  author = {Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  date = {2017},
  journaltitle = {34th International Conference on Machine Learning, ICML 2017},
  volume = {3},
  eprint = {1703.02910},
  eprinttype = {arXiv},
  pages = {1923--1932},
  abstract = {Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolu-tional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).},
  isbn = {9781510855144}
}

@article{galImprovingPILCOBayesian,
  title = {Improving {{PILCO}} with {{Bayesian Neural Network Dynamics Models}}},
  author = {Gal, Yarin and Mcallister, Rowan Thomas and Rasmussen, Carl Edward},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/2Z7Y494X/Gal, Mcallister, Rasmussen - 2016 - Improving PILCO with Bayesian Neural Network Dynamics Models.pdf}
}

@online{gargIQLearnInverseSoftQ2022,
  title = {{{IQ-Learn}}: {{Inverse}} Soft-{{Q Learning}} for {{Imitation}}},
  shorttitle = {{{IQ-Learn}}},
  author = {Garg, Divyansh and Chakraborty, Shuvam and Cundy, Chris and Song, Jiaming and Geist, Matthieu and Ermon, Stefano},
  date = {2022-11-03},
  eprint = {2106.12142},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2106.12142},
  urldate = {2023-08-25},
  abstract = {In many sequential decision-making problems (e.g., robotics control, game playing, sequential prediction), human or expert data is available containing useful information about the task. However, imitation learning (IL) from a small amount of expert data can be challenging in high-dimensional environments with complex dynamics. Behavioral cloning is a simple method that is widely used due to its simplicity of implementation and stable convergence but doesn't utilize any information involving the environment's dynamics. Many existing methods that exploit dynamics information are difficult to train in practice due to an adversarial optimization process over reward and policy approximators or biased, high variance gradient estimators. We introduce a method for dynamics-aware IL which avoids adversarial training by learning a single Q-function, implicitly representing both reward and policy. On standard benchmarks, the implicitly learned rewards show a high positive correlation with the ground-truth rewards, illustrating our method can also be used for inverse reinforcement learning (IRL). Our method, Inverse soft-Q learning (IQ-Learn) obtains state-of-the-art results in offline and online imitation learning settings, significantly outperforming existing methods both in the number of required environment interactions and scalability in high-dimensional spaces, often by more than 3x.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/S7RAWTGC/Garg et al. - 2022 - IQ-Learn Inverse soft-Q Learning for Imitation.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/56Z7IZCC/Garg et al. - 2022 - IQ-Learn Inverse soft-Q Learning for Imitation.html}
}

@unpublished{gawlikowskiSurveyUncertaintyDeep2021,
  title = {A {{Survey}} of {{Uncertainty}} in {{Deep Neural Networks}}},
  author = {Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and Shahzad, Muhammad and Yang, Wen and Bamler, Richard and Zhu, Xiao Xiang},
  date = {2021},
  eprint = {2107.03342},
  eprinttype = {arXiv},
  pages = {1--41},
  url = {http://arxiv.org/abs/2107.03342},
  abstract = {Due to their increasing spread, confidence in neural network predictions became more and more important. However, basic neural networks do not deliver certainty estimates or suffer from over or under confidence. Many researchers have been working on understanding and quantifying uncertainty in a neural network's prediction. As a result, different types and sources of uncertainty have been identified and a variety of approaches to measure and quantify uncertainty in neural networks have been proposed. This work gives a comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. It is intended to give anyone interested in uncertainty estimation in neural networks a broad overview and introduction, without presupposing prior knowledge in this field. A comprehensive introduction to the most crucial sources of uncertainty is given and their separation into reducible model uncertainty and not reducible data uncertainty is presented. The modeling of these uncertainties based on deterministic neural networks, Bayesian neural networks, ensemble of neural networks, and test-time data augmentation approaches is introduced and different branches of these fields as well as the latest developments are discussed. For a practical application, we discuss different measures of uncertainty, approaches for the calibration of neural networks and give an overview of existing baselines and implementations. Different examples from the wide spectrum of challenges in different fields give an idea of the needs and challenges regarding uncertainties in practical applications. Additionally, the practical limitations of current methods for mission- and safety-critical real world applications are discussed and an outlook on the next steps towards a broader usage of such methods is given.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/HUVY8MNT/Gawlikowski et al. - 2021 - A Survey of Uncertainty in Deep Neural Networks.pdf}
}

@book{Gelman,
  title = {Bayesian {{Data Analysis Third Edition}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubon, Donald B.},
  url = {https://the-eye.eu/public/Books/qt.vidyagam.es/library/Monitoring and Analysis/Bayesian Data Analysis%2C Third Edition/Bayesian Data Analysis%2C Third Edition - Andrew Gelman %26 John B. Carlin %26 Hal S. Stern %26 David B. Dunson %26 Aki Vehtari %26 Dona},
  urldate = {2018-08-18},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YHYYIQ33/full-text.pdf}
}

@article{gershmanTutorialBayesianNonparametric2012,
  title = {A Tutorial on {{Bayesian}} Nonparametric Models},
  author = {Gershman, Samuel J. and Blei, David M.},
  date = {2012},
  journaltitle = {Journal of Mathematical Psychology},
  volume = {56},
  number = {1},
  eprint = {1106.2697},
  eprinttype = {arXiv},
  pages = {1--12},
  publisher = {Elsevier Inc.},
  issn = {00222496},
  doi = {10.1016/j.jmp.2011.08.004},
  url = {http://dx.doi.org/10.1016/j.jmp.2011.08.004},
  abstract = {A key problem in statistical modeling is model selection, that is, how to choose a model at an appropriate level of complexity. This problem appears in many settings, most prominently in choosing the number of clusters in mixture models or the number of factors in factor analysis. In this tutorial, we describe Bayesian nonparametric methods, a class of methods that side-steps this issue by allowing the data to determine the complexity of the model. This tutorial is a high-level introduction to Bayesian nonparametric methods and contains several examples of their application. © 2011 Elsevier Inc.},
  keywords = {Bayesian methods,Chinese restaurant process,Indian buffet process},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/8DNEXK7X/Gershman, Blei - 2012 - A tutorial on Bayesian nonparametric models.pdf}
}

@unpublished{Ghavamzadeh2016,
  title = {Bayesian {{Reinforcement Learning}}: {{A Survey}}},
  author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
  date = {2016-09-14},
  eprint = {1609.04436},
  eprinttype = {arXiv},
  doi = {10.1561/2200000049},
  url = {http://arxiv.org/abs/1609.04436},
  urldate = {2019-05-04},
  abstract = {Bayesian methods for machine learning have been widely investigated, yielding principled methods for incorporating prior information into inference algorithms. In this survey, we provide an in-depth review of the role of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian reasoning in RL are: 1) it provides an elegant approach to action-selection (exploration/exploitation) as a function of the uncertainty in learning; and 2) it provides a machinery to incorporate prior knowledge into the algorithms. We first discuss models and methods for Bayesian inference in the simple single-step Bandit model. We then review the extensive recent literature on Bayesian methods for model-based RL, where prior information can be expressed on the parameters of the Markov model. We also present Bayesian methods for model-free RL, where priors are expressed over the value function or policy class. The objective of the paper is to provide a comprehensive survey on Bayesian RL algorithms and their theoretical and empirical properties.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FBGSZ95L/full-text.pdf}
}

@unpublished{Gilotte2018,
  title = {Offline {{A}}/{{B}} Testing for {{Recommender Systems}}},
  author = {Gilotte, Alexandre and Calauzènes, Clément and Nedelec, Thomas and Abraham, Alexandre and Dollé, Simon},
  date = {2018},
  eprint = {1801.07030},
  eprinttype = {arXiv},
  doi = {10.1145/3159652.3159687},
  url = {http://arxiv.org/abs/1801.07030%0Ahttp://dx.doi.org/10.1145/3159652.3159687},
  abstract = {Before A/B testing online a new version of a recommender system, it is usual to perform some offline evaluations on historical data. We focus on evaluation methods that compute an estimator of the potential uplift in revenue that could generate this new technology. It helps to iterate faster and to avoid losing money by detecting poor policies. These estimators are known as counterfactual or off-policy estimators. We show that traditional counterfactual estimators such as capped importance sampling and normalised importance sampling are experimentally not having satisfying bias-variance compromises in the context of personalised product recommendation for online advertising. We propose two variants of counterfactual estimates with different modelling of the bias that prove to be accurate in real-world conditions. We provide a benchmark of these estimators by showing their correlation with business metrics observed by running online A/B tests on a commercial recommender system.},
  isbn = {9781450355810},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SFWN84JG/Gilotte et al. - 2018 - Offline AB testing for Recommender Systems.pdf}
}

@article{Girshick2012,
  title = {Rich Feature Hierarchies for Accu- Rate Object Detection and Semantic Segmentation},
  author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  date = {2012},
  journaltitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages = {580--587},
  keywords = {Ross Girshick Jeff Donahue Trevor Darrell Jitendra},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FTE2A3RY/m-api-303a78ad-1078-f7ff-26c8-5cefda06fea0.pdf}
}

@online{golkarXValContinuousNumber2023,
  title = {{{xVal}}: {{A Continuous Number Encoding}} for {{Large Language Models}}},
  shorttitle = {{{xVal}}},
  author = {Golkar, Siavash and Pettee, Mariel and Eickenberg, Michael and Bietti, Alberto and Cranmer, Miles and Krawezik, Geraud and Lanusse, Francois and McCabe, Michael and Ohana, Ruben and Parker, Liam and Blancard, Bruno Régaldo-Saint and Tesileanu, Tiberiu and Cho, Kyunghyun and Ho, Shirley},
  date = {2023-10-04},
  eprint = {2310.02989},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2310.02989},
  urldate = {2024-07-24},
  abstract = {Large Language Models have not yet been broadly adapted for the analysis of scientific datasets due in part to the unique difficulties of tokenizing numbers. We propose XVAL, a numerical encoding scheme that represents any real number using just a single token. XVAL represents a given real number by scaling a dedicated embedding vector by the number value. Combined with a modified number-inference approach, this strategy renders the model end-to-end continuous when considered as a map from the numbers of the input string to those of the output string. This leads to an inductive bias that is generally more suitable for applications in scientific domains. We empirically evaluate our proposal on a number of synthetic and real-world datasets. Compared with existing number encoding schemes, we find that XVAL is more token-efficient and demonstrates improved generalization.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3VCUWB6Q/2310.02989v1.pdf}
}

@article{Gonen2014a,
  title = {Kernelized {{Bayesian}} Transfer Learning},
  author = {Gönen, Mehmet and Margolin, Adam A.},
  date = {2014},
  journaltitle = {Proceedings of the National Conference on Artificial Intelligence},
  volume = {3},
  number = {2011},
  pages = {1831--1839},
  abstract = {Transfer learning considers related but distinct tasks defined on heterogenous domains and tries to transfer knowledge between these tasks to improve generalization performance. It is particularly useful when we do not have sufficient amount of labeled training data in some tasks, which may be very costly, laborious, or even infeasible to obtain. Instead, learning the tasks jointly enables us to effectively increase the amount of labeled training data. In this paper, we formulate a kernelized Bayesian transfer learning framework that is a principled combination of kernel-based dimensionality reduction models with task-specific projection matrices to find a shared subspace and a coupled classification model for all of the tasks in this subspace. Our two main contributions are: (i) two novel probabilistic models for binary and multiclass classification, and (ii) very efficient variational approximation procedures for these models. We illustrate the generalization performance of our algorithms on two different applications. In computer vision experiments, our method outperforms the state-of-the-art algorithms on nine out of 12 benchmark supervised domain adaptation experiments defined on two object recognition data sets. In cancer biology experiments, we use our algorithm to predict mutation status of important cancer genes from gene expression profiles using two distinct cancer populations, namely, patient-derived primary tumor data and in-vitro-derived cancer cell line data. We show that we can increase our generalization performance on primary tumors using cell lines as an auxiliary data source.},
  isbn = {9781577356790},
  keywords = {Novel Machine Learning Algorithms},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/CE79TX4W/Gönen, Margolin - 2014 - Kernelized Bayesian transfer learning.pdf}
}

@article{Gong2015,
  title = {Hashtag Recommendation Using Dirichlet Process Mixture Models Incorporating Types of Hashtags},
  author = {Gong, Yeyun and Zhang, Qi and Huang, Xuanjing},
  date = {2015},
  journaltitle = {Conference Proceedings - EMNLP 2015: Conference on Empirical Methods in Natural Language Processing},
  pages = {401--410},
  doi = {10.18653/v1/d15-1046},
  abstract = {In recent years, the task of recommending hashtags for microblogs has been given increasing attention. Various methods have been proposed to study the problem from different aspects. However, most of the recent studies have not considered the differences in the types or uses of hashtags. In this paper, we introduce a novel nonparametric Bayesian method for this task. Based on the Dirichlet Process Mixture Models (DPMM), we incorporate the type of hashtag as a hidden variable. The results of experiments on the data collected from a real world microblogging service demonstrate that the proposed method outperforms stateof-the-art methods that do not consider these aspects. By taking these aspects into consideration, the relative improvement of the proposed method over the state-of-theart methods is around 12.2\% in Fl-score.},
  isbn = {9781941643327}
}

@book{goodfellowDeepLearning2016,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {MIT Press},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3R8ANC7C/Ian Goodfellow, Yoshua Bengio, Aaron Courville - Deep Learning (2017, MIT).pdf}
}

@article{Gopalan2013,
  title = {Scalable {{Recommendation}} with {{Poisson Factorization}}},
  author = {Gopalan, Prem and Hofman, Jake M and Blei, David M},
  date = {2013},
  journaltitle = {arXiv preprint},
  eprint = {15003161},
  eprinttype = {pmid},
  pages = {1--10},
  issn = {01451707},
  doi = {10.1002/jae},
  abstract = {We develop a Bayesian Poisson matrix factorization model for forming recommendations from sparse user behavior data. These data are large user/item matrices where each user has provided feedback on only a small subset of items, ei- ther explicitly (e.g., through star ratings) or implicitly (e.g., through views or purchases). In contrast to traditional matrix factorization approaches, Poisson factorization implicitly models each user's limited attention to consume items. Moreover, because of the mathematical form of the Poisson likelihood, the model needs only to explicitly consider the observed entries in the matrix, leading to both scalable computation and good predictive performance. We develop a variational inference algorithm for approximate posterior inference that scales up to massive data sets. This is an efficient algorithm that iterates over the observed entries and adjusts an approximate posterior over the user/item representations. We apply our method to large real-world user data containing users rating movies, users listening to songs, and users reading scientific papers. In all these settings, Bayesian Poisson factorization outperforms state-of-the-art matrix factorization methods.},
  isbn = {9780000000002},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/HPPWMIDB/m-api-0e34ec2f-3730-1ff7-125b-b87b97471610.pdf}
}

@inproceedings{Graepel2010,
  title = {Web-{{Scale Bayesian Click-Through Rate Prediction}} for {{Sonsored Search Advertising}} in {{Microsofts}}'s {{Bing Search Engine}}},
  booktitle = {{{ICML}}},
  author = {Graepel, Thore and Candela, Joaquin Quinonero and Bochert, Thomas and Herbrich, Ralf and Com, Rherb Microsoft},
  date = {2010},
  eprint = {22705860},
  eprinttype = {pmid},
  pages = {13--20},
  issn = {1872-7549},
  doi = {10.1016/j.bbr.2012.06.005},
  abstract = {We describe a new Bayesian click-through rate (CTR) prediction algorithm used for Sponsored Search in Microsofts Bing search engine. The algorithm is based on a probit regression model that maps discrete or real-valued input features to probabilities. It maintains Gaussian beliefs over weights of the model and performs Gaussian online updates derived from approximate message passing. Scalability of the algorithm is ensured through a principled weight pruning procedure and an approximate parallel implementation. We discuss the challenges arising from evaluating and tuning the predictor as part of the complex system of sponsored search where the predictions made by the algorithm decide about future training sample composition. Finally, we show experimental results from the production system and compare to a calibrated Naïve Bayes algorithm.},
  isbn = {978-1-60558-907-7},
  issue = {April 2009},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5W9MFQYP/full-text.pdf}
}

@unpublished{Grave2016,
  title = {Efficient Softmax Approximation for {{GPUs}}},
  author = {Grave, Edouard and Joulin, Armand and Cissé, Moustapha and Grangier, David and Jégou, Hervé},
  date = {2016},
  eprint = {2407808},
  eprinttype = {pmid},
  issn = {1938-7228},
  doi = {10.1002/pbc.20795},
  url = {http://arxiv.org/abs/1609.04309},
  abstract = {We propose an approximate strategy to efficiently train neural network based language models over very large vocabularies. Our approach, called adaptive softmax, circumvents the linear dependency on the vocabulary size by exploiting the unbalanced word distribution to form clusters that explicitly minimize the expectation of computation time. Our approach further reduces the computational time by exploiting the specificities of modern architectures and matrix-matrix vector operations, making it particularly suited for graphical processing units. Our experiments carried out on standard benchmarks, such as EuroParl and One Billion Word, show that our approach brings a large gain in efficiency over standard approximations while achieving an accuracy close to that of the full softmax. The code of our method is available at https://github.com/facebookresearch/adaptive-softmax.},
  isbn = {9781510855144},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/74PVMK2X/Grave et al. - 2016 - Efficient softmax approximation for GPUs(2).pdf}
}

@article{greenModellingHeterogeneityDirichlet2018,
  title = {Modelling {{Heterogeneity}} with and without the {{Dirichlet Process}}},
  author = {Green, Peter J and Richardson, Sylvia},
  date = {2018},
  volume = {28},
  number = {2},
  pages = {355--375},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IX4LTSLV/Green - 2018 - Board of the Foundation of the Scandinavian Journal of Statistics Modelling Heterogeneity with and without the Dirichlet.pdf}
}

@online{gudibandeFalsePromiseImitating2023,
  title = {The {{False Promise}} of {{Imitating Proprietary LLMs}}},
  author = {Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
  date = {2023-05-25},
  eprint = {2305.15717},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.15717},
  url = {http://arxiv.org/abs/2305.15717},
  urldate = {2023-06-05},
  abstract = {An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model's capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data sources, and imitation data amounts (0.3M--150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models -- they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT's style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/W84FNFVF/2305.15717.pdf}
}

@article{guilliardAutonomousThermallingPartially2018,
  title = {Autonomous {{Thermalling}} as a {{Partially Observable Markov Decision Process}} ( {{Extended Version}} )},
  author = {Guilliard, Iain and Rogahn, Richard and Piavis, Jim and Kolobov, Andrey},
  date = {2018},
  journaltitle = {International Conference on Intelligent Robots and Systems (IROS)},
  eprint = {1805.09875v1},
  eprinttype = {arXiv},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/M9HAQFZX/Guilliard et al. - 2018 - Autonomous Thermalling as a Partially Observable Markov Decision Process ( Extended Version ).pdf}
}

@article{Gunther2010,
  title = {Neuralnet: {{Training}} of {{Neural Networks}}},
  author = {Günther, Frauke and Fritsch, Stefan},
  date = {2010},
  journaltitle = {The R Journal},
  volume = {2},
  number = {1},
  eprint = {22057480},
  eprinttype = {pmid},
  pages = {30--38},
  issn = {2073-4859},
  doi = {10.1109/SP.2010.25},
  abstract = {Artificial neural networks are applied in many situations. neuralnet is built to train multi-layer perceptrons in the context of regres- sion analyses, i.e. to approximate functional rela- tionships between covariates and response vari- ables. Thus, neural networks are used as exten- sions of generalized linear models. neuralnet is a very flexible package. The back- propagation algorithm and three versions of re- silient backpropagation are implemented and it provides a custom-choice of activation and er- ror function. An arbitrary number of covariates and response variables as well as of hidden lay- ers can theoretically be included. The paper gives a brief introduction to multi- layer perceptrons and resilient backpropagation and demonstrates the application of neuralnet using the data set infert, which is contained in the R distribution.},
  isbn = {0-387-95457-0},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/8ET4LXFN/Günther, Fritsch - 2010 - neuralnet Training of Neural Networks.pdf}
}

@inproceedings{Guo,
  title = {Deep {{Bayesian Bandits}}: {{Exploring}} in {{Online Personalized Recommendations}}},
  booktitle = {Fourteenth {{ACM Conference}} on {{Recommender Systems}}},
  author = {Guo, Dalin and Ktena, Sofia Ira and Myana, Pranay Kumar and Huszar, Ferenc and Shi, Wenzhe and Tejani, Alykhan and Kneier, Michael and Das, Sourav},
  date = {2020-09-22},
  eprint = {2008.00727},
  eprinttype = {arXiv},
  pages = {456--461},
  publisher = {ACM},
  location = {New York, NY, USA},
  doi = {10.1145/3383313.3412214},
  url = {https://arxiv.org/abs/2008.00727},
  abstract = {Recommender systems trained in a continuous learning fashion are plagued by the feedback loop problem, also known as algorithmic bias. This causes a newly trained model to act greedily and favor items that have already been engaged by users. This behavior is particularly harmful in personalised ads recommendations, as it can also cause new campaigns to remain unexplored. Exploration aims to address this limitation by providing new information about the environment, which encompasses user preference, and can lead to higher long-term reward. In this work, we formulate a display advertising recommender as a contextual bandit and implement exploration techniques that require sampling from the posterior distribution of click-through-rates in a computationally tractable manner. Traditional large-scale deep learning models do not provide uncertainty estimates by default. We approximate these uncertainty measurements of the predictions by employing a bootstrapped model with multiple heads and dropout units. We benchmark a number of different models in an offline simulation environment using a publicly available dataset of user-ads engagements. We test our proposed deep Bayesian bandits algorithm in the offline simulation and online AB setting with large-scale production traffic, where we demonstrate a positive gain of our exploration model.},
  isbn = {978-1-4503-7583-2},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9QLYF6J7/Guo, Diego, Huszar - Unknown - Deep Bayesian Bandits Exploring in Online Personalized Recommendations.pdf}
}

@unpublished{Guo2017,
  title = {Long {{Text Generation}} via {{Adversarial Training}} with {{Leaked Information}}},
  author = {Guo, Jiaxian and Lu, Sidi and Cai, Han and Zhang, Weinan and Yu, Yong and Wang, Jun},
  date = {2017-09-24},
  eprint = {1709.08624},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1709.08624},
  urldate = {2017-11-28},
  abstract = {Automatically generating coherent and semantically meaningful text has many applications in machine translation, dialogue systems, image captioning, etc. Recently, by combining with policy gradient, Generative Adversarial Nets (GAN) that use a discriminative model to guide the training of the generative model as a reinforcement learning policy has shown promising results in text generation. However, the scalar guiding signal is only available after the entire text has been generated and lacks intermediate information about text structure during the generative process. As such, it limits its success when the length of the generated text samples is long (more than 20 words). In this paper, we propose a new framework, called LeakGAN, to address the problem for long text generation. We allow the discriminative net to leak its own high-level extracted features to the generative net to further help the guidance. The generator incorporates such informative signals into all generation steps through an additional Manager module, which takes the extracted features of current generated words and outputs a latent vector to guide the Worker module for next-word generation. Our extensive experiments on synthetic data and various real-world tasks with Turing test demonstrate that LeakGAN is highly effective in long text generation and also improves the performance in short text generation scenarios. More importantly, without any supervision, LeakGAN would be able to implicitly learn sentence structures only through the interaction between Manager and Worker.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/KQ6Q9K5E/Guo et al. - 2017 - Long Text Generation via Adversarial Training with Leaked Information.pdf}
}

@unpublished{Haarnoja2018,
  title = {Soft {{Actor-Critic}}: {{Off-Policy Maximum Entropy Deep Reinforcement Learning}} with a {{Stochastic Actor}}},
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  date = {2018},
  eprint = {11032563},
  eprinttype = {pmid},
  doi = {arXiv:1801.01290v2},
  url = {http://arxiv.org/abs/1801.01290},
  abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
  isbn = {0264-410X (Print)\textbackslash r0264-410X (Linking)},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9I2W4Z3M/Haarnoja et al. - 2018 - Soft Actor-Critic Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.pdf}
}

@online{haoReasoningLanguageModel2023,
  title = {Reasoning with {{Language Model}} Is {{Planning}} with {{World Model}}},
  author = {Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  date = {2023-10-23},
  eprint = {2305.14992},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.14992},
  urldate = {2023-12-02},
  abstract = {Large language models (LLMs) have shown remarkable reasoning capabilities, especially when prompted to generate intermediate reasoning steps (e.g., Chain-of-Thought, CoT). However, LLMs can still struggle with problems that are easy for humans, such as generating action plans for executing tasks in a given environment, or performing complex math, logical, and commonsense reasoning. The deficiency stems from the key fact that LLMs lack an internal \$\textbackslash textit\{world model\}\$ to predict the world \$\textbackslash textit\{state\}\$ (e.g., environment status, intermediate variable values) and simulate long-term outcomes of actions. This prevents LLMs from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new LLM reasoning framework, \$\textbackslash underline\{R\}\$easoning vi\$\textbackslash underline\{a\}\$ \$\textbackslash underline\{P\}\$lanning \$\textbackslash textbf\{(RAP)\}\$. RAP repurposes the LLM as both a world model and a reasoning agent, and incorporates a principled planning algorithm (based on Monto Carlo Tree Search) for strategic exploration in the vast reasoning space. During reasoning, the LLM (as agent) incrementally builds a reasoning tree under the guidance of the LLM (as world model) and task-specific rewards, and obtains a high-reward reasoning path efficiently with a proper balance between exploration \$\textbackslash textit\{vs.\}\$ exploitation. We apply RAP to a variety of challenging reasoning problems including plan generation, math reasoning, and logical inference. Empirical results on these tasks demonstrate the superiority of RAP over various strong baselines, including CoT and least-to-most prompting with self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33\% relative improvement in a plan generation setting.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DNSTU7DM/Hao et al. - 2023 - Reasoning with Language Model is Planning with Wor.pdf}
}

@book{Harrel2001,
  title = {Springer {{Series}} in {{Statistics Springer Series}} in {{Statistics}}},
  author = {family=Harrel, given=Jr. F. E., given-i={{Jr}}FE},
  date = {2001},
  eprint = {15772297},
  eprinttype = {pmid},
  issn = {01727397},
  doi = {10.1007/978-0-387-98135-2},
  isbn = {978-1-4419-2918-1},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/N9JDJ63L/Harrel - 2001 - Springer Series in Statistics Springer Series in Statistics.pdf}
}

@book{HastieTrevor2009,
  title = {The Elements of Statistical Learning : Data Mining, Inference, and Prediction},
  author = {Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome;},
  date = {2009},
  journaltitle = {2009},
  eprint = {15512507},
  eprinttype = {pmid},
  issn = {0343-6993},
  doi = {10.1007/BF02985802},
  url = {http://ucl-primo.hosted.exlibrisgroup.com/primo_library/libweb/action/display.do;jsessionid=078607CD6BD74BEB05E0179C6387A2E2?tabs=detailsTab&ct=display&fn=search&doc=UCL_LMS_DS001238326&indx=1&recIds=UCL_LMS_DS001238326&recIdxs=0&elementId=0&renderMode=po},
  isbn = {978-0-387-84857-0},
  pagetotal = {745},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7P5JSY3P/Hastie, Trevor Tibshirani, Robert Friedman - 2009 - The elements of statistical learning data mining, inference, and prediction.pdf}
}

@online{hayouLoRAEfficientLow2024,
  title = {{{LoRA}}+: {{Efficient Low Rank Adaptation}} of {{Large Models}}},
  shorttitle = {{{LoRA}}+},
  author = {Hayou, Soufiane and Ghosh, Nikhil and Yu, Bin},
  date = {2024-02-19},
  eprint = {2402.12354},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2402.12354},
  urldate = {2024-03-04},
  abstract = {In this paper, we show that Low Rank Adaptation (LoRA) as originally introduced in [17] leads to suboptimal finetuning of models with large width (embedding dimension). This is due to the fact that adapter matrices A and B in LoRA are updated with the same learning rate. Using scaling arguments for large width networks, we demonstrate that using the same learning rate for A and B does not allow efficient feature learning. We then show that this suboptimality of LoRA can be corrected simply by setting different learning rates for the LoRA adapter matrices A and B with a well-chosen fixed ratio. We call this proposed algorithm LoRA+. In our extensive experiments, LoRA+ improves performance (1\% − 2\% improvements) and finetuning speed (up to ∼ 2X SpeedUp), at the same computational cost as LoRA.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/58W4T6ZK/Hayou et al. - 2024 - LoRA+ Efficient Low Rank Adaptation of Large Mode.pdf}
}

@unpublished{He2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015},
  volume = {7},
  number = {3},
  eprint = {23554596},
  eprinttype = {pmid},
  pages = {171--180},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00124},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn- ing residual functions with reference to the layer inputs, in- stead of learning unreferenced functions. We provide com- prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complex- ity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex- tremely deep representations, we obtain a 28\% relative im- provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet local- ization, COCO detection, and COCO segmentation.},
  isbn = {978-1-4673-6964-0},
  keywords = {deep learning,denoising auto-encoder,image denoising},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/32C2YKX2/m-api-1096cf17-d69b-5b9b-7776-e198a7f71034.pdf}
}

@article{Heinrich2015,
  title = {Fictitious {{Self-Play}} in {{Extensive-Form Games}}},
  author = {Heinrich, Johannes and Lanctot, Marc and Silver, David},
  date = {2015},
  journaltitle = {ICML'15 Proceedings of the 32nd International Conference on International Conference on Machine Learning},
  issn = {1938-7228},
  abstract = {Fictitious play is a popular game-theoretic model of learning in games. However, it has received little attention in practical applications to large problems. This paper introduces two variants of fictitious play that are implemented in be-havioural strategies of an extensive-form game. The first variant is a full-width process that is re-alization equivalent to its normal-form counter-part and therefore inherits its convergence guar-antees. However, its computational requirements are linear in time and space rather than exponen-tial. The second variant, Fictitious Self-Play, is a machine learning framework that implements fictitious play in a sample-based fashion. Ex-periments in imperfect-information poker games compare our approaches and demonstrate their convergence to approximate Nash equilibria.},
  isbn = {9781510810587}
}

@article{Heinrich2016,
  title = {Deep {{Reinforcement Learning}} from {{Self-Play}} in {{Imperfect-Information Games}}},
  author = {Heinrich, Johannes and Silver, David},
  date = {2016},
  journaltitle = {Arxiv},
  eprint = {1603.01121},
  eprinttype = {arXiv},
  abstract = {Many real-world applications can be described as large-scale games of imperfect information. To deal with these challenging domains, prior work has focused on computing Nash equilib-ria in a handcrafted abstraction of the domain. In this paper we introduce the first scalable end-to-end approach to learning approximate Nash equilibria without any prior knowledge. Our method combines fictitious self-play with deep reinforcement learning. When applied to Leduc poker, Neural Fictitious Self-Play (NFSP) ap-proached a Nash equilibrium, whereas common reinforcement learning methods diverged. In Limit Texas Hold'em, a poker game of real-world scale, NFSP learnt a competitive strategy that approached the performance of human ex-perts and state-of-the-art methods.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/U2SQVZ6S/Heinrich, Silver - 2016 - Deep Reinforcement Learning from Self-Play in Imperfect-Information Games.pdf}
}

@online{hejnaContrastivePreferenceLearning2023,
  title = {Contrastive {{Preference Learning}}: {{Learning}} from {{Human Feedback}} without {{RL}}},
  shorttitle = {Contrastive {{Preference Learning}}},
  author = {Hejna, Joey and Rafailov, Rafael and Sikchi, Harshit and Finn, Chelsea and Niekum, Scott and Knox, W. Bradley and Sadigh, Dorsa},
  date = {2023-10-23},
  eprint = {2310.13639},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.13639},
  urldate = {2024-03-06},
  abstract = {Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular paradigm for aligning models with human intent. Typically RLHF algorithms operate in two phases: first, use human preferences to learn a reward function and second, align the model by optimizing the learned reward via reinforcement learning (RL). This paradigm assumes that human preferences are distributed according to reward, but recent work suggests that they instead follow the regret under the user’s optimal policy. Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase. Because of these optimization challenges, contemporary RLHF methods restrict themselves to contextual bandit settings (e.g., as in large language models) or limit observation dimensionality (e.g., state-based robotics). We overcome these limitations by introducing a new family of algorithms for optimizing behavior from human feedback using the regret-based model of human preferences. Using the principle of maximum entropy, we derive Contrastive Preference Learning (CPL), an algorithm for learning optimal policies from preferences without learning reward functions, circumventing the need for RL. CPL is fully off-policy, uses only a simple contrastive objective, and can be applied to arbitrary MDPs. This enables CPL to elegantly scale to high-dimensional and sequential RLHF problems while being simpler than prior methods.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/J3XPUFCL/Hejna et al. - 2023 - Contrastive Preference Learning Learning from Hum.pdf}
}

@article{hermansLikelihoodfreeMCMCAmortized2020,
  title = {Likelihood-Free {{MCMC}} with Amortized Approximate Ratio Estimators},
  author = {Hermans, Joeri and Begy, Volodimir and Louppe, Gilles},
  date = {2020},
  journaltitle = {37th International Conference on Machine Learning, ICML 2020},
  volume = {PartF16814},
  number = {i},
  eprint = {1903.04057},
  eprinttype = {arXiv},
  pages = {4187--4198},
  abstract = {Posterior inference with an intractable likelihood is becoming an increasingly common task in scientific domains which rely on sophisticated computer simulations. Typically, these forward models do not admit tractable densities forcing practitioners to make use of approximations. This work introduces a novel approach to address the intractability of the likelihood and the marginal model. We achieve this by learning a flexible amortized estimator which approximates the likelihood-to-evidence ratio. We demonstrate that the learned ratio estimator can be embedded in MCMC samplers to approximate likelihood-ratios between consecutive states in the Markov chain, allowing us to draw samples from the intractable posterior. Techniques are presented to improve the numerical stability and to measure the quality of an approximation. The accuracy of our approach is demonstrated on a variety of benchmarks against well-established techniques. Scientific applications in physics show its applicabilit.},
  isbn = {9781713821120},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Q86V7RCL/Hermans, Begy, Louppe - 2020 - Likelihood-free MCMC with amortized approximate ratio estimators.pdf}
}

@unpublished{Hessel2017,
  title = {Rainbow: {{Combining Improvements}} in {{Deep Reinforcement Learning}}},
  author = {Hessel, Matteo and Modayil, Joseph and family=Hasselt, given=Hado, prefix=van, useprefix=true and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  date = {2017},
  eprint = {1710.02298},
  eprinttype = {arXiv},
  issn = {15205126},
  doi = {10.1021/ja00048a049},
  url = {http://arxiv.org/abs/1710.02298},
  abstract = {The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.},
  isbn = {1710.02298v1},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/272C6Q69/1710.02298.pdf}
}

@report{Hidasi,
  title = {Organization {{Workshop}} Chairs {{Program}} Committee},
  author = {Hidasi, Balázs and Sar-Shalom, Oren and Vasile, Flavian and Dieleman, Criteo Sander and Quadrana, Massimo and Usa, Pandora and Mcauley, Julian},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Y3RPJ4BN/dlrs2018_proceedings.pdf}
}

@inproceedings{hidasi2016,
  title = {Session-Based Recommendations with Recurrent Neural Networks},
  booktitle = {4th {{International Conference}} on {{Learning Representations}}, {{ICLR}} 2016 - {{Conference Track Proceedings}}},
  author = {Hidasi, Balázs and Karatzoglou, Alexandros and Baltrunas, Linas and Tikk, Domonkos},
  date = {2016},
  eprint = {1511.06939},
  eprinttype = {arXiv},
  abstract = {We apply recurrent neural networks (RNN) on a new domain, namely recommender systems. Real-life recommender systems often face the problem of having to base recommendations only on short session-based data (e.g. a small sportsware website) instead of long user histories (as in the case of Netflix). In this situation the frequently praised matrix factorization approaches are not accurate. This problem is usually overcome in practice by resorting to item-to-item recommendations, i.e. recommending similar items. We argue that by modeling the whole session, more accurate recommendations can be provided. We therefore propose an RNN-based approach for session-based recommendations. Our approach also considers practical aspects of the task and introduces several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem. Experimental results on two data-sets show marked improvements over widely used approaches.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YDTUXVL5/1511.06939.pdf}
}

@inproceedings{Hidasi2016,
  title = {Parallel {{Recurrent Neural Network Architectures}} for {{Feature-rich Session-based Recommendations}}},
  booktitle = {Proceedings of the 10th {{ACM Conference}} on {{Recommender Systems}} - {{RecSys}} '16},
  author = {Hidasi, Balázs and Quadrana, Massimo and Karatzoglou, Alexandros and Tikk, Domonkos},
  date = {2016},
  pages = {241--248},
  issn = {00030007},
  doi = {10.1145/2959100.2959167},
  abstract = {Reallife recommender systems often face the daunting task of providing recommendations based only on the clicks of a user session. Methods that rely on user profiles – such as matrix factorization – perform very poorly in this setting, thus itemtoitem recommendations are used most of the time. However the items typically have rich feature representations such as pictures and text descriptions that can be used to model the sessions. Here we investigate how these features can be exploited in Recurrent Neural Network based session models using deep learning. We show that obvious approaches do not leverage these data sources. We thus introduce a number of parallel RNN (pRNN) architectures to model sessions based on the clicks and the features (images and text) of the clicked items. We also propose alternative training strategies for pRNNs that suit them better than standard training. We show that pRNN architectures with proper training have significant performance improvements over featureless session models while all sessionbased models outperform the itemtoitem type baseline.},
  isbn = {978-1-4503-4035-9},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/P5HD4CZ7/p_rnn_recsys16.pdf}
}

@inproceedings{Hidasi2018,
  title = {Recurrent {{Neural Net-works}} with {{Top-k Gains}} for {{Session-based Recommendations}}},
  booktitle = {Proceedings of the 27th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Hidasi, Balázs and Karatzoglou, Alexandros},
  date = {2018},
  eprint = {1706.03847v3},
  eprinttype = {arXiv},
  pages = {10},
  publisher = {ACM},
  doi = {10.1145/3269206.3271761},
  url = {https://dl.acm.org/citation.cfm?id=3271761},
  urldate = {2019-01-27},
  abstract = {RNNs have been shown to be excellent models for sequential data and in particular for data that is generated by users in an session-based manner. The use of RNNs provides impressive performance benefits over classical methods in session-based recommendations. In this work we introduce novel ranking loss functions tailored to RNNs in the recommendation setting. The improved performance of these losses over alternatives, along with further tricks and refinements described in this work, allow for an overall improvement of up to 35\% in terms of MRR and Recall@20 over previous session-based RNN solutions and up to 53\% over classical collaborative filtering approaches. Unlike data augmentation-based improvements, our method does not increase training times significantly. We further demonstrate the performance gain of the RNN over baselines in an online A/B test.},
  isbn = {978-1-4503-6014-2},
  keywords = {loss function,ranking,recommender systems,recurrent neural networks,session-based recommendation},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BX2VIC63/full-text.pdf}
}

@online{hoDenoisingDiffusionProbabilistic2020,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  date = {2020-12-16},
  eprint = {2006.11239},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2006.11239},
  url = {http://arxiv.org/abs/2006.11239},
  urldate = {2023-03-25},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BFWCATP7/Ho et al. - 2020 - Denoising Diffusion Probabilistic Models.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/L863XWHW/2006.html}
}

@online{hoDenoisingDiffusionProbabilistic2020a,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  date = {2020-12-16},
  eprint = {2006.11239},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2006.11239},
  urldate = {2024-09-27},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/2489E9TX/Ho et al. - 2020 - Denoising Diffusion Probabilistic Models.pdf}
}

@article{Hoffman2013,
  title = {Stochastic {{Variational Inference}}},
  author = {Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John and Edu, Jpaisley@berkeley and Jaakkola, Tommi},
  date = {2013},
  journaltitle = {Journal of Machine Learning Research},
  volume = {14},
  pages = {1303--1347},
  abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
  keywords = {Bayesian inference,Bayesian nonparametrics,stochastic optimization,topic models,variational inference},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/MSUUW9K7/m-api-669a26df-173d-2457-7062-6619fd654a5c.pdf}
}

@article{Hoffman2017,
  title = {Learning {{Deep Latent Gaussian Models}} with {{Markov Chain Monte Carlo}}},
  author = {Hoffman, Matthew D},
  date = {2017},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3RDW26XD/Hoffman - 2017 - Learning Deep Latent Gaussian Models with Markov Chain Monte Carlo.pdf}
}

@online{hollmannTabPFNTransformerThat2023,
  title = {{{TabPFN}}: {{A Transformer That Solves Small Tabular Classification Problems}} in a {{Second}}},
  shorttitle = {{{TabPFN}}},
  author = {Hollmann, Noah and Müller, Samuel and Eggensperger, Katharina and Hutter, Frank},
  date = {2023-09-16},
  eprint = {2207.01848},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.01848},
  urldate = {2024-11-03},
  abstract = {We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN performs in-context learning (ICL), it learns to make predictions using sequences of labeled examples (x, f(x)) given in the input, without requiring further parameter updates. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to 230× speedup. This increases to a 5 700× speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML. We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AK7TLMDY/Hollmann et al. - 2023 - TabPFN A Transformer That Solves Small Tabular Cl.pdf}
}

@online{holtzmanCuriousCaseNeural2020,
  title = {The {{Curious Case}} of {{Neural Text Degeneration}}},
  author = {Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  date = {2020-02-14},
  eprint = {1904.09751},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1904.09751},
  url = {http://arxiv.org/abs/1904.09751},
  urldate = {2023-01-15},
  abstract = {Despite considerable advancements with deep neural language models, the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, using likelihood as a decoding objective leads to text that is bland and strangely repetitive. In this paper, we reveal surprising distributional differences between human text and machine text. In addition, we find that decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model. Our findings motivate Nucleus Sampling, a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/74QS3G4N/Holtzman et al. - 2020 - The Curious Case of Neural Text Degeneration.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/NH4WCV6K/1904.html}
}

@misc{HowJing,
  title = {Neural {{Survival Recommender How}}},
  author = {{How Jing} and Smola, Alexander J},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SL6P3T7X/How Jing, Smola - Unknown - Neural Survival Recommender How.pdf}
}

@unpublished{Hron2020,
  title = {Exact Posterior Distributions of Wide {{Bayesian}} Neural Networks},
  author = {Hron, Jiri and Bahri, Yasaman and Novak, Roman and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
  date = {2020},
  eprint = {2006.10541},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2006.10541},
  abstract = {Recent work has shown that the prior over functions induced by a deep Bayesian neural network (BNN) behaves as a Gaussian process (GP) as the width of all layers becomes large. However, many BNN applications are concerned with the BNN function space posterior. While some empirical evidence of the posterior convergence was provided in the original works of Neal (1996) and Matthews et al. (2018), it is limited to small datasets or architectures due to the notorious difficulty of obtaining and verifying exactness of BNN posterior approximations. We provide the missing theoretical proof that the exact BNN posterior converges (weakly) to the one induced by the GP limit of the prior. For empirical validation, we show how to generate exact samples from a finite BNN on a small dataset via rejection sampling.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Q44TE2P8/Hron et al. - 2020 - Exact posterior distributions of wide Bayesian neural networks.pdf}
}

@article{Hsieh2017,
  title = {Collaborative Metric Learning},
  author = {Hsieh, Cheng Kang and Yang, Longqi and Cui, Yin and Lin, Tsung Yi and Belongie, Serge and Estrin, Deborah},
  date = {2017},
  journaltitle = {26th International World Wide Web Conference, WWW 2017},
  pages = {193--201},
  doi = {10.1145/3038912.3052639},
  abstract = {Metric learning algorithms produce distance metrics that capture the important relationships among data. In this work, we study the connection between metric learning and collaborative filtering. We propose Collaborative Metric Learning (CML) which learns a joint metric space to encode not only users’ preferences but also the user-user and item-item similarity. The proposed algorithm outperforms state-of-the-art collaborative filtering algorithms on a wide range of recommendation tasks and uncovers the underlying spectrum of users’ fine-grained preferences. CML also achieves significant speedup for Top-K recommendation tasks using off-the-shelf, approximate nearest-neighbor search, with negligible accuracy reduction.},
  isbn = {9781450349130},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/X9AVNGBU/Hsieh et al. - 2017 - Collaborative metric learning.pdf}
}

@inproceedings{Hu2008,
  title = {Collaborative {{Filtering}} for {{Implicit Feedback Datasets}}},
  booktitle = {2008 {{Eighth IEEE International Conference}} on {{Data Mining}}},
  author = {Hu, Yifan and Koren, Yehuda and Volinsky, Chris},
  date = {2008-12},
  pages = {263--272},
  publisher = {IEEE},
  issn = {15504786},
  doi = {10.1109/ICDM.2008.22},
  url = {https://www.mendeley.com/import/},
  isbn = {978-0-7695-3502-9},
  keywords = {academic research,academic software,academics,bibliography,digital library,library management,library software,reference software,research paper,research tool,researcher},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/N44S9L8M/Hu, Koren, Volinsky - 2008 - Collaborative Filtering for Implicit Feedback Datasets.pdf}
}

@article{hueberEvaluatingPotentialGain2020,
  title = {Evaluating the Potential Gain of Auditory and Audiovisual Speech-Predictive Coding Using Deep Learning},
  author = {Hueber, Thomas and Tatulli, Eric and Girin, Laurent and Schwartz, Jean Luc},
  date = {2020},
  journaltitle = {Neural Computation},
  volume = {32},
  number = {3},
  eprint = {31951798},
  eprinttype = {pmid},
  pages = {596--625},
  issn = {1530888X},
  doi = {10.1162/neco_a_01264},
  abstract = {Sensory processing is increasingly conceived in a predictive framework in which neurons would constantly process the error signal resulting from the comparison of expected and observed stimuli. Surprisingly, few data exist on the accuracy of predictions that can be computed in real sensory scenes. Here, we focus on the sensory processing of auditory and audiovisual speech. We propose a set of computational models based on artificial neural networks (mixing deep feedforward and convolutional networks), which are trained to predict future audio observations from present and past audio or audiovisual observations (i.e., including lip movements). Those predictions exploit purely local phonetic regularities with no explicit call to higher linguistic levels. Experiments are conducted on the multispeaker LibriSpeech audio speech database (around 100 hours) and on the NTCD-TIMIT audiovisual speech database (around 7 hours). They appear to be efficient in a short temporal range (25–50 ms), predicting 50\% to 75\% of the variance of the incoming stimulus, which could result in potentially saving up to three-quarters of the processing power. Then they quickly decrease and almost vanish after 250 ms. Adding information on the lips slightly improves predictions, with a 5\% to 10\% increase in explained variance. Interestingly the visual gain vanishes more slowly, and the gain is maximum for a delay of 75 ms between image and predicted sound.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/NBH78VJS/Hueber et al. - 2020 - Evaluating the potential gain of auditory and audiovisual speech-predictive coding using deep learning.pdf}
}

@online{HuggingFaceAI,
  title = {Hugging {{Face}} – {{The AI}} Community Building the Future.},
  url = {https://huggingface.co/},
  urldate = {2023-01-24},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7EZCGA5V/huggingface.co.html}
}

@inproceedings{huLoRALowRankAdaptation2022,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  date = {2022-01-28},
  eprint = {2106.09685},
  eprinttype = {arXiv},
  eprintclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2106.09685},
  url = {https://openreview.net/forum?id=nZeVKeeFYf9},
  urldate = {2023-05-05},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SS2PKGNK/Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/G2566QPX/Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.html}
}

@article{Hummer2000,
  title = {Summary Questions},
  author = {Hummer, K. E. and Sniezko, R.},
  date = {2000},
  journaltitle = {HortTechnology},
  volume = {10},
  number = {3},
  pages = {570},
  issn = {10630198},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZMUYXMHU/Hummer, Sniezko - 2000 - Summary questions.pdf}
}

@article{Ie2019,
  title = {Reinforcement Learning for Slate-Based Recommender Systems: {{A}} Tractable Decomposition and Practical Methodology},
  author = {Ie, Eugene and Jain, Vihan and Wang, Jing and Narvekar, Sanmit and Agarwal, Ritesh and Wu, Rui and Cheng, Heng Tze and Lustman, Morgane and Gatto, Vince and Covington, Paul and McFadden, Jim and Chandra, Tushar and Boutilier, Craig},
  date = {2019-05-29},
  journaltitle = {arXiv},
  eprint = {1905.12767},
  eprinttype = {arXiv},
  pages = {1--38},
  issn = {23318422},
  url = {http://arxiv.org/abs/1905.12767},
  abstract = {Most practical recommender systems focus on estimating immediate user engagement without considering the long-term effects of recommendations on user behavior. Reinforcement learning (RL) methods offer the potential to optimize recommendations for long-term user engagement. However, since users are often presented with slates of multiple items-which may have interacting effects on user choice-methods are required to deal with the combinatorics of the RL action space. In this work, we address the challenge of making slate-based recommendations to optimize long-term value using RL. Our contributions are three-fold. (i) We develop SLATEQ, a decomposition of value-based temporal-difference and Q-learning that renders RL tractable with slates. Under mild assumptions on user choice behavior, we show that the long-term value (LTV) of a slate can be decomposed into a tractable function of its component item-wise LTVs. (ii) We outline a methodology that leverages existing myopic learning-based recommenders to quickly develop a recommender that handles LTV. (iii) We demonstrate our methods in simulation, and validate the scalability of decomposed TD-learning using SLATEQ in live experiments on YouTube.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5SZ368DN/Ie et al. - 2019 - Reinforcement learning for slate-based recommender systems A tractable decomposition and practical methodology.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/HXJRI4GJ/Ie et al. - 2019 - Reinforcement learning for slate-based recommender systems A tractable decomposition and practical methodology(2).pdf}
}

@article{Ie2019a,
  title = {{{SLateq}}: {{A}} Tractable Decomposition for Reinforcement Learning with Recommendation Sets},
  author = {Ie, Eugene and Jain, Vihan and Wang, Jing and Narvekar, Sanmit and Agarwal, Ritesh and Wu, Rui and Cheng, Heng Tze and Chandra, Tushar and Boutilier, Craig},
  date = {2019},
  journaltitle = {IJCAI International Joint Conference on Artificial Intelligence},
  volume = {2019-Augus},
  pages = {2592--2599},
  issn = {10450823},
  doi = {10.24963/ijcai.2019/360},
  abstract = {Reinforcement learning (RL) methods for recommender systems optimize recommendations for long-term user engagement. However, since users are often presented with slates of multiple items-which may have interacting effects on user choice-methods are required to deal with the combinatorics of the RL action space. We develop SLATEQ, a decomposition of value-based temporal-difference and Q-learning that renders RL tractable with slates. Under mild assumptions on user choice behavior, we show that the long-term value (LTV) of a slate can be decomposed into a tractable function of its component item-wise LTVs. We demonstrate our methods in simulation, and validate the scalability and effectiveness of decomposed TD-learning on YouTube.},
  isbn = {9780999241141},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/USF2TK2D/Ie et al. - 2019 - SLateq A tractable decomposition for reinforcement learning with recommendation sets.pdf}
}

@article{ieyRECSIMConfigurableSimulation2019,
  title = {{{RECSIM}}: {{A}} Configurable Simulation Platform for Recommender Systems},
  author = {Iey, Eugene and Hsu, Chih Wei and Mladenov, Martin and Jain, Vihan and Narvekarx, Sanmit and Wang, Jing and Wu, Rui and Boutilier, Craig},
  date = {2019},
  journaltitle = {arXiv},
  eprint = {1909.04847},
  eprinttype = {arXiv},
  pages = {1--23},
  issn = {23318422},
  abstract = {We propose RECSIM, a configurable platform for authoring simulation environments for recommender systems (RSs) that naturally supports sequential interaction with users. RECSIM allows the creation of new environments that reflect particular aspects of user behavior and item structure at a level of abstraction well-suited to pushing the limits of current reinforcement learning (RL) and RS techniques in sequential interactive recommendation problems. Environments can be easily configured that vary assumptions about: User preferences and item familiarity; user latent state and its dynamics; and choice models and other user response behavior. We outline how RECSIM offers value to RL and RS researchers and practitioners, and how it can serve as a vehicle for academic-industrial collaboration.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BGXBCD2Z/Iey et al. - 2019 - RECSIM A configurable simulation platform for recommender systems.pdf}
}

@online{ImplicitBayesianInference2022,
  title = {Implicit {{Bayesian Inference}} in {{Large Language Models}}},
  date = {2022-03-03T13:57:26},
  url = {https://www.inference.vc/implicit-bayesian-inference-in-sequence-models/},
  urldate = {2023-01-12},
  abstract = {This intriguing paper kept me thinking long enough for me to I decide it's time to resurrect my blogging (I started writing this during ICLR review period, and realised it might be a good idea to wait until that's concluded) Sang Michael Xie, Aditi Raghunathan, Percy Liang and Tengyu Ma...},
  langid = {english},
  organization = {inFERENCe},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DS4X3QFE/implicit-bayesian-inference-in-sequence-models.html}
}

@online{ivisonCamelsChangingClimate2023,
  title = {Camels in a {{Changing Climate}}: {{Enhancing LM Adaptation}} with {{Tulu}} 2},
  shorttitle = {Camels in a {{Changing Climate}}},
  author = {Ivison, Hamish and Wang, Yizhong and Pyatkin, Valentina and Lambert, Nathan and Peters, Matthew and Dasigi, Pradeep and Jang, Joel and Wadden, David and Smith, Noah A. and Beltagy, Iz and Hajishirzi, Hannaneh},
  date = {2023-11-19},
  eprint = {2311.10702},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.10702},
  url = {http://arxiv.org/abs/2311.10702},
  urldate = {2023-11-24},
  abstract = {Since the release of T\textbackslash "ULU [Wang et al., 2023b], open resources for instruction tuning have developed quickly, from better base models to new finetuning techniques. We test and incorporate a number of these advances into T\textbackslash "ULU, resulting in T\textbackslash "ULU 2, a suite of improved T\textbackslash "ULU models for advancing the understanding and best practices of adapting pretrained language models to downstream tasks and user preferences. Concretely, we release: (1) T\textbackslash "ULU-V2-mix, an improved collection of high-quality instruction datasets; (2) T\textbackslash "ULU 2, LLAMA-2 models finetuned on the V2 mixture; (3) T\textbackslash "ULU 2+DPO, T\textbackslash "ULU 2 models trained with direct preference optimization (DPO), including the largest DPO-trained model to date (T\textbackslash "ULU 2+DPO 70B); (4) CODE T\textbackslash "ULU 2, CODE LLAMA models finetuned on our V2 mix that outperform CODE LLAMA and its instruction-tuned variant, CODE LLAMA-Instruct. Our evaluation from multiple perspectives shows that the T\textbackslash "ULU 2 suite achieves state-of-the-art performance among open models and matches or exceeds the performance of GPT-3.5-turbo-0301 on several benchmarks. We release all the checkpoints, data, training and evaluation code to facilitate future open efforts on adapting large language models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/36DS43TH/2311.10702.pdf}
}

@unpublished{Izadinia2016,
  title = {{{Im2Cad}}},
  author = {Izadinia, Hamid and Shan, Qi and Seitz, Steven M.},
  date = {2016},
  eprint = {1608.05137},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1608.05137},
  abstract = {Given a single photo of a room and a large database of furniture CAD models, our goal is to reconstruct a scene that is as similar as possible to the scene depicted in the photograph, and composed of objects drawn from the database. We present a completely automatic system to address this IM2CAD problem that produces high quality results on challenging imagery from interior home design and remodeling websites. Our approach iteratively optimizes the placement and scale of objects in the room to best match scene renderings to the input photo, using image comparison metrics trained via deep convolutional neural nets. By operating jointly on the full scene at once, we account for inter-object occlusions. We also show the applicability of our method in standard scene understanding benchmarks where we obtain significant improvement.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BFB95MFI/Izadinia, Shan, Seitz - 2016 - Im2Cad.pdf}
}

@unpublished{Izmailov2021,
  title = {What {{Are Bayesian Neural Network Posteriors Really Like}}?},
  author = {Izmailov, Pavel and Vikram, Sharad and Hoffman, Matthew D. and Wilson, Andrew Gordon},
  date = {2021},
  eprint = {2104.14421},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2104.14421},
  abstract = {The posterior over Bayesian neural network (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in Bayesian deep learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) BNNs can achieve significant performance gains over standard training and deep ensembles; (2) a single long HMC chain can provide a comparable representation of the posterior to multiple shorter chains; (3) in contrast to recent studies, we find posterior tempering is not needed for near-optimal performance, with little evidence for a "cold posterior" effect, which we show is largely an artifact of data augmentation; (4) BMA performance is robust to the choice of prior scale, and relatively similar for diagonal Gaussian, mixture of Gaussian, and logistic priors; (5) Bayesian neural networks show surprisingly poor generalization under domain shift; (6) while cheaper alternatives such as deep ensembles and SGMCMC methods can provide good generalization, they provide distinct predictive distributions from HMC. Notably, deep ensemble predictive distributions are similarly close to HMC as standard SGLD, and closer than standard variational inference.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/D9XF7JKF/Izmailov et al. - 2021 - What Are Bayesian Neural Network Posteriors Really Like.pdf}
}

@article{jadidinejadSimpsonParadoxOffline2021,
  title = {The {{Simpson}}'s {{Paradox}} in the {{Offline Evaluation}} of {{Recommendation Systems}}},
  author = {Jadidinejad, Amir H. and Macdonald, Craig and Ounis, Iadh},
  date = {2021},
  journaltitle = {ACM Transactions on Information Systems},
  volume = {1},
  number = {1},
  eprint = {2104.08912},
  eprinttype = {arXiv},
  pages = {1--21},
  publisher = {Association for Computing Machinery},
  doi = {10.1145/xxxxxxx},
  url = {http://arxiv.org/abs/2104.08912},
  abstract = {Recommendation systems are often evaluated based on user's interactions that were collected from an existing, already deployed recommendation system. In this situation, users only provide feedback on the exposed items and they may not leave feedback on other items since they have not been exposed to them by the deployed system. As a result, the collected feedback dataset that is used to evaluate a new model is influenced by the deployed system, as a form of closed loop feedback. In this paper, we show that the typical offline evaluation of recommender systems suffers from the so-called Simpson's paradox. Simpson's paradox is the name given to a phenomenon observed when a significant trend appears in several different sub-populations of observational data but disappears or is even reversed when these sub-populations are combined together. Our in-depth experiments based on stratified sampling reveal that a very small minority of items that are frequently exposed by the deployed system plays a confounding factor in the offline evaluation of recommendation systems. In addition, we propose a novel evaluation methodology that takes into account the confounder, i.e the deployed system's characteristics. Using the relative comparison of many recommendation models as in the typical offline evaluation of recommender systems, and based on the Kendall rank correlation coefficient, we show that our proposed evaluation methodology exhibits statistically significant improvements of 14\% and 40\% on the examined open loop datasets (Yahoo! and Coat), respectively, in reflecting the true ranking of systems with an open loop (randomised) evaluation in comparison to the standard evaluation.},
  keywords = {Offline Evaluation Simpson's Paradox Experimenta},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/U5BY5SGN/Jadidinejad, Macdonald, Ounis - 2021 - The Simpson's Paradox in the Offline Evaluation of Recommendation Systems.pdf}
}

@article{jainSplitMergeMarkovChain2004,
  title = {A {{Split-Merge Markov Chain Monte Carlo Procedure}} for the {{Dirichlet Process Mixture Model}}},
  author = {Jain, Sonia and Neal, Radford M.},
  date = {2004},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {13},
  number = {1},
  pages = {158--182},
  issn = {10618600},
  doi = {10.1198/1061860043001},
  abstract = {This article proposes a split-merge Markov chain algorithm to address the problem of inefficient sampling for conjugate Dirichlet process mixture models. Traditional Markov chain Monte Carlo methods for Bayesian mixture models, such as Gibbs sampling, can become trapped in isolated modes corresponding to an inappropriate clustering of data points. This article describes a Metropolis-Hastings procedure that can escape such local modes by splitting or merging mixture components. Our algorithm employs a new technique in which an appropriate proposal for splitting or merging components is obtained by using a restricted Gibbs sampling scan. We demonstrate empirically that our method outperforms the Gibbs sampler in situations where two or more components are similar in structure.},
  isbn = {1061860043001},
  keywords = {Gibbs sampler,Latent class analysis,Metropolis-Hastings algorithm},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/WQ62H5A5/Jain, Neal - 2004 - A Split-Merge Markov Chain Monte Carlo Procedure for the Dirichlet Process Mixture Model.pdf}
}

@online{jannerPlanningDiffusionFlexible2022,
  title = {Planning with {{Diffusion}} for {{Flexible Behavior Synthesis}}},
  author = {Janner, Michael and Du, Yilun and Tenenbaum, Joshua B. and Levine, Sergey},
  date = {2022-12-20},
  eprint = {2205.09991},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.09991},
  url = {http://arxiv.org/abs/2205.09991},
  urldate = {2023-06-06},
  abstract = {Model-based reinforcement learning methods often use learning only for the purpose of estimating an approximate dynamics model, offloading the rest of the decision-making work to classical trajectory optimizers. While conceptually simple, this combination has a number of empirical shortcomings, suggesting that learned models may not be well-suited to standard trajectory optimization. In this paper, we consider what it would look like to fold as much of the trajectory optimization pipeline as possible into the modeling problem, such that sampling from the model and planning with it become nearly identical. The core of our technical approach lies in a diffusion probabilistic model that plans by iteratively denoising trajectories. We show how classifier-guided sampling and image inpainting can be reinterpreted as coherent planning strategies, explore the unusual and useful properties of diffusion-based planning methods, and demonstrate the effectiveness of our framework in control settings that emphasize long-horizon decision-making and test-time flexibility.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AI3ADA3G/2205.09991.pdf}
}

@online{jeunenLessonsLearnedWinning,
  title = {Lessons {{Learned}} from {{Winning}} the {{RecoGym Challenge}}},
  author = {Jeunen, Olivier},
  url = {https://olivierjeunen.github.io/recogym/},
  urldate = {2023-01-04},
  abstract = {Lead Decision Scientist @ ShareChat, UK},
  langid = {english},
  organization = {Olivier Jeunen},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/UYCVXEB8/recogym.html}
}

@article{Jiang2019,
  title = {B {{Eyond G Reedy R Anking}} : {{S Late O Ptimization Via L Ist}} -{{Cvae}}},
  author = {Jiang, Ray and Rezende, Danilo J},
  date = {2019},
  pages = {1--12},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/JXKXHSWH/8b798ab071e46e499aadcf608054b7f73633a19d.pdf}
}

@online{jiangMoRAHighRankUpdating2024,
  title = {{{MoRA}}: {{High-Rank Updating}} for {{Parameter-Efficient Fine-Tuning}}},
  shorttitle = {{{MoRA}}},
  author = {Jiang, Ting and Huang, Shaohan and Luo, Shengyue and Zhang, Zihan and Huang, Haizhen and Wei, Furu and Deng, Weiwei and Sun, Feng and Zhang, Qi and Wang, Deqing and Zhuang, Fuzhen},
  date = {2024-05-20},
  eprint = {2405.12130},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2405.12130},
  urldate = {2024-06-06},
  abstract = {Low-rank adaptation (LoRA) is a popular parameter-efficient fine-tuning (PEFT) method for large language models (LLMs). In this paper, we analyze the impact of low-rank updating, as implemented in LoRA. Our findings suggest that the low-rank updating mechanism may limit the ability of LLMs to effectively learn and memorize new knowledge. Inspired by this observation, we propose a new method called MoRA, which employs a square matrix to achieve high-rank updating while maintaining the same number of trainable parameters. To achieve it, we introduce the corresponding non-parameter operators to reduce the input dimension and increase the output dimension for the square matrix. Furthermore, these operators ensure that the weight can be merged back into LLMs, which makes our method can be deployed like LoRA. We perform a comprehensive evaluation of our method across five tasks: instruction tuning, mathematical reasoning, continual pretraining, memory and pretraining. Our method outperforms LoRA on memoryintensive tasks and achieves comparable performance on other tasks. Our code will be available at https://github.com/kongds/MoRA.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TFSZF987/2405.12130v1.pdf}
}

@article{jinStudyMixtureModels2006,
  title = {A Study of Mixture Models for Collaborative Filtering},
  author = {Jin, Rong and Si, Luo and Zhai, Chengxiang},
  date = {2006},
  journaltitle = {Information Retrieval},
  volume = {9},
  number = {3},
  pages = {357--382},
  issn = {13864564},
  doi = {10.1007/s10791-006-4651-1},
  abstract = {Collaborative filtering is a general technique for exploiting the preference patterns of a group of users to predict the utility of items for a particular user. Three different components need to be modeled in a collaborative filtering problem: users, items, and ratings. Previous research on applying probabilistic models to collaborative filtering has shown promising results. However, there is a lack of systematic studies of different ways to model each of the three components and their interactions. In this paper, we conduct a broad and systematic study on different mixture models for collaborative filtering. We discuss general issues related to using a mixture model for collaborative filtering, and propose three properties that a graphical model is expected to satisfy. Using these properties, we thoroughly examine five different mixture models, including Bayesian Clustering (BC), Aspect Model (AM), Flexible Mixture Model (FMM), Joint Mixture Model (JMM), and the Decoupled Model (DM). We compare these models both analytically and experimentally. Experiments over two datasets of movie ratings under different configurations show that in general, whether a model satisfies the proposed properties tends to be correlated with its performance. In particular, the Decoupled Model, which satisfies all the three desired properties, outperforms the other mixture models as well as many other existing approaches for collaborative filtering. Our study shows that graphical models are powerful tools for modeling collaborative filtering, but careful design is necessary to achieve good performance. © Springer Science + Business Media, LLC 2006.},
  keywords = {Collaborative filtering,Graphical model,Probabilistic model},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FBBVPRTS/Jin, Si, Zhai - 2006 - A study of mixture models for collaborative filtering.pdf}
}

@inproceedings{Joachims,
  title = {Deep Learning with Logged Bandit Feedback},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Joachims, Thorsten and Swaminathan, Adith and De Rijke, Maarten},
  date = {2018},
  url = {http://www.joachims.org/banditnet/},
  abstract = {We propose a new output layer for deep neural networks that permits the use of logged contextual bandit feedback for training. Such contextual bandit feedback can be available in huge quantities (e.g., logs of search engines, recommender systems) at little cost, opening up a path for training deep networks on orders of magnitude more data. To this effect, we propose a counterfactual risk minimization approach for training deep networks using an equivariant empirical risk estima-tor with variance regularization, BanditNet, and show how the resulting objective can be decomposed in a way that allows stochastic gradient descent training. We empirically demonstrate the effectiveness of the method by showing how deep networks-ResNets in particular-can be trained for object recognition without conventionally labeled images.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9JPAFNII/joachims_etal_18a.pdf}
}

@online{JoinConversation,
  title = {Join Conversation},
  url = {https://teams.microsoft.com/dl/launcher/launcher.html?url=%2F_%23%2Fl%2Fteam%2F19%3A323a217dfe5e49d094b195da5837692c%40thread.tacv2%2Fconversations%3FtenantId%3D09a10672-822f-4467-a5ba-5bb375967c05&type=team&deeplinkId=0ca0dd08-445d-48d1-b47d-fafda102e295&directDl=true&msLaunch=true&enableMobilePage=true&suppressPrompt=true},
  urldate = {2023-02-27},
  langid = {british},
  organization = {Microsoft Teams},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TYITSMM8/launcher.html}
}

@article{Jordan1999a,
  title = {Variational {{MCMC}}},
  author = {{Freitas}},
  date = {1999},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/L88S2W4T/Jordan, Russell, Hall - 1999 - Nan do de Freitas.pdf}
}

@article{Jun2014,
  title = {The Possibility of Using Search Traffic Information to Explore Consumer Product Attitudes and Forecast Consumer Preference},
  author = {Jun, Seung Pyo and Park, Do Hyung and Yeom, Jaeho},
  date = {2014},
  journaltitle = {Technological Forecasting and Social Change},
  volume = {86},
  pages = {237--253},
  publisher = {Elsevier Inc.},
  issn = {00401625},
  doi = {10.1016/j.techfore.2013.10.021},
  url = {http://dx.doi.org/10.1016/j.techfore.2013.10.021},
  abstract = {In recent years, many researchers have devoted their attention to using search traffic information gathered from Google Insights to carry out consumer attitude research. The purpose of this study is to assess the effectiveness of using search traffic information to analyze actual consumer attitudes regarding a product. By comparing the results of conventional survey-based attitude research with the results of search traffic information, this study reveals that search traffic information indicates consumers' level of interest regarding a product, the product attributes that they are considering, and the importance of each attribute to them. Also, it demonstrates the potential benefits of search traffic analysis, which can be useful for forecasting consumer preferences regarding products. Focusing on the Prius, a hybrid car, this study shows that search traffic information serves as an accurate indicator of consumer attitudes, and even succeeds in identifying consumers' hidden attitudes toward the Prius, which can be explained by cognitive dissonance theory. Finally, this study utilizes search traffic information to forecast changes in consumer attitudes and to develop an econometric model of consumer demand for the Prius by incorporating environmental variables such as the WTI (West Texas Intermediate) price. This study concludes that search traffic information offers new potential advantages, in that it not only overcomes the limitations imposed by the high cost of conducting surveys, in terms of money and time, but also helps to reduce the distortions caused by conscious or unconscious errors committed by survey respondents. © 2013 Elsevier Inc.},
  keywords = {Attribute in selection,Big data,Consumer attitude,Consumer search index,Demand forecasting,Google Insights,Search traffic},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SEPD3C6T/Jun, Park, Yeom - 2014 - The possibility of using search traffic information to explore consumer product attitudes and forecast consumer.pdf}
}

@unpublished{kamronnDisentangledRecognitionNonlinear,
  title = {A {{Disentangled Recognition}} and {{Nonlinear Dynamics Model}} for {{Unsupervised Learning}}},
  author = {Kamronn, Simon},
  eprint = {1710.05741v2},
  eprinttype = {arXiv},
  issue = {section 5},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZLKTKEAT/Fraccaro et al. - 2017 - A disentangled recognition and nonlinear dynamics model for unsupervised learning.pdf}
}

@inproceedings{kangReinforcementLearningBased2023,
  title = {Reinforcement {{Learning Based Pallet Loading Algorithm}} and Its {{Application}} to a {{Real Manipulator System}}},
  booktitle = {2023 20th {{International Conference}} on {{Ubiquitous Robots}} ({{UR}})},
  author = {Kang, Seong Woo and Min, Ye Rin and Choi, Kyuwon and Ahn, Woo Jin and Baek, Sang Ryul and Choi, Dae Woo and Lim, Myo Taeg},
  date = {2023-06-25},
  pages = {115--118},
  publisher = {IEEE},
  location = {Honolulu, HI, USA},
  doi = {10.1109/UR57808.2023.10202516},
  url = {https://ieeexplore.ieee.org/document/10202516/},
  urldate = {2023-10-01},
  abstract = {Manufacturers pallet loading problem (MPLP) aims to fit the maximum number of boxes into a fixed-size pallet capacity. Solving MPLP can be time-consuming due to its complexity, leading to the use of heuristic methods which may not produce optimal results. This paper proposes a pallet loading algorithm using reinforcement learning to find the optimal solution. Simulation results indicate that the proposed method utilizes the given pallet space more efficiently than the existing heuristic methods. In addition, we introduce a real-life automatic pallet loading system and demonstrate the effectiveness of the proposed algorithm.},
  eventtitle = {2023 20th {{International Conference}} on {{Ubiquitous Robots}} ({{UR}})},
  isbn = {9798350335170},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YQRG6RNG/Kang et al. - 2023 - Reinforcement Learning Based Pallet Loading Algori.pdf}
}

@unpublished{Kannan2016,
  title = {Smart {{Reply}}: {{Automated Response Suggestion}} for {{Email}}},
  author = {Kannan, Anjuli and Kurach, Karol and Ravi, Sujith and Kaufmann, Tobias and Tomkins, Andrew and Miklos, Balint and Corrado, Greg and Lukacs, Laszlo and Ganea, Marina and Young, Peter and Ramavajjala, Vivek},
  date = {2016},
  eprint = {6239336},
  eprinttype = {pmid},
  issn = {0146-4833},
  doi = {10.475/123},
  url = {http://arxiv.org/abs/1606.04870},
  abstract = {In this paper we propose and investigate a novel end-to-end method for automatically generating short email responses, called Smart Reply. It generates semantically diverse suggestions that can be used as complete email responses with just one tap on mobile. The system is currently used in Inbox by Gmail and is responsible for assisting with 10\% of all mobile responses. It is designed to work at very high throughput and process hundreds of millions of messages daily. The system exploits state-of-the-art, large-scale deep learning. We describe the architecture of the system as well as the challenges that we faced while building it, like response diversity and scalability. We also introduce a new method for semantic clustering of user-generated content that requires only a modest amount of explicitly labeled data.},
  isbn = {9781450335423},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/CUHKMYRU/Kannan et al. - 2016 - Smart Reply Automated Response Suggestion for Email.pdf}
}

@article{karmakarStochasticApproximationIterateDependent2021,
  title = {Stochastic {{Approximation}} with {{Iterate-Dependent Markov Noise}} under {{Verifiable Conditions}} in {{Compact State Space}} with the {{Stability}} of {{Iterates Not Ensured}}},
  author = {Karmakar, Prasenjit and Bhatnagar, Shalabh},
  date = {2021},
  journaltitle = {IEEE Transactions on Automatic Control},
  volume = {66},
  number = {12},
  eprint = {1601.02217},
  eprinttype = {arXiv},
  pages = {5941--5954},
  publisher = {IEEE},
  issn = {15582523},
  doi = {10.1109/TAC.2021.3057299},
  abstract = {This article compiles several aspects of the dynamics of stochastic approximation algorithms with Markov iterate-dependent noise when the iterates are not known to be stable beforehand. We achieve the same by extending the lock-in probability (i.e., the probability of convergence of the iterates to a specific attractor of the limiting ordinary differential equation (o.d.e.) given that the iterates are in its domain of attraction after a sufficiently large number of iterations (say) \$n\_0\$) framework to such recursions. Specifically, with the more restrictive assumption of Markov iterate-dependent noise supported on a bounded subset of the Euclidean space, we give a lower bound for the lock-in probability. We use these results to prove almost sure convergence of the iterates to the specified attractor when the iterates satisfy an asymptotic tightness condition. The novelty of our approach is that if the state space of the Markov process is compact, we prove almost sure convergence under much weaker assumptions compared to the work by Andrieu et al., which solves the general state-space case under much restrictive assumptions by providing sufficient conditions for stability of the iterates. We also extend our single-timescale results to the case where there are two separate recursions over two different timescales. This, in turn, is shown to be useful in analyzing the tracking ability of general adaptive algorithms. Additionally, we show that our results can be used to derive a sample complexity estimate of such recursions, which then can be used for step-size selection.},
  keywords = {Adaptive algorithms,Lock-in probability,Markov noise,Sample complexity},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TVDIQIQN/Karmakar, Bhatnagar - 2021 - Stochastic Approximation with Iterate-Dependent Markov Noise under Verifiable Conditions in Compact State S.pdf}
}

@unpublished{Kendall,
  title = {Learning to {{Drive}} in a {{Day}}},
  author = {Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  date = {2018},
  eprint = {1807.00412},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1807.00412},
  abstract = {We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.},
  keywords = {Autonomous Vehicles,Deep Reinforcement Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/I5GCHPVY/1807.00412.pdf}
}

@article{killePlistaDataset2013,
  title = {The Plista Dataset},
  author = {Kille, Benjamin and Hopfgartner, Frank and Brodt, Torben and Heintz, Tobias},
  date = {2013},
  journaltitle = {ACM International Conference Proceeding Series},
  pages = {16--23},
  doi = {10.1145/2516641.2516643},
  abstract = {Releasing datasets has fostered research in fields such as information retrieval and recommender systems. Datasets are typically tailored for specific scenarios. In this work, we present the plista dataset. The dataset contains a collection of news articles published on 13 news portals. Additionally, the dataset comprises user interactions with those articles. We inctroduce the dataset's main characteristics. Further, we illustrate possible applications of the dataset. © 2013 ACM.},
  isbn = {9781450323024},
  keywords = {dataset,news,recommender systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/JCWS4J3G/Kille et al. - 2013 - The plista dataset.pdf}
}

@article{Kim2015,
  title = {Deep {{Neural Network}} for {{Real-Time Autonomous Indoor Navigation}}},
  author = {Kim, Dong Ki and Chen, Tsuhan},
  date = {2015},
  journaltitle = {arXiv},
  eprint = {1511.04668},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1511.04668},
  abstract = {Autonomous indoor navigation of Micro Aerial Vehicles (MAVs) possesses many challenges. One main reason is that GPS has limited precision in indoor environments. The additional fact that MAVs are not able to carry heavy weight or power consuming sensors, such as range finders, makes indoor autonomous navigation a challenging task. In this paper, we propose a practical system in which a quadcopter autonomously navigates indoors and finds a specific target, i.e., a book bag, by using a single camera. A deep learning model, Convolutional Neural Network (ConvNet), is used to learn a controller strategy that mimics an expert pilot's choice of action. We show our system's performance through real-time experiments in diverse indoor locations. To understand more about our trained network, we use several visualization techniques.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/6GZTBBMP/Kim, Chen - 2015 - Deep Neural Network for Real-Time Autonomous Indoor Navigation.pdf}
}

@article{Kingma2014,
  title = {Auto-Encoding Variational Bayes},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2014},
  journaltitle = {2nd International Conference on Learning Representations, ICLR 2014 - Conference Track Proceedings},
  eprint = {1312.6114},
  eprinttype = {arXiv},
  pages = {1--14},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  issue = {Ml},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TMH47XF3/Kingma, Welling - 2014 - Auto-encoding variational bayes.pdf}
}

@article{Kirkpatrick2017,
  title = {Overcoming Catastrophic Forgetting in Neural Networks},
  author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
  date = {2017},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {114},
  number = {13},
  eprint = {28292907},
  eprinttype = {pmid},
  pages = {3521--3526},
  issn = {10916490},
  doi = {10.1073/pnas.1611835114},
  abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially.},
  keywords = {Artificial intelligence,Continual learning,Deep learning,Stability plasticity,Synaptic consolidation},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/68TMHJYQ/Kirkpatrick et al. - 2017 - Overcoming catastrophic forgetting in neural networks.pdf}
}

@article{Kleinberg2004,
  title = {Using Mixture Models for Collaborative Filtering},
  author = {Kleinberg, Jon and Sandler, Mark},
  date = {2004},
  journaltitle = {Conference Proceedings of the Annual ACM Symposium on Theory of Computing},
  pages = {569--578},
  issn = {07349025},
  doi = {10.1145/1007352.1007439},
  abstract = {A collaborative, filtering system at an e-commerce site or similar service uses data about aggregate user behavior to make recommendations tailored to specific user interests. We develop recommendation algorithms with provable performance guarantees in a probabilistic mixture model for collaborative filtering proposed by Hoffman and Puzicha. We identify certain novel parameters of mixture models that are closely connected with the best achievable performance of a recommendation algorithm; we show that for any system in which these parameters are bounded, it is possible to give recommendations whose quality converges to optimal as the amount of data grows. All our bounds depend on a new measure of independence that can be viewed as an L1-analogue of the smallest singular value of a matrix. Using this, we introduce a technique based on generalized pseudoinverse matrices and linear programming for handling sets of high-dimensional vectors. We also show that standard approaches based on L2 spectral methods are not strong enough to yield comparable results, thereby suggesting some inherent limitations of spectral analysis.},
  isbn = {1581138520},
  keywords = {Clustering,Collaborative filtering,Latent class models,Linear programming,Mixture models,Singular value decomposition,Text classification},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7HQURXVS/Kleinberg, Sandler - 2004 - Using mixture models for collaborative filtering.pdf}
}

@article{Kobyzev2020,
  title = {Normalizing {{Flows}}: {{An Introduction}} and {{Review}} of {{Current Methods}}},
  author = {Kobyzev, Ivan and Prince, Simon and Brubaker, Marcus},
  date = {2020},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  eprint = {1908.09257},
  eprinttype = {arXiv},
  pages = {1--1},
  issn = {0162-8828},
  doi = {10.1109/tpami.2020.2992934},
  abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GU8YJDJP/Kobyzev, Prince, Brubaker - 2020 - Normalizing Flows An Introduction and Review of Current Methods.pdf}
}

@online{koluguriTitaNetNeuralModel2021,
  title = {{{TitaNet}}: {{Neural Model}} for Speaker Representation with {{1D Depth-wise}} Separable Convolutions and Global Context},
  shorttitle = {{{TitaNet}}},
  author = {Koluguri, Nithin Rao and Park, Taejin and Ginsburg, Boris},
  date = {2021-10-08},
  eprint = {2110.04410},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2110.04410},
  url = {http://arxiv.org/abs/2110.04410},
  urldate = {2024-11-26},
  abstract = {In this paper, we propose TitaNet, a novel neural network architecture for extracting speaker representations. We employ 1D depth-wise separable convolutions with Squeeze-and-Excitation (SE) layers with global context followed by channel attention based statistics pooling layer to map variable-length utterances to a fixed-length embedding (t-vector). TitaNet is a scalable architecture and achieves state-of-the-art performance on speaker verification task with an equal error rate (EER) of 0.68\% on the VoxCeleb1 trial file and also on speaker diarization tasks with diarization error rate (DER) of 1.73\% on AMI-MixHeadset, 1.99\% on AMI-Lapel and 1.11\% on CH109. Furthermore, we investigate various sizes of TitaNet and present a light TitaNet-S model with only 6M parameters that achieve near state-of-the-art results in diarization tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/RP57D8P6/Koluguri et al. - 2021 - TitaNet Neural Model for speaker representation with 1D Depth-wise separable convolutions and globa.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/RMNXJ4I9/2110.html}
}

@article{Koren2009,
  title = {Matrix Factorization Techniques for Recommender Systems},
  author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
  date = {2009},
  journaltitle = {Computer},
  volume = {42},
  number = {8},
  eprint = {17255001},
  eprinttype = {pmid},
  pages = {30--37},
  issn = {00189162},
  doi = {10.1109/MC.2009.263},
  abstract = {As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.},
  isbn = {0018-9162},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GZMEFHPK/Koren, Bell, Volinsky - 2009 - Matrix factorization techniques for recommender systems.pdf}
}

@article{Koren2009a,
  title = {Collaborative Filtering with Temporal Dynamics},
  author = {Koren, Yehuda},
  date = {2009},
  journaltitle = {Proc. of KDD '09},
  eprint = {9659936},
  eprinttype = {pmid},
  pages = {447--456},
  issn = {00010782},
  doi = {10.1145/1557019.1557072},
  url = {http://dx.doi.org/10.1145/1557019.1557072},
  abstract = {Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset.},
  isbn = {978-1-60558-495-9},
  keywords = {online},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/X6N5DJNU/Koren - 2009 - Collaborative filtering with temporal dynamics.pdf}
}

@article{Kostøl,
  title = {Kabler i Arbeidsmarkedet : {{Hvordan}} Kan Stillingsannonser Fra {{FINN}} Brukes for å Lære Om ( Fremtidens ) Jobber ?},
  author = {Kostøl, Andreas},
  pages = {1--4},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/RSB7NV8M/Kostøl - Unknown - Kabler i arbeidsmarkedet Hvordan kan stillingsannonser fra FINN brukes for å lære om ( fremtidens ) jobber.pdf}
}

@article{koukiLabProductionCase2020,
  title = {From the Lab to Production: {{A}} Case Study of Session-Based Recommendations in the Home-Improvement Domain},
  author = {Kouki, Pigi and Fountalis, Ilias and Vasiloglou, Nikolaos and Cui, Xiquan and Liberty, Edo and Al Jadda, Khalifeh},
  date = {2020},
  journaltitle = {RecSys 2020 - 14th ACM Conference on Recommender Systems},
  pages = {140--149},
  doi = {10.1145/3383313.3412235},
  abstract = {E-commerce applications rely heavily on session-based recommendation algorithms to improve the shopping experience of their customers. Recent progress in session-based recommendation algorithms shows great promise. However, translating that promise to real-world outcomes is a challenging task for several reasons, but mostly due to the large number and varying characteristics of the available models. In this paper, we discuss the approach and lessons learned from the process of identifying and deploying a successful session-based recommendation algorithm for a leading e-commerce application in the home-improvement domain. To this end, we initially evaluate fourteen session-based recommendation algorithms in an offline setting using eight different popular evaluation metrics on three datasets. The results indicate that offline evaluation does not provide enough insight to make an informed decision since there is no clear winning method on all metrics. Additionally, we observe that standard offline evaluation metrics fall short for this application. Specifically, they reward an algorithm only when it predicts the exact same item that the user clicked next or eventually purchased. In a practical scenario, however, there are near-identical products which, although they are assigned different identifiers, they should be considered as equally-good recommendations. To overcome these limitations, we perform an additional round of evaluation, where human experts provide both objective and subjective feedback for the recommendations of five algorithms that performed the best in the offline evaluation. We find that the experts' opinion is oftentimes different from the offline evaluation results. Analysis of the feedback confirms that the performance of all models is significantly higher when we evaluate near-identical product recommendations as relevant. Finally, we run an A/B test with one of the models that performed the best in the human evaluation phase. The treatment model increased conversion rate by 15.6\% and revenue per visit by 18.5\% when compared with a leading third-party solution.},
  isbn = {9781450375832},
  keywords = {A/B test,comparison of offline evaluation metrics with labe,evaluation using human experts,session-based recommendations},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZKDJRKLL/Kouki et al. - 2020 - From the lab to production A case study of session-based recommendations in the home-improvement domain.pdf}
}

@article{Krishnan,
  title = {Ethics Considerations in Global Mobile Phone-Based Surveys of Noncommunicable Diseases:{{A}} Conceptual Exploration},
  author = {Ali, Joseph and Labrique, Alain B. and Gionfriddo, Kara and Pariyo, George and Gibson, Dustin G. and Pratt, Bridget and Deutsch-Feldman, Molly and Hyder, Adnan A.},
  date = {2017},
  journaltitle = {Journal of Medical Internet Research},
  volume = {19},
  number = {5},
  eprint = {1609.09869v2},
  eprinttype = {arXiv},
  issn = {14388871},
  doi = {10.2196/jmir.7326},
  url = {www.aaai.org},
  urldate = {2019-02-01},
  abstract = {Mobile phone coverage has grown, particularly within low- and middle-income countries (LMICs), presenting an opportunity to augment routine health surveillance programs. Several LMICs and global health partners are seeking opportunities to launch basic mobile phone-based surveys of noncommunicable diseases (NCDs). The increasing use of such technology in LMICs brings forth a cluster of ethical challenges; however, much of the existing literature regarding the ethics of mobile or digital health focuses on the use of technologies in high-income countries and does not consider directly the specific ethical issues associated with the conduct of mobile phone surveys (MPS) for NCD risk factor surveillance in LMICs. In this paper, we explore conceptually several of the central ethics issues in this domain, which mainly track the three phases of the MPS process: predata collection, during data collection, and postdata collection. These include identifying the nature of the activity; stakeholder engagement; appropriate design; anticipating and managing potential harms and benefits; consent; reaching intended respondents; data ownership, access and use; and ensuring LMIC sustainability. We call for future work to develop an ethics framework and guidance for the use of mobile phones for disease surveillance globally.},
  isbn = {1609.09869v2},
  keywords = {Bioethics,Ethics,Mhealth,Mobile phone survey,Noncommunicable diseases,Research ethics},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/S2STCAMP/full-text.pdf}
}

@unpublished{Krishnan2016,
  title = {Structured {{Inference Networks}} for {{Nonlinear State Space Models}}},
  author = {Krishnan, Rahul G. and Shalit, Uri and Sontag, David},
  date = {2016-09-30},
  eprint = {1609.09869},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1609.09869},
  urldate = {2019-05-03},
  abstract = {Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FI8424PR/full-text.pdf}
}

@article{krizhevskyImageNetClassificationDeep2017,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  date = {2017-05-24},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {60},
  number = {6},
  pages = {84--90},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3065386},
  url = {https://dl.acm.org/doi/10.1145/3065386},
  urldate = {2024-10-27},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AY4BUJ7D/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf}
}

@online{KubectlCheatSheet,
  title = {Kubectl {{Cheat Sheet}} - {{Kubernetes}}},
  url = {https://kubernetes.io/docs/user-guide/kubectl-cheatsheet/},
  urldate = {2017-08-12}
}

@article{Kula2015,
  title = {Metadata {{Embeddings}} for {{User}} and {{Item Cold-start Recommendations}}},
  author = {Kula, Maciej},
  date = {2015-07-30},
  journaltitle = {CEUR Workshop Proceedings},
  volume = {1448},
  eprint = {1507.08439},
  eprinttype = {arXiv},
  pages = {14--21},
  issn = {16130073},
  url = {http://arxiv.org/abs/1507.08439},
  abstract = {I present a hybrid matrix factorisation model representing users and items as linear combinations of their content features' latent factors. The model outperforms both collaborative and content-based models in cold-start or sparse interaction data scenarios (using both user and item metadata), and performs at least as well as a pure collaborative matrix factorisation model where interaction data is abundant. Additionally, feature embeddings produced by the model encode semantic information in a way reminiscent of word embedding approaches, making them useful for a range of related tasks such as tag recommendations.},
  keywords = {Cold-start,Matrix Factorization,Recommender Systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/2F6WK4FF/Kula - 2015 - Metadata embeddings for user and item cold-start recommendations.pdf}
}

@article{kummervoldOperationalizingNationalDigital,
  title = {Operationalizing a {{National Digital Library}}: {{The Case}} for a {{Norwegian Transformer Model}}},
  author = {Kummervold, Per E},
  abstract = {In this work, we show the process of building a large-scale training set from digital and digitized collections at a national library. The resulting Bidirectional Encoder Representations from Transformers (BERT)-based language model for Norwegian outperforms multilingual BERT (mBERT) models in several token and sequence classification tasks for both Norwegian Bokma˚l and Norwegian Nynorsk. Our model also improves the mBERT performance for other languages present in the corpus such as English, Swedish, and Danish. For languages not included in the corpus, the weights degrade moderately while keeping strong multilingual properties. Therefore, we show that building high-quality models within a memory institution using somewhat noisy optical character recognition (OCR) content is feasible, and we hope to pave the way for other memory institutions to follow.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/8GBFCDW9/Kummervold - Operationalizing a National Digital Library The C.pdf}
}

@article{lapponiTalkNorwayRichly2018,
  title = {The {{Talk}} of {{Norway}}: A Richly Annotated Corpus of the {{Norwegian}} Parliament, 1998–2016},
  shorttitle = {The {{Talk}} of {{Norway}}},
  author = {Lapponi, Emanuele and Søyland, Martin G. and Velldal, Erik and Oepen, Stephan},
  date = {2018-09-01},
  journaltitle = {Language Resources and Evaluation},
  shortjournal = {Lang Resources \& Evaluation},
  volume = {52},
  number = {3},
  pages = {873--893},
  issn = {1574-0218},
  doi = {10.1007/s10579-018-9411-5},
  url = {https://doi.org/10.1007/s10579-018-9411-5},
  urldate = {2024-02-18},
  abstract = {In this work we present the Talk of Norway (ToN) data set, a collection of Norwegian Parliament speeches from 1998 to 2016.Every speech is richly annotated with metadata harvested from different sources, and augmented with language type, sentence, token, lemma, part-of-speech, and morphological feature annotations. We also present a pilot study on party classification in the Norwegian Parliament, carried out in the context of a cross-faculty collaboration involving researchers from both Political Science and Computer Science. Our initial experiments demonstrate how the linguistic and institutional annotations in ToN can be used to gather insights on how different aspects of the political process affect classification.},
  langid = {english},
  keywords = {Computational political sciences,Computational social science,Language technology,Natural language processing,Parliamentary proceedings},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/B8QUPQ8F/Lapponi et al. - 2018 - The Talk of Norway a richly annotated corpus of t.pdf}
}

@article{Lattimore2020,
  title = {Bandit {{Algorithms}}},
  author = {Lattimore, Tor and Szepesvári, Csaba},
  date = {2020},
  journaltitle = {Bandit Algorithms},
  doi = {10.1017/9781108571401},
  abstract = {After nearly two years since starting to write the blog we have at last completed a first draft of the book, which is to be published by Cambridge University Press. The book is available for free as a PDF and will remain so after publication. We’re grateful to Cambridge for allowing this. Without further ado, here is the link. Although we still have a few things we want to do, the manuscript is sufficiently polished to be useful. Of course we would greatly appreciate any comments you might have, including typos, errors in the proofs, missing references, confusing explanations or anything else you might notice. We will periodically update the book, so it would be helpful if you could quote the revision number on the cover when sending us your comments (banditalgs@gmail.com). The manuscript includes a lot of material not in the blog. The last seven chapters are all new, covering combinatorial (semi-)bandits, non-stationary bandits, ranking, pure exploration, Bayesian methods, Thompson sampling, partial monitoring and an introduction to learning in Markov decision processes. Those chapters that are based on blog posts have been cleaned up and often we have added significant depth. There is a lot of literature that we have not covered. Some of these missing topics are discussed in extreme brevity in the introduction to Part VII. It really is amazing how large the bandit literature has become and we’re sorry not to have found space for everything. The book includes around 250 exercises, some of which have solutions. On average the exercises have been proofread less carefully than the rest of the book, so some caution is advised. The solutions to selected exercises are available here. Finally, we’re very thankful for all the feedback already received, both on the blog and early drafts of the book.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/EXUDNM9U/Lattimore, Szepesvári - 2020 - Bandit Algorithms.pdf}
}

@article{lecunPathAutonomousMachine,
  title = {A {{Path Towards Autonomous Machine Intelligence Version}} 0.9.2, 2022-06-27},
  author = {LeCun, Yann},
  abstract = {How could machines learn as efficiently as humans and animals? How could machines learn to reason and plan? How could machines learn representations of percepts and action plans at multiple levels of abstraction, enabling them to reason, predict, and plan at multiple time horizons? This position paper proposes an architecture and training paradigms with which to construct autonomous intelligent agents. It combines concepts such as configurable predictive world model, behavior driven through intrinsic motivation, and hierarchical joint embedding architectures trained with self-supervised learning.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7FTJTCQA/LeCun - A Path Towards Autonomous Machine Intelligence Ver.pdf}
}

@article{Ledwich2019,
  title = {Algorithmic {{Extremism}}: {{Examining YouTube}}’s {{Rabbit Hole}} of {{Radicalization}}},
  author = {Ledwich, Mark and Zaitsev, Anna},
  date = {2019},
  journaltitle = {arXiv},
  eprint = {1912.11211},
  eprinttype = {arXiv},
  issn = {1396-0466},
  doi = {10.5210/fm.v25i3.10419},
  abstract = {—The role that YouTube and its behind-the-scenes recommendation algorithm plays in encouraging online radicalization has been suggested by both journalists and academics alike. This study directly quantifies these claims by examining the role that YouTubes algorithm plays in suggesting radicalized content. After categorizing nearly 800 political channels, we were able to differentiate between political schemas in order to analyze the algorithm traffic flows out and between each group. After conducting a detailed analysis of recommendations received by each channel type, we refute the popular radicalization claims. To the contrary, these data suggest that YouTubes recommendation algorithm actively discourages viewers from visiting radicalizing or extremist content. Instead, the algorithm is shown to favor mainstream media and cable news content over independent YouTube channels with slant towards left-leaning or politically neutral channels. Our study thus suggests that YouTubes recommendation algorithm fails to promote inflammatory or radicalized content, as previously claimed by several outlets.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YABNB483/Ledwich, Zaitsev - 2019 - Algorithmic Extremism Examining YouTube’s Rabbit Hole of Radicalization.pdf}
}

@article{Leslie2012,
  title = {Recommending {{Mallows}}},
  author = {Leslie, David and Frigessi, Arnoldo},
  date = {2012},
  journaltitle = {Journal of Machine Learning Research, forthcoming. Journal of Machine Learning Research},
  volume = {13},
  number = {1},
  pages = {2069--2106},
  abstract = {In a recommendation setting, one might assume that each individual has a ranking over the possible items that could be recommended. For example, of the available items on an auction site, each individual might have a preference order for these items. The Mallows model provides a distribution over rankings, based on some distance from a (population) consensus ranking ρ (a location), and a scale parameter α indicating how variable the population is. Individuals j in a population are each assumed to have a personal ranking R j ∼ Mallows(ρ, α), although even the R j are probably not fully observed. Learning either ρ or individual rankings R j allows one to recommend highly ranked items to individuals from the population. Frigessi's research team have developed a Bayesian Mallows model for preference learning (e.g. [1]), and associated MCMC schemes to infer the parameters, when the data are partial observations of R j 's, such as pairwise preferences, partial rankings, or even simply clicks on sufficiently high-ranked items. However, to date, the focus of effort has been to infer parameters of the model conditional on fixed data, and little effort has been made to consider the online learning challenge, in which one must balance exploration and exploitation. We are interested in quickly improving our knowledge to lead to better recommendations. A simple framework is as follows. Suppose that we wish to recommend items to a sequence of individuals j = 1, 2, . . ., each of whom has a personal ranking R j ∼ Mallows(ρ, α). The recommender's action j is an item a j recommended to user j. The system receives reward equal to the actual ranking by individual j of action a j , and updates the beliefs about ρ. The objective is to try to minimise the cumulative ranking (small rank numbers are good). This is a simple objective, and the inference is easy, although the data assumptions are unrealistic; the next step might well be a slightly more complicated model in which the system receives 0/1 reward indicating whether the recommended item was " good enough " for the user. A greedy policy will always take the action currently believed to be best, but may well result in insufficient information gain. In this setting, the greedy action is the a which minimises E[R j,a | History] = n r=1 rp(R j,a = r | ρ, α)p(ρ | History). A Thompson sampling [2] approach will not integrate out all this uncertainty. Instead it will draw a singl ρ from the belief distribution p(ρ | History) then choose a to minimise E[R j,a ρ, α] = n r=1 rp(R j,a = r ρ, α). This additional randomness in Thompson sampling will ensure that if the belief distribution p(ρ | History) is not particularly focused, exploratory actions are taken which will hopefully improve knowledge about ρ. Note however one of the critical gaps with Thompson sampling: it is far from clear whether the action selected will indeed be the most informative. We believe that if some of the distributions involved in the Mallows inference can be explicitly dealt with then further approaches such as UCB or knowledge gradient may well be easily implemented, and this is one direction we could follow if a more theoretical project appealed. You will test your developed approach using several experimental and benchmark datasets, building on examples already constructed by Frigessi's team. If you are successful, we will also test the methods in an on-line industrial framework in which scalability issues, when either the number of users or items become large, will need to be carefully considered. Skills required: You will be working with MCMC, so will need to be comfortable with computer programming. You will be doing Bayesian stats, and thinking about decision-making. A theoretical slant on the project would involve some advanced probability, whereas a practical slant would be more computational.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BW8VK4MN/m-api-7fa26fbb-c645-bbcd-303b-4368d094d014.pdf}
}

@report{Leslie2019,
  title = {Building Blocks of Reinforcement Learning: Teaching Notes},
  author = {Leslie, David S},
  date = {2019},
  abstract = {Caveat: These are notes used to teach from. They are neither carefully constructed nor comprehensive. These notes were the backbone of a day-long session with objective to introduce people to the basic building blocks of reinforcement learning. This was the theory part, while Jupyter notebooks were provided to help people experiment with the methods. The standard start-point for RL is Sutton and Barto (1998). 1 Basic bandit algorithms At each time t ∈ N a decision-maker selects an action/arm a t in a finite set A, then receives a reward R t ∼ ν at with expected value r(a t). Rewards are independent across time steps, and all rewards from action a are identically distributed (ie no temporal dependence). The decision-maker does not know ν a or r(a) in advance. The objective is to maximise the cumulative reward. It is necessary for the decision-maker to trade off exploring, to find out information about the reward distributions, with explointing, selecting actions which are known to perform well in order to gain reward. This is a fundamental problem in all online learning/acting frameworks, and the bandit problem is a simple framework in which to investigate the explore-exploit dilemna. At time t, a natural estimator of r(a) is the average reward received so far when action a has been played. Let N t (a) = t s=1 I as=a denote the number of times action a has been played up to time t, and let Q t (a) = N t (a) −1 t s=1 I at=a R t be the average reward. (Probably) every policy discussed here will use the Q t (a) values to select an action at time t + 1. Note that these can be maintained in an online fashion, so that the full history need not be retained: basic algebraic manipulations show that Q t (a) = Q t−1 (a) + I at=a 1 N t (a) \{R t − Q t−1 (a)\}. A very poor policy is the greedy policy, for which a t+1 ∈ argmax a Q t (a). This policy performs no exploration at all, and if the optimal action happens to give a poor reward on the first try it may never get selected ever again. A slight improvement is the-greedy algorithm, which on each time step selects the greedy action with probability 1 − , and otherwise selects an action uniformly at random.-greedy carries out sufficient exploration to ensure that eventually the greedy action is indeed the optimal action (i.e. argmax a r(a)). However there is always a fixed probability of playing an arbitrary suboptimal action, so action selection can never converge to the optimal.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/W35B9XHE/RLnotes2019.pdf}
}

@unpublished{leslieDynamicSlateRecommendation2021,
  title = {Dynamic {{Slate Recommendation}} with {{Gated Recurrent Units}} and {{Thompson Sampling}}},
  author = {Leslie, David S. and Frigessi, Arnoldo and Eide, Simen},
  date = {2021},
  eprint = {2104.15046},
  eprinttype = {arXiv},
  pages = {1--31},
  url = {http://arxiv.org/abs/2104.15046},
  abstract = {We consider the problem of recommending relevant content to users of an internet platform in the form of lists of items, called slates. We introduce a variational Bayesian Recurrent Neural Net recommender system that acts on time series of interactions between the internet platform and the user, and which scales to real world industrial situations. The recommender system is tested both online on real users, and on an offline dataset collected from a Norwegian web-based marketplace, FINN.no, that is made public for research. This is one of the first publicly available datasets which includes all the slates that are presented to users as well as which items (if any) in the slates were clicked on. Such a data set allows us to move beyond the common assumption that implicitly assumes that users are considering all possible items at each interaction. Instead we build our likelihood using the items that are actually in the slate, and evaluate the strengths and weaknesses of both approaches theoretically and in experiments. We also introduce a hierarchical prior for the item parameters based on group memberships. Both item parameters and user preferences are learned probabilistically. Furthermore, we combine our model with bandit strategies to ensure learning, and introduce `in-slate Thompson Sampling' which makes use of the slates to maximise explorative opportunities. We show experimentally that explorative recommender strategies perform on par or above their greedy counterparts. Even without making use of exploration to learn more effectively, click rates increase simply because of improved diversity in the recommended slates.}
}

@inproceedings{lesterPowerScaleParameterEfficient2021,
  title = {The {{Power}} of {{Scale}} for {{Parameter-Efficient Prompt Tuning}}},
  booktitle = {Proceedings of the 2021 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  date = {2021-11},
  pages = {3045--3059},
  publisher = {Association for Computational Linguistics},
  location = {Online and Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.emnlp-main.243},
  url = {https://aclanthology.org/2021.emnlp-main.243},
  urldate = {2023-05-10},
  abstract = {In this work, we explore “prompt tuning,” a simple yet effective mechanism for learning “soft prompts” to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method “closes the gap” and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed “prefix tuning” of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient “prompt ensembling.” We release code and model checkpoints to reproduce our experiments.},
  eventtitle = {{{EMNLP}} 2021},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/WJKJ3W77/2021.emnlp-main.243.pdf}
}

@article{Levine2016,
  title = {Learning {{Hand-Eye Coordination}} for {{Robotic Grasping}} with {{Deep Learning}} and {{Large-Scale Data Collection}}},
  author = {Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Quillen, Deirdre},
  date = {2016},
  journaltitle = {arXiv},
  eprint = {21156984},
  eprinttype = {pmid},
  pages = {1--1},
  issn = {00032999},
  doi = {10.1145/2835776.2835844},
  abstract = {We describe a learning-based approach to hand-eye coordination for robotic grasping from monocular images. To learn hand-eye coordination for grasping, we trained a large convolutional neural network to predict the probability that task-space motion of the gripper will result in successful grasps, using only monocular camera images and independently of camera calibration or the current robot pose. This requires the network to observe the spatial relationship between the gripper and objects in the scene, thus learning hand-eye coordination. We then use this network to servo the gripper in real time to achieve successful grasps. To train our network, we collected over 800,000 grasp attempts over the course of two months, using between 6 and 14 robotic manipulators at any given time, with differences in camera placement and hardware. Our experimental evaluation demonstrates that our method achieves effective real-time control, can successfully grasp novel objects, and corrects mistakes by continuous servoing.},
  isbn = {978-1-4503-3716-8},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/CPHN83KA/m-api-38addca2-d9e0-de9b-7742-def702272678.pdf}
}

@unpublished{Levine2018,
  title = {Reinforcement {{Learning}} and {{Control}} as {{Probabilistic Inference}}: {{Tutorial}} and {{Review}}},
  author = {Levine, Sergey},
  date = {2018},
  eprint = {1805.00909},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1805.00909},
  abstract = {The framework of reinforcement learning or optimal control provides a mathematical formalization of intelligent decision making that is powerful and broadly applicable. While the general form of the reinforcement learning problem enables effective reasoning about uncertainty, the connection between reinforcement learning and inference in probabilistic models is not immediately obvious. However, such a connection has considerable value when it comes to algorithm design: formalizing a problem as probabilistic inference in principle allows us to bring to bear a wide array of approximate inference tools, extend the model in flexible and powerful ways, and reason about compositionality and partial observability. In this article, we will discuss how a generalization of the reinforcement learning or optimal control problem, which is sometimes termed maximum entropy reinforcement learning, is equivalent to exact probabilistic inference in the case of deterministic dynamics, and variational inference in the case of stochastic dynamics. We will present a detailed derivation of this framework, overview prior work that has drawn on this and related ideas to propose new reinforcement learning and control algorithms, and describe perspectives on future research.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YX53NPLM/Levine - 2018 - Reinforcement Learning and Control as Probabilistic Inference Tutorial and Review.pdf}
}

@article{levineInverseReinforcementLearning,
  title = {Inverse {{Reinforcement Learning CS}} 285},
  author = {Levine, Instructor Sergey},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/VWGSHYMS/Levine - Unknown - Inverse Reinforcement Learning CS 285.pdf}
}

@online{lewSequentialMonteCarlo2023,
  title = {Sequential {{Monte Carlo Steering}} of {{Large Language Models}} Using {{Probabilistic Programs}}},
  author = {Lew, Alexander K. and Zhi-Xuan, Tan and Grand, Gabriel and Mansinghka, Vikash K.},
  date = {2023-11-26},
  eprint = {2306.03081},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2306.03081},
  urldate = {2024-04-20},
  abstract = {Even after fine-tuning and reinforcement learning, large language models (LLMs) can be difficult, if not impossible, to control reliably with prompts alone. We propose a new inference-time approach to enforcing syntactic and semantic constraints on the outputs of LLMs, called sequential Monte Carlo (SMC) steering. The key idea is to specify language generation tasks as posterior inference problems in a class of discrete probabilistic sequence models, and replace standard decoding with sequential Monte Carlo inference. For a computational cost similar to that of beam search, SMC can steer LLMs to solve diverse tasks, including infilling, generation under syntactic constraints, and prompt intersection. To facilitate experimentation with SMC steering, we present a probabilistic programming library, LLaMPPL (https://github.com/probcomp/hfppl), for concisely specifying new generation tasks as language model probabilistic programs, and automating steering of LLaMA-family Transformers.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Programming Languages,Statistics - Computation},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/APKFHGXX/Lew et al. - 2023 - Sequential Monte Carlo Steering of Large Language .pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/LV52U9LW/2306.html}
}

@report{Li,
  title = {Online {{Learning}} to {{Rank}} with {{Features}}},
  author = {Li, Shuai and Lattimore, Tor and Szepesvári, Csaba},
  eprint = {1810.02567v2},
  eprinttype = {arXiv},
  abstract = {We introduce a new model for online ranking in which the click probability factors into an examination and attractiveness function and the attractiveness function is a linear function of a feature vector and an unknown parameter. Only relatively mild assumptions are made on the examination function. A novel algorithm for this setup is analysed , showing that the dependence on the number of items is replaced by a dependence on the dimension , allowing the new algorithm to handle a large number of items. When reduced to the orthogonal case, the regret of the algorithm improves on the state-of-the-art.},
  isbn = {1810.02567v2},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9YA4ZI7G/m-api-04a8857a-f2d3-fdf7-3ec5-121ec8d607d4.pdf}
}

@article{Li2010,
  title = {Improving One-Class Collaborative Filtering by Incorporating Rich User Information},
  author = {Li, Yanen and Hu, Jia and Zhai, ChengXiang and Chen, Ye},
  date = {2010},
  journaltitle = {Proceedings of the 19th ACM international conference on Information and knowledge management - CIKM '10},
  abstract = {One-Class Collaborative Filtering (OCCF) is an emerging setup in collaborative filtering in which only positive exam-ples or implicit feedback can be observed. Compared with the traditional collaborative filtering setting where the data has ratings, OCCF is more realistic in many scenarios when no ratings are available. In this paper, we propose to im-prove OCCF accuracy by exploiting the rich user informa-tion that is often naturally available in community-based interactive information systems, including a user's search query history, purchasing and browsing activities. We pro-pose two ways to incorporate such user information into the OCCF models: one is to linearly combine scores from dif-ferent sources and the other is to embed user information into collaborative filtering. Experimental results on a large-scale retail data set from a major e-commerce company show that the proposed methods are effective and can improve the performance of the One-Class Collaborative Filtering over baseline methods through leveraging rich user information.}
}

@unpublished{Li2010a,
  title = {Unbiased {{Offline Evaluation}} of {{Contextual-bandit-based News Article Recommendation Algorithms}}},
  author = {Li, Lihong and Chu, Wei and Langford, John and Wang, Xuanhui},
  date = {2010},
  eprint = {1003.5956},
  eprinttype = {arXiv},
  issn = {1450304931},
  doi = {10.1145/1935826.1935878},
  url = {http://arxiv.org/abs/1003.5956%0Ahttp://dx.doi.org/10.1145/1935826.1935878},
  abstract = {Contextual bandit algorithms have become popular for online recommendation systems such as Digg, Yahoo! Buzz, and news recommendation in general. \textbackslash emph\{Offline\} evaluation of the effectiveness of new algorithms in these applications is critical for protecting online user experiences but very challenging due to their "partial-label" nature. Common practice is to create a simulator which simulates the online environment for the problem at hand and then run an algorithm against this simulator. However, creating simulator itself is often difficult and modeling bias is usually unavoidably introduced. In this paper, we introduce a \textbackslash emph\{replay\} methodology for contextual bandit algorithm evaluation. Different from simulator-based approaches, our method is completely data-driven and very easy to adapt to different applications. More importantly, our method can provide provably unbiased evaluations. Our empirical results on a large-scale news article recommendation dataset collected from Yahoo! Front Page conform well with our theoretical results. Furthermore, comparisons between our offline replay and online bucket evaluation of several contextual bandit algorithms show accuracy and effectiveness of our offline evaluation method.},
  isbn = {9781450304931},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IARKNGQJ/Li et al. - 2010 - Unbiased Offline Evaluation of Contextual-bandit-based News Article Recommendation Algorithms.pdf}
}

@article{Li2016,
  title = {Collaborative {{Filtering Bandits}}},
  author = {Li, Shuai and Karatzoglou, Alexandros and Gentile, Claudio},
  date = {2016},
  journaltitle = {Sigir},
  eprint = {21526112},
  eprinttype = {pmid},
  pages = {539--548},
  issn = {9781450321389},
  doi = {10.1145/2911451.2911548},
  abstract = {Classical collaborative filtering, and content-based filtering methods try to learn a static recommendation model given training data. These approaches are far from ideal in highly dynamic recommendation domains such as news recommen-dation and computational advertisement, where the set of items and users is very fluid. In this work, we investigate an adaptive clustering technique for content recommenda-tion based on exploration-exploitation strategies in contex-tual multi-armed bandit settings. Our algorithm takes into account the collaborative effects that arise due to the inter-action of the users with the items, by dynamically grouping users based on the items under consideration and, at the same time, grouping items based on the similarity of the clusterings induced over the users. The resulting algorithm thus takes advantage of preference patterns in the data in a way akin to collaborative filtering methods. We provide an empirical analysis on medium-size real-world datasets, showing scalability and increased prediction performance (as measured by click-through rate) over state-of-the-art meth-ods for clustering bandits. We also provide a regret analysis within a standard linear stochastic noise setting.},
  isbn = {9781450340694},
  keywords = {bandits,clustering,collaborative filtering,computational advertising,filtering and recommending,line learning,on-,recommender systems,regret},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/QVHTWZ49/Li, Karatzoglou, Gentile - 2016 - Collaborative Filtering Bandits.pdf}
}

@article{Li2016a,
  title = {Rényi Divergence Variational Inference},
  author = {Li, Yingzhen and Turner, Richard E.},
  date = {2016},
  journaltitle = {Advances in Neural Information Processing Systems},
  pages = {1081--1089},
  issn = {10495258},
  abstract = {This paper introduces the variational Rényi bound (VR) that extends traditional vari-ational inference to Rényi's α-divergences. This new family of variational methods unifies a number of existing approaches, and enables a smooth interpolation from the evidence lower-bound to the log (marginal) likelihood that is controlled by the value of α that parametrises the divergence. The reparameterization trick, Monte Carlo approximation and stochastic optimisation methods are deployed to obtain a tractable and unified framework for optimisation. We further consider negative α values and propose a novel variational inference method as a new special case in the proposed framework. Experiments on Bayesian neural networks and variational auto-encoders demonstrate the wide applicability of the VR bound.},
  issue = {Nips},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5DNKECII/Li, Turner - 2016 - Rényi divergence variational inference.pdf}
}

@article{Li2017a,
  title = {Approximate Inference with Amortised {{MCMC}}},
  author = {Li, Yingzhen and Turner, Richard E. and Liu, Qiang},
  date = {2017},
  journaltitle = {arXiv},
  eprint = {1702.08343},
  eprinttype = {arXiv},
  pages = {1--17},
  issn = {23318422},
  abstract = {We propose a novel approximate inference framework that approximates a target distribution by amortising the dynamics of a user-selected Markov chain Monte Carlo (MCMC) sampler. The idea is to initialise MCMC using samples from an approximation network, apply the MCMC operator to improve these samples, and finally use the samples to update the approximation network thereby improving its quality. This provides a new generic framework for approximate inference, allowing us to deploy highly complex, or implicitly defined approximation families with intractable densities, including approximations produced by warping a source of randomness through a deep neural network. Experiments consider Bayesian neural network classification and image modelling with deep generative models. Deep models trained using amortised MCMC are shown to generate realistic looking samples as well as producing diverse imputations for images with regions of missing pixels.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/MVIFDKNR/Li, Turner, Liu - 2017 - Approximate inference with amortised MCMC.pdf}
}

@article{Li2019,
  title = {{{HHMF}}: Hidden Hierarchical Matrix Factorization for Recommender Systems},
  author = {Li, Hui and Liu, Yu and Qian, Yuqiu and Mamoulis, Nikos and Tu, Wenting and Cheung, David W.},
  date = {2019},
  journaltitle = {Data Mining and Knowledge Discovery},
  volume = {33},
  number = {6},
  pages = {1548--1582},
  publisher = {Springer US},
  issn = {1573756X},
  doi = {10.1007/s10618-019-00632-4},
  url = {https://doi.org/10.1007/s10618-019-00632-4},
  abstract = {Matrix factorization (MF) is one of the most powerful techniques used in recommender systems. MF models the (user, item) interactions behind historical explicit or implicit ratings. Standard MF does not capture the hierarchical structural correlations, such as publisher and advertiser in advertisement recommender systems, or the taxonomy (e.g., tracks, albums, artists, genres) in music recommender systems. There are a few hierarchical MF approaches, but they require the hierarchical structures to be known beforehand. In this paper, we propose a Hidden Hierarchical Matrix Factorization (HHMF) technique, which learns the hidden hierarchical structure from the user-item rating records. HHMF does not require the prior knowledge of hierarchical structure; hence, as opposed to existing hierarchical MF methods, HHMF can be applied when this information is either explicit or implicit. According to our extensive experiments, HHMF outperforms existing methods, demonstrating that the discovery of latent hierarchical structures indeed improves the quality of recommendation.},
  keywords = {Collaborative filtering,Hierarchical matrix factorization,Recommender systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LKWFAKFD/Li et al. - 2019 - HHMF hidden hierarchical matrix factorization for recommender systems.pdf}
}

@article{Li2019a,
  title = {A Tutorial on {{Dirichlet}} Process Mixture Modeling},
  author = {Li, Yuelin and Schofield, Elizabeth and Gönen, Mithat},
  date = {2019},
  journaltitle = {Journal of Mathematical Psychology},
  volume = {91},
  pages = {128--144},
  publisher = {Elsevier Inc.},
  issn = {10960880},
  doi = {10.1016/j.jmp.2019.04.004},
  url = {https://doi.org/10.1016/j.jmp.2019.04.004},
  abstract = {Bayesian nonparametric (BNP) models are becoming increasingly important in psychology, both as theoretical models of cognition and as analytic tools. However, existing tutorials tend to be at a level of abstraction largely impenetrable by non-technicians. This tutorial aims to help beginners understand key concepts by working through important but often omitted derivations carefully and explicitly, with a focus on linking the mathematics with a practical computation solution for a Dirichlet Process Mixture Model (DPMM)—one of the most widely used BNP methods. Abstract concepts are made explicit and concrete to non-technical readers by working through the theory that gives rise to them. A publicly accessible computer program written in the statistical language R is explained line-by-line to help readers understand the computation algorithm. The algorithm is also linked to a construction method called the Chinese Restaurant Process in an accessible tutorial in this journal (Gershman and Blei, 2012). The overall goals are to help readers understand more fully the theory and application so that they may apply BNP methods in their own work and leverage the technical details in this tutorial to develop novel methods.},
  keywords = {Bayesian nonparametric,Chinese Restaurant Process,Dirichlet process,Gibbs sampling,Mixture model},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5GDDERYY/Li, Schofield, Gönen - 2019 - A tutorial on Dirichlet process mixture modeling.pdf}
}

@article{Liang2016,
  title = {Causal {{Inference}} for {{Recommendation}}},
  author = {Liang, Dawen and Charlin, Laurent and Blei, David M},
  date = {2016},
  journaltitle = {Conference on Uncertainty in Artificial Intelligence},
  url = {http://arxiv.org},
  abstract = {Abstract We develop a causal inference approach to recommender systems. Observational recommendation data contains two sources of information: which items each user decided to look at and which of those items each user liked. We assume these two types of ...\textbackslash n},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7KVQ68HR/Liang, Charlin, Blei - Unknown - Causal Inference for Recommendation.pdf}
}

@article{Liang2016c,
  title = {Modeling User Exposure in Recommendation},
  author = {Liang, Dawen and Charlin, Laurent and McInerney, James and Blei, David M.},
  date = {2016},
  journaltitle = {25th International World Wide Web Conference, WWW 2016},
  eprint = {1510.07025},
  eprinttype = {arXiv},
  pages = {951--961},
  doi = {10.1145/2872427.2883090},
  abstract = {Collaborative -ltering analyzes user preferences for items (e.g., books, movies, restaurants, academic papers) by exploiting the similarity patterns across users. In implicit feedback settings, all the items, including the ones that a user did not consume, are taken into consideration. But this assumption does not accord with the common sense understanding that users have a limited scope and awareness of items. For example, a user might not have heard of a certain paper, or might live too far away from a restaurant to experience it. In the language of causal analysis [9], the assignment mechanism (i.e., the items that a user is exposed to) is a latent variable that may change for various user/item combinations. In this paper, we propose a new probabilistic approach that directly incorporates user exposure to items into collaborative ffltering. The exposure is modeled as a latent variable and the model infers its value from data. In doing so, we recover one of the most successful state-of-Theart approaches as a special case of our model [8], and provide a plug-in method for conditioning exposure on various forms of exposure covariates (e.g., topics in text, venue locations). We show that our scalable inference algorithm outperforms existing benchmarks in four difierent domains both with and without exposure covariates.},
  isbn = {9781450341431},
  keywords = {Collaborative filtering,Matrix factorization,Recommender systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SNMF72L3/Liang et al. - 2016 - Modeling user exposure in recommendation.pdf}
}

@article{Liang2018,
  title = {Variational Autoencoders for Collaborative Filtering},
  author = {Liang, Dawen and Krishnan, Rahul G. and Hoffman, Matthew D. and Jebara, Tony},
  date = {2018},
  journaltitle = {The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018},
  eprint = {1802.05814},
  eprinttype = {arXiv},
  pages = {689--698},
  doi = {10.1145/3178876.3186150},
  abstract = {We extend variational autoencoders (VAEs) to collaborative filtering for implicit feedback. This non-linear probabilistic model enables us to go beyond the limited modeling capacity of linear factor models which still largely dominate collaborative filtering research.We introduce a generative model with multinomial likelihood and use Bayesian inference for parameter estimation. Despite widespread use in language modeling and economics, the multinomial likelihood receives less attention in the recommender systems literature. We introduce a different regularization parameter for the learning objective, which proves to be crucial for achieving competitive performance. Remarkably, there is an efficient way to tune the parameter using annealing. The resulting model and learning algorithm has information-theoretic connections to maximum entropy discrimination and the information bottleneck principle. Empirically, we show that the proposed approach significantly outperforms several state-of-the-art baselines, including two recently-proposed neural network approaches, on several real-world datasets. We also provide extended experiments comparing the multinomial likelihood with other commonly used likelihood functions in the latent factor collaborative filtering literature and show favorable results. Finally, we identify the pros and cons of employing a principled Bayesian inference approach and characterize settings where it provides the most significant improvements.},
  isbn = {9781450356398},
  keywords = {Bayesian models,Collaborative filtering,Implicit feedback,Recommender systems,Variational autoencoder},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ERLKQR3R/Liang et al. - 2018 - Variational autoencoders for collaborative filtering.pdf}
}

@online{liBLIP2BootstrappingLanguageImage2023,
  title = {{{BLIP-2}}: {{Bootstrapping Language-Image Pre-training}} with {{Frozen Image Encoders}} and {{Large Language Models}}},
  shorttitle = {{{BLIP-2}}},
  author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  date = {2023-06-15},
  eprint = {2301.12597},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2301.12597},
  urldate = {2023-11-10},
  abstract = {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7\% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model’s emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LZQXY4PC/Li et al. - 2023 - BLIP-2 Bootstrapping Language-Image Pre-training .pdf}
}

@online{liDeepModelFusion2023,
  title = {Deep {{Model Fusion}}: {{A Survey}}},
  shorttitle = {Deep {{Model Fusion}}},
  author = {Li, Weishi and Peng, Yong and Zhang, Miao and Ding, Liang and Hu, Han and Shen, Li},
  date = {2023-09-27},
  eprint = {2309.15698},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2309.15698},
  url = {http://arxiv.org/abs/2309.15698},
  urldate = {2024-12-03},
  abstract = {Deep model fusion/merging is an emerging technique that merges the parameters or predictions of multiple deep learning models into a single one. It combines the abilities of different models to make up for the biases and errors of a single model to achieve better performance. However, deep model fusion on large-scale deep learning models (e.g., LLMs and foundation models) faces several challenges, including high computational cost, high-dimensional parameter space, interference between different heterogeneous models, etc. Although model fusion has attracted widespread attention due to its potential to solve complex real-world tasks, there is still a lack of complete and detailed survey research on this technique. Accordingly, in order to understand the model fusion method better and promote its development, we present a comprehensive survey to summarize the recent progress. Specifically, we categorize existing deep model fusion methods as four-fold: (1) "Mode connectivity", which connects the solutions in weight space via a path of non-increasing loss, in order to obtain better initialization for model fusion; (2) "Alignment" matches units between neural networks to create better conditions for fusion; (3) "Weight average", a classical model fusion method, averages the weights of multiple models to obtain more accurate results closer to the optimal solution; (4) "Ensemble learning" combines the outputs of diverse models, which is a foundational technique for improving the accuracy and robustness of the final model. In addition, we analyze the challenges faced by deep model fusion and propose possible research directions for model fusion in the future. Our review is helpful in deeply understanding the correlation between different model fusion methods and practical application methods, which can enlighten the research in the field of deep model fusion.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5MEXQFMQ/Li et al. - 2023 - Deep Model Fusion A Survey.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/GYFBKNZ2/2309.html}
}

@article{Lillicrap,
  title = {{{CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING}}},
  author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the de-terministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our al-gorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is com-petitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies " end-to-end " : directly from raw pixel in-puts.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/NHUUFXYH/Lillicrap et al. - Unknown - CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING.pdf}
}

@article{Lin2020,
  title = {Pretrained {{Transformers}} for {{Text Ranking}}: {{BERT}} and {{Beyond}}},
  author = {Lin, Jimmy and Nogueira, Rodrigo and Yates, Andrew},
  date = {2020-10-13},
  journaltitle = {arXiv},
  eprint = {2010.06467},
  eprinttype = {arXiv},
  issn = {23318422},
  url = {http://arxiv.org/abs/2010.06467},
  abstract = {The goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query. Although the most common formulation of text ranking is search, instances of the task can also be found in many natural language processing applications. This survey provides an overview of text ranking with neural network architectures known as transformers, of which BERT is the best-known example. The combination of transformers and self-supervised pretraining has, without exaggeration, revolutionized the fields of natural language processing (NLP), information retrieval (IR), and beyond. In this survey, we provide a synthesis of existing work as a single point of entry for practitioners who wish to gain a better understanding of how to apply transformers to text ranking problems and researchers who wish to pursue work in this area. We cover a wide range of modern techniques, grouped into two high-level categories: transformer models that perform reranking in multi-stage ranking architectures and learned dense representations that attempt to perform ranking directly. There are two themes that pervade our survey: techniques for handling long documents, beyond the typical sentence-by-sentence processing approaches used in NLP, and techniques for addressing the tradeoff between effectiveness (result quality) and efficiency (query latency). Although transformer architectures and pretraining techniques are recent innovations, many aspects of how they are applied to text ranking are relatively well understood and represent mature techniques. However, there remain many open research questions, and thus in addition to laying out the foundations of pretrained transformers for text ranking, this survey also attempts to prognosticate where the field is heading.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IN6YDYYT/Lin, Nogueira, Yates - 2020 - Pretrained transformers for text ranking BERT and beyond.pdf}
}

@article{Linden2003,
  title = {Amazon.Com Recommendations: {{Item-to-item}} Collaborative Filtering},
  author = {Linden, Greg and Smith, Brent and York, Jeremy},
  date = {2003},
  journaltitle = {IEEE Internet Computing},
  volume = {7},
  number = {1},
  pages = {76--80},
  issn = {10897801},
  doi = {10.1109/MIC.2003.1167344},
  abstract = {Recommendation algorithms are best known for their use on e-commerce Web sites. It provides an effective form of targeted marketing by creating a personalized shopping experience for each customer. Amazon.com uses them to personalize the online store for each customer. Most of these algorithms start by finding a set of customers whose purchased and rated items overlap the user's purchased and rated items.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/JEA997AW/Linden, Smith, York - 2003 - Amazon.com recommendations Item-to-item collaborative filtering.pdf}
}

@online{lipmanFlowMatchingGenerative2023,
  title = {Flow {{Matching}} for {{Generative Modeling}}},
  author = {Lipman, Yaron and Chen, Ricky T. Q. and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  date = {2023-02-08},
  eprint = {2210.02747},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2210.02747},
  url = {http://arxiv.org/abs/2210.02747},
  urldate = {2024-12-02},
  abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples -- which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/8SQGZGSX/Lipman et al. - 2023 - Flow Matching for Generative Modeling.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/XG3G99D8/2210.html}
}

@unpublished{Liu2017,
  title = {{{PBODL}} : {{Parallel Bayesian Online Deep Learning}} for {{Click-Through Rate Prediction}} in {{Tencent Advertising System}}},
  author = {Liu, Xun and Xue, Wei and Xiao, Lei and Zhang, Bo},
  date = {2017},
  eprint = {1707.00802},
  eprinttype = {arXiv},
  issn = {0098-7484},
  doi = {10.1001/jama.268.12.1581},
  abstract = {We describe a parallel bayesian online deep learning framework (PBODL) for click-through rate (CTR) prediction within today's Tencent advertising system, which provides quick and accurate learning of user preferences. We first explain the framework with a deep probit regression model, which is trained with probabilistic back-propagation in the mode of assumed Gaussian density filtering. Then we extend the model family to a variety of bayesian online models with increasing feature embedding capabilities, such as Sparse-MLP, FM-MLP and FFM-MLP. Finally, we implement a parallel training system based on a stream computing infrastructure and parameter servers. Experiments with public available datasets and Tencent industrial datasets show that models within our framework perform better than several common online models, such as AdPredictor, FTRL-Proximal and MatchBox. Online A/B test within Tencent advertising system further proves that our framework could achieve CTR and CPM lift by learning more quickly and accurately.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/HMGPGW8V/1707.00802.pdf}
}

@article{Liu2018,
  title = {When {{Simple Exploration}} Is {{Sample Efficient}}: {{Identifying Sufficient Conditions}} for {{Random Exploration}} to {{Yield PAC RL Algorithms}}},
  author = {Liu, Yao and Brunskill, Emma},
  date = {2018},
  abstract = {Efficient exploration is one of the key challenges for reinforcement learning (RL) algorithms. Most traditional sample efficiency bounds require strategic exploration. Recently many deep RL algorithm with simple heuristic exploration strategies that have few formal guarantees, achieve surprising success in many domains. These results pose an important question about understand-ing these exploration strategies such as e-greedy, as well as understanding what characterize the difficulty of exploration in MDPs. In this work we propose problem specific sample complexity bounds of Q learning with random walk exploration that rely on several structural properties. We also link our theoretical results to some empirical benchmark domains, to illustrate if our bound gives polynomial sample complexity or not in these domains and how that is related with the empirical performance in these domains.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/4Z9H4WMR/m-api-3dcf5b65-b9b4-a9e9-75d7-fa4480ff77e4.pdf}
}

@unpublished{Liu2019,
  title = {Bandit {{Learning}} for {{Diversified Interactive Recommendation}}},
  author = {Liu, Yong and Xiao, Yingtai and Wu, Qiong and Miao, Chunyan and Zhang, Juyong},
  date = {2019},
  eprint = {1907.01647},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1907.01647},
  abstract = {Interactive recommender systems that enable the interactions between users and the recommender system have attracted increasing research attentions. Previous methods mainly focus on optimizing recommendation accuracy. However, they usually ignore the diversity of the recommendation results, thus usually results in unsatisfying user experiences. In this paper, we propose a novel diversified recommendation model, named Diversified Contextual Combinatorial Bandit (DC\$\textasciicircum 2\$B), for interactive recommendation with users' implicit feedback. Specifically, DC\$\textasciicircum 2\$B employs determinantal point process in the recommendation procedure to promote diversity of the recommendation results. To learn the model parameters, a Thompson sampling-type algorithm based on variational Bayesian inference is proposed. In addition, theoretical regret analysis is also provided to guarantee the performance of DC\$\textasciicircum 2\$B. Extensive experiments on real datasets are performed to demonstrate the effectiveness of the proposed method.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ES9VSRSA/Liu et al. - 2019 - Bandit Learning for Diversified Interactive Recommendation.pdf}
}

@article{Liu2020,
  title = {Kalman Filtering Attention for User Behavior Modeling in {{CTR}} Prediction},
  author = {Liu, Hu and Lu, Jing and Zhao, Xiwei and Xu, Sulong and Peng, Hao and Liu, Yutong and Zhang, Zehua and Li, Jian and Jin, Junsheng and Bao, Yongjun and Yan, Weipeng},
  date = {2020},
  journaltitle = {arXiv},
  eprint = {2010.00985},
  eprinttype = {arXiv},
  issn = {23318422},
  abstract = {Click-through rate (CTR) prediction is one of the fundamental tasks for e-commerce search engines. As search becomes more personalized, it is necessary to capture the user interest from rich behavior data. Existing user behavior modeling algorithms develop different attention mechanisms to emphasize query-relevant behaviors and suppress irrelevant ones. Despite being extensively studied, these attentions still suffer from two limitations. First, conventional attentions mostly limit the attention field only to a single user’s behaviors, which is not suitable in e-commerce where users often hunt for new demands that are irrelevant to any historical behaviors. Second, these attentions are usually biased towards frequent behaviors, which is unreasonable since high frequency does not necessarily indicate great importance. To tackle the two limitations, we propose a novel attention mechanism, termed Kalman Filtering Attention (KFAtt), that considers the weighted pooling in attention as a maximum a posteriori (MAP) estimation. By incorporating a priori, KFAtt resorts to global statistics when few user behaviors are relevant. Moreover, a frequency capping mechanism is incorporated to correct the bias towards frequent behaviors. Offline experiments on both benchmark and a 10 billion scale real production dataset, together with an Online A/B test, show that KFAtt outperforms all compared state-of-the-arts. KFAtt has been deployed in the ranking system of JD.com, one of the largest B2C e-commerce websites in China, serving the main traffic of hundreds of millions of active users.},
  issue = {NeurIPS},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/6FI5H69U/Liu et al. - 2020 - Kalman filtering attention for user behavior modeling in CTR prediction.pdf}
}

@article{Liu2020a,
  title = {Variable {{Selection}} via {{Thompson Sampling}}},
  author = {Liu, Yi and Ročková, Veronika},
  date = {2020},
  journaltitle = {arXiv},
  eprint = {2007.00187},
  eprinttype = {arXiv},
  issn = {23318422},
  abstract = {Thompson sampling is a heuristic algorithm for the multi-armed bandit problem which has a long tradition in machine learning. The algorithm has a Bayesian spirit in the sense that it selects arms based on posterior samples of reward probabilities of each arm. By forging a connection between combinatorial binary bandits and spike-and-slab variable selection, we propose a stochastic optimization approach to subset selection called Thompson Variable Selection (TVS). TVS is a framework for interpretable machine learning which does not rely on the underlying model to be linear. TVS brings together Bayesian reinforcement and machine learning in order to extend the reach of Bayesian subset selection to non-parametric models and large datasets with very many predictors and/or very many observations. Depending on the choice of a reward, TVS can be deployed in offline as well as online setups with streaming data batches. Tailoring multiplay bandits to variable selection, we provide regret bounds without necessarily assuming that the arm mean rewards be unrelated. We show a very strong empirical performance on both simulated and real data. Unlike deterministic optimization methods for spike-and-slab variable selection, the stochastic nature makes TVS less prone to local convergence and thereby more robust.},
  keywords = {BART,Combinatorial Bandits,Interpretable Machine Learning,Spike-and-Slab,Thompson Sampling,Variable Selection},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/RT755IVK/Liu, Ročková - 2020 - Variable Selection via Thompson Sampling.pdf}
}

@online{liuDoRAWeightDecomposedLowRank2024,
  title = {{{DoRA}}: {{Weight-Decomposed Low-Rank Adaptation}}},
  shorttitle = {{{DoRA}}},
  author = {Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  date = {2024-03-05},
  eprint = {2402.09353},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.09353},
  urldate = {2024-03-27},
  abstract = {Among the widely used parameter-efficient finetuning (PEFT) methods, LoRA and its variants have gained considerable popularity because of avoiding additional inference costs. However, there still often exists an accuracy gap between these methods and full fine-tuning (FT). In this work, we first introduce a novel weight decomposition analysis to investigate the inherent differences between FT and LoRA. Aiming to resemble the learning capacity of FT from the findings, we propose Weight-Decomposed LowRank Adaptation (DoRA). DoRA decomposes the pre-trained weight into two components, magnitude and direction, for fine-tuning, specifically employing LoRA for directional updates to efficiently minimize the number of trainable parameters. By employing DoRA, we enhance both the learning capacity and training stability of LoRA while avoiding any additional inference overhead. DoRA consistently outperforms LoRA on fine-tuning LLaMA, LLaVA, and VL-BART on various downstream tasks, such as commonsense reasoning, visual instruction tuning, and image/video-text understanding.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/WP33KTGV/Liu et al. - 2024 - DoRA Weight-Decomposed Low-Rank Adaptation.pdf}
}

@online{liuImprovedBaselinesVisual2023,
  title = {Improved {{Baselines}} with {{Visual Instruction Tuning}}},
  author = {Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  date = {2023-10-05},
  eprint = {2310.03744},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.03744},
  urldate = {2023-11-06},
  abstract = {Large multimodal models (LMM) have recently shown encouraging progress with visual instruction tuning. In this note, we show that the fully-connected vision-language cross-modal connector in LLaVA is surprisingly powerful and data-efficient. With simple modifications to LLaVA, namely, using CLIP-ViT-L-336px with an MLP projection and adding academic-task-oriented VQA data with simple response formatting prompts, we establish stronger baselines that achieve state-of-the-art across 11 benchmarks. Our final 13B checkpoint uses merely 1.2M publicly available data, and finishes full training in ∼1 day on a single 8-A100 node. We hope this can make state-of-the-art LMM research more accessible. Code and model will be publicly available.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TGFL4Y7B/Liu et al. - 2023 - Improved Baselines with Visual Instruction Tuning.pdf}
}

@online{liuNLEBenchNorGLMComprehensive2023,
  title = {{{NLEBench}}+{{NorGLM}}: {{A Comprehensive Empirical Analysis}} and {{Benchmark Dataset}} for {{Generative Language Models}} in {{Norwegian}}},
  shorttitle = {{{NLEBench}}+{{NorGLM}}},
  author = {Liu, Peng and Zhang, Lemei and Farup, Terje Nissen and Lauvrak, Even W. and Ingvaldsen, Jon Espen and Eide, Simen and Gulla, Jon Atle and Yang, Zhirong},
  date = {2023-12-03},
  eprint = {2312.01314},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2312.01314},
  urldate = {2024-09-27},
  abstract = {Recent advancements in Generative Language Models (GLMs) have transformed Natural Language Processing (NLP) by showcasing the effectiveness of the “pre-train, prompt, and predict” paradigm in utilizing pre-trained GLM knowledge for diverse applications. Despite their potential, these capabilities lack adequate quantitative characterization due to the absence of comprehensive benchmarks, particularly for low-resource languages. Existing low-resource benchmarks focus on discriminative language models like BERT, neglecting the evaluation of generative language models. Moreover, current benchmarks often overlook measuring generalization performance across multiple tasks, a crucial metric for GLMs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZKQRDIDV/Liu et al. - 2023 - NLEBench+NorGLM A Comprehensive Empirical Analysi.pdf}
}

@article{liuQue2SearchFastAccurate2021,
  title = {{{Que2Search}} : {{Fast}} and {{Accurate Query}} and {{Document Understanding}} for {{Search}} at {{Facebook}}},
  author = {Liu, Yiqun and Rangadurai, Kaushik and He, Yunzhong and Malreddy, Siddarth and Gui, Xunlong and Liu, Xiaoyi and Borisyuk, Fedor},
  date = {2021},
  isbn = {9781450383325},
  keywords = {e-commerce,embed-,multi-modal learning,product understanding},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/RPMCUZGI/Liu et al. - 2021 - Que2Search Fast and Accurate Query and Document Understanding for Search at Facebook.pdf}
}

@inproceedings{liuTransformerBasedVariationalAutoencoder2019,
  title = {A {{Transformer-Based Variational Autoencoder}} for {{Sentence Generation}}},
  booktitle = {2019 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Liu, Danyang and Liu, Gongshen},
  date = {2019-07},
  pages = {1--7},
  issn = {2161-4407},
  doi = {10.1109/IJCNN.2019.8852155},
  abstract = {The variational autoencoder(VAE) has been proved to be a most efficient generative model, but its applications in natural language tasks have not been fully developed. A novel variational autoencoder for natural texts generation is presented in this paper. Compared to the previously introduced variational autoencoder for natural text where both the encoder and decoder are RNN-based, we propose a new transformer-based architecture and augment the decoder with an LSTM language model layer to fully exploit information of latent variables. We also propose some methods to deal with problems during training time, such as KL divergency collapsing and model degradation. In the experiment, we use random sampling and linear interpolation to test our model. Results show that the generated sentences by our approach are more meaningful and the semantics are more coherent in the latent space.},
  eventtitle = {2019 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  keywords = {Computer architecture,Decoding,Gaussian distribution,Natural languages,Neural networks,self-attention,Task analysis,text generation,Training,transformer,variational autoencoder},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/PHRSECNP/8852155.html}
}

@online{liuVisualInstructionTuning2023,
  title = {Visual {{Instruction Tuning}}},
  author = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  date = {2023-04-17},
  eprint = {2304.08485},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.08485},
  urldate = {2023-11-06},
  abstract = {Instruction tuning large language models (LLMs) using machine-generated instruction-following data has improved zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. In this paper, we present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and LLM for generalpurpose visual and language understanding. Our early experiments show that LLaVA demonstrates impressive multimodel chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1\% relative score compared with GPT-4 on a synthetic multimodal instructionfollowing dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53\%. We make GPT-4 generated visual instruction tuning data, our model and code base publicly available.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/E6QMRPQS/Liu et al. - 2023 - Visual Instruction Tuning.pdf}
}

@inproceedings{loshchilovDecoupledWeightDecay2018,
  title = {Decoupled {{Weight Decay Regularization}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  date = {2018-09-27},
  volume = {2019},
  eprint = {1711.05101},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  publisher = {International Conference on Learning Representations},
  doi = {10.48550/arXiv.1711.05101},
  url = {http://arxiv.org/abs/1711.05101},
  urldate = {2024-02-18},
  abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \textbackslash emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \textbackslash emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/2ZCAC2YH/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/LCJNNJDC/1711.html}
}

@online{lovelaceDiffusionGuidedLanguage2024,
  title = {Diffusion {{Guided Language Modeling}}},
  author = {Lovelace, Justin and Kishore, Varsha and Chen, Yiwei and Weinberger, Kilian Q.},
  date = {2024-08-08},
  eprint = {2408.04220},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2408.04220},
  url = {http://arxiv.org/abs/2408.04220},
  urldate = {2024-08-10},
  abstract = {Current language models demonstrate remarkable proficiency in text generation. However, for many applications it is desirable to control attributes, such as sentiment, or toxicity, of the generated language -- ideally tailored towards each specific use case and target audience. For auto-regressive language models, existing guidance methods are prone to decoding errors that cascade during generation and degrade performance. In contrast, text diffusion models can easily be guided with, for example, a simple linear sentiment classifier -- however they do suffer from significantly higher perplexity than auto-regressive alternatives. In this paper we use a guided diffusion model to produce a latent proposal that steers an auto-regressive language model to generate text with desired properties. Our model inherits the unmatched fluency of the auto-regressive approach and the plug-and-play flexibility of diffusion. We show that it outperforms previous plug-and-play guidance methods across a wide range of benchmark data sets. Further, controlling a new attribute in our framework is reduced to training a single logistic regression classifier.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9SC37Z5J/2408.04220v1.pdf}
}

@article{Lucas2019,
  title = {Understanding Posterior Collapse in Generative Latent Variable Models},
  author = {Lucas, James and Tucker, George and Grosse, Roger and Norouzi, Mohammad},
  date = {2019},
  journaltitle = {Deep Generative Models for Highly Structured Data, DGS@ICLR 2019 Workshop},
  pages = {1--16},
  abstract = {Posterior collapse in Variational Autoencoders (VAEs) arises when the variational distribution closely matches the uninformative prior for a subset of latent variables. This paper presents a simple and intuitive explanation for posterior collapse through the analysis of linear VAEs and their direct correspondence with Probabilistic PCA (pPCA). We identify how local maxima can emerge from the marginal log-likelihood of pPCA, which yields similar local maxima for the evidence lower bound (ELBO). We show that training a linear VAE with variational inference recovers a uniquely identifiable global maximum corresponding to the principal component directions. We provide empirical evidence that the presence of local maxima causes posterior collapse in non-linear VAEs. Our findings help to explain a wide range of heuristic approaches in the literature that attempt to diminish the effect of the KL term in the ELBO to alleviate posterior collapse.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TJG4C2WC/Lucas et al. - 2019 - Understanding posterior collapse in generative latent variable models.pdf}
}

@article{Ludewig2018,
  title = {Evaluation of Session-Based Recommendation Algorithms},
  author = {Ludewig, Malte and Jannach, Dietmar},
  date = {2018-12-01},
  journaltitle = {User Modeling and User-Adapted Interaction},
  volume = {28},
  number = {4-5},
  eprint = {1803.09587},
  eprinttype = {arXiv},
  pages = {331--390},
  issn = {0924-1868},
  doi = {10.1007/s11257-018-9209-6},
  url = {http://arxiv.org/abs/1803.09587},
  urldate = {2018-08-21},
  abstract = {Recommender systems help users find relevant items of interest, for example on e-commerce or media streaming sites. Most academic research is concerned with approaches that personalize the recommendations according to long-term user profiles. In many real-world applications, however, such long-term profiles often do not exist and recommendations therefore have to be made solely based on the observed behavior of a user during an ongoing session. Given the high practical relevance of the problem, an increased interest in this problem can be observed in recent years, leading to a number of proposals for session-based recommendation algorithms that typically aim to predict the user's immediate next actions. In this work, we present the results of an in-depth performance comparison of a number of such algorithms, using a variety of datasets and evaluation measures. Our comparison includes the most recent approaches based on recurrent neural networks like GRU4REC, factorized Markov model approaches such as FISM or Fossil, as well as more simple methods based, e.g., on nearest neighbor schemes. Our experiments reveal that algorithms of this latter class, despite their sometimes almost trivial nature, often perform equally well or significantly better than today's more complex approaches based on deep neural networks. Our results therefore suggest that there is substantial room for improvement regarding the development of more sophisticated session-based recommendation algorithms.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BDMV2F4H/full-text.pdf}
}

@article{ludewigPerformanceComparisonNeural2019,
  title = {Performance Comparison of Neural and Non-Neural Approaches to Session-Based Recommendation},
  author = {Ludewig, Malte and Mauro, Noemi and Latif, Sara and Jannach, Dietmar},
  date = {2019},
  journaltitle = {RecSys 2019 - 13th ACM Conference on Recommender Systems},
  pages = {462--466},
  doi = {10.1145/3298689.3347041},
  abstract = {The benefts of neural approaches are undisputed in many application areas. However, today's research practice in applied machine learning-where researchers often use a variety of baselines, datasets, and evaluation procedures-can make it difcult to understand how much progress is actually achieved through novel technical approaches. In this work, we focus on the fast-developing area of session-based recommendation and aim to contribute to a better understanding of what represents the state-of-the-art. To that purpose, we have conducted an extensive set of experiments, using a variety of datasets, in which we benchmarked four neural approaches that were published in the last three years against each other and against a set of simpler baseline techniques, e.g., based on nearest neighbors. The evaluation of the algorithms under the exact same conditions revealed that the benefts of applying today's neural approaches to session-based recommendations are still limited. In the majority of the cases, and in particular when precision and recall are used, it turned out that simple techniques in most cases outperform recent neural approaches. Our fndings therefore point to certain major limitations of today's research practice. By sharing our evaluation framework publicly, we hope that some of these limitations can be overcome in the future.},
  isbn = {9781450362436},
  issue = {February},
  keywords = {Evaluation,Reproducibility,Session-based Recommendation},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/XAKQ9VL6/Ludewig et al. - 2019 - Performance comparison of neural and non-neural approaches to session-based recommendation.pdf}
}

@article{luengoFullyAdaptiveGaussian2013,
  title = {Fully Adaptive {{Gaussian}} Mixture {{Metropolis-Hastings}} Algorithm},
  author = {Luengo, David and Martino, Luca},
  date = {2013},
  journaltitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  eprint = {1212.0122},
  eprinttype = {arXiv},
  pages = {6148--6152},
  issn = {15206149},
  doi = {10.1109/ICASSP.2013.6638846},
  abstract = {Markov Chain Monte Carlo methods are widely used in signal processing and communications for statistical inference and stochastic optimization. In this work, we introduce an efficient adaptive Metropolis-Hastings algorithm to draw samples from generic multimodal and multidimensional target distributions. The proposal density is a mixture of Gaussian densities with all parameters (weights, mean vectors and covariance matrices) updated using all the previously generated samples applying simple recursive rules. Numerical results for the one and two-dimensional cases are provided. © 2013 IEEE.},
  isbn = {9781479903566},
  issue = {Mcmc},
  keywords = {adaptive Metropolis-Hastings,Gaussian mixtures,Markov Chain Monte Carlo (MCMC)},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/949IQXJQ/Luengo, Martino - 2013 - Fully adaptive Gaussian mixture Metropolis-Hastings algorithm.pdf}
}

@article{luGraphbasedMultilingualProduct2019,
  title = {Graph-Based {{Multilingual Product Retrieval}} in {{E-Commerce Search}}},
  author = {Lu, Hanqing and Wu, Tony and Yin, Bing},
  date = {2019},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/QY6E8J2A/Lu, Wu, Yin - 2019 - Graph-based Multilingual Product Retrieval in E-Commerce Search.pdf}
}

@article{Ma2019,
  title = {Sampling Can Be Faster than Optimization},
  author = {Ma, Yi An and Chen, Yuansi and Jin, Chi and Flammarion, Nicolas and Jordan, Michael I.},
  date = {2019},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {116},
  number = {42},
  pages = {20881--20885},
  issn = {10916490},
  doi = {10.1073/pnas.1820003116},
  abstract = {Optimization algorithms and Monte Carlo sampling algorithms have provided the computational foundations for the rapid growth in applications of statistical machine learning in recent years. There is, however, limited theoretical understanding of the relationships between these 2 kinds of methodology, and limited understanding of relative strengths and weaknesses. Moreover, existing results have been obtained primarily in the setting of convex functions (for optimization) and log-concave functions (for sampling). In this setting, where local properties determine global properties, optimization algorithms are unsurprisingly more efficient computationally than sampling algorithms. We instead examine a class of nonconvex objective functions that arise in mixture modeling and multistable systems. In this nonconvex setting, we find that the computational complexity of sampling algorithms scales linearly with the model dimension while that of optimization algorithms scales exponentially.},
  isbn = {1820003116},
  keywords = {Computational complexity,Langevin Monte Carlo,Nonconvex optimization},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/WRZ223DX/Ma et al. - 2019 - Sampling can be faster than optimization.pdf}
}

@article{Ma2020,
  title = {Off-Policy {{Learning}} in {{Two-stage Recommender Systems}}},
  author = {Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Yang, Ji and Chen, Minmin and Tang, Jiaxi and Hong, Lichan and Chi, Ed H.},
  date = {2020},
  journaltitle = {The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020},
  pages = {463--473},
  doi = {10.1145/3366423.3380130},
  abstract = {Many real-world recommender systems need to be highly scalable: matching millions of items with billions of users, with milliseconds latency. The scalability requirement has led to widely used two-stage recommender systems, consisting of efficient candidate generation model(s) in the first stage and a more powerful ranking model in the second stage. Logged user feedback, e.g., user clicks or dwell time, are often used to build both candidate generation and ranking models for recommender systems. While it's easy to collect large amount of such data, they are inherently biased because the feedback can only be observed on items recommended by the previous systems. Recently, off-policy correction on such biases have attracted increasing interest in the field of recommender system research. However, most existing work either assumed that the recommender system is a single-stage system or only studied how to apply off-policy correction to the candidate generation stage of the system without explicitly considering the interactions between the two stages. In this work, we propose a two-stage off-policy policy gradient method, and showcase that ignoring the interaction between the two stages leads to a sub-optimal policy in two-stage recommender systems. The proposed method explicitly takes into account the ranking model when training the candidate generation model, which helps improve the performance of the whole system. We conduct experiments on real-world datasets with large item space and demonstrate the effectiveness of our proposed method.},
  isbn = {9781450370233},
  issue = {May},
  keywords = {Neural Networks,Off-policy Learning,Recommender Systems,Two-stage Systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/QXEZFKUL/Ma et al. - 2020 - Off-policy Learning in Two-stage Recommender Systems.pdf}
}

@article{Maas2012,
  title = {Recurrent {{Neural Networks}} for {{Noise Reduction}} in {{Robust ASR}}.},
  author = {Maas, Andrew L. and Le, Quoc V. and O'Neil, Tyler M. and Vinyals, Oriol and Nguyen, Patrick and Ng, Andrew Y.},
  date = {2012},
  journaltitle = {Interspeech},
  eprint = {18557655},
  eprinttype = {pmid},
  pages = {3--6},
  issn = {1558-7916},
  doi = {10.1016/j.patcog.2005.01.025},
  abstract = {Recent work on deep neural networks as acoustic mod- els for automatic speech recognition (ASR) have demon- strated substantial performance improvements. We intro- duce a model which uses a deep recurrent auto encoder neural network to denoise input features for robust ASR. The model is trained on stereo (noisy and clean) audio features to predict clean features given noisy input. The model makes no assumptions about how noise affects the signal, nor the existence of distinct noise environments. Instead, the model can learn to model any type of distor- tion or additive noise given sufficient training data. We demonstrate the model is competitive with existing fea- ture denoising approaches on the Aurora2 task, and out- performs a tandem approach where deep networks are used to predict phoneme posteriors directly.},
  isbn = {9781622767595},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YKLPKFXB/m-api-60e29368-7b5a-8dc9-2660-57ac8e672b28.pdf}
}

@inreference{MachineLearningWikipedia2024,
  title = {Machine Learning (Wikipedia)},
  booktitle = {Wikipedia},
  date = {2024-06-11T09:27:55Z},
  url = {https://en.wikipedia.org/w/index.php?title=Machine_learning&oldid=1228454210},
  urldate = {2024-06-15},
  abstract = {Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, artificial neural networks have been able to surpass many previous approaches in performance. ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. When applied to business problems, it is known under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods. The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.  From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.},
  langid = {english},
  annotation = {Page Version ID: 1228454210},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/82CXZAUW/Machine_learning.html}
}

@article{Mackay,
  title = {Intro\_gausian\_processes},
  author = {Mackay, David J.C.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/MMTXPC3R/m-api-6e3ec4d7-cd04-35e8-6f6d-58a906f75464.pdf}
}

@unpublished{Maddox2021,
  title = {Fast {{Adaptation}} with {{Linearized Neural Networks}}},
  author = {Maddox, Wesley J. and Tang, Shuai and Moreno, Pablo Garcia and Wilson, Andrew Gordon and Damianou, Andreas},
  date = {2021},
  volume = {130},
  eprint = {2103.01439},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2103.01439},
  abstract = {The inductive biases of trained neural networks are difficult to understand and, consequently, to adapt to new settings. We study the inductive biases of linearizations of neural networks, which we show to be surprisingly good summaries of the full network functions. Inspired by this finding, we propose a technique for embedding these inductive biases into Gaussian processes through a kernel designed from the Jacobian of the network. In this setting, domain adaptation takes the form of interpretable posterior inference, with accompanying uncertainty estimation. This inference is analytic and free of local optima issues found in standard techniques such as fine-tuning neural network weights to a new task. We develop significant computational speed-ups based on matrix multiplies, including a novel implementation for scalable Fisher vector products. Our experiments on both image classification and regression demonstrate the promise and convenience of this framework for transfer learning, compared to neural network fine-tuning. Code is available at https://github.com/amzn/xfer/tree/master/finite\_ntk.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FHQVHUS8/Maddox et al. - 2021 - Fast Adaptation with Linearized Neural Networks.pdf}
}

@article{Mandt2016,
  title = {Variational Tempering},
  author = {Mandt, Stephan and McInerney, James and Abrol, Farhan and Ranganath, Rajesh and Blei, David},
  date = {2016},
  journaltitle = {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, AISTATS 2016},
  volume = {41},
  eprint = {1411.1810},
  eprinttype = {arXiv},
  pages = {704--712},
  abstract = {Variational inference (VI) combined with data subsampling enables approximate posterior inference over large data sets, but suffers from poor local optima. We first formulate a deterministic annealing approach for the generic class of conditionally conjugate exponential family models. This approach uses a decreasing temperature parameter which deterministically deforms the objective during the course of the optimization. A well-known drawback to this annealing approach is the choice of the cooling schedule. We therefore introduce variational tempering, a variational algorithm that introduces a temperature latent variable to the model. In contrast to related work in the Markov chain Monte Carlo literature, this algorithm results in adaptive annealing schedules. Lastly, we develop local variational tempering, which assigns a latent temperature to each data point; this allows for dynamic annealing that varies across data. Compared to the traditional VI, all proposed approaches find improved predictive likelihoods on held-out data.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/MKIKSCEN/Mandt et al. - 2016 - Variational tempering.pdf}
}

@online{mannHowSampleLanguage2019,
  title = {How to Sample from Language Models},
  author = {Mann, Ben},
  date = {2019-05-30T21:58:16},
  url = {https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277},
  urldate = {2023-01-15},
  abstract = {Causal language models like GPT-2 are trained to predict the probability of the next word given some context. For example, given “I ate a…},
  langid = {english},
  organization = {Medium},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/J9BP5CGB/how-to-sample-from-language-models-682bceb97277.html}
}

@article{Marquez2013,
  title = {Proceedings of the {{Sixth International Conference}} on {{Management Science}} and {{Engineering Management}}},
  author = {Márquez, Fausto Pedro García and Nieto, Marta Ramos Martín},
  date = {2013},
  journaltitle = {Lecture Notes in Electrical Engineering},
  volume = {185},
  pages = {23--37},
  issn = {18761100},
  doi = {10.1007/978-1-4471-4600-1},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867697326&partnerID=tZOtx3y1},
  abstract = {This paper describes a real case study has been considered. It presents a dual optimization problem that consists in finding the optimal routes in the called principal and capillary routes. The problem has been considered as a travel salesman problem with time windows (TSPTW). The restrictions of Miller et al. have been used in order to reduce the computational cost [56]. A recurrent neural network approach is employed, which involves not just unsupervised learning to train neurons, but an integrated approach where Genetic Algorithm is utilized for training neurons so as to obtain a model with the least error. © 2013 Springer-Verlag.},
  isbn = {978-1-4471-4599-8},
  keywords = {Genetic algorithm,Logistics,Recurrent neural network,Travelling salesman problem},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/CFDEF2NT/Márquez, Nieto - 2013 - Proceedings of the Sixth International Conference on Management Science and Engineering Management.pdf}
}

@article{matsuoDeepLearningReinforcement2022,
  title = {Deep Learning, Reinforcement Learning, and World Models},
  author = {Matsuo, Yutaka and LeCun, Yann and Sahani, Maneesh and Precup, Doina and Silver, David and Sugiyama, Masashi and Uchibe, Eiji and Morimoto, Jun},
  date = {2022-08-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {152},
  pages = {267--275},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2022.03.037},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608022001150},
  urldate = {2023-08-27},
  abstract = {Deep learning (DL) and reinforcement learning (RL) methods seem to be a part of indispensable factors to achieve human-level or super-human AI systems. On the other hand, both DL and RL have strong connections with our brain functions and with neuroscientific findings. In this review, we summarize talks and discussions in the “Deep Learning and Reinforcement Learning” session of the symposium, International Symposium on Artificial Intelligence and Brain Science. In this session, we discussed whether we can achieve comprehensive understanding of human intelligence based on the recent advances of deep learning and reinforcement learning algorithms. Speakers contributed to provide talks about their recent studies that can be key technologies to achieve human-level intelligence.},
  keywords = {Artificial intelligence,Deep learning,Machine learning,Reinforcement learning,World models},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3I4BGPH8/1-s2.0-S0893608022001150-main.pdf}
}

@article{maureraEvaluationRecommenderSystems2022,
  title = {Towards the {{Evaluation}} of {{Recommender Systems}} with {{Impressions}}},
  author = {Maurera, Fernando B Pérez and Dacrema, Maurizio Ferrari and Cremonesi, Paolo},
  date = {2022},
  pages = {6},
  abstract = {In Recommender Systems, impressions are a relatively new type of information that records all products previously shown to the users. They are also a complex source of information, combining the effects of the recommender system that generated them, search results, or business rules that may select specific products for recommendations. The fact that the user interacted with a specific item given a list of recommended ones may benefit from a richer interaction signal, in which some items the user did not interact with may be considered negative interactions. This work presents a preliminary evaluation of recommendation models with impressions. First, impressions are characterized by describing their assumptions, signals, and challenges. Then, an evaluation study with impressions is described. The study’s goal is two-fold: to measure the effects of impressions data on properly-tuned recommendation models using current open-source datasets and disentangle the signals within impressions data. Preliminary results suggest that impressions data and signals are nuanced, complex, and effective at improving the recommendation quality of recommenders. This work publishes the source code, datasets, and scripts used in the evaluation to promote reproducibility in the domain.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Z9JTHY52/Maurera et al. - 2022 - Towards the Evaluation of Recommender Systems with.pdf}
}

@article{Maurya2012,
  title = {Running , {{Iterate}} from {{Plan A}} to a {{Plan That Works}}},
  author = {Maurya, Ash},
  date = {2012},
  pages = {240},
  url = {http://shop.oreilly.com/product/0636920020141.do},
  isbn = {978-1-4493-0517-8},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/RW8BF72H/Maurya - 2012 - Running , Iterate from Plan A to a Plan That Works.pdf}
}

@article{May2000,
  title = {{{OPTIMISTIC BAYESIAN SAMPLING IN CONTEXTUAL-BANDIT PROBLEMS}}},
  author = {May, By Benedict C and Korda, Nathan and Lee, Anthony and Leslie, S},
  date = {2000},
  journaltitle = {Annals of Applied Probability},
  pages = {1--24},
  abstract = {In sequential decision problems in an unknown environment, the decision maker often faces a dilemma over whether to explore to discover more about the environment, or to exploit current knowledge. We address the exploration-exploitation dilemma in a general setting encompassing both standard and contextualised bandit problems. The contextual bandit problem has recently resurfaced in attempts to maximise click-through rates in web based applications, a task with significant commercial interest. In this article we consider an approach of Thompson (1933) which makes use of samples from the posterior distributions for the instantaneous value of each action. We extend the approach by introducing a new algorithm, Optimistic Bayesian Sampling (OBS), in which the probability of playing an action increases with the uncertainty in the estimate of the action value. This results in better directed exploratory behaviour. We prove that, under unrestrictive assumptions, both approaches result in optimal behaviour with respect to the average reward criterion of Yang and Zhu (2002). We implement OBS and measure its performance in simulated Bernoulli bandit and linear regression domains, and also when tested with the task of personalised news article recommendation on a Yahoo! Front Page Today Module data set. We find that OBS performs competitively when compared to recently proposed benchmark algorithms and outperforms Thompson's method throughout. © 2012 Benedict C. May, Nathan Korda, Anthony Lee and David S. Leslie.},
  keywords = {contextual bandits,exploration-exploitation,multi-armed bandits,sequential alloca-tion,Thompson sampling},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/V7UZ34Y4/may12a.pdf}
}

@inproceedings{maystreTemporallyConsistentSurvivalAnalysis2022,
  title = {Temporally-{{Consistent Survival Analysis}}},
  author = {Maystre, Lucas and Russo, Daniel},
  date = {2022-10-31},
  url = {https://openreview.net/forum?id=r-CsquKaHvk},
  urldate = {2022-11-27},
  abstract = {We study survival analysis in the dynamic setting: We seek to model the time to an event of interest given sequences of states. Taking inspiration from temporal-difference learning, a central idea in reinforcement learning, we develop algorithms that estimate a discrete-time survival model by exploiting a temporal-consistency condition. Intuitively, this condition captures the fact that the survival distribution at consecutive states should be similar, accounting for the delay between states. Our method can be combined with any parametric survival model and naturally accommodates right-censored observations. We demonstrate empirically that it achieves better sample-efficiency and predictive performance compared to approaches that directly regress the observed survival outcome.},
  eventtitle = {Advances in {{Neural Information Processing Systems}}},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/VUBD2RQ3/temporally_consistent_survival.pdf}
}

@article{McInerney2018,
  title = {Explore, {{Exploit}}, and {{Ex-plain}}: {{Personalizing Explainable Recommendations}} with {{Bandits}}},
  author = {McInerney, James and Lacker, Benjamin and Hansen, Samantha and Higley, Karl and Bouchard, Hugues and Gruson, Alois and Mehrotra Spotify, Rishabh},
  date = {2018},
  doi = {10.1145/3240323.3240354},
  url = {https://doi.org/10.1145/3240323.3240354},
  abstract = {The multi-armed bandit is an important framework for balancing exploration with exploitation in recommendation. Exploitation recommends content (e.g., products, movies, music playlists) with the highest predicted user engagement and has traditionally been the focus of recommender systems. Exploration recommends content with uncertain predicted user engagement for the purpose of gathering more information. The importance of exploration has been recognized in recent years, particularly in settings with new users, new items, non-stationary preferences and attributes. In parallel, explaining recommendations ("recsplanations") is crucial if users are to understand their recommendations. Existing work has looked at bandits and explanations independently. We provide the first method that combines both in a principled manner. In particular, our method is able to jointly (1) learn which explanations each user responds to; (2) learn the best content to recommend for each user; and (3) balance exploration with exploitation to deal with uncertainty. Experiments with historical log data and tests with live production traffic in a large-scale music recommendation service show a significant improvement in user engagement.},
  isbn = {9781450359016},
  keywords = {• Computing methodologies → Causal rea-soning and,CCS CONCEPTS • Information systems → Recommender s,Collabo-rative filtering,Reinforcement learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/EVU2LMBJ/BartRecSys.pdf}
}

@article{McMahan2013,
  title = {Ad Click Prediction: A View from the Trenches},
  author = {McMahan, H Brendan and Holt, Gary and Sculley, D and Young, Michael and Ebner, Dietmar and Grady, Julian and Nie, Lan and Phillips, Todd and Davydov, Eugene and Golovin, Daniel and Chikkerur, Sharat and Liu, Dan and Wattenberg, Martin and Hrafnkelsson, Arnar Mar and Boulos, Tom and Kubica, Jeremy},
  date = {2013},
  journaltitle = {Kdd},
  eprint = {1301.3781v2},
  eprinttype = {arXiv},
  pages = {1222--1230},
  issn = {9781450321747},
  doi = {10.1145/2487575.2488200},
  abstract = {Predicting ad click--through rates (CTR) is a massive-scale learning problem that is central to the multi-billion dollar online advertising industry. We present a selection of case studies and topics drawn from recent experiments in the setting of a deployed CTR prediction system. These include improvements in the context of traditional supervised learning based on an FTRL-Proximal online learning algorithm (which has excellent sparsity and convergence properties) and the use of per-coordinate learning rates. We also explore some of the challenges that arise in a real-world system that may appear at first to be outside the domain of traditional machine learning research. These include useful tricks for memory savings, methods for assessing and visualizing performance, practical methods for providing confidence estimates for predicted probabilities, calibration methods, and methods for automated management of features. Finally, we also detail several directions that did not turn out to be beneficial for us, despite promising results elsewhere in the literature. The goal of this paper is to highlight the close relationship between theoretical advances and practical engineering in this industrial setting, and to show the depth of challenges that appear when applying traditional machine learning methods in a complex dynamic system.},
  isbn = {9781450321747},
  keywords = {data mining,large-scale learning,online advertising},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/P2GL5DC9/McMahan et al. - 2013 - Ad click prediction a view from the trenches.pdf}
}

@online{mengSimPOSimplePreference2024,
  title = {{{SimPO}}: {{Simple Preference Optimization}} with a {{Reference-Free Reward}}},
  shorttitle = {{{SimPO}}},
  author = {Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  date = {2024-07-08},
  eprint = {2405.14734},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2405.14734},
  urldate = {2024-10-04},
  abstract = {Direct Preference Optimization (DPO) is a widely used offline preference optimization algorithm that reparameterizes reward functions in reinforcement learning from human feedback (RLHF) to enhance simplicity and training stability. In this work, we propose SimPO, a simpler yet more effective approach. The effectiveness of SimPO is attributed to a key design: using the average log probability of a sequence as the implicit reward. This reward formulation better aligns with model generation and eliminates the need for a reference model, making it more compute and memory efficient. Additionally, we introduce a target reward margin to the Bradley-Terry objective to encourage a larger margin between the winning and losing responses, further enhancing the algorithm's performance. We compare SimPO to DPO and its latest variants across various state-of-the-art training setups, including both base and instruction-tuned models like Mistral and Llama3. We evaluated on extensive instruction-following benchmarks, including AlpacaEval 2, MT-Bench, and the recent challenging Arena-Hard benchmark. Our results demonstrate that SimPO consistently and significantly outperforms existing approaches without substantially increasing response length. Specifically, SimPO outperforms DPO by up to 6.4 points on AlpacaEval 2 and by up to 7.5 points on Arena-Hard. Our top-performing model, built on Llama3-8B-Instruct, achieves a remarkable 53.7 length-controlled win rate on AlpacaEval 2 -- surpassing Claude 3 Opus on the leaderboard, and a 36.5 win rate on Arena-Hard -- making it the strongest 8B open-source model.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/MJT77RDC/Meng et al. - 2024 - SimPO Simple Preference Optimization with a Refer.pdf}
}

@unpublished{Merity2018a,
  title = {An {{Analysis}} of {{Neural Language Modeling}} at {{Multiple Scales}}},
  author = {Merity, Stephen and Keskar, Nitish Shirish and Socher, Richard},
  date = {2018-03-22},
  eprint = {1803.08240},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1803.08240},
  urldate = {2018-03-23},
  abstract = {Many of the leading approaches in language modeling introduce novel, complex and specialized architectures. We take existing state-of-the-art word level language models based on LSTMs and QRNNs and extend them to both larger vocabularies as well as character-level granularity. When properly tuned, LSTMs and QRNNs achieve state-of-the-art results on character-level (Penn Treebank, enwik8) and word-level (WikiText-103) datasets, respectively. Results are obtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single modern GPU.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ADXXHDIC/Merity, Keskar, Socher - 2018 - An Analysis of Neural Language Modeling at Multiple Scales.pdf}
}

@online{mialonAugmentedLanguageModels2023,
  title = {Augmented {{Language Models}}: A {{Survey}}},
  shorttitle = {Augmented {{Language Models}}},
  author = {Mialon, Grégoire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
  date = {2023-02-15},
  eprint = {2302.07842},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.07842},
  url = {http://arxiv.org/abs/2302.07842},
  urldate = {2023-02-17},
  abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3TPFH5P4/Mialon et al. - 2023 - Augmented Language Models a Survey.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/HC2LJNW7/2302.html}
}

@online{MixtureExpertsExplained,
  title = {Mixture of {{Experts Explained}}},
  url = {https://huggingface.co/blog/moe},
  urldate = {2023-12-17},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/WR4SESTY/Mixture of Experts Explained.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/A6M5J8QY/moe.html}
}

@unpublished{mladenovRecSimNGPrincipled2021,
  title = {{{RecSim NG}}: {{Toward Principled Uncertainty Modeling}} for {{Recommender Ecosystems}}},
  author = {Mladenov, Martin and Hsu, Chih-Wei and Jain, Vihan and Ie, Eugene and Colby, Christopher and Mayoraz, Nicolas and Pham, Hubert and Tran, Dustin and Vendrov, Ivan and Boutilier, Craig},
  date = {2021},
  eprint = {2103.08057},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2103.08057},
  abstract = {The development of recommender systems that optimize multi-turn interaction with users, and model the interactions of different agents (e.g., users, content providers, vendors) in the recommender ecosystem have drawn increasing attention in recent years. Developing and training models and algorithms for such recommenders can be especially difficult using static datasets, which often fail to offer the types of counterfactual predictions needed to evaluate policies over extended horizons. To address this, we develop RecSim NG, a probabilistic platform for the simulation of multi-agent recommender systems. RecSim NG is a scalable, modular, differentiable simulator implemented in Edward2 and TensorFlow. It offers: a powerful, general probabilistic programming language for agent-behavior specification; tools for probabilistic inference and latent-variable model learning, backed by automatic differentiation and tracing; and a TensorFlow-based runtime for running simulations on accelerated hardware. We describe RecSim NG and illustrate how it can be used to create transparent, configurable, end-to-end models of a recommender ecosystem, complemented by a small set of simple use cases that demonstrate how RecSim NG can help both researchers and practitioners easily develop and train novel algorithms for recommender systems.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TAFLNJC7/Mladenov et al. - 2021 - RecSim NG Toward Principled Uncertainty Modeling for Recommender Ecosystems.pdf}
}

@article{Mnih2016,
  title = {Asynchronous Methods for Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  date = {2016},
  journaltitle = {arXiv preprint},
  volume = {48},
  eprint = {1000272564},
  eprinttype = {pmid},
  pages = {1--28},
  issn = {1938-7228},
  url = {http://arxiv.org/abs/1602.01783},
  abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task involving finding rewards in random 3D mazes using a visual input.},
  isbn = {9781510829008},
  issue = {arXiv:1602.01783v1 [cs.LG]},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5ZPLFQEQ/Mnih et al. - 2016 - Asynchronous methods for deep reinforcement learning.pdf}
}

@article{moitraGaussianMixtureModels2018,
  title = {Gaussian {{Mixture Models}}},
  author = {Moitra, Ankur},
  date = {2018},
  journaltitle = {Algorithmic Aspects of Machine Learning},
  number = {2},
  pages = {107--131},
  doi = {10.1017/9781316882177.008},
  abstract = {A description of Gaussian Mixture Models as applied to instrument classification},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BGQIIX6L/Moitra - 2018 - Gaussian Mixture Models.pdf}
}

@unpublished{Moravcik2017,
  title = {{{DeepStack}}: {{Expert-Level Artificial Intelligence}} in {{No-Limit Poker}}},
  author = {Moravčík, Matej and Schmid, Martin and Burch, Neil and Lisý, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
  date = {2017},
  volume = {6960},
  eprint = {28254783},
  eprinttype = {pmid},
  pages = {1--32},
  issn = {0036-8075},
  doi = {10.1126/science.aam6960},
  abstract = {Artificial intelligence has seen a number of breakthroughs in recent years, with games often serving as significant milestones. A common feature of games with these successes is that they involve information symmetry among the players, where all players have identical information. This property of perfect information, though, is far more common in games than in real-world problems. Poker is the quintessential game of imperfect information, and it has been a longstanding challenge problem in artificial intelligence. In this paper we introduce DeepStack, a new algorithm for imperfect information settings such as poker. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition about arbitrary poker situations that is automatically learned from self-play games using deep learning. In a study involving dozens of participants and 44,000 hands of poker, DeepStack becomes the first computer program to beat professional poker players in heads-up no-limit Texas hold'em. Furthermore, we show this approach dramatically reduces worst-case exploitability compared to the abstraction paradigm that has been favored for over a decade.},
  issue = {February},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/UJFC42FM/Moravčík et al. - 2017 - DeepStack Expert-Level Artificial Intelligence in No-Limit Poker.pdf}
}

@article{naessethElementsSequentialMonte2019,
  title = {Elements of Sequential {{Monte Carlo}}},
  author = {Naesseth, Christian A. and Lindsten, Fredrik and Schön, Thomas B.},
  date = {2019},
  journaltitle = {Foundations and Trends in Machine Learning},
  volume = {12},
  number = {3},
  eprint = {1903.04797},
  eprinttype = {arXiv},
  pages = {187--306},
  issn = {19358245},
  doi = {10.1561/2200000074},
  abstract = {A core problem in statistics and probabilistic machine learning is to compute probability distributions and expectations. This is the fundamental problem of Bayesian statistics and machine learning, which frames all inference as expectations with respect to the posterior distribution. The key challenge is to approximate these intractable expectations. In this tutorial, we review sequential Monte Carlo (SMC), a random-sampling-based class of methods for approximate inference. First, we explain the basics of SMC, discuss practical issues, and review theoretical results. We then examine two of the main user design choices: the proposal distributions and the so called intermediate target distributions. We review recent results on how variational inference and amortization can be used to learn efficient proposals and target distributions. Next, we discuss the SMC estimate of the normalizing constant, how this can be used for pseudo-marginal inference and inference evaluation. Throughout the tutorial we illustrate the use of SMC on various models commonly used in machine learning, such as stochastic recurrent neural networks, probabilistic graphical models, and probabilistic programs.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/VILM6TBS/Naesseth, Lindsten, Schön - 2019 - Elements of sequential Monte Carlo.pdf}
}

@article{Nagabandi2018,
  title = {Neural {{Network Dynamics}} for {{Model-Based Deep Reinforcement Learning}} with {{Model-Free Fine-Tuning}}},
  author = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S. and Levine, Sergey},
  date = {2018},
  journaltitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  eprint = {1708.02596},
  eprinttype = {arXiv},
  pages = {7579--7586},
  issn = {10504729},
  doi = {10.1109/ICRA.2018.8463189},
  abstract = {Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5times on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.},
  isbn = {9781538630815},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/NIVUG98B/Nagabandi et al. - 2018 - Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning.pdf}
}

@article{nealMarkovChainSampling2000,
  title = {Markov {{Chain Sampling Methods}} for {{Dirichlet Process Mixture Models}}},
  author = {Neal, Radford M.},
  date = {2000},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {9},
  number = {2},
  pages = {249--265},
  issn = {15372715},
  doi = {10.1080/10618600.2000.10474879},
  abstract = {This article reviews Markov chain methods for sampling from the posterior distribution of a Dirichlet process mixture model and presents two new classes of methods. One new approach is to make Metropolis—Hastings updates of the indicators specifying which mixture component is associated with each observation, perhaps supplemented with a partial form of Gibbs sampling. The other new approach extends Gibbs sampling for these indicators by using a set of auxiliary parameters. These methods are simple to implement and are more efficient than previous ways of handling general Dirichlet process mixture models with non-conjugate priors. © 2000 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
  keywords = {Auxiliary variable methods,Density estimation,Latent class models,Metropolis—Hasting algorithm,Monte Carlo},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/VPGJ7I2G/Neal - 2000 - Markov Chain Sampling Methods for Dirichlet Proces.pdf}
}

@article{Nemeth2020,
  title = {Stochastic {{Gradient Markov Chain Monte Carlo}}},
  author = {Nemeth, Christopher and Fearnhead, Paul},
  date = {2020},
  journaltitle = {Journal of the American Statistical Association},
  eprint = {1907.06986},
  eprinttype = {arXiv},
  pages = {1--31},
  issn = {1537274X},
  doi = {10.1080/01621459.2020.1847120},
  url = {http://arxiv.org/abs/1907.06986},
  abstract = {Markov chain Monte Carlo (MCMC) algorithms are generally regarded as the gold standard technique for Bayesian inference. They are theoretically well-understood and conceptually simple to apply in practice. The drawback of MCMC is that performing exact inference generally requires all of the data to be processed at each iteration of the algorithm. For large datasets, the computational cost of MCMC can be prohibitive, which has led to recent developments in scalable Monte Carlo algorithms that have a significantly lower computational cost than standard MCMC. In this article, we focus on a particular class of scalable Monte Carlo algorithms, stochastic gradient Markov chain Monte Carlo (SGMCMC) which utilizes data subsampling techniques to reduce the per-iteration cost of MCMC. We provide an introduction to some popular SGMCMC algorithms and review the supporting theoretical results, as well as comparing the efficiency of SGMCMC algorithms against MCMC on benchmark examples. The supporting R code is available online athttps://github.com/chris-nemeth/sgmcmc-review-paper.},
  keywords = {bayesian inference,Bayesian inference,markov chain monte carlo,Markov chain Monte Carlo,scalable monte carlo,Scalable Monte Carlo,stochastic,Stochastic gradients},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BZACCMPF/Nemeth, Fearnhead - 2020 - Stochastic Gradient Markov Chain Monte Carlo.pdf}
}

@report{Neumann,
  title = {{{THEORY OF GAMES AND ECONOMIC BEHAVIOR}}},
  author = {Neumann, John Yon and Princeton, Oskar Morgenstern},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/F7W7Z6CQ/-348509302.pdf}
}

@article{NewsPersonalizationUsing,
  title = {News Personalization Using {{Bernoulli Matrix Factorization}} for Implicit Data},
  pages = {51},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/4L9YSNJA/News personalization using Bernoulli Matrix Factor.pdf}
}

@article{Ngaffo2020,
  title = {A {{Bayesian Inference Based Hybrid Recommender System}}},
  author = {Ngaffo, Armielle Noulapeu and Ayeb, Walid El and Choukair, Zied},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {101682--101701},
  issn = {21693536},
  doi = {10.1109/ACCESS.2020.2998824},
  abstract = {The large mass of various products/services accessible on the Internet has motivated the development of recommender systems to refine the selection of items aligned with users' expectations. Recommender systems have been developed to tackle the item targeting problem. They are crucial tools that quickly target items fitting users' needs, thus allowing them to easily identify the items that fit their tastes and preferences. Following state-of-the-art methods, a distinction is made between content-based recommender approaches and collaborative filtering-based recommender approaches. Collaborative filtering-based recommender approaches are the most widely adopted methods. They are divided into memory-based methods that show the advantage of their easy-understandability, and model-based methods that are data sparsity resilient and high-accurate. In this paper, we propose a hybrid model-based recommendation approach, a combination of a user-based approach and an item-based approach. Our method estimates the probability with which a user would rate an item. It performs a Bayesian inference of future end-user interests and shows the advantage of the easy-understandability of memory-based methods and the effectiveness of model-based methods. Experiments are conducted on real-world datasets and show that our method outperforms several state-of-the-art recommendation methods regarding the prediction accuracy and the recommendation quality.},
  keywords = {Bayesian inference,collaborative filtering,Dirichlet distribution,maximum a posteriori estimation,recommender system},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/D476QVLH/Ngaffo, Ayeb - 2020 - A Bayesian Inference based Hybrid Recommender System.pdf}
}

@unpublished{Nichol2018,
  title = {On {{First-Order Meta-Learning Algorithms}}},
  author = {Nichol, Alex and Achiam, Joshua and Schulman, John},
  date = {2018-03-08},
  eprint = {1803.02999},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1803.02999},
  urldate = {2018-04-07},
  abstract = {This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution. We analyze a family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only first-order derivatives for the meta-learning updates. This family includes and generalizes first-order MAML, an approximation to MAML obtained by ignoring second-order derivatives. It also includes Reptile, a new algorithm that we introduce here, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task. We expand on the results from Finn et al. showing that first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification, and we provide theoretical analysis aimed at understanding why these algorithms work.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/WWLVFIGT/Nichol, Achiam, Schulman - 2018 - On First-Order Meta-Learning Algorithms.pdf}
}

@unpublished{Nickel2018,
  title = {Learning {{Continuous Hierarchies}} in the {{Lorentz Model}} of {{Hyperbolic Geometry}}},
  author = {Nickel, Maximilian and Kiela, Douwe},
  date = {2018},
  eprint = {1806.03417},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1806.03417},
  abstract = {We are concerned with the discovery of hierarchical relationships from large-scale unstructured similarity scores. For this purpose, we study different models of hyperbolic space and find that learning embeddings in the Lorentz model is substantially more efficient than in the Poincar\textbackslash 'e-ball model. We show that the proposed approach allows us to learn high-quality embeddings of large taxonomies which yield improvements over Poincar\textbackslash 'e embeddings, especially in low dimensions. Lastly, we apply our model to discover hierarchies in two real-world datasets: we show that an embedding in hyperbolic space can reveal important aspects of a company's organizational structure as well as reveal historical relationships between language families.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DRS7W78K/1806.03417.pdf}
}

@article{nielsenScandEvalBenchmarkScandinavian,
  title = {{{ScandEval}}: {{A Benchmark}} for {{Scandinavian Natural Language Processing}}},
  author = {Nielsen, Dan Saattrup},
  abstract = {This paper introduces a Scandinavian benchmarking platform, ScandEval, which can benchmark any pretrained model on four different tasks in the Scandinavian languages. The datasets used in two of the tasks, linguistic acceptability and question answering, are new. We develop and release a Python package and command-line interface, scandeval, which can benchmark any model that has been uploaded to the Hugging Face Hub, with reproducible results. Using this package, we benchmark more than 100 Scandinavian or multilingual models and present the results of these in an interactive online leaderboard1, as well as provide an analysis of the results. The analysis shows that there is substantial cross-lingual transfer among the Mainland Scandinavian languages (Danish, Swedish and Norwegian), with limited cross-lingual transfer between the group of Mainland Scandinavian languages and the group of Insular Scandinavian languages (Icelandic and Faroese). The benchmarking results also show that the investment in language technology in Norway, Sweden and Denmark has led to language models that outperform massively multilingual models such as XLM-RoBERTa and mDeBERTaV3. We release the source code for both the package2 and leaderboard3.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3ZHVLJKI/Nielsen - ScandEval A Benchmark for Scandinavian Natural La.pdf}
}

@online{NoraLLM,
  title = {Nora {{LLM}}},
  url = {https://huggingface.co/norallm}
}

@article{obergruberDevelopmentParaglideControl2016,
  title = {Development of a {{Paraglide Control System}} for {{Automatic Pitch Stabilization}} to {{Increase}} the {{Passive Safety}}},
  author = {Obergruber, Julian and Mehnen, Lars},
  date = {2016},
  journaltitle = {Procedia Engineering},
  volume = {147},
  pages = {26--31},
  publisher = {The Author(s)},
  issn = {18777058},
  doi = {10.1016/j.proeng.2016.06.184},
  url = {http://dx.doi.org/10.1016/j.proeng.2016.06.184},
  abstract = {Paragliders tend to collapse when entering a too low pitch angle, which can lead to dangerous situations. The aim of this project was to develop a system, which is able to stabilize the pitch axis/movement of a paraglider in order to avoid critical angles of attack and resulting front collapses. A 6 DOF sensor measured these critical pitch values during flight, a microcontroller unit activates linear actuators located in the harness of the pilot, and pulls on the D-risers of the paraglider to stabilize the overshooting. This substitutes the active reaction of a pilot and therefore is able to prevent critical flight situations. For evaluation, pitch values with and without stabilization system, during artificially induced overshooting maneuvers, got compared. The evaluation results showed a distinct influence of the system on the pitch behavior of the canopy proving the successful realization of the concept. This project was a feasibility study in terms of electronic stabilization systems for paragliders. It showed such a system is able to increase the safety of paragliders.},
  keywords = {automation,overshoot,paragliding,safety,stabilisation},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TEFVIVFN/Obergruber, Mehnen - 2016 - Development of a paraglide control system for automatic pitch stabilization to increase the passive safety.pdf}
}

@unpublished{ODonoghue2020,
  title = {Making {{Sense}} of {{Reinforcement Learning}} and {{Probabilistic Inference}}},
  author = {O'Donoghue, Brendan and Osband, Ian and Ionescu, Catalin},
  date = {2020},
  eprint = {2001.00805},
  eprinttype = {arXiv},
  pages = {1--16},
  url = {http://arxiv.org/abs/2001.00805},
  abstract = {Reinforcement learning (RL) combines a control problem with statistical estimation: the system dynamics are not known to the agent, but can be learned through experience. A recent line of research casts `RL as inference' and suggests a particular framework to generalize the RL problem as probabilistic inference. Our paper surfaces a key shortcoming in that approach, and clarifies the sense in which RL can be coherently cast as an inference problem. In particular, an RL agent must consider the effects of its actions upon future rewards and observations: the exploration-exploitation tradeoff. In all but the most simple settings, the resulting inference is computationally intractable so that practical RL algorithms must resort to approximation. We demonstrate that the popular `RL as inference' approximation can perform poorly in even very basic problems. However, we show that with a small modification the framework does yield algorithms that can provably perform well, and we show that the resulting algorithm is equivalent to the recently proposed K-learning, which we further connect with Thompson sampling.}
}

@unpublished{Okada2019,
  title = {Variational {{Inference MPC}} for {{Bayesian Model-based Reinforcement Learning}}},
  author = {Okada, Masashi},
  date = {2019},
  eprint = {1907.04202v2},
  eprinttype = {arXiv},
  pages = {1--15},
  issue = {CoRL},
  keywords = {model predictive control,model-based rein-,variational inference},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FJWU2QF8/Okada - 2019 - Variational Inference MPC for Bayesian Model-based Reinforcement Learning.pdf}
}

@online{onalGaussianStochasticWeight2024,
  title = {Gaussian {{Stochastic Weight Averaging}} for {{Bayesian Low-Rank Adaptation}} of {{Large Language Models}}},
  author = {Onal, Emre and Flöge, Klemens and Caldwell, Emma and Sheverdin, Arsen and Fortuin, Vincent},
  date = {2024-07-20},
  eprint = {2405.03425},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2405.03425},
  urldate = {2024-07-24},
  abstract = {Fine-tuned Large Language Models (LLMs) often suffer from overconfidence and poor calibration, particularly when fine-tuned on small datasets. To address these challenges, we propose a simple combination of Low-Rank Adaptation (LoRA) with Gaussian Stochastic Weight Averaging (SWAG), facilitating approximate Bayesian inference in LLMs. Through extensive testing across several Natural Language Processing (NLP) benchmarks, we demonstrate that our straightforward and computationally efficient approach improves model generalization and calibration competitively with comparable, more sophisticated methods for Bayesian inference in LLMs. We further show that our method exhibits greater robustness against distribution shift, as reflected in its improved performance on out-of-distribution tasks.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/PYRRH5P6/Onal et al. - 2024 - Gaussian Stochastic Weight Averaging for Bayesian .pdf}
}

@article{Opper1997,
  title = {A {{Bayesian Approach}} to {{On-line Learning}}},
  author = {Opper, Manfred},
  date = {1997},
  journaltitle = {On-Line Learning in Neural Networks},
  pages = {363--378},
  doi = {10.1017/CBO9780511569920.017},
  url = {https://www.cambridge.org/core/product/identifier/CBO9780511569920A023/type/book_part},
  abstract = {Online learning is discussed from the viewpoint of Bayesian statistical inference. By replacing the true posterior distribution with a simpler parametric distribution, one can define an online algorithm by a repetition of two steps: An update of the approximate posterior, when a new example arrives, and an optimal projection into the parametric family. Choosing this family to be Gaussian, we show that the algorithm achieves asymptotic efficiency. An application to learning in single layer neural networks is given.},
  isbn = {0262194163},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3UIUMHBP/Op98b.pdf}
}

@unpublished{Orabona2017,
  title = {Training {{Deep Networks}} without {{Learning Rates Through Coin Betting}}},
  author = {Orabona, Francesco and Tommasi, Tatiana},
  date = {2017-05-22},
  eprint = {1705.07795},
  eprinttype = {arXiv},
  issn = {1054-139X},
  doi = {10.1016/j.jadohealth.2010.10.003},
  url = {http://arxiv.org/abs/1705.07795},
  urldate = {2017-11-27},
  abstract = {Deep learning methods achieve state-of-the-art performance in many application scenarios. Yet, these methods require a significant amount of hyperparameters tuning in order to achieve the best results. In particular, tuning the learning rates in the stochastic optimization process is still one of the main bottlenecks. In this paper, we propose a new stochastic gradient descent procedure for deep networks that does not require any learning rate setting. Contrary to previous methods, we do not adapt the learning rates nor we make use of the assumed curvature of the objective function. Instead, we reduce the optimization process to a game of betting on a coin and propose a learning-rate-free optimal algorithm for this scenario. Theoretical convergence is proven for convex and quasi-convex functions and empirical evidence shows the advantage of our algorithm over popular stochastic gradient algorithms.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LSKCHMLX/Orabona, Tommasi - 2017 - Training Deep Networks without Learning Rates Through Coin Betting.pdf}
}

@unpublished{Osband,
  title = {Generalization and {{Exploration}} via {{Randomized Value Functions}}},
  author = {Osband, Ian and Roy, Benjamin Van and Wen, Zheng},
  eprint = {1402.0635v3},
  eprinttype = {arXiv},
  abstract = {We propose randomized least-squares value iteration (RLSVI)-a new reinforcement learning algorithm designed to explore and generalize efficiently via linearly parameterized value functions. We explain why versions of least-squares value iteration that use Boltzmann or-greedy exploration can be highly inefficient, and we present computational results that demonstrate dramatic efficiency gains enjoyed by RLSVI. Further, we establish an upper bound on the expected regret of RLSVI that demonstrates near-optimality in a tabula rasa learning context. More broadly, our results suggest that random-ized value functions offer a promising approach to tackling a critical challenge in reinforcement learning: synthesizing efficient exploration and effective generalization.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LIH9CIE9/1714160165.pdf}
}

@article{P-rom,
  title = {Leitevegen 71},
  author = {P-rom, Einebustad},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IEXD3HGA/prospekt leitevegen.pdf}
}

@article{palenikIsoTrotterVisuallyGuided2021,
  title = {{{IsoTrotter}}: {{Visually Guided Empirical Modelling}} of {{Atmospheric Convection}}},
  author = {Pálenik, Juraj and Spengler, Thomas and Hauser, Helwig},
  date = {2021},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {27},
  number = {2},
  eprint = {33079665},
  eprinttype = {pmid},
  pages = {775--784},
  issn = {19410506},
  doi = {10.1109/TVCG.2020.3030389},
  abstract = {Empirical models, fitted to data from observations, are often used in natural sciences to describe physical behaviour and support discoveries. However, with more complex models, the regression of parameters quickly becomes insufficient, requiring a visual parameter space analysis to understand and optimize the models. In this work, we present a design study for building a model describing atmospheric convection. We present a mixed-initiative approach to visually guided modelling, integrating an interactive visual parameter space analysis with partial automatic parameter optimization. Our approach includes a new, semi-automatic technique called IsoTrotting, where we optimize the procedure by navigating along isocontours of the model. We evaluate the model with unique observational data of atmospheric convection based on flight trajectories of paragliders.},
  keywords = {atmospheric convection,scientific modelling,visual parameter space exploration},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/4BE9ISZQ/Pálenik, Spengler, Hauser - 2021 - IsoTrotter Visually Guided Empirical Modelling of Atmospheric Convection.pdf}
}

@online{papamarkouPositionPaperBayesian2024,
  title = {Position {{Paper}}: {{Bayesian Deep Learning}} in the {{Age}} of {{Large-Scale AI}}},
  shorttitle = {Position {{Paper}}},
  author = {Papamarkou, Theodore and Skoularidou, Maria and Palla, Konstantina and Aitchison, Laurence and Arbel, Julyan and Dunson, David and Filippone, Maurizio and Fortuin, Vincent and Hennig, Philipp and Lobato, Jose Miguel Hernandez and Hubin, Aliaksandr and Immer, Alexander and Karaletsos, Theofanis and Khan, Mohammad Emtiyaz and Kristiadi, Agustinus and Li, Yingzhen and Mandt, Stephan and Nemeth, Christopher and Osborne, Michael A. and Rudner, Tim G. J. and Rügamer, David and Teh, Yee Whye and Welling, Max and Wilson, Andrew Gordon and Zhang, Ruqi},
  date = {2024-02-06},
  eprint = {2402.00809},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2402.00809},
  url = {http://arxiv.org/abs/2402.00809},
  urldate = {2024-02-12},
  abstract = {In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZGJSNX4H/2402.00809.pdf}
}

@report{Paquim,
  title = {Learning {{Depth}} from {{Single Monocular Images Using Stereo Supervisory Input}}},
  author = {Paquim, João and De Croon, Guido},
  journaltitle = {Index Terms—Depth Estimation, Conditional Random Field},
  abstract = {Stereo vision systems are often employed in robotics as a means for obstacle avoidance and navigation. These systems have inherent depth-sensing limitations, with significant problems in occluded and untextured regions, leading to sparse depth maps. We propose using a monocular depth estimation algorithm to tackle these problems, in a Self-Supervised Learning (SSL) framework. The algorithm learns online from the sparse depth map generated by a stereo vision system, producing a dense depth map. The algorithm is designed to be computationally efficient, for implementation onboard resource-constrained mobile robots and unmanned aerial vehicles. Within that context, it can be used to provide both reliability against a stereo camera failure, as well as more accurate depth perception, by filling in missing depth information, in occluded and low texture regions. This in turn allows the use of more efficient sparse stereo vision algorithms. We test the algorithm offline on a new, high resolution, stereo dataset, of scenes shot in indoor environments, and processed using both sparse and dense stereo matching algorithms. It is shown that the algorithm's performance doesn't deteriorate, and in fact sometimes improves, when learning only from sparse, high confidence regions rather than from the computationally expensive, dense, occlusion-filled and highly post-processed dense depth maps. This makes the approach very promising for self-supervised learning on autonomous robots.},
  keywords = {Index Terms-Monocular depth estimation,robotics,self-supervised learning,stereo vision},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/HSALGPN9/m-api-0b12c163-b817-e031-0440-6035a6b4911c.pdf}
}

@online{ParameterEfficientFineTuningUsing,
  title = {Parameter-{{Efficient Fine-Tuning}} Using 🤗 {{PEFT}}},
  url = {https://huggingface.co/blog/peft},
  urldate = {2023-02-15},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/6275CVUE/peft.html}
}

@article{Park2013,
  title = {Hierarchical {{Bayesian}} Matrix Factorization with Side Information},
  author = {Park, Sunho and Kim, Yong Deok and Choi, Seungjin},
  date = {2013},
  journaltitle = {IJCAI International Joint Conference on Artificial Intelligence},
  pages = {1593--1599},
  issn = {10450823},
  abstract = {Bayesian treatment of matrix factorization has been successfully applied to the problem of collaborative prediction, where unknown ratings are determined by the predictive distribution, inferring posterior distributions over user and item factor matrices that are used to approximate the user-item matrix as their product. In practice, however, Bayesian matrix factorization suffers from cold-start problems, where inferences are required for users or items about which a sufficient number of ratings are not gathered. In this paper we present a method for Bayesian matrix factorization with side information, to handle cold-start problems. To this end, we place Gaussian-Wishart priors on mean vectors and precision matrices of Gaussian user and item factor matrices, such that mean of each prior distribution is regressed on corresponding side information. We develop variational inference algorithms to approximately compute posterior distributions over user and item factor matrices. In addition, we provide Bayesian Cramér-Rao Bound for our model, showing that the hierarchical Bayesian matrix factorization with side information improves the reconstruction over the standard Bayesian matrix factorization where the side information is not used. Experiments on MovieLens data demonstrate the useful behavior of our model in the case of cold-start problems.},
  isbn = {9781577356332},
  keywords = {Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/HLKSWF8R/Park, Kim, Choi - 2013 - Hierarchical Bayesian matrix factorization with side information.pdf}
}

@online{parkFinetuningPretrainedTransformers2021,
  title = {Finetuning {{Pretrained Transformers}} into {{Variational Autoencoders}}},
  author = {Park, Seongmin and Lee, Jihwa},
  date = {2021-11-23},
  eprint = {2108.02446},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2108.02446},
  urldate = {2023-03-01},
  abstract = {Text variational autoencoders (VAEs) are notorious for posterior collapse, a phenomenon where the model's decoder learns to ignore signals from the encoder. Because posterior collapse is known to be exacerbated by expressive decoders, Transformers have seen limited adoption as components of text VAEs. Existing studies that incorporate Transformers into text VAEs (Li et al., 2020; Fang et al., 2021) mitigate posterior collapse using massive pretraining, a technique unavailable to most of the research community without extensive computing resources. We present a simple two-phase training scheme to convert a sequence-to-sequence Transformer into a VAE with just finetuning. The resulting language model is competitive with massively pretrained Transformer-based VAEs in some internal metrics while falling short on others. To facilitate training we comprehensively explore the impact of common posterior collapse alleviation techniques in the literature. We release our code for reproducability.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LMYLXULY/Park and Lee - 2021 - Finetuning Pretrained Transformers into Variationa.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/XG6HSP8V/2108.html}
}

@article{paszkePyTorchImperativeStyle2019,
  title = {{{PyTorch}}: {{An}} Imperative Style, High-Performance Deep Learning Library},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  date = {2019},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {32},
  eprint = {1912.01703},
  eprinttype = {arXiv},
  issn = {10495258},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
  issue = {NeurIPS},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/72P258DD/Paszke et al. - 2019 - PyTorch An imperative style, high-performance deep learning library.pdf}
}

@online{PathAutonomousMachine,
  title = {A {{Path Towards Autonomous Machine Intelligence}}},
  url = {https://openreview.net/forum?id=BZ5a1r-kVsf},
  urldate = {2023-02-06},
  abstract = {How could machines learn as efficiently as humans and animals?  How could machines learn to reason and plan?  How could machines learn representations of percepts and action plans at multiple...},
  langid = {english},
  organization = {OpenReview},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AGI23FJU/forum.html}
}

@article{Pearl2010,
  title = {The {{International Journal}} of {{Biostatistics An Introduction}} to {{Causal Inference An Introduction}} to {{Causal Inference}} ∗},
  author = {Pearl, Judea},
  date = {2010},
  journaltitle = {The international journal of biostatistics},
  volume = {6},
  number = {2},
  eprint = {20305706},
  eprinttype = {pmid},
  pages = {Article 7},
  issn = {1557-4679},
  doi = {10.2202/1557-4679.1203},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2836213&tool=pmcentrez&rendertype=abstract},
  abstract = {This paper summarizes recent advances in causal inference and underscores the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underlie all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: those about (1) the effects of potential interventions, (2) probabilities of counterfactuals, and (3) direct and indirect effects (also known as "mediation"). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both. The tools are demonstrated in the analyses of mediation, causes of effects, and probabilities of causation.},
  keywords = {Algorithms,Causality,Confounding Factors (Epidemiology),Humans,Models,Research Design,Statistical},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/448AVSXQ/Pearl - 2010 - An Introduction to Causal Inference.pdf}
}

@article{pengVOICECRAFTZeroShotSpeech,
  title = {{{VOICECRAFT}}: {{Zero-Shot Speech Editing}} and {{Text-to-Speech}} in the {{Wild}}},
  author = {Peng, Puyuan and Huang, Po-Yao and Li, Daniel and Mohamed, Abdelrahman and Harwath, David},
  abstract = {We introduce VOICECRAFT, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts1. VOICECRAFT employs a Transformer decoder architecture and introduces a token rearrangement procedure that combines causal masking and delayed stacking to enable generation within an existing sequence. On speech editing tasks, VOICECRAFT produces edited speech that is nearly indistinguishable from unedited recordings in terms of naturalness, as evaluated by humans; for zero-shot TTS, our model outperforms prior SotA models including VALLE and the popular commercial model XTTS v2. Crucially, the models are evaluated on challenging and realistic datasets, that consist of diverse accents, speaking styles, recording conditions, and background noise and music, and our model performs consistently well compared to other models and real recordings. In particular, for speech editing evaluation, we introduce a high quality, challenging, and realistic dataset named REALEDIT. We encourage readers to listen to the demos at https: //jasonppy.github.io/VoiceCraft\_web.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/PKGGF746/Peng et al. - VOICECRAFT Zero-Shot Speech Editing and Text-to-S.pdf}
}

@article{perezmaureraContentWiseImpressionsIndustrial2020,
  title = {{{ContentWise Impressions}}: {{An Industrial Dataset}} with {{Impressions Included}}},
  author = {Pérez Maurera, Fernando B. and Ferrari Dacrema, Maurizio and Saule, Lorenzo and Scriminaci, Mario and Cremonesi, Paolo},
  date = {2020},
  journaltitle = {International Conference on Information and Knowledge Management, Proceedings},
  eprint = {2008.01212},
  eprinttype = {arXiv},
  pages = {3093--3100},
  doi = {10.1145/3340531.3412774},
  abstract = {In this article, we introduce the \textbackslash dataset dataset, a collection of implicit interactions and impressions of movies and TV series from an Over-The-Top media service, which delivers its media contents over the Internet. The dataset is distinguished from other already available multimedia recommendation datasets by the availability of impressions, \textbackslash idest the recommendations shown to the user, its size, and by being open-source. We describe the data collection process, the preprocessing applied, its characteristics, and statistics when compared to other commonly used datasets. We also highlight several possible use cases and research questions that can benefit from the availability of user impressions in an open-source dataset. Furthermore, we release software tools to load and split the data, as well as examples of how to use both user interactions and impressions in several common recommendation algorithms.},
  isbn = {9781450368599},
  keywords = {collaborative filtering,dataset,implicit feedback,impressions,open source},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TLB5QW37/Pérez Maurera et al. - 2020 - ContentWise Impressions An Industrial Dataset with Impressions Included.pdf}
}

@report{Pike-Burke2018,
  title = {Recovering {{Bandits}}},
  author = {Pike-Burke, Ciara and Grünewälder, Steffen},
  date = {2018},
  journaltitle = {European Workshop on Reinforcement Learning},
  volume = {14},
  abstract = {We study a variant of the non-stationary stochastic K-armed bandit problem which we call recovering bandits. In this problem, the expected reward of each arm changes depending on the time since the arm was last played according to some unknown recovery function. This problem arises in many settings, for example in product recommendation when after a user makes a purchase, we wish to wait before suggesting the same product again. In the recovering bandits problem, the reward at time t depends on all previous actions, so finding the optimal sequence of T actions would be infeasible. In this paper, we discuss alternative strategies which perform well theoretically and experimentally. Specifically, we assume the recovery functions take the form of a Gaussian process and present UCB and Thompson Sampling algorithms which achieve high instantaneous reward (reward from the played arm) and lookahead reward (total reward from the next d arms).},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/KERNI8HM/document.pdf}
}

@unpublished{Pinder2020,
  title = {Stein {{Variational Gaussian Processes}}},
  author = {Pinder, Thomas and Nemeth, Christopher and Leslie, David},
  date = {2020},
  eprint = {2009.12141},
  eprinttype = {arXiv},
  pages = {1--25},
  url = {http://arxiv.org/abs/2009.12141},
  abstract = {We show how to use Stein variational gradient descent (SVGD) to carry out inference in Gaussian process (GP) models with non-Gaussian likelihoods and large data volumes. Markov chain Monte Carlo (MCMC) is extremely computationally intensive for these situations, but the parametric assumptions required for efficient variational inference (VI) result in incorrect inference when they encounter the multi-modal posterior distributions that are common for such models. SVGD provides a non-parametric alternative to variational inference which is substantially faster than MCMC but unhindered by parametric assumptions. We prove that for GP models with Lipschitz gradients the SVGD algorithm monotonically decreases the Kullback-Leibler divergence from the sampling distribution to the true posterior. Our method is demonstrated on benchmark problems in both regression and classification, and a real air quality example with 11440 spatiotemporal observations, showing substantial performance improvements over MCMC and VI.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/MVXPRRYD/Pinder, Nemeth, Leslie - 2020 - Stein Variational Gaussian Processes.pdf}
}

@article{Polson2017,
  title = {Deep Learning: {{A Bayesian}} Perspective},
  author = {Polson, Nicholas G. and Sokolov, Vadim},
  date = {2017},
  journaltitle = {Bayesian Analysis},
  volume = {12},
  number = {4},
  eprint = {1706.00473},
  eprinttype = {arXiv},
  pages = {1275--1304},
  issn = {19316690},
  doi = {10.1214/17-BA1082},
  abstract = {Deep learning is a form of machine learning for nonlinear high dimensional pattern matching and prediction. By taking a Bayesian probabilistic perspective, we provide a number of insights into more efficient algorithms for optimisation and hyper-parameter tuning. Traditional high-dimensional data reduction techniques, such as principal component analysis (PCA), partial least squares (PLS), reduced rank regression (RRR), projection pursuit regression (PPR) are all shown to be shallow learners. Their deep learning counterparts exploit multiple deep layers of data reduction which provide predictive performance gains. Stochastic gradient descent (SGD) training optimisation and Dropout (DO) regularization provide estimation and variable selection. Bayesian regularization is central to finding weights and connections in networks to optimize the predictive bias-variance trade-off. To illustrate our methodology, we provide an analysis of international bookings on Airbnb. Finally, we conclude with directions for future research.},
  keywords = {Artificial Intelligence,Bayesian hierarchical models,Deep learning,LSTM models,Machine learning,Pattern matching,Prediction,TensorFlow},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FDVVXJ7X/Polson, Sokolov - 2017 - Deep learning A Bayesian perspective.pdf}
}

@article{Porteous2010,
  title = {Bayesian Matrix Factorization with Side Information and Dirichlet Process Mixtures},
  author = {Porteous, Ian and Asuncion, Arthur and Welling, Max},
  date = {2010},
  journaltitle = {Proceedings of the National Conference on Artificial Intelligence},
  volume = {1},
  pages = {563--568},
  abstract = {Matrix factorization is a fundamental technique in machine learning that is applicable to collaborative filtering, information retrieval and many other areas. In collaborative filtering and many other tasks, the objective is to fill in missing elements of a sparse data matrix. One of the biggest challenges in this case is filling in a column or row of the matrix with very few observations. In this paper we introduce a Bayesian matrix factorization model that performs regression against side information known about the data in addition to the observations. The side information helps by adding observed entries to the factored matrices. We also introduce a nonpara-metric mixture model for the prior of the rows and columns of the factored matrices that gives a different regularization for each latent class. Besides providing a richer prior, the posterior distribution of mixture assignments reveals the latent classes. Using Gibbs sampling for inference, we apply our model to the Netflix Prize problem of predicting movie ratings given an incomplete user-movie ratings matrix. In-corporating rating information with gathered metadata infor-mation, our Bayesian approach outperforms other matrix fac-torization techniques even when using fewer dimensions. Copyright © 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
  isbn = {9781577354642},
  keywords = {Technical Papers -- Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FQLUTWA3/Porteous, Asuncion, Welling - 2010 - Bayesian matrix factorization with side information and dirichlet process mixtures.pdf}
}

@article{pradoAdvancesFinancialMachine2018,
  title = {Advances in {{Financial Machine Learning}}},
  author = {Prado, Marcos Lopez},
  date = {2018},
  pages = {395},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TJBP52SE/Bailey - 2018 - Advances in Financial Machine Learning.pdf}
}

@article{PublicationAgreement,
  title = {Publication {{Agreement}}},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/M24QE8NU/Publication Agreement.pdf}
}

@article{puzichaLatentClassModels2014,
  title = {Latent {{Class Models}} for {{Collaborative Filtering}} . {{L}} a t e n t {{Class M}} o d e l s for {{C}} o l l a b o r a t i v e {{F}} i l t e r i n g {{Thomas Hofmann}} and {{International CS Institute Institut}} Fur {{Informatik}}},
  author = {Puzicha, Jan and Gmbh, Leanix},
  date = {2014},
  issue = {March},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/RD5G58QD/Puzicha, Gmbh - 2014 - Latent Class Models for Collaborative Filtering . L a t e n t Class M o d e l s for C o l l a b o r a t i v e F i.pdf}
}

@report{pyysaloFirstLanguageModels2024,
  title = {First Language Models Trained},
  author = {Pyysalo, Sampo and Luukonen, Risto and Kutuzov, Andrey and Samuel, David},
  date = {2024-02-29},
  abstract = {This report provides a description of deliverable D4.1 – the initial release of language models created in the HPLT project. The release includes encoder-only models for 75 languages and and decoderonly models for languages selected for inclusion in initial model training. Evaluation of the models demonstrates advances over previously existing models for several languages and serves also to validate the quality of the HPLT data},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/RYEK4CZS/HPLT_D4_1___First_language_models_trained.pdf}
}

@report{Quadrana2018,
  title = {Sequence-{{Aware Recommender Systems}}},
  author = {Quadrana, Massimo and Cremonesi, Paolo and Jannach, Dietmar},
  date = {2018},
  eprint = {1802.08452},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1802.08452},
  urldate = {2018-12-16},
  abstract = {Recommender systems are one of the most successful applications of data mining and machine learning technology in practice. Academic research in the field is historically often based on the matrix completion problem formulation, where for each user-item-pair only one interaction (e.g., a rating) is considered. In many application domains, however, multiple user-item interactions of different types can be recorded over time. And, a number of recent works have shown that this information can be used to build richer individual user models and to discover additional behavioral patterns that can be leveraged in the recommendation process. In this work we review existing works that consider information from such sequentially-ordered user- item interaction logs in the recommendation process. Based on this review, we propose a categorization of the corresponding recommendation tasks and goals, summarize existing algorithmic solutions, discuss methodological approaches when benchmarking what we call sequence-aware recommender systems, and outline open challenges in the area.},
  keywords = {• Computing methodologies → Learning from implicit,Additional Key Words and Phrases: sequence sessio,CCS Concepts: • Information systems → Recommender,Collaborative filtering},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BSYKLL8N/full-text.pdf}
}

@article{Rabinowitz,
  title = {Machine {{Theory}} of {{Mind}}},
  author = {Rabinowitz, Neil C and Perbet, Frank and Song, H Francis and Zhang, Chiyuan and Eslami, Ali and Botvinick, Matthew},
  abstract = {Theory of mind (ToM; Premack \& Woodruff, 1978) broadly refers to humans' ability to rep-resent the mental states of others, including their desires, beliefs, and intentions. We propose to train a machine to build such models too. We de-sign a Theory of Mind neural network – a ToM-net – which uses meta-learning to build models of the agents it encounters, from observations of their behaviour alone. Through this process, it acquires a strong prior model for agents' be-haviour, as well as the ability to bootstrap to richer predictions about agents' characteristics and mental states using only a small number of behavioural observations. We apply the ToM-net to agents behaving in simple gridworld en-vironments, showing that it learns to model ran-dom, algorithmic, and deep reinforcement learn-ing agents from varied populations, and that it passes classic ToM tasks such as the " Sally-Anne " test (Wimmer \& Perner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold false beliefs about the world. We argue that this system – which autonomously learns how to model other agents in its world – is an impor-tant step forward for developing multi-agent AI systems, for building intermediating technology for machine-human interaction, and for advanc-ing the progress on interpretable AI.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/QHCJTTK9/Rabinowitz et al. - Unknown - Machine Theory of Mind.pdf}
}

@article{RaceAILabs,
  entrysubtype = {magazine},
  title = {The Race of the {{AI}} Labs Heats Up},
  journaltitle = {The Economist},
  issn = {0013-0613},
  url = {https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up?giftId=befa6230-71a8-4b3f-9cb4-09be6c1763c6},
  urldate = {2023-02-01},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZMQ2LM7P/the-race-of-the-ai-labs-heats-up.html}
}

@article{radfordLanguageModelsAre,
  title = {Language {{Models}} Are {{Unsupervised Multitask Learners}}},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GF8TRU42/Radford et al. - Language Models are Unsupervised Multitask Learner.pdf}
}

@online{rafailovDirectPreferenceOptimization2023,
  title = {Direct {{Preference Optimization}}: {{Your Language Model}} Is {{Secretly}} a {{Reward Model}}},
  shorttitle = {Direct {{Preference Optimization}}},
  author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D. and Finn, Chelsea},
  date = {2023-12-13},
  eprint = {2305.18290},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.18290},
  urldate = {2023-12-19},
  abstract = {While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper we introduce a new parameterization of the reward model in RLHF that enables extraction of the corresponding optimal policy in closed form, allowing us to solve the standard RLHF problem with only a simple classification loss. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for sampling from the LM during fine-tuning or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of generations, and matches or improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/TWLXWU3H/Rafailov et al. - 2023 - Direct Preference Optimization Your Language Mode.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/4BY5D3PV/2305.html}
}

@article{Raffel2019,
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author = {Raffel, Colin and Roberts, Adam and Liu, Peter J and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Peter, Wei Li and Liu, J.},
  date = {2020},
  journaltitle = {Journal of Machine Learning Research},
  volume = {21},
  number = {140},
  eprint = {1910.10683},
  eprinttype = {arXiv},
  pages = {1--67},
  issn = {23318422},
  url = {http://jmlr.org/papers/v21/20-074.html},
  abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.1.},
  keywords = {attention-,multi-task learning,natural language processing,transfer learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/PXIK6ZCA/Transformer et al. - 2019 - Exploring the limits of transfer learning with a unified text-to-text transformer.pdf}
}

@online{raffelExploringLimitsTransfer2023,
  title = {Exploring the {{Limits}} of {{Transfer Learning}} with a {{Unified Text-to-Text Transformer}}},
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  date = {2023-09-19},
  eprint = {1910.10683},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1910.10683},
  urldate = {2024-03-30},
  abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/689NUIAF/Raffel et al. - 2023 - Exploring the Limits of Transfer Learning with a U.pdf}
}

@article{rakeshEfficacyBayesianNeural2021,
  title = {Efficacy of Bayesian Neural Networks in Active Learning},
  author = {Rakesh, Vineeth and Jain, Swayambhoo},
  date = {2021},
  journaltitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
  eprint = {2104.00896},
  eprinttype = {arXiv},
  pages = {2601--2609},
  issn = {21607516},
  doi = {10.1109/CVPRW53098.2021.00294},
  abstract = {Obtaining labeled data for machine learning tasks can be prohibitively expensive. Active learning mitigates this issue by exploring the unlabeled data space and prioritizing the selection of data that can best improve the model performance. A common approach to active learning is to pick a small sample of data for which the model is most uncertain. In this paper, we explore the efficacy of Bayesian neural networks for active learning, which naturally models uncertainty by learning distribution over the weights of neural networks. By performing a comprehensive set of experiments, we show that Bayesian neural networks are more efficient than ensemble based techniques in capturing uncertainty. Our findings also reveal some key drawbacks of the ensemble techniques, which was recently shown to be more effective than Monte Carlo dropouts.},
  isbn = {9781665448994}
}

@article{Ramachandran2007,
  title = {Bayesian Inverse Reinforcement Learning},
  author = {Ramachandran, Deepak and Amir, Eyal},
  date = {2007},
  journaltitle = {IJCAI International Joint Conference on Artificial Intelligence},
  pages = {2586--2591},
  issn = {10450823},
  abstract = {Inverse Reinforcement Learning (IRL) is the problem of learning the reward function underlying a Markov Decision Process given the dynamics of the system and the behaviour of an expert. IRL is motivated by situations where knowledge of the rewards is a goal by itself (as in preference elicitation) and by the task of apprenticeship learning (learning policies from an expert). In this paper we show how to combine prior knowledge and evidence from the expert's actions to derive a probability distribution over the space of reward functions. We present efficient algorithms that find solutions for the reward learning and apprenticeship learning tasks that generalize well over these distributions. Experimental results show strong improvement for our methods over previous heuristic-based approaches.},
  keywords = {Markov-decision processes,reinforcement learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZTXFNYZV/Ramachandran, Amir - 2007 - Bayesian inverse reinforcement learning.pdf}
}

@article{Ranganath2014,
  title = {Black Box Variational Inference},
  author = {Ranganath, Rajesh and Gerrish, Sean and Blei, David M.},
  date = {2014},
  journaltitle = {Journal of Machine Learning Research},
  volume = {33},
  eprint = {1401.0118},
  eprinttype = {arXiv},
  pages = {814--822},
  issn = {15337928},
  abstract = {Variational inference has become a widely used method to approximate posteriors in complex latent variables models. However, deriving a variational inference algorithm generally requires significant model-specific analysis. These efforts can hinder and deter us from quickly developing and exploring a variety of models for a problem at hand. In this paper, we present a "black box" variational inference algorithm, one that can be quickly applied to many models with little additional derivation. Our method is based on a stochastic optimization of the variational objective where the noisy gradient is computed from Monte Carlo samples from the variational distribution. We develop a number of methods to reduce the variance of the gradient, always maintaining the criterion that we want to avoid difficult model-based derivations. We evaluate our method against the corresponding black box sampling based methods. We find that our method reaches better predictive likelihoods much faster than sampling methods. Finally, we demonstrate that Black Box Variational Inference lets us easily explore a wide space of models by quickly constructing and evaluating several models of longitudinal healthcare data.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DEIEAF3S/Ranganath, Gerrish, Blei - 2014 - Black box variational inference.pdf}
}

@unpublished{Razavi2019,
  title = {Generating {{Diverse High-Fidelity Images}} with {{VQ-VAE-2}}},
  author = {Razavi, Ali and family=Oord, given=Aaron, prefix=van den, useprefix=false and Vinyals, Oriol},
  date = {2019},
  eprint = {1906.00446},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1906.00446},
  abstract = {We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before. We use simple feed-forward encoder and decoder networks, making our model an attractive candidate for applications where the encoding and/or decoding speed is critical. Additionally, VQ-VAE requires sampling an autoregressive model only in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN's known shortcomings such as mode collapse and lack of diversity.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/CH865FXS/Razavi, Oord, Vinyals - 2019 - Generating Diverse High-Fidelity Images with VQ-VAE-2.pdf}
}

@report{RecommendationsReinforcementLearning2018,
  title = {Recommendations as {{Reinforcement Learning}}},
  date = {2018},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/F77N295G/TDT4501 - Olav Nymoen.pdf}
}

@inproceedings{Redmon2016,
  title = {{{YOLO9000}}: {{Better}}, Faster, Stronger},
  booktitle = {Proceedings - 30th {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}, {{CVPR}} 2017},
  author = {Redmon, Joseph and Farhadi, Ali},
  date = {2017-12-25},
  volume = {2017-Janua},
  eprint = {1612.08242},
  eprinttype = {arXiv},
  pages = {6517--6525},
  doi = {10.1109/CVPR.2017.690},
  url = {http://arxiv.org/abs/1612.08242},
  urldate = {2017-08-21},
  abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
  isbn = {978-1-5386-0457-1},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/X3XEW4RL/Redmon, Farhadi - 2016 - YOLO9000 Better, Faster, Stronger.pdf}
}

@book{rekabsazTripClickLogFiles2021,
  title = {{{TripClick}}: {{The Log Files}} of a {{Large Health Web Search Engine}}},
  author = {Rekabsaz, Navid and Lesota, Oleg and Schedl, Markus and Brassey, Jon and Eickhoff, Carsten},
  date = {2021},
  journaltitle = {Montreal '21: ACM Special Interest Group on Information Retrieval, July 11, 2021, Montreal, Canada},
  volume = {1},
  number = {1},
  eprint = {2103.07901},
  eprinttype = {arXiv},
  publisher = {Association for Computing Machinery},
  url = {http://arxiv.org/abs/2103.07901},
  abstract = {Click logs are valuable resources for a variety of information retrieval (IR) tasks. This includes query understanding/analysis, as well as learning effective IR models particularly when the models require large amounts of training data. We release a large-scale domain-specific dataset of click logs, obtained from user interactions of the Trip Database health web search engine. Our click log dataset comprises approximately 5.2 million user interactions collected between 2013 and 2020. We use this dataset to create a standard IR evaluation benchmark -- TripClick -- with around 700,000 unique free-text queries and 1.3 million pairs of query-document relevance signals, whose relevance is estimated by two click-through models. As such, the collection is one of the few datasets offering the necessary data richness and scale to train neural IR models with a large amount of parameters, and notably the first in the health domain. Using TripClick, we conduct experiments to evaluate a variety of IR models, showing the benefits of exploiting this data to train neural architectures. In particular, the evaluation results show that the best performing neural IR model significantly improves the performance by a large margin relative to classical IR models, especially for more frequent queries.},
  keywords = {acm reference format,click logs,click logs collection health information retriev,collection,health information retrieval,medical informa-,neural ranking models,tion retrieval},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/KI9K5M2X/Rekabsaz et al. - 2021 - TripClick The Log Files of a Large Health Web Search Engine.pdf}
}

@article{Ren2017,
  title = {Faster {{R-CNN}}: {{Towards Real-Time Object Detection}} with {{Region Proposal Networks}}},
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  date = {2017},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {39},
  number = {6},
  eprint = {27295650},
  eprinttype = {pmid},
  pages = {1137--1149},
  issn = {01628828},
  doi = {10.1109/TPAMI.2016.2577031},
  abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [7] and Fast R-CNN [5] have reduced the running time of these detection networks, exposing region pro-posal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. RPNs are trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. With a simple alternating optimization, RPN and Fast R-CNN can be trained to share convolu-tional features. For the very deep VGG-16 model [18], our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007 (73.2\% mAP) and 2012 (70.4\% mAP) using 300 proposals per image. The code will be released.},
  isbn = {0162-8828 VO - PP},
  keywords = {convolutional neural network,Object detection,region proposal},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/J8J5492Z/Ren et al. - 2017 - Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks.pdf}
}

@inproceedings{Rendle2009,
  title = {{{BPR}}: {{Bayesian Personalized Ranking}} from {{Implicit Feedback}}},
  booktitle = {Proceedings of the {{Twenty-Fifth Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Rendle, Steffen and Freudenthaler, Christoph and Gantner, Zeno and Schmidt-Thieme, Lars},
  date = {2009},
  pages = {452--461},
  url = {https://dl.acm.org/doi/10.5555/1795114.1795167},
  urldate = {2018-11-12},
  abstract = {Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive k-nearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of per-sonalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YZKQ7RMD/m-api-74ee8b03-6dcf-484d-7c74-643ddcd50620.pdf}
}

@article{Rendle2010,
  title = {Factorization Machines},
  author = {Rendle, Steffen},
  date = {2010},
  journaltitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
  eprint = {1530748},
  eprinttype = {pmid},
  pages = {995--1000},
  issn = {15504786},
  doi = {10.1109/ICDM.2010.127},
  abstract = {In this paper, we introduce Factorization Machines (FM) which are a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models. Like SVMs, FMs are a general predictor working with any real valued feature vector. In contrast to SVMs, FMs model all interactions between variables using factorized parameters. Thus they are able to estimate interactions even in problems with huge sparsity (like recommender systems) where SVMs fail. We show that the model equation of FMs can be calculated in linear time and thus FMs can be optimized directly. So unlike nonlinear SVMs, a transformation in the dual form is not necessary and the model parameters can be estimated directly without the need of any support vector in the solution. We show the relationship to SVMs and the advantages of FMs for parameter estimation in sparse settings. On the other hand there are many different factorization models like matrix factorization, parallel factor analysis or specialized models like SVD++, PITF or FPMC. The drawback of these models is that they are not applicable for general prediction tasks but work only with special input data. Furthermore their model equations and optimization algorithms are derived individually for each task. We show that FMs can mimic these models just by specifying the input data (i.e. the feature vectors). This makes FMs easily applicable even for users without expert knowledge in factorization models.},
  isbn = {9780769542560},
  keywords = {Factorization machine,Sparse data,Support vector machine,Tensor factorization},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/NLR25HGS/Rendle - 2010 - Factorization machines.pdf}
}

@article{Resources2016,
  title = {{{TOWARDS AN IMPROVED EUROPEAN AUXILIARY MATRIX FOR ASSESSING}}},
  author = {Resources, Norwegian Water and Directorate, Energy and Mitterer, Christoph},
  date = {2016},
  pages = {1--4},
  issue = {October},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SFYELASP/Resources, Directorate, Mitterer - 2016 - TOWARDS AN IMPROVED EUROPEAN AUXILIARY MATRIX FOR ASSESSING.pdf}
}

@article{Rezende2016,
  title = {One-{{Shot Generalization}} in {{Deep Generative Models}}},
  author = {Rezende, Danilo and {Shakir} and Danihelka, Ivo and Gregor, Karol and Wierstra, Daan},
  date = {2016},
  journaltitle = {Proceedings of The 33rd International Conference on Machine Learning},
  volume = {48},
  number = {5},
  eprint = {1603.05106},
  eprinttype = {arXiv},
  pages = {1521--1529},
  url = {http://proceedings.mlr.press/v48/rezende16.html},
  abstract = {Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples—having seen new examples just once—providing an important class of general-purpose models for one-shot machine learning.},
  isbn = {9781510829008},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AIJVMZDN/Rezende et al. - 2016 - One-Shot Generalization in Deep Generative Models.pdf}
}

@online{ribeiroAmplificationParadoxRecommender2023,
  title = {The {{Amplification Paradox}} in {{Recommender Systems}}},
  author = {Ribeiro, Manoel Horta and Veselovsky, Veniamin and West, Robert},
  date = {2023-02-22},
  eprint = {2302.11225},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.11225},
  url = {http://arxiv.org/abs/2302.11225},
  urldate = {2023-02-28},
  abstract = {Automated audits of recommender systems found that blindly following recommendations leads users to increasingly partisan, conspiratorial, or false content. At the same time, studies using real user traces suggest that recommender systems are not the primary driver of attention toward extreme content; on the contrary, such content is mostly reached through other means, e.g., other websites. In this paper, we explain the following apparent paradox: if the recommendation algorithm favors extreme content, why is it not driving its consumption? With a simple agent-based model where users attribute different utilities to items in the recommender system, we show that the collaborative-filtering nature of recommender systems and the nicheness of extreme content can resolve the apparent paradox: although blindly following recommendations would indeed lead users to niche content, users rarely consume niche content when given the option because it is of low utility to them, which can lead the recommender system to deamplify such content. Our results call for a nuanced interpretation of ``algorithmic amplification'' and highlight the importance of modeling the utility of content to users when auditing recommender systems.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/R7A7LDAF/Ribeiro et al. - 2023 - The Amplification Paradox in Recommender Systems.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/94B4AC89/2302.html}
}

@article{Rice2014,
  title = {Bayesian {{Statistics}} (a Very Brief Introduction)},
  author = {Rice, Ken},
  date = {2014},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Q7TBQEX7/Rice - 2014 - Bayesian Statistics (a very brief introduction).pdf}
}

@misc{Riedmiller,
  title = {Playing {{Atari}} with {{Deep Reinforcement Learning}}},
  author = {Riedmiller, Volodymyr Mnih Koray Kavukcuoglu David Silver Alex Graves Ioannis Antonoglou DaanWierstra Martin},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/S35ICY3J/Riedmiller - Unknown - Playing Atari with Deep Reinforcement Learning.pdf}
}

@article{Ritter2018,
  title = {Online Structured Laplace Approximations for Overcoming Catastrophic Forgetting},
  author = {Ritter, Hippolyt and Botev, Aleksandar and Barber, David},
  date = {2018},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {2018-Decem},
  eprint = {1805.07810},
  eprinttype = {arXiv},
  pages = {3738--3748},
  issn = {10495258},
  abstract = {We introduce the Kronecker factored online Laplace approximation for overcoming catastrophic forgetting in neural networks. The method is grounded in a Bayesian online learning framework, where we recursively approximate the posterior after every task with a Gaussian, leading to a quadratic penalty on changes to the weights. The Laplace approximation requires calculating the Hessian around a mode, which is typically intractable for modern architectures. In order to make our method scalable, we leverage recent block-diagonal Kronecker factored approximations to the curvature. Our algorithm achieves over 90\% test accuracy across a sequence of 50 instantiations of the permuted MNIST dataset, substantially outperforming related methods for overcoming catastrophic forgetting.},
  issue = {NeurIPS},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Q8GG343U/Ritter, Botev, Barber - 2018 - Online structured laplace approximations for overcoming catastrophic forgetting.pdf}
}

@article{robertsExponentialConvergenceLangevin1996,
  title = {Exponential Convergence of {{Langevin}} Distributions and Their Discrete Approximations},
  author = {Roberts, Gareth O and Tweedie, Richard L},
  date = {1996},
  journaltitle = {Bernoulli},
  volume = {2},
  number = {4},
  pages = {341--363},
  keywords = {1,a real explosion in,chain monte carlo methods,geometric convergence of markov,hastings and metropolis,markov chain monte carlo,methods,the langevin method for,the use of the,there has recently been},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/REBR4UG6/Roberts, Tweedie - 1996 - Exponential convergence of Langevin distributions and their discrete approximations.pdf}
}

@online{robertsScalingModelsData2022,
  title = {Scaling {{Up Models}} and {{Data}} with \$\textbackslash texttt\{t5x\}\$ and \$\textbackslash texttt\{seqio\}\$},
  author = {Roberts, Adam and Chung, Hyung Won and Levskaya, Anselm and Mishra, Gaurav and Bradbury, James and Andor, Daniel and Narang, Sharan and Lester, Brian and Gaffney, Colin and Mohiuddin, Afroz and Hawthorne, Curtis and Lewkowycz, Aitor and Salcianu, Alex and family=Zee, given=Marc, prefix=van, useprefix=true and Austin, Jacob and Goodman, Sebastian and Soares, Livio Baldini and Hu, Haitang and Tsvyashchenko, Sasha and Chowdhery, Aakanksha and Bastings, Jasmijn and Bulian, Jannis and Garcia, Xavier and Ni, Jianmo and Chen, Andrew and Kenealy, Kathleen and Clark, Jonathan H. and Lee, Stephan and Garrette, Dan and Lee-Thorp, James and Raffel, Colin and Shazeer, Noam and Ritter, Marvin and Bosma, Maarten and Passos, Alexandre and Maitin-Shepard, Jeremy and Fiedel, Noah and Omernick, Mark and Saeta, Brennan and Sepassi, Ryan and Spiridonov, Alexander and Newlan, Joshua and Gesmundo, Andrea},
  date = {2022-03-31},
  eprint = {2203.17189},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2203.17189},
  url = {http://arxiv.org/abs/2203.17189},
  urldate = {2023-02-27},
  abstract = {Recent neural network-based language models have benefited greatly from scaling up the size of training datasets and the number of parameters in the models themselves. Scaling can be complicated due to various factors including the need to distribute computation on supercomputer clusters (e.g., TPUs), prevent bottlenecks when infeeding data, and ensure reproducible results. In this work, we present two software libraries that ease these issues: \$\textbackslash texttt\{t5x\}\$ simplifies the process of building and training large language models at scale while maintaining ease of use, and \$\textbackslash texttt\{seqio\}\$ provides a task-based API for simple creation of fast and reproducible training data and evaluation pipelines. These open-source libraries have been used to train models with hundreds of billions of parameters on datasets with multiple terabytes of training data. Along with the libraries, we release configurations and instructions for T5-like encoder-decoder models as well as GPT-like decoder-only architectures. \$\textbackslash texttt\{t5x\}\$ and \$\textbackslash texttt\{seqio\}\$ are open source and available at https://github.com/google-research/t5x and https://github.com/google/seqio, respectively.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IY542DJD/Roberts et al. - 2022 - Scaling Up Models and Data with $texttt t5x $ and.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/CWXMA2IE/2203.html}
}

@article{Rossi2019,
  title = {Good Initializations of Variational Bayes for Deep Models},
  author = {Rossi, Simone and Michiardi, Pietro and Filippone, Maurizio},
  date = {2019},
  journaltitle = {36th International Conference on Machine Learning, ICML 2019},
  volume = {2019-June},
  eprint = {1810.08083},
  eprinttype = {arXiv},
  pages = {9659--9669},
  abstract = {Stochastic variational inference is an established way to carry out approximate Bayesian inference for deep models flexibly and at scale. While there have been effective proposals for good initializations for loss minimization in deep learning, far less attention has been devoted to the issue of initialization of stochastic variational inference. We address this by proposing a novel layer-wise initialization strategy based on Bayesian linear models. The proposed method is extensively validated on regression and classification tasks, including Bayesian Deep Nets and Conv Nets, showing faster and better convergence compared to alternatives inspired by the literature on initializations for loss minimization.},
  isbn = {9781510886988},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/6KGXTAUG/Rossi, Michiardi, Filippone - 2019 - Good initializations of variational bayes for deep models.pdf}
}

@article{Rounce2020,
  title = {Quantifying Parameter Uncertainty in a Large-Scale Glacier Evolution Model Using {{Bayesian}} Inference: {{Application}} to {{High Mountain Asia}}},
  author = {Rounce, David R. and Khurana, Tushar and Short, Margaret B. and Hock, Regine and Shean, David E. and Brinkerhoff, Douglas J.},
  date = {2020},
  journaltitle = {Journal of Glaciology},
  volume = {66},
  number = {256},
  pages = {175--187},
  issn = {00221430},
  doi = {10.1017/jog.2019.91},
  abstract = {Abstract The response of glaciers to climate change has major implications for sea-level change and water resources around the globe. Large-scale glacier evolution models are used to project glacier runoff and mass loss, but are constrained by limited observations, which result in models being over-parameterized. Recent systematic geodetic mass-balance observations provide an opportunity to improve the calibration of glacier evolution models. In this study, we develop a calibration scheme for a glacier evolution model using a Bayesian inverse model and geodetic mass-balance observations, which enable us to quantify model parameter uncertainty. The Bayesian model is applied to each glacier in High Mountain Asia using Markov chain Monte Carlo methods. After 10,000 steps, the chains generate a sufficient number of independent samples to estimate the properties of the model parameters from the joint posterior distribution. Their spatial distribution shows a clear orographic effect indicating the resolution of climate data is too coarse to resolve temperature and precipitation at high altitudes. Given the glacier evolution model is over-parameterized, particular attention is given to identifiability and the need for future work to integrate additional observations in order to better constrain the plausible sets of model parameters.},
  keywords = {glaciers,High Mountain Asia,Key wordsBayesian model,Markov chain Monte Carlo,mass change,parameter uncertainty}
}

@report{Ruiz2018,
  title = {Augment and {{Reduce}}: {{Stochastic Inference}} for {{Large Categorical Distributions}}},
  author = {Ruiz, Francisco J R and Titsias, Michalis K and Dieng, Adji B and Blei, David M},
  date = {2018},
  abstract = {Categorical distributions are ubiquitous in machine learning, e.g., in classification, language models, and recommendation systems. However, when the number of possible outcomes is very large, using categorical distributions becomes computationally expensive, as the complexity scales linearly with the number of outcomes. To address this problem, we propose augment and reduce (A\&R), a method to alleviate the computational complexity. A\&R uses two ideas: latent variable augmentation and stochastic variational inference. It maximizes a lower bound on the marginal likelihood of the data. Unlike existing methods which are specific to softmax, A\&R is more general and is amenable to other categorical models, such as multinomial probit. On several large-scale classification problems, we show that A\&R provides a tighter bound on the marginal likelihood and has better predictive performance than existing approaches.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GVM85V3H/m-api-630ba907-b1fb-0f99-0174-d91e346f3784.pdf}
}

@article{rumelhartLearningRepresentationsBackpropagating1986,
  title = {Learning Representations by Back-Propagating Errors},
  author = {Rumelhart, David E and Hintont, Geoffrey E and Williams, Ronald J},
  date = {1986},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/N5T653ET/Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf}
}

@article{ruoppReasonableEffectivenessData2016,
  title = {The Reasonable Effectiveness of Data},
  author = {Ruopp, Achim},
  date = {2016},
  journaltitle = {Proceedings - AMTA 2016: 12th Conference of the Association for Machine Translation in the Americas},
  volume = {2},
  pages = {123--142},
  isbn = {9780000000002},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/I5DJQ34N/Ruopp - 2016 - The reasonable effectiveness of data.pdf}
}

@article{Russo2017,
  title = {A {{Tutorial}} on {{Thompson Sampling}}},
  author = {Russo, Daniel J. and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng},
  date = {2018},
  journaltitle = {Foundations and Trends® in Machine Learning},
  volume = {11},
  number = {1},
  eprint = {1707.02038},
  eprinttype = {arXiv},
  pages = {1--96},
  issn = {1935-8237},
  doi = {10.1561/2200000070},
  url = {http://www.nowpublishers.com/article/Details/MAL-070},
  abstract = {Thompson sampling is an algorithm for online decision problems where actions are taken sequentially in a manner that must balance between exploiting what is known to maximize immediate performance and investing to accumulate new information that may improve future performance. The algorithm addresses a broad range of problems in a computationally efficient manner and is therefore enjoying wide use. This tutorial covers the algorithm and its application, illustrating concepts through a range of examples, including Bernoulli bandit problems, shortest path problems, dynamic pricing, recommendation, active learning with neural networks, and reinforcement learning in Markov decision processes. Most of these problems involve complex information structures, where information revealed by taking an action informs beliefs about other actions. We will also discuss when and why Thompson sampling is or is not effective and relations to alternative algorithms.},
  isbn = {9781680833683},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9L2EAIBB/1707.02038.pdf}
}

@unpublished{Sachdeva,
  title = {Sequential {{Variational Autoencoders}} for {{Collaborative Filtering}}},
  author = {Sachdeva, Noveen and Manco, Giuseppe and Ritacco, Ettore and Pudi, Vikram},
  date = {2018},
  eprint = {1811.09975},
  eprinttype = {arXiv},
  doi = {10.1145/3178876.3186150},
  url = {http://arxiv.org/abs/1811.09975},
  urldate = {2019-02-15},
  abstract = {Variational autoencoders were proven successful in domains such as computer vision and speech processing. Their adoption for modeling user preferences is still unexplored, although recently it is starting to gain attention in the current literature. In this work, we propose a model which extends variational autoencoders by exploiting the rich information present in the past preference history. We introduce a recurrent version of the VAE, where instead of passing a subset of the whole history regardless of temporal dependencies, we rather pass the consumption sequence subset through a recurrent neural network. At each time-step of the RNN, the sequence is fed through a series of fully-connected layers, the output of which models the probability distribution of the most likely future preferences. We show that handling temporal information is crucial for improving the accuracy of the VAE: In fact, our model beats the current state-of-the-art by valuable margins because of its ability to capture temporal dependencies among the user-consumption sequence using the recurrent encoder still keeping the fundamentals of variational autoencoders intact.},
  isbn = {9781450356398},
  keywords = {• Computing methodologies → Supervised learn-ing,CCS CONCEPTS • Information systems → Collaborative,KEYWORDS Variational Autoencoders,Latent variable models,Neural networks,Ranking,Recommender systems,Recurrent Networks,Sequence modeling},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZJDA39EE/m-api-7acf1056-2c56-f3ad-5438-aedcea2ac7cc.pdf}
}

@online{sachdevaHowTrainDataEfficient2024,
  title = {How to {{Train Data-Efficient LLMs}}},
  author = {Sachdeva, Noveen and Coleman, Benjamin and Kang, Wang-Cheng and Ni, Jianmo and Hong, Lichan and Chi, Ed H. and Caverlee, James and McAuley, Julian and Cheng, Derek Zhiyuan},
  date = {2024-02-14},
  eprint = {2402.09668},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.09668},
  urldate = {2024-03-08},
  abstract = {The training of large language models (LLMs) is expensive. In this paper, we study data-efficient approaches for pre-training LLMs, i.e., techniques that aim to optimize the Pareto frontier of model quality and training resource/data consumption. We seek to understand the tradeoffs associated with data selection routines based on (i) expensiveto-compute data-quality estimates, and (ii) maximization of coverage and diversity-based measures in the feature space. Our first technique, ASK-LLM, leverages the zero-shot reasoning capabilities of instruction-tuned LLMs to directly assess the quality of a training example. To target coverage, we propose DENSITY sampling, which models the data distribution to select a diverse sample. In our comparison of 19 samplers, involving hundreds of evaluation tasks and pre-training runs, we find that ASK-LLM and DENSITY are the best methods in their respective categories. Coverage sampling can recover the performance of the full data, while models trained on ASK-LLM data consistently outperform full-data training—even when we reject 90\% of the original dataset, while converging up to 70\% faster.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ZPVKH7D6/Sachdeva et al. - 2024 - How to Train Data-Efficient LLMs.pdf}
}

@article{Saito2020,
  title = {A {{Large-scale Open Dataset}} for {{Bandit Algorithms}}},
  author = {Saito, Yuta and Matsutani, Megumi and Aihara, Shunsuke and Narita, Yusuke},
  date = {2020},
  journaltitle = {arXiv},
  issn = {23318422},
  abstract = {We build and publicize the Open Bandit Dataset and Pipeline to facilitate scalable and reproducible research on bandit algorithms. They are especially suitable for off-policy evaluation (OPE), which attempts to predict the performance of hypothetical algorithms using data generated by a different algorithm. We construct the dataset based on experiments and implementations on a large-scale fashion e-commerce platform, ZOZOTOWN. The data contain the ground-truth about the performance of several bandit policies and enable the fair comparisons of different OPE estimators. We also provide a pipeline to make its implementation easy and consistent. As a proof of concept, we use the dataset and pipeline to implement and evaluate OPE estimators. First, we find that a well-established estimator fails, suggesting that it is critical to choose an appropriate estimator. We then select a well-performing estimator and use it to improve the platform’s fashion item recommendation. Our analysis succeeds in finding a counterfactual policy that significantly outperforms the historical ones. Our open data and pipeline will allow researchers and practitioners to easily evaluate and compare their bandit algorithms and OPE estimators with others in a large, real-world setting.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/C2PVCHP4/Saito et al. - 2020 - A Large-scale Open Dataset for Bandit Algorithms.pdf}
}

@inproceedings{Salakhutdinov2008,
  title = {Bayesian Probabilistic Matrix Factorization Using {{Markov}} Chain {{Monte Carlo}}},
  booktitle = {Proceedings of the 25th International Conference on {{Machine}} Learning - {{ICML}} '08},
  author = {Salakhutdinov, Ruslan and Mnih, Andriy},
  date = {2008},
  eprint = {1990511},
  eprinttype = {pmid},
  pages = {880--887},
  publisher = {ACM Press},
  location = {New York, New York, USA},
  issn = {1049-5258},
  doi = {10.1145/1390156.1390267},
  url = {http://portal.acm.org/citation.cfm?doid=1390156.1390267},
  isbn = {978-1-60558-205-4},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3B2V7WI8/bpmf.pdf}
}

@online{samuelNorBenchBenchmarkNorwegian2023,
  title = {{{NorBench}} -- {{A Benchmark}} for {{Norwegian Language Models}}},
  author = {Samuel, David and Kutuzov, Andrey and Touileb, Samia and Velldal, Erik and Øvrelid, Lilja and Rønningstad, Egil and Sigdel, Elina and Palatkina, Anna},
  date = {2023-05-05},
  eprint = {2305.03880},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.03880},
  urldate = {2024-09-27},
  abstract = {We present NorBench: a streamlined suite of NLP tasks and probes for evaluating Norwegian language models (LMs) on standardized data splits and evaluation metrics. We also introduce a range of new Norwegian language models (both encoder and encoder-decoder based). Finally, we compare and analyze their performance, along with other existing LMs, across the different benchmark tests of NorBench.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/E7ZCLHRA/Samuel et al. - 2023 - NorBench -- A Benchmark for Norwegian Language Mod.pdf}
}

@online{sanhMultitaskPromptedTraining2022,
  title = {Multitask {{Prompted Training Enables Zero-Shot Task Generalization}}},
  author = {Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H. and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and Dey, Manan and Bari, M. Saiful and Xu, Canwen and Thakker, Urmish and Sharma, Shanya Sharma and Szczechla, Eliza and Kim, Taewoon and Chhablani, Gunjan and Nayak, Nihal and Datta, Debajyoti and Chang, Jonathan and Jiang, Mike Tian-Jian and Wang, Han and Manica, Matteo and Shen, Sheng and Yong, Zheng Xin and Pandey, Harshit and Bawden, Rachel and Wang, Thomas and Neeraj, Trishala and Rozen, Jos and Sharma, Abheesht and Santilli, Andrea and Fevry, Thibault and Fries, Jason Alan and Teehan, Ryan and Bers, Tali and Biderman, Stella and Gao, Leo and Wolf, Thomas and Rush, Alexander M.},
  date = {2022-03-17},
  eprint = {2110.08207},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2110.08207},
  url = {http://arxiv.org/abs/2110.08207},
  urldate = {2024-12-03},
  abstract = {Large language models have recently been shown to attain reasonable zero-shot generalization on a diverse set of tasks (Brown et al., 2020). It has been hypothesized that this is a consequence of implicit multitask learning in language models' pretraining (Radford et al., 2019). Can zero-shot generalization instead be directly induced by explicit multitask learning? To test this question at scale, we develop a system for easily mapping any natural language tasks into a human-readable prompted form. We convert a large set of supervised datasets, each with multiple prompts with diverse wording. These prompted datasets allow for benchmarking the ability of a model to perform completely held-out tasks. We fine-tune a pretrained encoder-decoder model (Raffel et al., 2020; Lester et al., 2021) on this multitask mixture covering a wide variety of tasks. The model attains strong zero-shot performance on several standard datasets, often outperforming models up to 16x its size. Further, our approach attains strong performance on a subset of tasks from the BIG-bench benchmark, outperforming models up to 6x its size. All trained models are available at https://github.com/bigscience-workshop/t-zero and all prompts are available at https://github.com/bigscience-workshop/promptsource.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/CSMK7Y9V/Sanh et al. - 2022 - Multitask Prompted Training Enables Zero-Shot Task Generalization.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/X2ZB5448/2110.html}
}

@online{sapienzaDifferentiableProgrammingDifferential2024,
  title = {Differentiable {{Programming}} for {{Differential Equations}}: {{A Review}}},
  shorttitle = {Differentiable {{Programming}} for {{Differential Equations}}},
  author = {Sapienza, Facundo and Bolibar, Jordi and Schäfer, Frank and Groenke, Brian and Pal, Avik and Boussange, Victor and Heimbach, Patrick and Hooker, Giles and Pérez, Fernando and Persson, Per-Olof and Rackauckas, Christopher},
  date = {2024-06-13},
  eprint = {2406.09699},
  eprinttype = {arXiv},
  eprintclass = {physics, stat},
  doi = {10.48550/arXiv.2406.09699},
  url = {http://arxiv.org/abs/2406.09699},
  urldate = {2024-07-10},
  abstract = {The differentiable programming paradigm is a cornerstone of modern scientific computing. It refers to numerical methods for computing the gradient of a numerical model's output. Many scientific models are based on differential equations, where differentiable programming plays a crucial role in calculating model sensitivities, inverting model parameters, and training hybrid models that combine differential equations with data-driven approaches. Furthermore, recognizing the strong synergies between inverse methods and machine learning offers the opportunity to establish a coherent framework applicable to both fields. Differentiating functions based on the numerical solution of differential equations is non-trivial. Numerous methods based on a wide variety of paradigms have been proposed in the literature, each with pros and cons specific to the type of problem investigated. Here, we provide a comprehensive review of existing techniques to compute derivatives of numerical solutions of differential equations. We first discuss the importance of gradients of solutions of differential equations in a variety of scientific domains. Second, we lay out the mathematical foundations of the various approaches and compare them with each other. Third, we cover the computational considerations and explore the solutions available in modern scientific software. Last but not least, we provide best-practices and recommendations for practitioners. We hope that this work accelerates the fusion of scientific models and data, and fosters a modern approach to scientific modelling.},
  pubstate = {prepublished},
  keywords = {34-04 49K40 65D25 65L09 65M32 86A22 90C31,Mathematics - Dynamical Systems,Mathematics - Numerical Analysis,Physics - Computational Physics,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/EW7M777Q/2406.09699v1.pdf}
}

@article{SaraSabourNicholasFrosst2015,
  title = {Dynamic {{Routing Between Capsules Sara}}},
  author = {Sara Sabour, Nicholas Frosst, Geoffrey E. Hinton},
  date = {2015},
  journaltitle = {Aquatic Biology},
  volume = {23},
  number = {2},
  eprint = {26338992},
  eprinttype = {pmid},
  pages = {159--166},
  issn = {18647790},
  doi = {10.3354/ab00617},
  abstract = {We provide first data on the life span, growth and seasonal aspects of the life history of Black Sea bottlenose dolphins Tursiops truncatus in the wild and compare these with historical data and conspecific populations in other geographical regions. Average life span is 20 to 32 yr; the oldest record is 41 yr. The reproductive season lasts at least from February to September or October and includes the coldest months of the year (February and March). Average adult body lengths are 240 ± 14 cm for females and 255 ± 10 cm for males. Rapid early body growth ceases by 3 to 4 yr. Two morphs, one large (offshore) and one small (coastal), possibly co-exist in the Black Sea. The larger morph may include winter-breeding migrants or immigrants from the Mediterran- ean Sea. The small coastal form is similar in body size and growth patterns to coastal populations in the eastern Mediterranean region and the Gulf of Mexico, but is characterized by early growth to maturity and small asymptotic body size. Small-sized dolphin populations in enclosed water bodies can be treated as an example of the ‘island rule’, and their dwarfism may hypothetically be explained as an effect of smaller prey size.},
  isbn = {1864-7790},
  keywords = {Black sea,Bottlenose dolphin,Dwarfism,Island rule,Life history},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/VS6VRQVI/Sabour et al. - Unknown - Dynamic Routing Between Capsules.pdf}
}

@book{Sataloff,
  title = {Machine {{Trading}} - {{Deploying}} Computer Algorithms to Conquer the Markets},
  author = {Chan, Ernest P.},
  isbn = {978-1-62623-977-7},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/NR8QBWIN/Sataloff, Johns, Kost - Unknown - No 主観的健康感を中心とした在宅高齢者における 健.pdf}
}

@article{savcisensUsingSequencesLifeevents2023,
  title = {Using {{Sequences}} of {{Life-events}} to {{Predict Human Lives}}},
  author = {Savcisens, Germans and Eliassi-Rad, Tina and Hansen, Lars Kai and Mortensen, Laust and Lilleholt, Lau and Rogers, Anna and Zettler, Ingo and Lehmann, Sune},
  date = {2023-12-18},
  journaltitle = {Nature Computational Science},
  shortjournal = {Nat Comput Sci},
  volume = {4},
  number = {1},
  eprint = {2306.03009},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  pages = {43--56},
  issn = {2662-8457},
  doi = {10.1038/s43588-023-00573-5},
  url = {http://arxiv.org/abs/2306.03009},
  urldate = {2024-01-25},
  abstract = {Over the past decade, machine learning has revolutionized computers’ ability to analyze text through flexible computational models [1]. Due to their structural similarity to written language, transformer-based architectures [2] have also shown promise as tools to make sense of a range of multi-variate sequences from protein-structures [3, 4], music [5, 6], electronic health records [7] to weather-forecasts [8, 9]. We can also represent human lives in a way that shares this structural similarity to language [10]. From one perspective, lives are simply sequences of events: People are born, visit the pediatrician, start school, move to a new location, get married, and so on. Here, we exploit this similarity to adapt innovations from natural language processing to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on arguably the most comprehensive registry data in existence, available for an entire nation of more than six million individuals across decades [11, 12, 13, 14]. Our data include information about life-events related to health, education, occupation, income, address, and working hours, recorded with day-to-day resolution. We create embeddings of life-events in a single vector space showing that this embedding space is robust and highly structured. Our models allow us to predict diverse outcomes ranging from early mortality to personality nuances, outperforming state-of-the-art models by a wide margin. Using methods for interpreting deep learning models, we probe the algorithm to understand the factors that enable our predictions. Our framework allows researchers to identify new potential mechanisms that impact life outcomes and associated possibilities for personalized interventions.},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Applications,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LZHA6RCR/Savcisens et al. - 2023 - Using Sequences of Life-events to Predict Human Li.pdf}
}

@online{schickToolformerLanguageModels2023,
  title = {Toolformer: {{Language Models Can Teach Themselves}} to {{Use Tools}}},
  shorttitle = {Toolformer},
  author = {Schick, Timo and Dwivedi-Yu, Jane and Dessì, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  date = {2023-02-09},
  eprint = {2302.04761},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.04761},
  urldate = {2024-03-01},
  abstract = {Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q\&A system, a search engine, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/E3FBVQ5W/Schick et al. - 2023 - Toolformer Language Models Can Teach Themselves t.pdf}
}

@article{schonLearningDynamicalSystems2017,
  title = {Learning of Dynamical Systems {{Particle}} Filters and {{Markov}} Chain Methods},
  author = {Schön, Thomas B and Lindsten, Fredrik},
  date = {2017},
  abstract = {Notes for the 2017 SMC Workshop at Uppsala University August 2017},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FXZCBW6H/Schön, Lindsten - 2017 - Learning of dynamical systems Particle filters and Markov chain methods.pdf}
}

@article{schrittwieserMasteringAtariGo2020,
  title = {Mastering {{Atari}}, {{Go}}, {{Chess}} and {{Shogi}} by {{Planning}} with a {{Learned Model}}},
  author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
  date = {2020-12-24},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {588},
  number = {7839},
  eprint = {1911.08265},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  pages = {604--609},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-020-03051-4},
  url = {http://arxiv.org/abs/1911.08265},
  urldate = {2023-08-31},
  abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FQ7FKM3V/1911.08265v2.pdf}
}

@unpublished{Schulman2017,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  date = {2017-07-19},
  eprint = {1707.06347},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1707.06347},
  urldate = {2017-08-12},
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/NIHLB8RD/Schulman et al. - 2017 - Proximal Policy Optimization Algorithms.pdf}
}

@article{Scott2010,
  title = {A Modern {{Bayesian}} Look at the Multi-Armed Bandit},
  author = {Scott, Steven L},
  date = {2010},
  journaltitle = {Applied Stochastic Models in Business and Industry},
  volume = {26},
  number = {6},
  pages = {639--658},
  issn = {15241904},
  doi = {10.1002/asmb.874},
  abstract = {A multi-armed bandit is an experiment with the goal of accumulating rewards from a payoff distribution with unknown parameters that are to be learned sequentially. This article describes a heuristic for managing multi-armed bandits called randomized probability matching, which randomly allocates observations to arms according the Bayesian posterior probability that each arm is optimal. Advances in Bayesian computation have made randomized probability matching easy to apply to virtually any payoff distribution. This flexibility frees the experimenter to work with payoff distributions that correspond to certain classical experimental designs that have the potential to outperform methods that are ‘optimal’ in simpler contexts. I summarize the relationships between randomized probability matching and several related heuristics that have been used in the reinforcement learning literature. Copyright},
  keywords = {Bayesian adaptive design,exploration vs exploitation,probability matching,sequential design},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/K9CNTS33/asmb.874.pdf}
}

@article{Shani2005,
  title = {An {{MDP-Based Recommender System}}},
  author = {Shani, Guy and Heckerman, David and Brafman, Ronen I.},
  date = {2005},
  journaltitle = {Journal of Machine Learning Research},
  volume = {1216--1220},
  number = {3},
  eprint = {1301.0600},
  eprinttype = {arXiv},
  pages = {1--11},
  issn = {1560-4292},
  doi = {arXiv:1301.0600},
  abstract = {This appendix provides suggestions for organisation of a research dissertation or thesis in the areas of applied linguistics and language learning research. They are not intended as a strait-jacket and in general it is a good idea to identify exemplary studies in your specific area of research and examine carefully how they are organised. The University at which you are studying may have its own guidelines on organising a dissertation or thesis, which do of course take precedence over these.},
  isbn = {92-5-104902-5},
  keywords = {- recommender system,assembly,augmented reality,commercial applications,constraint-based,data mining,Data mining,data stream clustering,Data stream clustering,divide-and-,Divide-and-conquer,e-learning,education,intelligent tutoring system,interface,learning,maintenance,markov decision processes,recommender systems,similarity,vector space model,Vector space model},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IFCUTGKT/full-text.pdf}
}

@online{shenMixtureofExpertsMeetsInstruction2023,
  title = {Mixture-of-{{Experts Meets Instruction Tuning}}:{{A Winning Combination}} for {{Large Language Models}}},
  shorttitle = {Mixture-of-{{Experts Meets Instruction Tuning}}},
  author = {Shen, Sheng and Hou, Le and Zhou, Yanqi and Du, Nan and Longpre, Shayne and Wei, Jason and Chung, Hyung Won and Zoph, Barret and Fedus, William and Chen, Xinyun and Vu, Tu and Wu, Yuexin and Chen, Wuyang and Webson, Albert and Li, Yunxuan and Zhao, Vincent and Yu, Hongkun and Keutzer, Kurt and Darrell, Trevor and Zhou, Denny},
  date = {2023-07-05},
  eprint = {2305.14705},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.14705},
  urldate = {2023-12-17},
  abstract = {Sparse Mixture-of-Experts (MoE) is a neural architecture design that can be utilized to add learnable parameters to Large Language Models (LLMs) without increasing inference cost. Instruction tuning is a technique for training LLMs to follow instructions. We advocate combining these two approaches, as we find that MoE models benefit more from instruction tuning than dense models. In particular, we conduct empirical studies across three experimental setups: (i) Direct finetuning on individual downstream tasks devoid of instruction tuning; (ii) Instructiontuning followed by in-context few-shot or zero-shot generalization on downstream tasks; and (iii) Instruction tuning supplemented by further finetuning on individual downstream tasks. In the first scenario, MoE models overall underperform dense models of identical computational capacity. This narrative, however, dramatically changes with the introduction of instruction tuning (second and third scenario), used independently or in conjunction with task-specific finetuning. Our most powerful model, FLAN-MOE-32B, surpasses the performance of FLAN-PALM-62B on four benchmark tasks, while using only a third of the FLOPs. The advancements embodied byFLAN-MOE inspire a reevaluation of the design principles of large-scale, high-performance language models in the framework of task-agnostic learning.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/F92VB3ZC/Shen et al. - 2023 - Mixture-of-Experts Meets Instruction TuningA Winn.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/SKT2WBVV/2305.html}
}

@unpublished{Shi2018,
  title = {Gradient {{Boosting With Piece-Wise Linear Regression Trees}}},
  author = {Shi, Yu and Li, Jian and Li, Zhize},
  date = {2018},
  eprint = {1802.05640},
  eprinttype = {arXiv},
  abstract = {Gradient boosting using decision trees as base learners, so called Gradient Boosted Decision Trees (GBDT), is a very successful ensemble learning algorithm widely used across a variety of applications. Recently, various GDBT construction algorithms and implementation have been designed and heavily optimized in some very popular open sourced toolkits such as XGBoost and LightGBM. In this paper, we show that both the accuracy and efficiency of GBDT can be further enhanced by using more complex base learners. Specifically, we extend gradient boosting to use piecewise linear regression trees (PL Trees), instead of piecewise constant regression trees. We show PL Trees can accelerate convergence of GBDT. Moreover, our new algorithm fits better to modern computer architectures with powerful Single Instruction Multiple Data (SIMD) parallelism. We propose optimization techniques to speedup our algorithm. The experimental results show that GBDT with PL Trees can provide very competitive testing accuracy with comparable or less training time. Our algorithm also produces much concise tree ensembles, thus can often reduce testing time costs.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/SH7FIK5T/1802.05640.pdf}
}

@article{shinnReflexionLanguageAgents,
  title = {Reflexion: {{Language Agents}} with {{Verbal Reinforcement Learning}}},
  author = {Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  abstract = {Large language models (LLMs) have been increasingly used to interact with external environments (e.g., games, compilers, APIs) as goal-driven agents. However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning. We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback. Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials. Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning). For example, Reflexion achieves a 91\% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous state-of-the-art GPT-4 that achieves 80\%. We also conduct ablation and analysis studies using different feedback signals, feedback incorporation methods, and agent types, and provide insights into how they affect performance. We release all code, demos, and datasets at https://github.com/noahshinn024/reflexion.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AIB93AKQ/Shinn et al. - Reflexion Language Agents with Verbal Reinforceme.pdf}
}

@article{Silver,
  title = {Alpha {{Go Zero}}},
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and Van Den Driessche, George and Graepel, Thore and Hassabis, Demis},
  eprint = {29052630},
  eprinttype = {pmid},
  issn = {0028-0836},
  doi = {10.1038/nature24270},
  abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, su-perhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated posi-tions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here, we introduce an algorithm based solely on reinforcement learning, without hu-man data, guidance, or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of tree search, re-sulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating AlphaGo. Much progress towards artificial intelligence has been made using supervised learning sys-tems that are trained to replicate the decisions of human experts 1–4 . However, expert data is often expensive, unreliable, or simply unavailable. Even when reliable data is available it may impose a ceiling on the performance of systems trained in this manner 5 . In contrast, reinforcement learn-ing systems are trained from their own experience, in principle allowing them to exceed human capabilities, and to operate in domains where human expertise is lacking. Recently, there has been rapid progress towards this goal, using deep neural networks trained by reinforcement learning. These systems have outperformed humans in computer games such as Atari 6, 7 and 3D virtual en-vironments 8–10 . However, the most challenging domains in terms of human intellect – such as the 1},
  isbn = {3013372370},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DL368C45/Silver et al. - Unknown - Mastering the Game of Go without Human Knowledge.pdf}
}

@article{Silver2016,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and family=Driessche, given=George, prefix=van den, useprefix=true and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  date = {2016},
  journaltitle = {Nature},
  volume = {529},
  number = {7587},
  eprint = {26819042},
  eprinttype = {pmid},
  pages = {484--489},
  publisher = {Nature Publishing Group},
  issn = {0028-0836},
  doi = {10.1038/nature16961},
  url = {http://dx.doi.org/10.1038/nature16961},
  abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
  isbn = {1476-4687 (Electronic)\textbackslash r0028-0836 (Linking)},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5R9FM9NT/Silver et al. - 2016 - Mastering the game of Go with deep neural networks and tree search.pdf}
}

@article{Silver2017,
  title = {Article {{Mastering}} the Game of {{Go}} without Human Knowledge},
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent},
  date = {2017},
  journaltitle = {Nature Publishing Group},
  volume = {550},
  number = {7676},
  pages = {354--359},
  publisher = {Nature Publishing Group},
  issn = {0028-0836},
  doi = {10.1038/nature24270},
  url = {http://dx.doi.org/10.1038/nature24270},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/2WXIE9Y7/Silver et al. - 2017 - Article Mastering the game of Go without human knowledge.pdf}
}

@online{simateamScalingInstructableAgents2024,
  title = {Scaling {{Instructable Agents Across Many Simulated Worlds}}},
  author = {{SIMA Team} and Raad, Maria Abi and Ahuja, Arun and Barros, Catarina and Besse, Frederic and Bolt, Andrew and Bolton, Adrian and Brownfield, Bethanie and Buttimore, Gavin and Cant, Max and Chakera, Sarah and Chan, Stephanie C. Y. and Clune, Jeff and Collister, Adrian and Copeman, Vikki and Cullum, Alex and Dasgupta, Ishita and family=Cesare, given=Dario, prefix=de, useprefix=true and Di Trapani, Julia and Donchev, Yani and Dunleavy, Emma and Engelcke, Martin and Faulkner, Ryan and Garcia, Frankie and Gbadamosi, Charles and Gong, Zhitao and Gonzales, Lucy and Gupta, Kshitij and Gregor, Karol and Hallingstad, Arne Olav and Harley, Tim and Haves, Sam and Hill, Felix and Hirst, Ed and Hudson, Drew A. and Hudson, Jony and Hughes-Fitt, Steph and Rezende, Danilo J. and Jasarevic, Mimi and Kampis, Laura and Ke, Rosemary and Keck, Thomas and Kim, Junkyung and Knagg, Oscar and Kopparapu, Kavya and Lampinen, Andrew and Legg, Shane and Lerchner, Alexander and Limont, Marjorie and Liu, Yulan and Loks-Thompson, Maria and Marino, Joseph and Cussons, Kathryn Martin and Matthey, Loic and Mcloughlin, Siobhan and Mendolicchio, Piermaria and Merzic, Hamza and Mitenkova, Anna and Moufarek, Alexandre and Oliveira, Valeria and Oliveira, Yanko and Openshaw, Hannah and Pan, Renke and Pappu, Aneesh and Platonov, Alex and Purkiss, Ollie and Reichert, David and Reid, John and Richemond, Pierre Harvey and Roberts, Tyson and Ruscoe, Giles and Elias, Jaume Sanchez and Sandars, Tasha and Sawyer, Daniel P. and Scholtes, Tim and Simmons, Guy and Slater, Daniel and Soyer, Hubert and Strathmann, Heiko and Stys, Peter and Tam, Allison C. and Teplyashin, Denis and Terzi, Tayfun and Vercelli, Davide and Vujatovic, Bojan and Wainwright, Marcus and Wang, Jane X. and Wang, Zhengdong and Wierstra, Daan and Williams, Duncan and Wong, Nathaniel and York, Sarah and Young, Nick},
  date = {2024-04-17},
  eprint = {2404.10179},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.10179},
  url = {http://arxiv.org/abs/2404.10179},
  urldate = {2024-07-27},
  abstract = {Building embodied AI systems that can follow arbitrary language instructions in any 3D environment is a key challenge for creating general AI. Accomplishing this goal requires learning to ground language in perception and embodied actions, in order to accomplish complex tasks. The Scalable, Instructable, Multiworld Agent (SIMA) project tackles this by training agents to follow free-form instructions across a diverse range of virtual 3D environments, including curated research environments as well as open-ended, commercial video games. Our goal is to develop an instructable agent that can accomplish anything a human can do in any simulated 3D environment. Our approach focuses on language-driven generality while imposing minimal assumptions. Our agents interact with environments in real-time using a generic, human-like interface: the inputs are image observations and language instructions and the outputs are keyboard-and-mouse actions. This general approach is challenging, but it allows agents to ground language across many visually complex and semantically rich environments while also allowing us to readily run agents in new environments. In this paper we describe our motivation and goal, the initial progress we have made, and promising preliminary results on several diverse research environments and a variety of commercial video games.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/64XWSIXI/2404.10179v2.pdf}
}

@article{Simpson2017,
  title = {Penalising Model Component Complexity: {{A}} Principled, Practical Approach to Constructing Priors},
  author = {Simpson, Daniel and Rue, Håvard and Riebler, Andrea and Martins, Thiago G. and Sørbye, Sigrunn H.},
  date = {2017},
  journaltitle = {Statistical Science},
  volume = {32},
  number = {1},
  eprint = {1403.4630},
  eprinttype = {arXiv},
  pages = {1--28},
  issn = {08834237},
  doi = {10.1214/16-STS576},
  abstract = {In this paper, we introduce a new concept for constructing prior distributions. We exploit the natural nested structure inherent to many model components, which defines the model component to be a flexible extension of a base model. Proper priors are defined to penalise the complexity induced by deviating from the simpler base model and are formulated after the input of a user-defined scaling parameter for that model component, both in the univariate and the multivariate case. These priors are invariant to reparameterisations, have a natural connection to Jeffreys' priors, are designed to support Occam's razor and seem to have excellent robustness properties, all which are highly desirable and allow us to use this approach to define default prior distributions. Through examples and theoretical results, we demonstrate the appropriateness of this approach and how it can be applied in various situations.},
  keywords = {Bayesian theory,Disease mapping,Hierarchical models,Information geometry,Interpretable prior distributions,Prior on correlation matrices},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/M77AKS8N/Simpson et al. - 2017 - Penalising model component complexity A principled, practical approach to constructing priors.pdf}
}

@article{sinhaVariationalAdversarialActive2019,
  title = {Variational Adversarial Active Learning},
  author = {Sinha, Samrath and Ebrahimi, Sayna and Darrell, Trevor},
  date = {2019},
  journaltitle = {Proceedings of the IEEE International Conference on Computer Vision},
  volume = {2019-Octob},
  eprint = {1904.00370},
  eprinttype = {arXiv},
  pages = {5971--5980},
  issn = {15505499},
  doi = {10.1109/ICCV.2019.00607},
  abstract = {Active learning aims to develop label-efficient algorithms by sampling the most representative queries to be labeled by an oracle. We describe a pool-based semi-supervised active learning algorithm that implicitly learns this sampling mechanism in an adversarial manner. Our method learns a latent space using a variational autoencoder (VAE) and an adversarial network trained to discriminate between unlabeled and labeled data. The mini-max game between the VAE and the adversarial network is played such that while the VAE tries to trick the adversarial network into predicting that all data points are from the labeled pool, the adversarial network learns how to discriminate between dissimilarities in the latent space. We extensively evaluate our method on various image classification and semantic segmentation benchmark datasets and establish a new state of the art on CIFAR10/100, Caltech-256, ImageNet, Cityscapes, and BDD100K. Our results demonstrate that our adversarial approach learns an effective low dimensional latent space in large-scale settings and provides for a computationally efficient sampling method. Our code is available at url\{https://github.com/sinhasam/vaal\}.},
  isbn = {9781728148038},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/F9EAD54A/Sinha, Ebrahimi, Darrell - 2019 - Variational adversarial active learning.pdf}
}

@article{skauliModellingShortTerm,
  title = {Modelling {{Short Term Changes}} in {{User Interest}} for {{Online Marketplaces}}},
  author = {Skauli, Øystein and Scheel, Ida and Eide, Simen and Wender, Stefan},
  pages = {1--5},
  keywords = {information retrieval},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/XMLESPQ9/Skauli et al. - Unknown - Modelling Short Term Changes in User Interest for Online Marketplaces.pdf}
}

@article{Statnikov2005,
  title = {A Comprehensive Evaluation of Multicategory Classification Methods for Microarray Gene Expression Cancer Diagnosis},
  author = {Statnikov, Alexander and Aliferis, Constantin F. and Tsamardinos, Ioannis and Hardin, Douglas and Levy, Shawn},
  date = {2005},
  journaltitle = {Bioinformatics},
  volume = {21},
  number = {5},
  eprint = {15374862},
  eprinttype = {pmid},
  pages = {631--643},
  issn = {13674803},
  doi = {10.1093/bioinformatics/bti033},
  abstract = {Cancer diagnosis is one of the most important emerging clinical applications of gene expression microarray technology. We are seeking to develop a computer system for powerful and reliable cancer diagnostic model creation based on microarray data. To keep a realistic perspective on clinical applications we focus on multicategory diagnosis. To equip the system with the optimum combination of classifier, gene selection and cross-validation methods, we performed a systematic and comprehensive evaluation of several major algorithms for multicategory classification, several gene selection methods, multiple ensemble classifier methods and two cross-validation designs using 11 datasets spanning 74 diagnostic categories and 41 cancer types and 12 normal tissue types.},
  isbn = {1367-4803},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/75WG566F/Statnikov et al. - 2005 - A comprehensive evaluation of multicategory classification methods for microarray gene expression cancer diagn.pdf}
}

@inproceedings{Sui2015,
  title = {Safe {{Exploration}} for {{Optimization}} with {{Gaussian Processes}}},
  booktitle = {{{ICML}}},
  author = {Sui, Yanan and Gotovos, Alkis and Burdick, Joel and Krause, Andreas},
  date = {2015},
  volume = {37},
  pages = {997--1005},
  issn = {16113349 03029743},
  doi = {10.1007/978-3-s319-23461-8},
  url = {http://jmlr.org/proceedings/papers/v37/sui15.html},
  urldate = {2018-06-22},
  abstract = {We consider sequential decision problems under uncertainty, where we seek to optimize an unknown function from noisy samples. This requires balancing exploration (learning about the objective) and exploitation (localizing the maximum), a problem well-studied in the multi-armed bandit literature. In many applications, however, we require that the sampled function values exceed some prespecified " safety " thresh-old, a requirement that existing algorithms fail to meet. Examples include medical applications where patient comfort must be guaranteed, recommender systems aiming to avoid user dissatisfaction, and robotic control, where one seeks to avoid controls causing physical harm to the platform. We tackle this novel, yet rich, set of problems under the assumption that the unknown function satisfies regularity conditions expressed via a Gaussian process prior. We develop an efficient algorithm called SAFEOPT, and theoretically guarantee its convergence to a natural notion of optimum reachable under safety constraints. We evaluate SAFEOPT on synthetic data, as well as two real applications: movie recommendation, and therapeutic spinal cord stimulation. Proceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W\&CP volume 37. Copy-right 2015 by the author(s).},
  isbn = {978-3-319-23461-8 978-3-319-23460-1},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/R5M3QBZL/m-api-317a5d8c-b3a7-d5db-1b08-09d0b4b5649c.pdf}
}

@article{Sun2019,
  title = {Functional Variational {{Bayesian}} Neural Networks},
  author = {Sun, Shengyang and Zhang, Guodong and Shi, Jiaxin and Grosse, Roger},
  date = {2019},
  journaltitle = {arXiv},
  eprint = {1903.05779},
  eprinttype = {arXiv},
  pages = {1--22},
  issn = {23318422},
  abstract = {Variational Bayesian neural networks (BNNs) perform variational inference over weights, but it is difficult to specify meaningful priors and approximate posteriors in a high-dimensional weight space. We introduce functional variational Bayesian neural networks (fBNNs), which maximize an Evidence Lower BOund (ELBO) defined directly on stochastic processes, i.e. distributions over functions. We prove that the KL divergence between stochastic processes equals the supremum of marginal KL divergences over all finite sets of inputs. Based on this, we introduce a practical training objective which approximates the functional ELBO using finite measurement sets and the spectral Stein gradient estimator. With fBNNs, we can specify priors entailing rich structures, including Gaussian processes and implicit stochastic processes. Empirically, we find fBNNs extrapolate well using various structured priors, provide reliable uncertainty estimates, and scale to large datasets.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/8JNPU56W/Sun et al. - 2019 - Functional variational Bayesian neural networks.pdf}
}

@article{Szegedy2016,
  title = {Rethinking the {{Inception Architecture}} for {{Computer Vision}}},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  date = {2016},
  journaltitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)},
  eprint = {8190083},
  eprinttype = {pmid},
  pages = {2818--2826},
  issn = {08866236},
  doi = {10.1002/2014GB005021},
  url = {http://arxiv.org/abs/1512.00567%5Cnhttp://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.html},
  abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible. We benchmark our methods on the ILSVRC 2012 classification challenge validation set and demonstrate substantial gains over the state of the art via to carefully factorized convolutions and aggressive regularization: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters.},
  isbn = {9781617796029},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YS7RU6AA/Szegedy et al. - 2016 - Rethinking the Inception Architecture for Computer Vision.pdf}
}

@book{tagliabueSIGIR2021ECommerce2021,
  title = {{{SIGIR}} 2021 {{E-Commerce Workshop Data Challenge}}},
  author = {Tagliabue, Jacopo and Greco, Ciro and Roy, Jean-Francis and Yu, Bingqing and Chia, Patrick John and Bianchi, Federico and Cassani, Giovanni},
  date = {2021},
  journaltitle = {Montreal '21: SIGIR eCom, July, 2021, Montreal,},
  volume = {1},
  number = {1},
  eprint = {2104.09423},
  eprinttype = {arXiv},
  publisher = {Association for Computing Machinery},
  url = {http://arxiv.org/abs/2104.09423},
  abstract = {The 2021 SIGIR workshop on eCommerce is hosting the Coveo Data Challenge for "In-session prediction for purchase intent and recommendations". The challenge addresses the growing need for reliable predictions within the boundaries of a shopping session, as customer intentions can be different depending on the occasion. The need for efficient procedures for personalization is even clearer if we consider the e-commerce landscape more broadly: outside of giant digital retailers, the constraints of the problem are stricter, due to smaller user bases and the realization that most users are not frequently returning customers. We release a new session-based dataset including more than 30M fine-grained browsing events (product detail, add, purchase), enriched by linguistic behavior (queries made by shoppers, with items clicked and items not clicked after the query) and catalog meta-data (images, text, pricing information). On this dataset, we ask participants to showcase innovative solutions for two open problems: a recommendation task (where a model is shown some events at the start of a session, and it is asked to predict future product interactions); an intent prediction task, where a model is shown a session containing an add-to-cart event, and it is asked to predict whether the item will be bought before the end of the session.},
  annotation = {CA},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/ISX6H7R7/Tagliabue et al. - 2021 - SIGIR 2021 E-Commerce Workshop Data Challenge.pdf}
}

@article{Tamar2016,
  title = {Value {{Iteration Networks}}},
  author = {Tamar, Aviv and Levine, Sergey and Abbeel, Pieter},
  date = {2016},
  journaltitle = {arXiv},
  eprint = {172808},
  eprinttype = {pmid},
  pages = {1--14},
  issn = {10495258},
  url = {http://arxiv.org/abs/1602.02867},
  abstract = {We introduce the value iteration network: a fully differentiable neural network with a `planning module' embedded within. Value iteration networks are suitable for making predictions about outcomes that involve planning-based reasoning, such as predicting a desired trajectory from an observation of a map. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate our value iteration networks on the task of predicting optimal obstacle-avoiding trajectories from an image of a landscape, both on synthetic data, and on challenging raw images of the Mars terrain.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/HLXSRZ7X/Tamar, Levine, Abbeel - 2016 - Value Iteration Networks.pdf}
}

@article{TensorFlow2015,
  title = {What Is Candidate Sampling},
  author = {{TensorFlow}},
  date = {2015},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/U9ANDGFE/TensorFlow - 2015 - What is candidate sampling.pdf}
}

@article{Tibshirani2011,
  title = {Regression Shrinkage and Selection via the Lasso: {{A}} Retrospective},
  author = {Tibshirani, Robert},
  date = {2011},
  journaltitle = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
  volume = {73},
  number = {3},
  pages = {273--282},
  abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. SUMMARY We propose a new method for estimation in linear models. The 'lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
  keywords = {l1-penalty,Penalization,Regularization}
}

@article{tinTurnDecisionMakingImproved2020,
  title = {Turn {{Decision-Making}} for {{Improved Autonomous Thermalling}} of {{Unmanned Aerial Gliders}}},
  author = {Tin, Fares El and Borowczyk, Alexandre and Sharf, Inna and Nahon, Meyer},
  date = {2020},
  isbn = {9781728142777},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/74HKCLTX/Tin et al. - 2020 - Turn Decision-Making for Improved Autonomous Thermalling of Unmanned Aerial Gliders.pdf}
}

@article{touvronLlamaOpenFoundation,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9S6FSXTJ/Touvron et al. - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf}
}

@unpublished{Tramer2016,
  title = {Stealing {{Machine Learning Models}} via {{Prediction APIs}}},
  author = {Tramèr, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K. and Ristenpart, Thomas},
  date = {2016},
  eprint = {1609.02943},
  eprinttype = {arXiv},
  pages = {19},
  issn = {2469-9985},
  doi = {10.1103/PhysRevC.94.034301},
  url = {http://arxiv.org/abs/1609.02943},
  abstract = {Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service ("predictive analytics") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis.   The tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., "steal") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.},
  isbn = {9781931971324},
  issue = {Ml},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/76YWHUN9/Tramèr et al. - 2016 - Stealing Machine Learning Models via Prediction APIs.pdf}
}

@article{Tran2019,
  title = {Improving Collaborative Metric Learning with Efficient Negative Sampling},
  author = {Tran, Viet Anh and Hennequin, Romain and Royo-Letelier, Jimena and Moussallam, Manuel},
  date = {2019},
  journaltitle = {SIGIR 2019 - Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  eprint = {1909.10912},
  eprinttype = {arXiv},
  pages = {1201--1204},
  doi = {10.1145/3331184.3331337},
  abstract = {Distance metric learning based on triplet loss has been applied with success in a wide range of applications such as face recognition, image retrieval, speaker change detection and recently recommendation with the Collaborative Metric Learning (CML) model. However, as we show in this article, CML requires large batches to work reasonably well because of a too simplistic uniform negative sampling strategy for selecting triplets. Due to memory limitations, this makes it difficult to scale in high-dimensional scenarios. To alleviate this problem, we propose here a 2-stage negative sampling strategy which finds triplets that are highly informative for learning. Our strategy allows CML to work effectively in terms of accuracy and popularity bias, even when the batch size is an order of magnitude smaller than what would be needed with the default uniform sampling. We demonstrate the suitability of the proposed strategy for recommendation and exhibit consistent positive results across various datasets.},
  isbn = {9781450361729},
  keywords = {Collaborative Filtering,Metric Learning,Recommender Systems,Triplet Loss},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/DZVCYIAA/Tran et al. - 2019 - Improving collaborative metric learning with efficient negative sampling.pdf}
}

@article{Turner2011,
  title = {Two Problems with Variational Expectation Maximisation for Time Series Models},
  author = {Turner, Richard Eric and Sahani, Maneesh},
  date = {2011},
  journaltitle = {Bayesian Time Series Models},
  volume = {9780521196},
  number = {3},
  pages = {104--124},
  doi = {10.1017/CBO9780511984679.006},
  abstract = {Variational methods are a key component of the approximate inference and learning toolbox. These methods fill an important middle ground, retaining distributional information about uncertainty in latent variables, unlike maximum a posteriori methods, and yet generally requiring less computational time than Markov chain Monte Carlo methods. In particular the variational expectation maximisation (vEM) and variational Bayes algorithms, both involving variational optimisation of a free-energy, are widely used in time series modelling. Here, we investigate the success of vEM in simple probabilistic time series models. First we consider the inference step of vEM, and show that a consequence of the well-known compactness property of variational inference is a failure to propagate uncertainty in time, thus limiting the usefulness of the retained distributional information. In particular, the uncertainty may appear to be smallest precisely when the approximation is poorest. Second, we consider parameter learning and analytically reveal systematic biases in the parameters found by vEM. Surprisingly, simpler variational approximations (such as mean-field) can lead to less bias than more complicated structured approximations. The variational approach. We begin this chapter with a brief theoretical review of the variational expectation maximisation algorithm, before illustrating the important concepts with a simple example in the next section. The vEM algorithm is an approximate version of the expectation maximisation (EM) algorithm [4]. Expectation maximisation is a standard approach to finding maximum likelihood (ML) parameters for latent variable models, including hidden Markov models and linear or non-linear state space models (SSMs) for time series.},
  isbn = {9780511984679},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/BE9EPHQQ/Turner, Sahani - 2011 - Two problems with variational expectation maximisation for time series models.pdf}
}

@unpublished{Vahdat2020,
  title = {{{NVAE}}: {{A Deep Hierarchical Variational Autoencoder}}},
  author = {Vahdat, Arash and Kautz, Jan},
  date = {2020},
  eprint = {2007.03898},
  eprinttype = {arXiv},
  pages = {1--20},
  url = {http://arxiv.org/abs/2007.03898},
  abstract = {Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ as shown in Fig. 1. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256\$\textbackslash times\$256 pixels.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/E8KMUE5R/Vahdat, Kautz - 2020 - NVAE A Deep Hierarchical Variational Autoencoder.pdf}
}

@article{VanDenOord2017,
  title = {Neural Discrete Representation Learning},
  author = {Van Den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
  date = {2017},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {2017-Decem},
  eprint = {1711.00937},
  eprinttype = {arXiv},
  pages = {6307--6316},
  issn = {10495258},
  abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" - where the latents are ignored when they are paired with a powerful autoregressive decoder - typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
  issue = {Nips},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/R6X9QGBQ/Van Den Oord, Vinyals, Kavukcuoglu - 2017 - Neural discrete representation learning.pdf}
}

@article{vaswaniAttentionAllYou,
  title = {Attention Is {{All}} You {{Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Z53EHC2Q/Vaswani et al. - Attention is All you Need.pdf}
}

@online{VikingLLM,
  title = {Viking {{LLM}}},
  url = {https://huggingface.co/collections/LumiOpen/viking-660fa4c659d8544c00f77d9b}
}

@article{Viola2001,
  title = {Robust Real-Time Object Detection},
  author = {Viola, Paul and Jones, Michael},
  date = {2001},
  journaltitle = {International Journal of Computer Vision},
  volume = {57},
  number = {2},
  eprint = {7143246},
  eprinttype = {pmid},
  pages = {137--154},
  issn = {09205691},
  doi = {http://dx.doi.org/10.1023/B:VISI.0000013087.49260.fb},
  url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Robust+Real-time+Object+Detection#0},
  abstract = {This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [6]. The third contribution is a method for combining classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performace comparable to the best previous systems [18, 13, 16, 12, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second.},
  isbn = {1094670599130},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/B56XTDNS/Viola, Jones - 2001 - Robust real-time object detection.pdf}
}

@unpublished{Vitelli2014,
  title = {Probabilistic Preference Learning with the {{Mallows}} Rank Model},
  author = {Vitelli, Valeria and Sørensen, Øystein and Crispino, Marta and Frigessi, Arnoldo and Arjas, Elja},
  date = {2014},
  eprint = {1405.7945},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1405.7945},
  abstract = {Ranking and comparing items is crucial for collecting information about preferences in many areas, from marketing to politics. The Mallows rank model is among the most successful approaches to analyse rank data, but its computational complexity has limited its use to a particular form based on Kendall distance. We develop new computationally tractable methods for Bayesian inference in Mallows models that work with any right-invariant distance. Our method performs inference on the consensus ranking of the items, also when based on partial rankings, such as top-k items or pairwise comparisons. We prove that items that none of the assessors has ranked do not influence the maximum a posteriori consensus ranking, and can therefore be ignored. When assessors are many or heterogeneous, we propose a mixture model for clustering them in homogeneous subgroups, with cluster-specific consensus rankings. We develop approximate stochastic algorithms that allow a fully probabilistic analysis, leading to coherent quantifications of uncertainties. We make probabilistic predictions on the class membership of assessors based on their ranking of just some items, and predict missing individual preferences, as needed in recommendation systems. We test our approach using several experimental and benchmark datasets.},
  keywords = {Incomplete Rankings,Markov Chain Monte Carlo,Pairwise Comparisons,Preference Learning with uncertainty,Recommendation Systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5F4ZWAWZ/Vitelli et al. - Unknown - Probabilistic preference learning with the Mallows rank model.pdf}
}

@unpublished{vlassisControlVariatesSlate2021,
  title = {Control {{Variates}} for {{Slate Off-Policy Evaluation}}},
  author = {Vlassis, Nikos and Chandrashekar, Ashok and Gil, Fernando Amat and Kallus, Nathan},
  date = {2021},
  number = {2017},
  eprint = {2106.07914},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2106.07914},
  abstract = {We study the problem of off-policy evaluation from batched contextual bandit data with multidimensional actions, often termed slates. The problem is common to recommender systems and user-interface optimization, and it is particularly challenging because of the combinatorially-sized action space. Swaminathan et al. (2017) have proposed the pseudoinverse (PI) estimator under the assumption that the conditional mean rewards are additive in actions. Using control variates, we consider a large class of unbiased estimators that includes as specific cases the PI estimator and (asymptotically) its self-normalized variant. By optimizing over this class, we obtain new estimators with risk improvement guarantees over both the PI and self-normalized PI estimators. Experiments with real-world recommender data as well as synthetic data validate these improvements in practice.}
}

@article{Vuurens2016,
  title = {Exploring {{Deep Space}}: {{Learning Personalized Ranking}} in a {{Semantic Space}}},
  author = {Vuurens, Jeroen B. P. and Larson, Martha and family=Vries, given=Arjen P., prefix=de, useprefix=true},
  date = {2016},
  journaltitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems - DLRS 2016},
  eprint = {1608.00276},
  eprinttype = {arXiv},
  pages = {23--28},
  doi = {10.1145/2988450.2988457},
  url = {http://arxiv.org/abs/1608.00276%5Cnhttp://dl.acm.org/citation.cfm?doid=2988450.2988457},
  abstract = {Recommender systems leverage both content and user interactions to generate recommendations that fit users' preferences. The recent surge of interest in deep learning presents new opportunities for exploiting these two sources of information. To recommend items we propose to first learn a user-independent high-dimensional semantic space in which items are positioned according to their substitutability, and then learn a user-specific transformation function to transform this space into a ranking according to the user's past preferences. An advantage of the proposed architecture is that it can be used to effectively recommend items using either content that describes the items or user-item ratings. We show that this approach significantly outperforms state-of-the-art recommender systems on the MovieLens 1M dataset.},
  isbn = {9781450347952},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/QFBBS8RV/Vuurens, Larson, de Vries - 2016 - Exploring Deep Space Learning Personalized Ranking in a Semantic Space.pdf}
}

@article{Wang2016,
  title = {Stacked {{Approximated Regression Machine}}: {{A Simple Deep Learning Approach}}},
  author = {Wang, Zhangyang and Chang, Shiyu and Ling, Qing and Huang, Shuai and Hu, Xia and Shi, Honghui and Huang, Thomas S.},
  date = {2016},
  journaltitle = {Advances in Neural Information Processing Systems 29 (NIPS 2016)},
  volume = {1},
  number = {3},
  eprint = {1608.04062},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1608.04062},
  abstract = {This paper proposes the Stacked Approximated Regression Machine (SARM), a novel, simple yet powerful deep learning (DL) baseline. We start by discussing the relationship between regularized regression models and feed-forward networks, with emphasis on the non-negative sparse coding and convolutional sparse coding models. We demonstrate how these models are naturally converted into a unified feed-forward network structure, which coincides with popular DL components. SARM is constructed by stacking multiple unfolded and truncated regression models. Compared to the PCANet, whose feature extraction layers are completely linear, SARM naturally introduces non-linearities, by embedding sparsity regularization. The parameters of SARM are easily obtained, by solving a series of light-weight problems, e.g., PCA or KSVD. Extensive experiments are conducted, which show that SARM outperforms the existing simple deep baseline, PCANet, and is on par with many state-of-the-art deep models, but with much lower computational loads.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/G56LJSZJ/Wang et al. - 2016 - Stacked Approximated Regression Machine A Simple Deep Learning Approach.pdf}
}

@online{wangBitNetScaling1bit2023,
  title = {{{BitNet}}: {{Scaling}} 1-Bit {{Transformers}} for {{Large Language Models}}},
  shorttitle = {{{BitNet}}},
  author = {Wang, Hongyu and Ma, Shuming and Dong, Li and Huang, Shaohan and Wang, Huaijie and Ma, Lingxiao and Yang, Fan and Wang, Ruiping and Wu, Yi and Wei, Furu},
  date = {2023-10-17},
  eprint = {2310.11453},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.11453},
  urldate = {2024-10-23},
  abstract = {The increasing size of large language models has posed challenges for deployment and raised concerns about environmental impact due to high energy consumption. In this work, we introduce BitNet, a scalable and stable 1-bit Transformer architecture designed for large language models. Specifically, we introduce BitLinear as a drop-in replacement of the nn.Linear layer in order to train 1-bit weights from scratch. Experimental results on language modeling show that BitNet achieves competitive performance while substantially reducing memory footprint and energy consumption, compared to state-of-the-art 8-bit quantization methods and FP16 Transformer baselines. Furthermore, BitNet exhibits a scaling law akin to full-precision Transformers, suggesting its potential for effective scaling to even larger language models while maintaining efficiency and performance benefits.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FZASQIAR/Wang et al. - 2023 - BitNet Scaling 1-bit Transformers for Large Langu.pdf}
}

@online{wangMaskGCTZeroShotTextSpeech2024,
  title = {{{MaskGCT}}: {{Zero-Shot Text-to-Speech}} with {{Masked Generative Codec Transformer}}},
  shorttitle = {{{MaskGCT}}},
  author = {Wang, Yuancheng and Zhan, Haoyue and Liu, Liwei and Zeng, Ruihong and Guo, Haotian and Zheng, Jiachen and Zhang, Qiang and Zhang, Xueyao and Zhang, Shunsi and Wu, Zhizheng},
  date = {2024-10-20},
  eprint = {2409.00750},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2409.00750},
  urldate = {2024-10-31},
  abstract = {The recent large-scale text-to-speech (TTS) systems are usually grouped as autoregressive and non-autoregressive systems. The autoregressive systems implicitly model duration but exhibit certain deficiencies in robustness and lack of duration controllability. Non-autoregressive systems require explicit alignment information between text and speech during training and predict durations for linguistic units (e.g. phone), which may compromise their naturalness. In this paper, we introduce Masked Generative Codec Transformer (MaskGCT), a fully non-autoregressive TTS model that eliminates the need for explicit alignment information between text and speech supervision, as well as phone-level duration prediction. MaskGCT is a two-stage model: in the first stage, the model uses text to predict semantic tokens extracted from a speech self-supervised learning (SSL) model, and in the second stage, the model predicts acoustic tokens conditioned on these semantic tokens. MaskGCT follows the mask-and-predict learning paradigm. During training, MaskGCT learns to predict masked semantic or acoustic tokens based on given conditions and prompts. During inference, the model generates tokens of a specified length in a parallel manner. Experiments with 100K hours of in-thewild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality, similarity, and intelligibility. Audio samples are available at https://maskgct.github.io/. We release our code and model checkpoints at https://github.com/open-mmlab/Amphion/blob/ main/models/tts/maskgct.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LK8256QI/Wang et al. - 2024 - MaskGCT Zero-Shot Text-to-Speech with Masked Gene.pdf}
}

@article{wangModelingDynamicMissingness2018,
  title = {Modeling Dynamic Missingness of Implicit Feedback for Recommendation},
  author = {Wang, Menghan and Zheng, Xiaolin and Gong, Mingming and Zhang, Kun},
  date = {2018},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {2018-Decem},
  eprint = {30971864},
  eprinttype = {pmid},
  pages = {6669--6678},
  issn = {10495258},
  abstract = {Implicit feedback is widely used in collaborative filtering methods for recommendation. It is well known that implicit feedback contains a large number of values that are missing not at random (MNAR); and the missing data is a mixture of negative and unknown feedback, making it difficult to learn users' negative preferences. Recent studies modeled exposure, a latent missingness variable which indicates whether an item is exposed to a user, to give each missing entry a confidence of being negative feedback. However, these studies use static models and ignore the information in temporal dependencies among items, which seems to be an essential underlying factor to subsequent missingness. To model and exploit the dynamics of missingness, we propose a latent variable named “user intent” to govern the temporal changes of item missingness, and a hidden Markov model to represent such a process. The resulting framework captures the dynamic item missingness and incorporate it into matrix factorization (MF) for recommendation. We also explore two types of constraints to achieve a more compact and interpretable representation of user intents. Experiments on real-world datasets demonstrate the superiority of our method against state-of-the-art recommender systems.},
  issue = {NeurIPS},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/LJ2LVRHM/Wang et al. - 2018 - Modeling dynamic missingness of implicit feedback for recommendation.pdf}
}

@online{wangMultilingualE5Text2024,
  title = {Multilingual {{E5 Text Embeddings}}: {{A Technical Report}}},
  shorttitle = {Multilingual {{E5 Text Embeddings}}},
  author = {Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu},
  date = {2024-02-08},
  eprint = {2402.05672},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.05672},
  urldate = {2024-09-27},
  abstract = {This technical report presents the training methodology and evaluation results of the opensource multilingual E5 text embedding models, released in mid-2023. Three embedding models of different sizes (small / base / large) are provided, offering a balance between the inference efficiency and embedding quality. The training procedure adheres to the English E5 model recipe, involving contrastive pre-training on 1 billion multilingual text pairs, followed by fine-tuning on a combination of labeled datasets. Additionally, we introduce a new instruction-tuned embedding model, whose performance is on par with state-of-the-art, English-only models of similar sizes. Information regarding the model release can be found at https://github.com/microsoft/unilm/ tree/master/e5.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/3ME82VPE/Wang et al. - 2024 - Multilingual E5 Text Embeddings A Technical Repor.pdf}
}

@online{welleckNeuralTextGeneration2019,
  title = {Neural {{Text Generation}} with {{Unlikelihood Training}}},
  author = {Welleck, Sean and Kulikov, Ilia and Roller, Stephen and Dinan, Emily and Cho, Kyunghyun and Weston, Jason},
  date = {2019-09-26},
  eprint = {1908.04319},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1908.04319},
  urldate = {2023-02-01},
  abstract = {Neural text generation is a key tool in natural language applications, but it is well known there are major problems at its core. In particular, standard likelihood training and decoding leads to dull and repetitive outputs. While some post-hoc fixes have been proposed, in particular top-\$k\$ and nucleus sampling, they do not address the fact that the token-level probabilities predicted by the model are poor. In this paper we show that the likelihood objective itself is at fault, resulting in a model that assigns too much probability to sequences containing repeats and frequent words, unlike those from the human training distribution. We propose a new objective, unlikelihood training, which forces unlikely generations to be assigned lower probability by the model. We show that both token and sequence level unlikelihood training give less repetitive, less dull text while maintaining perplexity, giving superior generations using standard greedy or beam search. According to human evaluations, our approach with standard beam search also outperforms the currently popular decoding methods of nucleus sampling or beam blocking, thus providing a strong alternative to existing techniques.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/V7RQDEG4/Welleck et al. - 2019 - Neural Text Generation with Unlikelihood Training.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/L6KRG3HA/1908.html}
}

@inproceedings{wellingBayesianLearningStochastic2011,
  title = {Bayesian {{Learning}} via {{Stochastic Gradient Langevin Dynamics}}},
  author = {Welling, Max and Teh, Yee Whye},
  date = {2011},
  pages = {8},
  abstract = {In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a “sampling threshold” and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/FVAI3NFH/Welling and Teh - Bayesian Learning via Stochastic Gradient Langevin.pdf}
}

@article{Wenzel2020,
  title = {How {{Good}} Is the {{Bayes Posterior}} in {{Deep Neural Networks Really}}?},
  author = {Wenzel, Florian and Roth, Kevin and Veeling, Bastiaan S. and Świątkowski, Jakub and Tran, Linh and Mandt, Stephan and Snoek, Jasper and Salimans, Tim and Jenatton, Rodolphe and Nowozin, Sebastian},
  date = {2020-02-06},
  journaltitle = {International Conference on Machine Learning},
  number = {1},
  eprint = {2002.02405},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2002.02405},
  abstract = {During the past five years the Bayesian deep learning community has developed increasingly accurate and efficient approximate inference procedures that allow for Bayesian inference in deep neural networks. However, despite this algorithmic progress and the promise of improved uncertainty quantification and sample efficiency there are---as of early 2020---no publicized deployments of Bayesian neural networks in industrial practice. In this work we cast doubt on the current understanding of Bayes posteriors in popular deep neural networks: we demonstrate through careful MCMC sampling that the posterior predictive induced by the Bayes posterior yields systematically worse predictions compared to simpler methods including point estimates obtained from SGD. Furthermore, we demonstrate that predictive performance is improved significantly through the use of a "cold posterior" that overcounts evidence. Such cold posteriors sharply deviate from the Bayesian paradigm but are commonly used as heuristic in Bayesian deep learning papers. We put forward several hypotheses that could explain cold posteriors and evaluate the hypotheses through experiments. Our work questions the goal of accurate posterior approximations in Bayesian deep learning: If the true Bayes posterior is poor, what is the use of more accurate approximations? Instead, we argue that it is timely to focus on understanding the origin of the improved performance of cold posteriors.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9RXHQEPY/Wenzel et al. - 2020 - How Good is the Bayes Posterior in Deep Neural Networks Really.pdf}
}

@unpublished{Wingate2013a,
  title = {Automated {{Variational Inference}} in {{Probabilistic Programming}}},
  author = {Wingate, David and Weber, Theophane},
  date = {2013},
  eprint = {1301.1299},
  eprinttype = {arXiv},
  pages = {1--7},
  url = {http://arxiv.org/abs/1301.1299},
  abstract = {We present a new algorithm for approximate inference in probabilistic programs, based on a stochastic gradient for variational programs. This method is efficient without restrictions on the probabilistic program; it is particularly practical for distributions which are not analytically tractable, including highly structured distributions that arise in probabilistic programs. We show how to automatically derive mean-field probabilistic programs and optimize them, and demonstrate that our perspective improves inference efficiency over other algorithms.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/VUMFEMRB/Wingate, Weber - 2013 - Automated Variational Inference in Probabilistic Programming.pdf}
}

@article{Wu,
  title = {Using {{Navigation}} to {{Improve}}},
  author = {Wu, Chao-yuan},
  number = {5},
  isbn = {9781450340359},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GEXTACVK/Wu - Unknown - Using Navigation to Improve.pdf}
}

@article{Wua,
  title = {Recurrent {{Recommender Networks}}},
  author = {Wu, Chao-Yuan and Ahmed, Amr and Beutel, Alex and Smola, Alexander J and Jing, How},
  doi = {10.1145/3018661.3018689},
  url = {http://dx.doi.org/10.1145/3018661.3018689},
  urldate = {2018-08-27},
  abstract = {Recommender systems traditionally assume that user profiles and movie attributes are static. Temporal dynamics are purely reactive, that is, they are inferred after they are observed , e.g. after a user's taste has changed or based on hand-engineered temporal bias corrections for movies. We propose Recurrent Recommender Networks (RRN) that are able to predict future behavioral trajectories. This is achieved by endowing both users and movies with a Long Short-Term Memory (LSTM) [14] autoregressive model that captures dynamics, in addition to a more traditional low-rank factor-ization. On multiple real-world datasets, our model offers excellent prediction accuracy and it is very compact, since we need not learn latent state but rather just the state transition function.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/WFJU63BQ/full-text.pdf}
}

@inproceedings{wuMINDLargescaleDataset2020,
  title = {{{MIND}}: {{A Large-scale Dataset}} for {{News Recommendation}}},
  shorttitle = {{{MIND}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Wu, Fangzhao and Qiao, Ying and Chen, Jiun-Hung and Wu, Chuhan and Qi, Tao and Lian, Jianxun and Liu, Danyang and Xie, Xing and Gao, Jianfeng and Wu, Winnie and Zhou, Ming},
  date = {2020},
  pages = {3597--3606},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2020.acl-main.331},
  url = {https://www.aclweb.org/anthology/2020.acl-main.331},
  urldate = {2022-09-22},
  abstract = {News recommendation is an important technique for personalized news service. Compared with product and movie recommendations which have been comprehensively studied, the research on news recommendation is much more limited, mainly due to the lack of a high-quality benchmark dataset. In this paper, we present a large-scale dataset named MIND for news recommendation. Constructed from the user click logs of Microsoft News, MIND contains 1 million users and more than 160k English news articles, each of which has rich textual content such as title, abstract and body. We demonstrate MIND a good testbed for news recommendation through a comparative study of several state-of-the-art news recommendation methods which are originally developed on different proprietary datasets. Our results show the performance of news recommendation highly relies on the quality of news content understanding and user interest modeling. Many natural language processing techniques such as effective text representation methods and pre-trained language models can effectively improve the performance of news recommendation. The MIND dataset will be available at https://msnews.github.io.},
  eventtitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  langid = {english},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AHTF2ISM/Wu et al. - 2020 - MIND A Large-scale Dataset for News Recommendatio.pdf}
}

@online{wuReFTRepresentationFinetuning2024,
  title = {{{ReFT}}: {{Representation Finetuning}} for {{Language Models}}},
  shorttitle = {{{ReFT}}},
  author = {Wu, Zhengxuan and Arora, Aryaman and Wang, Zheng and Geiger, Atticus and Jurafsky, Dan and Manning, Christopher D. and Potts, Christopher},
  date = {2024-05-22},
  eprint = {2404.03592},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.03592},
  urldate = {2024-10-23},
  abstract = {Parameter-efficient finetuning (PEFT) methods seek to adapt large neural models via updates to a small number of weights. However, much prior interpretability work has shown that representations encode rich semantic information, suggesting that editing representations might be a more powerful alternative. We pursue this hypothesis by developing a family of Representation Finetuning (ReFT) methods. ReFT methods operate on a frozen base model and learn task-specific interventions on hidden representations. We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT), and we identify an ablation of this method that trades some performance for increased efficiency. Both are drop-in replacements for existing PEFTs and learn interventions that are 15×–65× more parameter-efficient than LoRA. We showcase LoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks, instruction-tuning, and GLUE. In all these evaluations, our ReFTs deliver the best balance of efficiency and performance, and almost always outperform state-of-the-art PEFTs. We release a generic ReFT training library publicly at https://github.com/stanfordnlp/pyreft.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/Y7YUR2JJ/Wu et al. - 2024 - ReFT Representation Finetuning for Language Model.pdf}
}

@article{Xiao2019,
  title = {Dynamic Collaborative Recurrent Learning},
  author = {Xiao, Teng and Liang, Shangsong and Meng, Zaiqiao},
  date = {2019},
  journaltitle = {International Conference on Information and Knowledge Management, Proceedings},
  number = {2},
  pages = {1151--1160},
  doi = {10.1145/3357384.3357901},
  abstract = {In this paper, we provide a unified learning algorithm, dynamic collaborative recurrent learning, DCRL, of two directions of recommendations: temporal recommendations focusing on tracking the evolution of users' long-term preference and sequential recommendations focusing on capturing short-term preferences given a short time window. Our DCRL builds based on RNN and Sate Space Model (SSM), and thus it is not only able to collaboratively capture users' short-term and long-term preferences as in sequential recommendations, but also can dynamically track the evolution of users' long-term preferences as in temporal recommendations in a unified framework. In addition, we introduce two smoothing and filtering scalable inference algorithms for DCRL's offline and online learning, respectively, based on amortized variational inference, allowing us to effectively train the model jointly over all time. Experiments demonstrate DCRL outperforms the temporal and sequential recommender models, and does capture users' short-term preferences and track the evolution of long-term preferences.},
  isbn = {9781450369763},
  keywords = {Deep generative model,Sequential recommendation,Temporal recommendation},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/47JUAIHV/Xiao, Liang, Meng - 2019 - Dynamic collaborative recurrent learning.pdf}
}

@article{xieUnsupervisedLearningParagraph2019,
  title = {Unsupervised {{Learning}} of {{Paragraph Embeddings}} for {{Context-Aware Recommendation}}},
  author = {Xie, Jin and Zhu, Fuxi and Huang, Minxue and Xiong, Naixue and Huang, Sheng and Xiong, Wei},
  date = {2019},
  journaltitle = {IEEE Access},
  volume = {7},
  pages = {43100--43109},
  publisher = {IEEE},
  issn = {21693536},
  doi = {10.1109/ACCESS.2019.2906659},
  abstract = {The sparsity of data is one of the main reasons restricting the performance of recommender systems. In order to solve the sparsity problem, some recommender systems use auxiliary information, especially text information, as a supplement to increase the prediction accuracy of the ratings. However, the two mainstream approaches based on text analysis have some limitations. The bag-of-words-based model is one of them, being difficult to use the contextual information of the paragraph effectively so that only the shallow understanding of paragraph can be parsed. Another model based on deep learning can extract the contextual information of the paragraph, but it also increases the complexity of the model. This paper proposes a novel context-aware recommendation model named paragraph vector matrix factorization (P2VMF) which integrates the unsupervised learning of paragraph embeddings into probabilistic matrix factorization (PMF). Therefore, P2VMF can capture the semantic information of the paragraph and can improve the prediction accuracy of the ratings. Our extensive experiments on real-world datasets show that the performance of the P2VMF model is preferable as compared with those multiple recommendation models in the situation, where the ratings are quite sparse. And we also verified that the P2V part of the model can well express the semantics in the form of vectors.},
  keywords = {Context awareness,recommender systems,semantics,text analysis,unsupervised learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/4IGB7RRC/Xie et al. - 2019 - Unsupervised Learning of Paragraph Embeddings for Context-Aware Recommendation.pdf}
}

@article{Xin2020a,
  title = {Self-{{Supervised Reinforcement Learning}} for {{Recommender Systems}}},
  author = {Xin, Xin and Karatzoglou, Alexandros and Arapakis, Ioannis and Jose, Joemon M.},
  date = {2020},
  journaltitle = {SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  eprint = {2006.05779},
  eprinttype = {arXiv},
  pages = {931--940},
  doi = {10.1145/3397271.3401147},
  abstract = {In session-based or sequential recommendation, it is important to consider a number of factors like long-term user engagement, multiple types of user-item interactions such as clicks, purchases etc. The current state-of-the-art supervised approaches fail to model them appropriately. Casting sequential recommendation task as a reinforcement learning (RL) problem is a promising direction. A major component of RL approaches is to train the agent through interactions with the environment. However, it is often problematic to train a recommender in an on-line fashion due to the requirement to expose users to irrelevant recommendations. As a result, learning the policy from logged implicit feedback is of vital importance, which is challenging due to the pure off-policy setting and lack of negative rewards (feedback). In this paper, we propose self-supervised reinforcement learning for sequential recommendation tasks. Our approach augments standard recommendation models with two output layers: one for self-supervised learning and the other for RL. The RL part acts as a regularizer to drive the supervised layer focusing on specific rewards (e.g., recommending items which may lead to purchases rather than clicks) while the self-supervised layer with cross-entropy loss provides strong gradient signals for parameter updates. Based on such an approach, we propose two frameworks namely Self-Supervised Q-learning (SQN) and Self-Supervised Actor-Critic (SAC). We integrate the proposed frameworks with four state-of-the-art recommendation models. Experimental results on two real-world datasets demonstrate the effectiveness of our approach.},
  isbn = {9781450380164},
  keywords = {Q-learning,reinforcement learning,self-supervised learning,sequential recommendation,session-based recommendation},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/VLWVQLFP/Xin et al. - 2020 - Self-Supervised Reinforcement Learning for Recommender Systems.pdf}
}

@online{xuInfinitelyDeepBayesian2022,
  title = {Infinitely {{Deep Bayesian Neural Networks}} with {{Stochastic Differential Equations}}},
  author = {Xu, Winnie and Chen, Ricky T. Q. and Li, Xuechen and Duvenaud, David},
  date = {2022-01-30},
  eprint = {2102.06559},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2102.06559},
  url = {http://arxiv.org/abs/2102.06559},
  urldate = {2023-02-19},
  abstract = {We perform scalable approximate inference in continuous-depth Bayesian neural networks. In this model class, uncertainty about separate weights in each layer gives hidden units that follow a stochastic differential equation. We demonstrate gradient-based stochastic variational inference in this infinite-parameter setting, producing arbitrarily-flexible approximate posteriors. We also derive a novel gradient estimator that approaches zero variance as the approximate posterior over weights approaches the true posterior. This approach brings continuous-depth Bayesian neural nets to a competitive comparison against discrete-depth alternatives, while inheriting the memory-efficient training and tunable precision of Neural ODEs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YR66MLCR/Xu et al. - 2022 - Infinitely Deep Bayesian Neural Networks with Stoc.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/HTBCZ44P/2102.html}
}

@online{yadavTIESMergingResolvingInterference2023,
  title = {{{TIES-Merging}}: {{Resolving Interference When Merging Models}}},
  shorttitle = {{{TIES-Merging}}},
  author = {Yadav, Prateek and Tam, Derek and Choshen, Leshem and Raffel, Colin and Bansal, Mohit},
  date = {2023-10-27},
  eprint = {2306.01708},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2306.01708},
  url = {http://arxiv.org/abs/2306.01708},
  urldate = {2024-12-03},
  abstract = {Transfer learning - i.e., further fine-tuning a pre-trained model on a downstream task - can confer significant advantages, including improved downstream performance, faster convergence, and better sample efficiency. These advantages have led to a proliferation of task-specific fine-tuned models, which typically can only perform a single task and do not benefit from one another. Recently, model merging techniques have emerged as a solution to combine multiple task-specific models into a single multitask model without performing additional training. However, existing merging methods often ignore the interference between parameters of different models, resulting in large performance drops when merging multiple models. In this paper, we demonstrate that prior merging techniques inadvertently lose valuable information due to two major sources of interference: (a) interference due to redundant parameter values and (b) disagreement on the sign of a given parameter's values across models. To address this, we propose our method, TRIM, ELECT SIGN \& MERGE (TIES-Merging), which introduces three novel steps when merging models: (1) resetting parameters that only changed a small amount during fine-tuning, (2) resolving sign conflicts, and (3) merging only the parameters that are in alignment with the final agreed-upon sign. We find that TIES-Merging outperforms several existing methods in diverse settings covering a range of modalities, domains, number of tasks, model sizes, architectures, and fine-tuning settings. We further analyze the impact of different types of interference on model parameters, and highlight the importance of resolving sign interference. Our code is available at https://github.com/prateeky2806/ties-merging},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/XQ3RJ5BP/Yadav et al. - 2023 - TIES-Merging Resolving Interference When Merging Models.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/QYBLSEE8/2306.html}
}

@article{Yao2018,
  title = {Yes, but Did It Work?: {{Evaluating}} Variational Inference},
  author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
  date = {2018},
  journaltitle = {35th International Conference on Machine Learning, ICML 2018},
  volume = {12},
  eprint = {1802.02538},
  eprinttype = {arXiv},
  pages = {8887--8895},
  abstract = {While it's always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation". We propose two diagnostic algorithms to alleviate this problem. The Paretosmoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulationbased calibration (VSBC) assesses the average performance of point estimates.},
  isbn = {9781510867963},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/MD3L4SF8/Yao et al. - 2018 - Yes, but did it work Evaluating variational inference.pdf}
}

@online{yeMasteringAtariGames2021,
  title = {Mastering {{Atari Games}} with {{Limited Data}}},
  author = {Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
  date = {2021-12-11},
  eprint = {2111.00210},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2111.00210},
  url = {http://arxiv.org/abs/2111.00210},
  urldate = {2023-09-03},
  abstract = {Reinforcement learning has achieved great success in many applications. However, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 194.3\% mean human performance and 109.0\% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero's performance is also close to DQN's performance at 200 million frames while we consume 500 times less data. EfficientZero's low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at https://github.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5KVV8U55/Ye et al. - 2021 - Mastering Atari Games with Limited Data.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/RZJU9MVE/Ye et al. - 2021 - Mastering Atari Games with Limited Data.html}
}

@article{Yi2018,
  title = {Model-Based Reinforcement Learning: {{A}} Survey},
  author = {Yi, Fengji and Fu, Wenlong and Liang, Huan},
  date = {2018},
  journaltitle = {Proceedings of the International Conference on Electronic Business (ICEB)},
  volume = {2018-Decem},
  eprint = {2006.16712},
  eprinttype = {arXiv},
  pages = {421--429},
  issn = {16830040},
  abstract = {Reinforcement learning is an important branch of machine learning and artificial intelligence. Compared with traditional reinforcement learning, model-based reinforcement learning obtains the action of the next state by the model that has been learned, and then optimizes the policy, which greatly improves data efficiency. Based on the present status of research on model-based reinforcement learning at home and abroad, this paper comprehensively reviews the key techniques of model-based reinforcement learning, summarizes the characteristics, advantages and defects of each technology, and analyzes the application of model-based reinforcement learning in games, robotics and brain science.},
  keywords = {Data efficiency,Dynamic models,Optimizing,Reinforcement learning,Value function approximation},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/UYXPMVW8/Yi, Fu, Liang - 2018 - Model-based reinforcement learning A survey.pdf}
}

@article{Ying2018,
  title = {Graph {{Convolutional Neural Networks}} for {{Web-Scale Recommender Systems}}},
  author = {Ying, Rex and He, Ruining and Chen, Kaifeng and Eksombatchai, Pong and Hamilton, William L and Leskovec, Jure},
  date = {2018},
  volume = {10},
  publisher = {ACM},
  doi = {10.1145/3219819.3219890},
  url = {https://doi.org/10.1145/3219819.3219890},
  urldate = {2018-06-12},
  abstract = {Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains a challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm PinSage, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We deploy PinSage at Pinterest and train it on 7.5 billion exam-ples on a graph with 3 billion nodes representing pins and boards, and 18 billion edges. According to offline metrics, user studies and A/B tests, PinSage generates higher-quality recommendations than comparable deep learning and graph-based alternatives. To our knowledge, this is the largest application of deep graph embed-dings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/6NK56VK3/full-text.pdf}
}

@article{Ying2018a,
  title = {Sequential Recommender System Based on Hierarchical Attention Network},
  author = {Ying, Haochao and Zhuang, Fuzhen and Zhang, Fuzheng and Liu, Yanchi and Xu, Guandong and Xie, Xing and Xiong, Hui and Wu, Jian},
  date = {2018},
  journaltitle = {IJCAI International Joint Conference on Artificial Intelligence},
  volume = {2018-July},
  pages = {3926--3932},
  issn = {10450823},
  doi = {10.24963/ijcai.2018/546},
  abstract = {With a large amount of user activity data accumulated, it is crucial to exploit user sequential behavior for sequential recommendations. Conventionally, user general taste and recent demand are combined to promote recommendation performances. However, existing methods often neglect that user long-term preference keep evolving over time, and building a static representation for user general taste may not adequately reflect the dynamic characters. Moreover, they integrate user-item or itemitem interactions through a linear way which limits the capability of model. To this end, in this paper, we propose a novel two-layer hierarchical attention network, which takes the above properties into account, to recommend the next item user might be interested. Specifically, the first attention layer learns user long-term preferences based on the historical purchased item representation, while the second one outputs final user representation through coupling user long-term and short-term preferences. The experimental study demonstrates the superiority of our method compared with other state-of-the-art ones.},
  isbn = {9780999241127},
  issue = {July},
  keywords = {Machine Learning: Data Mining,Multidisciplinary Topics and Applications: Recomme},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/74HE966G/Ying et al. - 2018 - Sequential recommender system based on hierarchical attention network.pdf}
}

@article{yosinskiHowTransferableAre2014,
  title = {How Transferable Are Features in Deep Neural Networks?},
  author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  date = {2014-11-06},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {27},
  eprint = {1411.1792},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1411.1792},
  urldate = {2024-03-11},
  abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/H3D2PLYQ/Yosinski et al. - 2014 - How transferable are features in deep neural netwo.pdf}
}

@book{yotovCrossCountryParagliding2021,
  title = {Cross {{Country Paragliding}}},
  author = {Yotov, Nikolay},
  date = {2021},
  publisher = {Skynomad},
  url = {www.skynomad.com/books},
  abstract = {Cross country flying without an engine is the most difficult form of aviation, as it requires an extensive knowledge of aerodynamics and meteorology. At the same time, paragliders are the simplest aircraft to fly. There are top pilots and champions, who haven’t read a single book about flying; they inspire, but they cannot teach you their intuition and feelings about the wind and the wing. This book is an attempt to structure the complex matter of cross country flying and explain the major elements of this puzzle. It should help beginner cross country pilots to identify their mistakes and accelerate their progress. Advanced pilots might be challenged by some new ideas - or at least understand some techniques that, they’ve already been using subconsciously for years. This book may give comprehensive answers, but at the same time it may open a lot more questions. There is an entire universe of processes, even behind a simple wind gust, even behind a simple gliding flight. There is love and eternity when you merge with the wind and your wing. There is peace and humility when you let Nature be.},
  isbn = {978-619-91885-0-7},
  keywords = {paragliding},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GKLM2KHZ/Yotov - 2021 - Cross Country Paragliding.pdf}
}

@online{yuLanguageModelsAre2024,
  title = {Language {{Models}} Are {{Super Mario}}: {{Absorbing Abilities}} from {{Homologous Models}} as a {{Free Lunch}}},
  shorttitle = {Language {{Models}} Are {{Super Mario}}},
  author = {Yu, Le and Yu, Bowen and Yu, Haiyang and Huang, Fei and Li, Yongbin},
  date = {2024-06-13},
  eprint = {2311.03099},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2311.03099},
  url = {http://arxiv.org/abs/2311.03099},
  urldate = {2024-12-03},
  abstract = {In this paper, we unveil that Language Models (LMs) can acquire new capabilities by assimilating parameters from homologous models without retraining or GPUs. We first introduce DARE to set most delta parameters (i.e., the disparity between fine-tuned and pre-trained parameters) to zeros without affecting the abilities of Supervised Fine-Tuning (SFT) LMs, which randomly Drops delta parameters with a ratio \$p\$ And REscales the remaining ones by \$1 / (1 - p)\$ to approximate the original embeddings. Then, we use DARE as a versatile plug-in to sparsify delta parameters of multiple SFT homologous models for mitigating parameter interference and merge them into a single model by parameter fusing. We experiment with encoder- and decoder-based LMs, showing that: (1) SFT delta parameter value ranges are typically small (within 0.002) with extreme redundancy, and DARE can effortlessly eliminate 90\% or even 99\% of them; (2) DARE can merge multiple task-specific LMs into one LM with diverse capabilities. Notably, this phenomenon is more pronounced in large-scale LMs, where the merged LM reveals the potential to surpass the performance of any source LM, providing a new discovery. We also utilize DARE to create a merged LM that ranks first among models with 7 billion parameters on the Open LLM Leaderboard.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/7HNP5GP7/Yu et al. - 2024 - Language Models are Super Mario Absorbing Abilities from Homologous Models as a Free Lunch.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/XKLKBJHN/2311.html}
}

@article{Zebell2015,
  title = {Cell-{{Cycle Regulators}} and {{Cell Death}} in {{Immunity}}},
  author = {Zebell, Sophia G. and Dong, Xinnian},
  date = {2015},
  journaltitle = {Cell Host and Microbe},
  volume = {18},
  number = {4},
  eprint = {26468745},
  eprinttype = {pmid},
  pages = {402--407},
  issn = {19346069},
  doi = {10.1016/j.chom.2015.10.001},
  abstract = {Various cell death mechanisms are integral to host defense in both plants and mammals. Plant defense against biotrophic pathogens is associated with programmed cell death (PCD) of the infected cell. This effector-triggered PCD is partly analogous to pyroptosis, an inflammatory host cell death process that plays a crucial role in defense against microbial infections in mammals. Plant effector-triggered PCD also shares with mammalian apoptosis the involvement of cell-cycle regulators as signaling components. Here we explore the similarities between these different cell death programs as they relate to host defense and their relationship to the cell cycle.},
  isbn = {1934-6069 (Electronic)\textbackslash r1931-3128 (Linking)},
  keywords = {()},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/RAAB9UDG/m-api-3b61ca3e-5061-3f2d-2cba-e2876fb51660.pdf}
}

@article{Zhang,
  title = {A {{Comparative Analysis}} of {{Feature Selection Methods}} for {{Biomarker Discovery}} in {{Study}} of {{Toxicant-treated Atlantic Cod}} ( {{Gadus}} Morhua ) {{Liver}}},
  author = {Zhang, Xiaokang and Jonassen, Inge},
  keywords = {biomarker discovery,classification,feature selection,machine learning,stability},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/885DZXIP/NAIS-2019_paper_11 (1).pdf}
}

@article{Zhang2007,
  title = {Efficient Bayesian Hierarchical User Modeling for Recommendation System},
  author = {Zhang, Yi and Koren, Jonathan},
  date = {2007},
  journaltitle = {Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR'07},
  pages = {47--54},
  doi = {10.1145/1277741.1277752},
  abstract = {A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user's interest. A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model. Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive. The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications. This paper proposes a new fast learning technique to learn a large number of individual user profiles. The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens. Copyright 2007 ACM.},
  isbn = {1595935975},
  keywords = {Bayesian hierarchical models,EM algorithm,Information filtering,Personalization,Recommender systems},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/IMG8JFTD/Zhang, Koren - 2007 - Efficient bayesian hierarchical user modeling for recommendation system.pdf}
}

@unpublished{Zhang2016,
  title = {Deep {{Reinforcement Learning}} in {{Large Discrete Action Spaces}}},
  author = {Zhang, Jin and Maringer, Dietmar},
  date = {2016},
  eprint = {1512.07679},
  eprinttype = {arXiv},
  issn = {15729974},
  doi = {10.1007/s10614-015-9490-y},
  isbn = {9781450335423},
  keywords = {Algorithmic trading,Artificial intelligence,Genetic algorithm,Indicator selection,Recurrent reinforcement learning,Sharpe ratio},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/576769GP/Zhang, Maringer - 2016 - Deep Reinforcement Learning in Large Discrete Action Spaces.pdf}
}

@article{Zhang2016a,
  title = {{{StackGAN}}: {{Text}} to {{Photo-realistic Image Synthesis}} with {{Stacked Generative Adversarial Networks}}},
  author = {Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Huang, Xiaolei and Wang, Xiaogang and Metaxas, Dimitris},
  date = {2016},
  journaltitle = {arXiv preprint},
  eprint = {1612.03242},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/1612.03242},
  abstract = {Synthesizing photo-realistic images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing text-to-image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose stacked Generative Adversarial Networks (StackGAN) to generate photo-realistic images conditioned on text descriptions. The Stage-I GAN sketches the primitive shape and basic colors of the object based on the given text description, yielding Stage-I low resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high resolution images with photo-realistic details. The Stage-II GAN is able to rectify defects and add compelling details with the refinement process. Samples generated by StackGAN are more plausible than those generated by existing approaches. Importantly, our StackGAN for the first time generates realistic 256 x 256 images conditioned on only text descriptions, while state-of-the-art methods can generate at most 128 x 128 images. To demonstrate the effectiveness of the proposed StackGAN, extensive experiments are conducted on CUB and Oxford-102 datasets, which contain enough object appearance variations and are widely-used for text-to-image generation analysis.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GFQ6I8A4/Zhang et al. - 2016 - StackGAN Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.pdf}
}

@article{Zhang2018,
  title = {Advances in {{Variational Inference}}},
  author = {Zhang, Cheng and Butepage, Judith and Kjellstrom, Hedvig and Mandt, Stephan},
  date = {2019},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {41},
  number = {8},
  publisher = {IEEE Computer Society},
  issn = {19393539},
  doi = {10.1109/TPAMI.2018.2889774},
  abstract = {Many modern unsupervised or semi-supervised machine learning algorithms rely on Bayesian probabilistic models. These models are usually intractable and thus require approximate inference. Variational inference (VI) lets us approximate a high-dimensional Bayesian posterior with a simpler variational distribution by solving an optimization problem. This approach has been successfully used in various models and large-scale applications. In this review, we give an overview of recent trends in variational inference. We first introduce standard mean field variational inference, then review recent advances focusing on the following aspects: (a) scalable VI, which includes stochastic approximations, (b) generic VI, which extends the applicability of VI to a large class of otherwise intractable models, such as non-conjugate models, (c) accurate VI, which includes variational models beyond the mean field approximation or with atypical divergences, and (d) amortized VI, which implements the inference over local latent variables with inference networks. Finally, we provide a summary of promising future research directions.},
  keywords = {Approximate Bayesian Inference,Bayes methods,Computational modeling,Hidden Markov models,Inference Networks,Market research,Optimization,Probabilistic logic,Reparameterization Gradients,Scalable Inference,Stochastic processes,Structured Variational Approximations,Variational Inference},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/XTZWKZH6/1711.05597.pdf}
}

@unpublished{Zhang2019,
  title = {Cyclical {{Stochastic Gradient MCMC}} for {{Bayesian Deep Learning}}},
  author = {Zhang, Ruqi and Li, Chunyuan and Zhang, Jianyi and Chen, Changyou and Wilson, Andrew Gordon},
  date = {2019},
  number = {2017},
  eprint = {1902.03932},
  eprinttype = {arXiv},
  pages = {1--28},
  url = {http://arxiv.org/abs/1902.03932},
  abstract = {The posteriors over neural network weights are high dimensional and multimodal. Each mode typically characterizes a meaningfully different representation of the data. We develop Cyclical Stochastic Gradient MCMC (SG-MCMC) to automatically explore such distributions. In particular, we propose a cyclical stepsize schedule, where larger steps discover new modes, and smaller steps characterize each mode. We also prove non-asymptotic convergence of our proposed algorithm. Moreover, we provide extensive experimental results, including ImageNet, to demonstrate the scalability and effectiveness of cyclical SG-MCMC in learning complex multimodal distributions, especially for fully Bayesian inference with modern deep neural networks.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/YGSLA957/Zhang et al. - 2019 - Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning.pdf}
}

@online{zhangOPTOpenPretrained2022,
  title = {{{OPT}}: {{Open Pre-trained Transformer Language Models}}},
  shorttitle = {{{OPT}}},
  author = {Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Shuster, Kurt and Simig, Daniel and Koura, Punit Singh and Sridhar, Anjali and Wang, Tianlu and Zettlemoyer, Luke},
  date = {2022-06-21},
  eprint = {2205.01068},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.01068},
  url = {http://arxiv.org/abs/2205.01068},
  urldate = {2024-02-18},
  abstract = {Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/AASGH2R5/Zhang et al. - 2022 - OPT Open Pre-trained Transformer Language Models.pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/W86RTRIP/2205.html}
}

@online{zhangRAFTAdaptingLanguage2024,
  title = {{{RAFT}}: {{Adapting Language Model}} to {{Domain Specific RAG}}},
  shorttitle = {{{RAFT}}},
  author = {Zhang, Tianjun and Patil, Shishir G. and Jain, Naman and Shen, Sheng and Zaharia, Matei and Stoica, Ion and Gonzalez, Joseph E.},
  date = {2024-06-05},
  eprint = {2403.10131},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.10131},
  urldate = {2024-08-16},
  abstract = {Pretraining Large Language Models (LLMs) on large corpora of textual data is now a standard paradigm. When using these LLMs for many downstream applications, it is common to additionally incorporate new information into the pretrained model either through RAG-based-prompting, or finetuning. However, the best methodology to incorporate information remains an open question. In this paper, we present Retrieval Augmented Fine Tuning (RAFT), a training recipe which improves the model’s ability to answer questions in "open-book" in-domain settings. In training RAFT, given a question, and a set of retrieved documents, we train the model to ignore those documents that don’t help in answering the question, which we call, distractor documents. RAFT accomplishes this by citing verbatim the right sequence from the relevant document to help answer the question. This coupled with RAFT’s chain-of-thought-style response helps improve the model’s ability to reason. In domain specific RAG, RAFT consistently improves the model’s performance across PubMed, HotpotQA, and Gorilla datasets, presenting a post-training recipe to improve pre-trained LLMs to in-domain RAG.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/B2SNQ2GT/Zhang et al. - 2024 - RAFT Adapting Language Model to Domain Specific R.pdf}
}

@unpublished{Zhao,
  title = {Model-{{Based Reinforcement Learning}} for {{Whole-Chain Recommendations}}},
  author = {Zhao, Xiangyu and Xia, Long and Zhao, Yihong and Yin, Dawei and Tang, Jiliang},
  eprint = {1902.03987v1},
  eprinttype = {arXiv},
  pages = {10},
  publisher = {ACM},
  doi = {10.1145/3219819.3219886},
  url = {https://doi.org/10.1145/3219819.3219886},
  urldate = {2019-04-09},
  abstract = {With the recent prevalence of Reinforcement Learning (RL), there have been tremendous interests in developing RL-based recom-mender systems, which enjoy two major advantages-(i) they can continuously improve their recommendation strategies based on users' real-time feedback, and (ii) the optimal recommendation strategies aim to maximize the cumulative reward from users in the long run, e.g., the total revenue of a recommendation session. In practical recommendation sessions, users will sequentially access multiple scenarios, such as the entrance pages and the item detail pages, and each scenario has its own recommendation strategy. However, the majority of existing RL-based recommender systems focus on separately optimizing each strategy, which could lead to sub-optimal overall performance, because independently optimizing each scenario (i) overlooks the sequential correlation among scenarios, (ii) ignores users' behavior data from other scenarios, and (iii) only optimizes its own objective but neglects the overall objective of a session. Therefore, in this paper, we study the recommendation problem with multiple (consecutive) scenarios, i.e., whole-chain recommendations. We propose a multi-agent reinforcement learning based approach (DeepChain), which can capture the sequential correlation among different scenarios and jointly optimize multiple recommendation strategies. To be specific, all recommender agents share the same memory of users' historical behaviors, and they work collaboratively to maximize the overall reward of a session. Note that optimizing multiple recommendation strategies jointly faces two challenges-(i) it requires huge amounts of user behavior data, and (ii) the distribution of reward (users' feedback) are extremely unbalanced. In this paper, we introduce model-based reinforcement learning techniques to reduce the training data requirement and execute more accurate strategy updates. The experimental results based on data from a real e-commerce platform demonstrate the effectiveness of the proposed framework.},
  isbn = {9781450355520},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/5A8YQEC4/full-text.pdf}
}

@article{Zhao2018,
  title = {Deep {{Reinforcement Learning}} for {{List-wise Recommendations}}},
  author = {Zhao, Xiangyu and Zhang, Liang and Ding, Zhuoye and Yin, Dawei and Zhao, Yihong and Tang, Jiliang},
  date = {2018},
  number = {9},
  publisher = {ACM},
  doi = {10.1145/nnnnnnn.nnnnnnn},
  abstract = {Recommender systems play a crucial role in mitigating the problem of information overload by suggesting users' personalized items or services. The vast majority of traditional recommender systems consider the recommendation procedure as a static process and make recommendations following a fixed strategy. In this paper, we propose a novel recommender system with the capability of contin-uously improving its strategies during the interactions with users. We model the sequential interactions between users and a recom-mender system as a Markov Decision Process (MDP) and leverage Reinforcement Learning (RL) to automatically learn the optimal strategies via recommending trial-and-error items and receiving re-inforcements of these items from users' feedbacks. In particular, we introduce an online user-agent interacting environment simulator, which can pre-train and evaluate model parameters offline before applying the model online. Moreover, we validate the importance of list-wise recommendations during the interactions between users and agent, and develop a novel approach to incorporate them into the proposed framework LIRD for list-wide recommendations. The experimental results based on a real-world e-commerce dataset demonstrate the effectiveness of the proposed framework.},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/A9EELVY6/Zhao et al. - 2018 - Deep Reinforcement Learning for List-wise Recommendations.pdf}
}

@online{zhengSecretsRLHFLarge2023,
  title = {Secrets of {{RLHF}} in {{Large Language Models Part I}}: {{PPO}}},
  shorttitle = {Secrets of {{RLHF}} in {{Large Language Models Part I}}},
  author = {Zheng, Rui and Dou, Shihan and Gao, Songyang and Hua, Yuan and Shen, Wei and Wang, Binghai and Liu, Yan and Jin, Senjie and Liu, Qin and Zhou, Yuhao and Xiong, Limao and Chen, Lu and Xi, Zhiheng and Xu, Nuo and Lai, Wenbin and Zhu, Minghao and Chang, Cheng and Yin, Zhangyue and Weng, Rongxiang and Cheng, Wensen and Huang, Haoran and Sun, Tianxiang and Yan, Hang and Gui, Tao and Zhang, Qi and Qiu, Xipeng and Huang, Xuanjing},
  date = {2023-07-18},
  eprint = {2307.04964},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.04964},
  urldate = {2023-07-21},
  abstract = {Large language models (LLMs) have formulated a blueprint for the advancement of artificial general intelligence. Its primary objective is to function as a humancentric (helpful, honest, and harmless) assistant. Alignment with humans assumes paramount significance, and reinforcement learning with human feedback (RLHF) emerges as the pivotal technological paradigm underpinning this pursuit. Current technical routes usually include reward models to measure human preferences, Proximal Policy Optimization (PPO) to optimize policy model outputs, and process supervision to improve step-by-step reasoning capabilities. However, due to the challenges of reward design, environment interaction, and agent training, coupled with huge trial and error cost of large language models, there is a significant barrier for AI researchers to motivate the development of technical alignment and safe landing of LLMs. The stable training of RLHF has still been a puzzle.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/JRVPIBYJ/Zheng et al. - 2023 - Secrets of RLHF in Large Language Models Part I P.pdf}
}

@online{zhuRecoveringMentalRepresentations2024,
  title = {Recovering {{Mental Representations}} from {{Large Language Models}} with {{Markov Chain Monte Carlo}}},
  author = {Zhu, Jian-Qiao and Yan, Haijiang and Griffiths, Thomas L.},
  date = {2024-01-29},
  eprint = {2401.16657},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.16657},
  urldate = {2024-07-24},
  abstract = {Simulating sampling algorithms with people has proven a useful method for efficiently probing and understanding their mental representations. We propose that the same methods can be used to study the representations of Large Language Models (LLMs). While one can always directly prompt either humans or LLMs to disclose their mental representations introspectively, we show that increased efficiency can be achieved by using LLMs as elements of a sampling algorithm. We explore the extent to which we recover human-like representations when LLMs are interrogated with Direct Sampling and Markov chain Monte Carlo (MCMC). We found a significant increase in efficiency and performance using adaptive sampling algorithms based on MCMC. We also highlight the potential of our method to yield a more general method of conducting Bayesian inference with LLMs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/S87B3EI4/Zhu et al. - 2024 - Recovering Mental Representations from Large Langu.pdf}
}

@online{zhuSiRASparseMixture2023,
  title = {{{SiRA}}: {{Sparse Mixture}} of {{Low Rank Adaptation}}},
  shorttitle = {{{SiRA}}},
  author = {Zhu, Yun and Wichers, Nevan and Lin, Chu-Cheng and Wang, Xinyi and Chen, Tianlong and Shu, Lei and Lu, Han and Liu, Canoee and Luo, Liangchen and Chen, Jindong and Meng, Lei},
  date = {2023-11-15},
  eprint = {2311.09179},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2311.09179},
  urldate = {2023-12-09},
  abstract = {Parameter Efficient Tuning has been an prominent approach to adapt the Large Language Model to downstream tasks. Most previous works considers adding the dense trainable parameters, where all parameters are used to adapt certain task. We found this less effective empirically using the example of LoRA that introducing more trainable parameters does not help. Motivated by this we investigate the importance of leveraging “sparse” computation and propose SiRA: sparse mixture of low rank adaption. SiRA leverages the Sparse Mixture of Expert(SMoE) to boost the performance of LoRA. Specifically it enforces the top k experts routing with a capacity limit restricting the maximum number of tokens each expert can process. We propose a novel and simple expert dropout on top of gating network to reduce the over-fitting issue. Through extensive experiments, we verify SiRA performs better than LoRA and other mixture of expert approaches across different single tasks and multitask settings.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/9XX7RSJ8/Zhu et al. - 2023 - SiRA Sparse Mixture of Low Rank Adaptation.pdf}
}

@online{zouReinforcementLearningOptimize2019,
  title = {Reinforcement {{Learning}} to {{Optimize Long-term User Engagement}} in {{Recommender Systems}}},
  author = {Zou, Lixin and Xia, Long and Ding, Zhuoye and Song, Jiaxing and Liu, Weidong and Yin, Dawei},
  date = {2019-07-11},
  eprint = {1902.05570},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1902.05570},
  url = {http://arxiv.org/abs/1902.05570},
  urldate = {2023-01-05},
  abstract = {Recommender systems play a crucial role in our daily lives. Feed streaming mechanism has been widely used in the recommender system, especially on the mobile Apps. The feed streaming setting provides users the interactive manner of recommendation in never-ending feeds. In such an interactive manner, a good recommender system should pay more attention to user stickiness, which is far beyond classical instant metrics, and typically measured by \{\textbackslash bf long-term user engagement\}. Directly optimizing the long-term user engagement is a non-trivial problem, as the learning target is usually not available for conventional supervised learning methods. Though reinforcement learning\textasciitilde (RL) naturally fits the problem of maximizing the long term rewards, applying RL to optimize long-term user engagement is still facing challenges: user behaviors are versatile and difficult to model, which typically consists of both instant feedback\textasciitilde (e.g. clicks, ordering) and delayed feedback\textasciitilde (e.g. dwell time, revisit); in addition, performing effective off-policy learning is still immature, especially when combining bootstrapping and function approximation. To address these issues, in this work, we introduce a reinforcement learning framework --- FeedRec to optimize the long-term user engagement. FeedRec includes two components: 1)\textasciitilde a Q-Network which designed in hierarchical LSTM takes charge of modeling complex user behaviors, and 2)\textasciitilde an S-Network, which simulates the environment, assists the Q-Network and voids the instability of convergence in policy learning. Extensive experiments on synthetic data and a real-world large scale data show that FeedRec effectively optimizes the long-term user engagement and outperforms state-of-the-arts.},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Retrieval},
  file = {/Users/simen.eide@finn.no/gdrive/Zotero/storage/GQGWMEG3/Zou et al. - 2019 - Reinforcement Learning to Optimize Long-term User .pdf;/Users/simen.eide@finn.no/gdrive/Zotero/storage/PAR46FWS/1902.html}
}
